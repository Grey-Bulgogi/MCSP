{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import utility.Data_loader as D\n",
    "from utility.Model import Mcslt\n",
    "from utility.Custom import CustomDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 10736/10736 [00:02<00:00, 4763.59it/s]\n",
      "  0%|                                                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "1th- epoch: 0, train_loss = 131.19023767113686, train_acc = 0.760130414531905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DTools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:99: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.8608007448789572:\n",
      "1th- epoch: 1, train_loss = 43.96203000098467, train_acc = 0.9084769445738239\n",
      "test Acc 0.9073556797020484:\n",
      "1th- epoch: 2, train_loss = 30.780783776193857, train_acc = 0.9363064741499767\n",
      "test Acc 0.9278398510242085:\n",
      "1th- epoch: 3, train_loss = 24.49717727303505, train_acc = 0.9496972519795063\n",
      "test Acc 0.9390130353817505:\n",
      "1th- epoch: 4, train_loss = 20.67032276839018, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "1th- epoch: 5, train_loss = 18.01358439028263, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 6, train_loss = 16.034080408513546, train_acc = 0.9684443409408477\n",
      "test Acc 0.9557728119180633:\n",
      "1th- epoch: 7, train_loss = 14.477960899472237, train_acc = 0.9725197950628784\n",
      "test Acc 0.9599627560521415:\n",
      "1th- epoch: 8, train_loss = 13.21421879157424, train_acc = 0.9755472752678156\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 9, train_loss = 12.1604408249259, train_acc = 0.9777596646483465\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 10, train_loss = 11.266603451222181, train_acc = 0.9798556124825337\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 11, train_loss = 10.496859285980463, train_acc = 0.9807871448532837\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 12, train_loss = 9.82048013806343, train_acc = 0.9820680018630648\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 13, train_loss = 9.221172485500574, train_acc = 0.9832324173265021\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 14, train_loss = 8.68939027003944, train_acc = 0.9845132743362832\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 15, train_loss = 8.21407157368958, train_acc = 0.985910572892408\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 16, train_loss = 7.78881617449224, train_acc = 0.986376339077783\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 17, train_loss = 7.409668006002903, train_acc = 0.9868421052631579\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 18, train_loss = 7.06271306052804, train_acc = 0.9875407545412203\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 19, train_loss = 6.751609547063708, train_acc = 0.9881229622729389\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 20, train_loss = 6.4623727928847075, train_acc = 0.9888216115510013\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 21, train_loss = 6.202595988288522, train_acc = 0.9895202608290639\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 22, train_loss = 5.96682183817029, train_acc = 0.9901024685607824\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 23, train_loss = 5.746036855503917, train_acc = 0.9910340009315324\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 24, train_loss = 5.544514206238091, train_acc = 0.9916162086632511\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 25, train_loss = 5.360488888807595, train_acc = 0.9918490917559385\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 26, train_loss = 5.185326875187457, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 27, train_loss = 5.025005052797496, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 28, train_loss = 4.874474678188562, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 29, train_loss = 4.733296791091561, train_acc = 0.9928970656730322\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 30, train_loss = 4.601667261682451, train_acc = 0.9928970656730322\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 31, train_loss = 4.478874177671969, train_acc = 0.9934792734047508\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 32, train_loss = 4.3628854705020785, train_acc = 0.9935957149510946\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 33, train_loss = 4.251165843568742, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 34, train_loss = 4.148838802240789, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 35, train_loss = 4.050183369778097, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 36, train_loss = 3.9573997603729367, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 37, train_loss = 3.8687694435939193, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 38, train_loss = 3.783445805311203, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 39, train_loss = 3.7038150718435645, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 40, train_loss = 3.62668242957443, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 41, train_loss = 3.552171836607158, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 42, train_loss = 3.4827036233618855, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 43, train_loss = 3.4160194946452975, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 44, train_loss = 3.3521208306774497, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 45, train_loss = 3.2886227443814278, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 46, train_loss = 3.2319794557988644, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 47, train_loss = 3.1743112402036786, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 48, train_loss = 3.1213869089260697, train_acc = 0.9954587796925943\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 49, train_loss = 3.069091039709747, train_acc = 0.9954587796925943\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 50, train_loss = 3.019733226392418, train_acc = 0.9954587796925943\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 51, train_loss = 2.970949883107096, train_acc = 0.9954587796925943\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 52, train_loss = 2.924825854599476, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 53, train_loss = 2.8807983375154436, train_acc = 0.9954587796925943\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 54, train_loss = 2.8373449072241783, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 55, train_loss = 2.797025623265654, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 56, train_loss = 2.7571677514351904, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 57, train_loss = 2.718274893704802, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 58, train_loss = 2.6818013922311366, train_acc = 0.9956916627852818\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 59, train_loss = 2.6450836211442947, train_acc = 0.9956916627852818\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 60, train_loss = 2.6104608974419534, train_acc = 0.9956916627852818\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 61, train_loss = 2.5776055580936372, train_acc = 0.9956916627852818\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 62, train_loss = 2.545915340539068, train_acc = 0.9958081043316255\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 63, train_loss = 2.5150252445600927, train_acc = 0.9958081043316255\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 64, train_loss = 2.484827267471701, train_acc = 0.9958081043316255\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 65, train_loss = 2.456552309449762, train_acc = 0.996040987424313\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 66, train_loss = 2.429727576673031, train_acc = 0.996040987424313\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 67, train_loss = 2.4022695906460285, train_acc = 0.9961574289706567\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 68, train_loss = 2.3760133907198906, train_acc = 0.9961574289706567\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 69, train_loss = 2.3514898382127285, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 70, train_loss = 2.327055254485458, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 71, train_loss = 2.3025415339507163, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 72, train_loss = 2.2808476872742176, train_acc = 0.9963903120633442\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 73, train_loss = 2.2575502558611333, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 74, train_loss = 2.235945001244545, train_acc = 0.9963903120633442\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 75, train_loss = 2.215695136692375, train_acc = 0.996506753609688\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 76, train_loss = 2.194249918218702, train_acc = 0.996506753609688\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 77, train_loss = 2.1749184825457633, train_acc = 0.996506753609688\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 78, train_loss = 2.155997134745121, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 79, train_loss = 2.136895584408194, train_acc = 0.9968560782487191\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 80, train_loss = 2.118865955621004, train_acc = 0.9968560782487191\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 81, train_loss = 2.100083446595818, train_acc = 0.9967396367023754\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 82, train_loss = 2.0831646979786456, train_acc = 0.9968560782487191\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 83, train_loss = 2.065641323570162, train_acc = 0.9968560782487191\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 84, train_loss = 2.048859143164009, train_acc = 0.9967396367023754\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 85, train_loss = 2.032905580010265, train_acc = 0.9968560782487191\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 86, train_loss = 2.017991352826357, train_acc = 0.9967396367023754\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 87, train_loss = 2.0019969530403614, train_acc = 0.9967396367023754\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 88, train_loss = 1.9874638640321791, train_acc = 0.9968560782487191\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 89, train_loss = 1.9729025140404701, train_acc = 0.9968560782487191\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 90, train_loss = 1.9588371864520013, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 91, train_loss = 1.9442669325508177, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 92, train_loss = 1.9322432824410498, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 93, train_loss = 1.9180986532010138, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 94, train_loss = 1.904176705982536, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 95, train_loss = 1.8930685394443572, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 96, train_loss = 1.879949392285198, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 97, train_loss = 1.8679899512790143, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 98, train_loss = 1.8559616482816637, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 99, train_loss = 1.8453545644879341, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 100, train_loss = 1.8331768438220024, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 101, train_loss = 1.822089685825631, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 102, train_loss = 1.8112516477704048, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 103, train_loss = 1.8008373875636607, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 104, train_loss = 1.7904992040712386, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 105, train_loss = 1.7803101080935448, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 106, train_loss = 1.771011161385104, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 107, train_loss = 1.76088269171305, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 108, train_loss = 1.7506657466292381, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 109, train_loss = 1.7418370954692364, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 110, train_loss = 1.7322925999760628, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 111, train_loss = 1.7242519084829837, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 112, train_loss = 1.714162600459531, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 113, train_loss = 1.7061625644564629, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 114, train_loss = 1.6969307463150471, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 115, train_loss = 1.689510840922594, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 116, train_loss = 1.680380805162713, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 117, train_loss = 1.6727312232833356, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 118, train_loss = 1.6642542246263474, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 119, train_loss = 1.6562904752790928, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 120, train_loss = 1.649265829473734, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 121, train_loss = 1.641430067596957, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 122, train_loss = 1.6341568331699818, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 123, train_loss = 1.6271876122336835, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 124, train_loss = 1.620074725477025, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 125, train_loss = 1.6125413998961449, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 126, train_loss = 1.6057552844285965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 127, train_loss = 1.5983115460257977, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 128, train_loss = 1.5921344545204192, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 129, train_loss = 1.585806532530114, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 130, train_loss = 1.5784562230110168, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 131, train_loss = 1.5726793829817325, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 132, train_loss = 1.5657602150458843, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 133, train_loss = 1.5597900438588113, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 134, train_loss = 1.553207955090329, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 135, train_loss = 1.548252207459882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 136, train_loss = 1.5414413202088326, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 137, train_loss = 1.5356489680707455, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 138, train_loss = 1.5298562459647655, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 139, train_loss = 1.5242316834628582, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 140, train_loss = 1.5188297629356384, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 141, train_loss = 1.513460163027048, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 142, train_loss = 1.5073323387186974, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 143, train_loss = 1.502499305875972, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 144, train_loss = 1.4966016858816147, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 145, train_loss = 1.4918588127475232, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 146, train_loss = 1.4871010358911008, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 147, train_loss = 1.4813043549656868, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 148, train_loss = 1.4772065978031605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 149, train_loss = 1.4712495219428092, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 150, train_loss = 1.466883050976321, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 151, train_loss = 1.461849891813472, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 152, train_loss = 1.4573826019186527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 153, train_loss = 1.452127878786996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 154, train_loss = 1.4486100052017719, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 155, train_loss = 1.4433887489140034, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 156, train_loss = 1.4386854618787766, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 157, train_loss = 1.4344406698364764, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 158, train_loss = 1.429922852665186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 159, train_loss = 1.425363017944619, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 160, train_loss = 1.4214102302212268, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 161, train_loss = 1.417224022326991, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 162, train_loss = 1.4126200054306537, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 163, train_loss = 1.4090915236156434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 164, train_loss = 1.4048586152493954, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 165, train_loss = 1.4003618161659688, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 166, train_loss = 1.3969698436558247, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 167, train_loss = 1.393342754454352, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 168, train_loss = 1.3894962692866102, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 169, train_loss = 1.3848418295383453, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 170, train_loss = 1.3814108446240425, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 171, train_loss = 1.377804011106491, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 172, train_loss = 1.3743928037583828, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 173, train_loss = 1.370355762541294, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 174, train_loss = 1.3671071802964434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 175, train_loss = 1.3633233221480623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 176, train_loss = 1.3598739467561245, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 177, train_loss = 1.3558851145207882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 178, train_loss = 1.3530230186879635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 179, train_loss = 1.349361582309939, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 180, train_loss = 1.3459724424174055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 181, train_loss = 1.3427143158623949, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 182, train_loss = 1.339723369688727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 183, train_loss = 1.3362432792782784, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 184, train_loss = 1.3328047581017017, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 185, train_loss = 1.3296989649534225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 186, train_loss = 1.32654472196009, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 187, train_loss = 1.3239507377147675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 188, train_loss = 1.3201624987414107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 189, train_loss = 1.3168335892260075, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 190, train_loss = 1.313948574126698, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 191, train_loss = 1.3111803904175758, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 192, train_loss = 1.3083429286489263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 193, train_loss = 1.305699162185192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 194, train_loss = 1.3023390509188175, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 195, train_loss = 1.2997551411390305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 196, train_loss = 1.2964389423141256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 197, train_loss = 1.2937300192425027, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 198, train_loss = 1.2915988838067278, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 199, train_loss = 1.2884440360357985, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 200, train_loss = 1.2856522364309058, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 201, train_loss = 1.2828805657336488, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 202, train_loss = 1.2804871251573786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 203, train_loss = 1.2781349731376395, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 204, train_loss = 1.27511326468084, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 205, train_loss = 1.272654159576632, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 206, train_loss = 1.2695273930439726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 207, train_loss = 1.2670425275573507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 208, train_loss = 1.2649272568523884, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 209, train_loss = 1.2624082738766447, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 210, train_loss = 1.2601732636103407, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 211, train_loss = 1.2576732313027605, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 212, train_loss = 1.2549899592995644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 213, train_loss = 1.2527016227832064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 214, train_loss = 1.250032621086575, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 215, train_loss = 1.2477314919233322, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 216, train_loss = 1.245859065442346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 217, train_loss = 1.2432045029709116, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 218, train_loss = 1.2408015243709087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 219, train_loss = 1.238775705336593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 220, train_loss = 1.236105921328999, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 221, train_loss = 1.233985636383295, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 222, train_loss = 1.2315191688248888, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 223, train_loss = 1.2298009283840656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 224, train_loss = 1.2273443154990673, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 225, train_loss = 1.2247551729669794, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 226, train_loss = 1.2225606056163087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 227, train_loss = 1.2206490648677573, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 228, train_loss = 1.2182730300119147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 229, train_loss = 1.2163460900774226, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 230, train_loss = 1.214232592494227, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 231, train_loss = 1.2120688917348161, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 232, train_loss = 1.2105351524660364, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 233, train_loss = 1.2079375311732292, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 234, train_loss = 1.2060570841422305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 235, train_loss = 1.2039947410812601, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 236, train_loss = 1.2018860690295696, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 237, train_loss = 1.2001064656069502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 238, train_loss = 1.197801124304533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 239, train_loss = 1.1959321474423632, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 240, train_loss = 1.1936872340738773, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 241, train_loss = 1.192225699662231, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 242, train_loss = 1.1902517514536157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 243, train_loss = 1.187843038351275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 244, train_loss = 1.1863481737673283, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 245, train_loss = 1.184509406448342, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 246, train_loss = 1.1823172084987164, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 247, train_loss = 1.1807463442673907, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 248, train_loss = 1.1791006388375536, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 249, train_loss = 1.1767539294669405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 250, train_loss = 1.17534651607275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 251, train_loss = 1.173632238060236, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 252, train_loss = 1.1718105375766754, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 253, train_loss = 1.1697582924971357, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 254, train_loss = 1.1677031753351912, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 255, train_loss = 1.1666849019238725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 256, train_loss = 1.1648044822504744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 257, train_loss = 1.1625634245574474, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 258, train_loss = 1.1611524149775505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 259, train_loss = 1.1593616120517254, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 260, train_loss = 1.1580198568990454, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 261, train_loss = 1.156062752008438, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 262, train_loss = 1.1546909995377064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 263, train_loss = 1.1526764457812533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 264, train_loss = 1.1505156295606866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 265, train_loss = 1.1496677784016356, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 266, train_loss = 1.147879014373757, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 267, train_loss = 1.1460302347550169, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 268, train_loss = 1.1446489406516775, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 269, train_loss = 1.143071091384627, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 270, train_loss = 1.1417348260292783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 271, train_loss = 1.1401064371457323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 272, train_loss = 1.138458512723446, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 273, train_loss = 1.1363480016589165, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 274, train_loss = 1.1354239396750927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 275, train_loss = 1.1334046621923335, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 276, train_loss = 1.1325182653963566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 277, train_loss = 1.1307805242831819, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 278, train_loss = 1.1293595843017101, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 279, train_loss = 1.1269570142030716, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 280, train_loss = 1.1266226321458817, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 281, train_loss = 1.1246707973186858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 282, train_loss = 1.1231412813067436, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 283, train_loss = 1.1221814304590225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 284, train_loss = 1.1204110433463939, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 285, train_loss = 1.1186118361656554, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 286, train_loss = 1.1171825018827803, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 287, train_loss = 1.1160827639396302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 288, train_loss = 1.114948893606197, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 289, train_loss = 1.1131757770781405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 290, train_loss = 1.1118000323767774, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 291, train_loss = 1.110205803066492, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 292, train_loss = 1.1092545713181607, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 293, train_loss = 1.1079066420788877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 294, train_loss = 1.1061337391729467, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 295, train_loss = 1.104953943460714, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 296, train_loss = 1.1036687244777568, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 297, train_loss = 1.1021212513442151, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 298, train_loss = 1.1009667826001532, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 299, train_loss = 1.0993738385732286, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 300, train_loss = 1.0976678009028547, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 301, train_loss = 1.0970545944874175, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 302, train_loss = 1.09541504830122, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 303, train_loss = 1.0940415325458162, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 304, train_loss = 1.093199696391821, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 305, train_loss = 1.0922170976991765, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 306, train_loss = 1.0907739351387136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 307, train_loss = 1.0885031993384473, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 308, train_loss = 1.0876168732647784, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 309, train_loss = 1.0868906316463836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 310, train_loss = 1.0853526306455024, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 311, train_loss = 1.0838353335857391, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 312, train_loss = 1.0824621804058552, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 313, train_loss = 1.0811256294255145, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 314, train_loss = 1.0799048356711864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 315, train_loss = 1.0784698489005677, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 316, train_loss = 1.0771434977650642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 317, train_loss = 1.0765542462468147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 318, train_loss = 1.0750601403415203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 319, train_loss = 1.0733940030331723, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 320, train_loss = 1.0720629505813122, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 321, train_loss = 1.0711570319836028, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 322, train_loss = 1.0706909522414207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 323, train_loss = 1.0693400886957534, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 324, train_loss = 1.067822399258148, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 325, train_loss = 1.0662935078144073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 326, train_loss = 1.0656931176781654, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 327, train_loss = 1.0641626578872092, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 328, train_loss = 1.0627245617215522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 329, train_loss = 1.0618006711010821, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 330, train_loss = 1.061472401022911, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 331, train_loss = 1.059478568553459, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 332, train_loss = 1.0583193351631053, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 333, train_loss = 1.0573171228170395, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 334, train_loss = 1.0565608565812, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 335, train_loss = 1.0548164310748689, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 336, train_loss = 1.0540290835197084, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 337, train_loss = 1.05242258310318, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 338, train_loss = 1.052156777412165, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 339, train_loss = 1.0507143710856326, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 340, train_loss = 1.0495408698916435, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 341, train_loss = 1.0483927975292318, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 342, train_loss = 1.0472875709529035, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 343, train_loss = 1.0464449289138429, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 344, train_loss = 1.0457247880403884, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 345, train_loss = 1.04446791857481, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 346, train_loss = 1.0433159594540484, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 347, train_loss = 1.0417953953146935, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 348, train_loss = 1.0408318254048936, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 349, train_loss = 1.0397735138540156, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 350, train_loss = 1.0392850513453595, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 351, train_loss = 1.0384285475010984, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 352, train_loss = 1.0370351510937326, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 353, train_loss = 1.035798976838123, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 354, train_loss = 1.0350955501198769, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 355, train_loss = 1.0340191374416463, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 356, train_loss = 1.0326831378042698, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 357, train_loss = 1.0321380284731276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 358, train_loss = 1.0310369829530828, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 359, train_loss = 1.029706284403801, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 360, train_loss = 1.0293680541217327, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 361, train_loss = 1.027959926694166, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 362, train_loss = 1.0273574367165565, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 363, train_loss = 1.0261652891640551, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 364, train_loss = 1.0249385461211205, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 365, train_loss = 1.0243837237358093, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 366, train_loss = 1.0234520360827446, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 367, train_loss = 1.0223231042618863, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 368, train_loss = 1.0209188486333005, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 369, train_loss = 1.0205352666671388, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 370, train_loss = 1.0198146005277522, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 371, train_loss = 1.0186251774430275, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 372, train_loss = 1.0177457717363723, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 373, train_loss = 1.0173502949182875, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 374, train_loss = 1.015740814327728, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 375, train_loss = 1.0148983138496988, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 376, train_loss = 1.014223176985979, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 377, train_loss = 1.0128753073513508, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 378, train_loss = 1.0122724274988286, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 379, train_loss = 1.0115481751854531, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 380, train_loss = 1.0106536497478373, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 381, train_loss = 1.0093146674335003, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 382, train_loss = 1.009395246685017, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 383, train_loss = 1.0080112132127397, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 384, train_loss = 1.007122719020117, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 385, train_loss = 1.0061817305977456, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 386, train_loss = 1.0053446193342097, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 387, train_loss = 1.0042191210086457, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 388, train_loss = 1.0038733829860575, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 389, train_loss = 1.0025358473067172, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 390, train_loss = 1.002064935863018, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 391, train_loss = 1.000997209281195, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 392, train_loss = 1.0003637932240963, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 393, train_loss = 0.9993645859067328, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 394, train_loss = 0.9984216491575353, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 395, train_loss = 0.998134249181021, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 396, train_loss = 0.9967000807519071, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 397, train_loss = 0.996320016682148, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 398, train_loss = 0.9954427257180214, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 399, train_loss = 0.9945958008174784, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 400, train_loss = 0.9937181833083741, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 401, train_loss = 0.9927867986261845, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 402, train_loss = 0.9923588608507998, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 403, train_loss = 0.9912603236734867, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 404, train_loss = 0.9908325138385408, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 405, train_loss = 0.9896157085895538, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 406, train_loss = 0.9887499387259595, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 407, train_loss = 0.9882872353191487, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 408, train_loss = 0.9874277574126609, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 409, train_loss = 0.9869818563456647, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 410, train_loss = 0.9863056789035909, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 411, train_loss = 0.9850134153966792, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 412, train_loss = 0.984199567406904, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 413, train_loss = 0.9837749327416532, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 414, train_loss = 0.9828701019287109, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 415, train_loss = 0.9823162381653674, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 416, train_loss = 0.9811512145097367, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 417, train_loss = 0.9808232163195498, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 418, train_loss = 0.9794731711153872, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 419, train_loss = 0.9793850407004356, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 420, train_loss = 0.9782354173366912, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 421, train_loss = 0.9776588839595206, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 422, train_loss = 0.9772759489715099, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 423, train_loss = 0.9759423148934729, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 424, train_loss = 0.975258830934763, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 425, train_loss = 0.9746804324095137, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 426, train_loss = 0.9744334407150745, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 427, train_loss = 0.9734385386109352, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 428, train_loss = 0.972558755427599, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 429, train_loss = 0.9721087900106795, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 430, train_loss = 0.9711108679766767, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 431, train_loss = 0.9703267725999467, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 432, train_loss = 0.9700231303577311, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 433, train_loss = 0.9691177817876451, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 434, train_loss = 0.9682123747770675, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 435, train_loss = 0.9675136258010752, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 436, train_loss = 0.9674509887699969, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 437, train_loss = 0.9660344757139683, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 438, train_loss = 0.9660024170880206, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 439, train_loss = 0.9647236093878746, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 440, train_loss = 0.9641711314325221, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 441, train_loss = 0.9636800810694695, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 442, train_loss = 0.962664108723402, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 443, train_loss = 0.9622583488817327, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 444, train_loss = 0.961414071440231, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 445, train_loss = 0.9608533047139645, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 446, train_loss = 0.9602454081177711, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 447, train_loss = 0.9596353930828627, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 448, train_loss = 0.9587208988668863, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 449, train_loss = 0.9581796328129712, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 450, train_loss = 0.9575887694954872, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 451, train_loss = 0.9568447470664978, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 452, train_loss = 0.9565671434102114, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 453, train_loss = 0.9557495042681694, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 454, train_loss = 0.9550516419112682, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 455, train_loss = 0.9542646917107049, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 456, train_loss = 0.9537219479680061, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 457, train_loss = 0.9528541291656438, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 458, train_loss = 0.9526813303527888, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 459, train_loss = 0.9518531983194407, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 460, train_loss = 0.9512359239161015, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 461, train_loss = 0.9502634902892169, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 462, train_loss = 0.9502184875309467, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 463, train_loss = 0.9492405019700527, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 464, train_loss = 0.9492729380726814, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 465, train_loss = 0.9476571517589036, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 466, train_loss = 0.947849760443205, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 467, train_loss = 0.9466754756867886, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 468, train_loss = 0.946288143604761, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 469, train_loss = 0.9455793177185114, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 470, train_loss = 0.9450677707791328, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 471, train_loss = 0.9444932676851749, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 472, train_loss = 0.9438734762370586, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 473, train_loss = 0.9431205180881079, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 474, train_loss = 0.9427109112439211, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 475, train_loss = 0.9420385559496935, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 476, train_loss = 0.9413533186016139, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 477, train_loss = 0.9409849916992243, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 478, train_loss = 0.9401513387856539, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 479, train_loss = 0.9400083745422307, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 480, train_loss = 0.9391280474665109, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 481, train_loss = 0.9384252727031708, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 482, train_loss = 0.9380305906233843, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 483, train_loss = 0.9373713843524456, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 484, train_loss = 0.9367398656904697, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 485, train_loss = 0.9361429785785731, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 486, train_loss = 0.9359682674112264, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 487, train_loss = 0.9351560212671757, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 488, train_loss = 0.9345401687023696, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 489, train_loss = 0.93408333757543, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 490, train_loss = 0.9334946175513323, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 491, train_loss = 0.9325423228146974, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 492, train_loss = 0.9319652393460274, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 493, train_loss = 0.9315778588352259, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 494, train_loss = 0.9309624247252941, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 495, train_loss = 0.9307371216418687, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 496, train_loss = 0.9300251714885235, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 497, train_loss = 0.9293717853724957, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 498, train_loss = 0.92863499125815, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 499, train_loss = 0.928398327290779, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                      | 1/30 [09:26<4:34:01, 566.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "2th- epoch: 0, train_loss = 125.51846661418676, train_acc = 0.7744527247321844\n",
      "test Acc 0.8761638733705773:\n",
      "2th- epoch: 1, train_loss = 44.91896792128682, train_acc = 0.9137168141592921\n",
      "test Acc 0.9287709497206704:\n",
      "2th- epoch: 2, train_loss = 32.517977014184, train_acc = 0.9370051234280391\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 3, train_loss = 26.131156489253044, train_acc = 0.94981369352585\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 4, train_loss = 22.00563778169453, train_acc = 0.9572659524918491\n",
      "test Acc 0.9534450651769087:\n",
      "2th- epoch: 5, train_loss = 19.030975544825196, train_acc = 0.9637866790870983\n",
      "test Acc 0.957635009310987:\n",
      "2th- epoch: 6, train_loss = 16.79174419119954, train_acc = 0.9683278993945039\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 7, train_loss = 15.076815804466605, train_acc = 0.9708896134140661\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 8, train_loss = 13.725747218355536, train_acc = 0.9742664182580345\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 9, train_loss = 12.62045906856656, train_acc = 0.9765952491849091\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 10, train_loss = 11.690201630815864, train_acc = 0.9774103400093154\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 11, train_loss = 10.902600448578596, train_acc = 0.9785747554727526\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 12, train_loss = 10.210275173187256, train_acc = 0.9805542617605962\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 13, train_loss = 9.603102690540254, train_acc = 0.9812529110386586\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 14, train_loss = 9.065043112263083, train_acc = 0.9823008849557522\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 15, train_loss = 8.582936233840883, train_acc = 0.9834653004191896\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 16, train_loss = 8.151487064547837, train_acc = 0.9842803912435957\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 17, train_loss = 7.758092604577541, train_acc = 0.9853283651606893\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 18, train_loss = 7.402314313687384, train_acc = 0.9864927806241267\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 19, train_loss = 7.0757229728624225, train_acc = 0.9875407545412203\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 20, train_loss = 6.779607401229441, train_acc = 0.9884722869119702\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 21, train_loss = 6.508619054220617, train_acc = 0.9891709361900326\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 22, train_loss = 6.255302479490638, train_acc = 0.989869585468095\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 23, train_loss = 6.022747439332306, train_acc = 0.9906846762925011\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 24, train_loss = 5.806982401758432, train_acc = 0.990801117838845\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 25, train_loss = 5.60603719484061, train_acc = 0.9911504424778761\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 26, train_loss = 5.415760589763522, train_acc = 0.9916162086632511\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 27, train_loss = 5.241346818394959, train_acc = 0.9923148579413135\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 28, train_loss = 5.07497947756201, train_acc = 0.9926641825803446\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 29, train_loss = 4.92149234097451, train_acc = 0.9927806241266884\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 30, train_loss = 4.777651092968881, train_acc = 0.9927806241266884\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 31, train_loss = 4.641500327736139, train_acc = 0.9930135072193759\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 32, train_loss = 4.514158920850605, train_acc = 0.9931299487657196\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 33, train_loss = 4.394457070622593, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 34, train_loss = 4.278653645887971, train_acc = 0.9932463903120633\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 35, train_loss = 4.173903934191912, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 36, train_loss = 4.070218555163592, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 37, train_loss = 3.9745096061378717, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 38, train_loss = 3.8825534065254033, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 39, train_loss = 3.7964699286967516, train_acc = 0.9941779226828132\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 40, train_loss = 3.7126616197638214, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 41, train_loss = 3.634709650184959, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 42, train_loss = 3.560485925525427, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 43, train_loss = 3.4882441088557243, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 44, train_loss = 3.4211160633713007, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 45, train_loss = 3.356139135081321, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 46, train_loss = 3.2954363063909113, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 47, train_loss = 3.2367463330738246, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 48, train_loss = 3.1823906316421926, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 49, train_loss = 3.1281832600943744, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 50, train_loss = 3.0772876827977598, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 51, train_loss = 3.0270361360162497, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 52, train_loss = 2.981428189203143, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 53, train_loss = 2.935396700631827, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 54, train_loss = 2.8920071539469063, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 55, train_loss = 2.8508508619852364, train_acc = 0.9958081043316255\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 56, train_loss = 2.8113715541549027, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 57, train_loss = 2.772639584261924, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 58, train_loss = 2.7352066463790834, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 59, train_loss = 2.700113970320672, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 60, train_loss = 2.664383985567838, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 61, train_loss = 2.630123147275299, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 62, train_loss = 2.5982872643508017, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 63, train_loss = 2.566646466497332, train_acc = 0.9962738705170004\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 64, train_loss = 2.5360596771351993, train_acc = 0.9961574289706567\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 65, train_loss = 2.507038377225399, train_acc = 0.9962738705170004\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 66, train_loss = 2.4782212879508734, train_acc = 0.9962738705170004\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 67, train_loss = 2.4500372647307813, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 68, train_loss = 2.423306042794138, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 69, train_loss = 2.3969120904803276, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 70, train_loss = 2.3712207139469683, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 71, train_loss = 2.3472288963384926, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 72, train_loss = 2.3226877846755087, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 73, train_loss = 2.299457984510809, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 74, train_loss = 2.2770948908291757, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 75, train_loss = 2.255556183401495, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 76, train_loss = 2.2335367556661367, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 77, train_loss = 2.2125535998493433, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 78, train_loss = 2.193230494391173, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 79, train_loss = 2.1733367000706494, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 80, train_loss = 2.153463525697589, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 81, train_loss = 2.1353245959617198, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 82, train_loss = 2.116875045001507, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 83, train_loss = 2.0988255999982357, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 84, train_loss = 2.081233672099188, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 85, train_loss = 2.0646299205254763, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 86, train_loss = 2.047658196417615, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 87, train_loss = 2.032079781172797, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 88, train_loss = 2.015966781647876, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 89, train_loss = 2.0001263252925128, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 90, train_loss = 1.9854379526805133, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 91, train_loss = 1.9714698947500437, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 92, train_loss = 1.9564749728888273, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 93, train_loss = 1.9420927602332085, train_acc = 0.9967396367023754\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 94, train_loss = 1.9287333742249757, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 95, train_loss = 1.9147559311240911, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 96, train_loss = 1.9023563016671687, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 97, train_loss = 1.8896864652633667, train_acc = 0.9968560782487191\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 98, train_loss = 1.8770154509693384, train_acc = 0.9968560782487191\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 99, train_loss = 1.8645307254046202, train_acc = 0.9968560782487191\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 100, train_loss = 1.851832376793027, train_acc = 0.9969725197950629\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 101, train_loss = 1.8402865938842297, train_acc = 0.9969725197950629\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 102, train_loss = 1.8294881309848279, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 103, train_loss = 1.8178952280431986, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 104, train_loss = 1.8071042839437723, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 105, train_loss = 1.7968682206701487, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 106, train_loss = 1.7860801108181477, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 107, train_loss = 1.7761712304782122, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 108, train_loss = 1.7660195764619857, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 109, train_loss = 1.7567188527900726, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 110, train_loss = 1.7467589564621449, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 111, train_loss = 1.7372108630370349, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 112, train_loss = 1.728077857522294, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 113, train_loss = 1.7195304955821484, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 114, train_loss = 1.7100922774989158, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 115, train_loss = 1.7015523954760283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 116, train_loss = 1.69387546624057, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 117, train_loss = 1.6840012993197888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 118, train_loss = 1.6770988993812352, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 119, train_loss = 1.6685093492269516, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 120, train_loss = 1.6606160562951118, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 121, train_loss = 1.6525418013334274, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 122, train_loss = 1.6444769613444805, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 123, train_loss = 1.6380584340076894, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 124, train_loss = 1.6301736875902861, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 125, train_loss = 1.6226900729816407, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 126, train_loss = 1.6164419583510607, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 127, train_loss = 1.607894868357107, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 128, train_loss = 1.600704851327464, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 129, train_loss = 1.5946151297539473, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 130, train_loss = 1.5875958253163844, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 131, train_loss = 1.5804445184767246, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 132, train_loss = 1.574378376826644, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 133, train_loss = 1.5680203035008162, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 134, train_loss = 1.5622711062896997, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 135, train_loss = 1.5553278643637896, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 136, train_loss = 1.54950259369798, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 137, train_loss = 1.5435861814767122, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 138, train_loss = 1.5371000680606812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 139, train_loss = 1.5317576557863504, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 140, train_loss = 1.526566417887807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 141, train_loss = 1.5199337757658213, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 142, train_loss = 1.5145328678190708, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 143, train_loss = 1.5088576842099428, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 144, train_loss = 1.5036717677721754, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 145, train_loss = 1.4990732731530443, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 146, train_loss = 1.4928880067309365, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 147, train_loss = 1.487912799580954, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 148, train_loss = 1.483100907295011, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 149, train_loss = 1.4786177979549393, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 150, train_loss = 1.472826718701981, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 151, train_loss = 1.4681722335517406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 152, train_loss = 1.4633274240186438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 153, train_loss = 1.4585439339280128, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 154, train_loss = 1.4537580019095913, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 155, train_loss = 1.4494574269047007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 156, train_loss = 1.4443026582011953, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 157, train_loss = 1.4398183915764093, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 158, train_loss = 1.4355423512170091, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 159, train_loss = 1.4310727609554306, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 160, train_loss = 1.4268604224780574, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 161, train_loss = 1.422686775564216, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 162, train_loss = 1.4180796748260036, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 163, train_loss = 1.4137464308878407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 164, train_loss = 1.4098875721683726, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 165, train_loss = 1.4054638730594888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 166, train_loss = 1.401949260965921, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 167, train_loss = 1.3970196476439014, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 168, train_loss = 1.3931742074200884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 169, train_loss = 1.3899590143701062, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 170, train_loss = 1.3853656388819218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 171, train_loss = 1.3816527823219076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 172, train_loss = 1.3779480071971193, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 173, train_loss = 1.3737183971097693, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 174, train_loss = 1.3703024642309174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 175, train_loss = 1.3668995877960697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 176, train_loss = 1.3626407565316185, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 177, train_loss = 1.359758627251722, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 178, train_loss = 1.355500495643355, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 179, train_loss = 1.3524147737771273, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 180, train_loss = 1.3490582866361365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 181, train_loss = 1.34541078528855, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 182, train_loss = 1.3416066815843806, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 183, train_loss = 1.3384863696992397, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 184, train_loss = 1.3352765763411298, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 185, train_loss = 1.3315616609761491, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 186, train_loss = 1.3287645286181942, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 187, train_loss = 1.3254475109279156, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 188, train_loss = 1.3221536917844787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 189, train_loss = 1.3187060815980658, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 190, train_loss = 1.316023644641973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 191, train_loss = 1.3130694894352928, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 192, train_loss = 1.3093517000088468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 193, train_loss = 1.3064732054481283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 194, train_loss = 1.303473562002182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 195, train_loss = 1.3001434983452782, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 196, train_loss = 1.2981358108809218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 197, train_loss = 1.295070276944898, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 198, train_loss = 1.2915948182344437, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 199, train_loss = 1.2891775829484686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 200, train_loss = 1.286543638096191, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 201, train_loss = 1.2835349378874525, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 202, train_loss = 1.280797497718595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 203, train_loss = 1.2784843351691961, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 204, train_loss = 1.2750879786908627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 205, train_loss = 1.272618250339292, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 206, train_loss = 1.270117258070968, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 207, train_loss = 1.267196211963892, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 208, train_loss = 1.2648794489214197, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 209, train_loss = 1.26225672790315, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 210, train_loss = 1.2595946416258812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 211, train_loss = 1.2571671213954687, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 212, train_loss = 1.2545527840266004, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 213, train_loss = 1.2521634580334648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 214, train_loss = 1.2491398099809885, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 215, train_loss = 1.2471096584340557, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 216, train_loss = 1.244336120202206, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 217, train_loss = 1.2420045031467453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 218, train_loss = 1.2399118760367855, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 219, train_loss = 1.2371303917607293, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 220, train_loss = 1.2358628554502502, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 221, train_loss = 1.2327954532811418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 222, train_loss = 1.2306924754520878, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 223, train_loss = 1.2278101617703214, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 224, train_loss = 1.225594402581919, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 225, train_loss = 1.2233067993074656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 226, train_loss = 1.2214529694174416, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 227, train_loss = 1.2188263411517255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 228, train_loss = 1.2170078071649186, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 229, train_loss = 1.2142008735681884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 230, train_loss = 1.212193610786926, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 231, train_loss = 1.2103144551510923, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 232, train_loss = 1.2082631054217927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 233, train_loss = 1.2061560942674987, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 234, train_loss = 1.2042333862627856, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 235, train_loss = 1.2015745037351735, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 236, train_loss = 1.1993925049901009, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 237, train_loss = 1.1976910438388586, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 238, train_loss = 1.195766516670119, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 239, train_loss = 1.1937923437799327, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 240, train_loss = 1.1918510620598681, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 241, train_loss = 1.1896183732897043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 242, train_loss = 1.1883824095129967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 243, train_loss = 1.185666222765576, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 244, train_loss = 1.1844306346029043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 245, train_loss = 1.1826966162770987, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 246, train_loss = 1.1797547924215905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 247, train_loss = 1.1781741262529977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 248, train_loss = 1.1762992584262975, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 249, train_loss = 1.1748232704703696, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 250, train_loss = 1.1731752387131564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 251, train_loss = 1.1707617994397879, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 252, train_loss = 1.1692358230357058, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 253, train_loss = 1.1670043474878184, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 254, train_loss = 1.1656196092371829, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 255, train_loss = 1.1636623479425907, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 256, train_loss = 1.1623284059460275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 257, train_loss = 1.1598253101110458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 258, train_loss = 1.1584761310368776, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 259, train_loss = 1.1567774415016174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 260, train_loss = 1.1549518958781846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 261, train_loss = 1.1530773751437664, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 262, train_loss = 1.1511718593537807, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 263, train_loss = 1.1502716839313507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 264, train_loss = 1.1483909941161983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 265, train_loss = 1.1458070470835082, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 266, train_loss = 1.144919256970752, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 267, train_loss = 1.1430881209671497, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 268, train_loss = 1.1414272238616832, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 269, train_loss = 1.1400627779657952, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 270, train_loss = 1.138617068529129, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 271, train_loss = 1.1363891456276178, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 272, train_loss = 1.1352027996326797, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 273, train_loss = 1.133789171173703, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 274, train_loss = 1.1317185927182436, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 275, train_loss = 1.1305782732670195, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 276, train_loss = 1.129209402948618, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 277, train_loss = 1.1273908410221338, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 278, train_loss = 1.1259315970237367, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 279, train_loss = 1.1241828172351234, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 280, train_loss = 1.1233568235184066, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 281, train_loss = 1.1212003845721483, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 282, train_loss = 1.1197916927631013, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 283, train_loss = 1.1185479990090244, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 284, train_loss = 1.117217584804166, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 285, train_loss = 1.1158852819353342, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 286, train_loss = 1.1143728395109065, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 287, train_loss = 1.1124626379460096, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 288, train_loss = 1.111522362276446, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 289, train_loss = 1.109720479696989, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 290, train_loss = 1.1086677983403206, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 291, train_loss = 1.1069859905983321, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 292, train_loss = 1.1057469335501082, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 293, train_loss = 1.1048078562016599, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 294, train_loss = 1.1032729583675973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 295, train_loss = 1.10111254703952, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 296, train_loss = 1.100040068209637, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 297, train_loss = 1.099079616367817, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 298, train_loss = 1.0971110655809753, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 299, train_loss = 1.0965108759701252, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 300, train_loss = 1.094932743057143, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 301, train_loss = 1.093194657296408, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 302, train_loss = 1.0922771717305295, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 303, train_loss = 1.090904688462615, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 304, train_loss = 1.089524656534195, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 305, train_loss = 1.0886675659567118, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 306, train_loss = 1.087146755948197, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 307, train_loss = 1.085853389755357, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 308, train_loss = 1.0839314814656973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 309, train_loss = 1.0831948748673312, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 310, train_loss = 1.0825132771278732, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 311, train_loss = 1.0806606107507832, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 312, train_loss = 1.0795401707291603, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 313, train_loss = 1.0783699291641824, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 314, train_loss = 1.076741096272599, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 315, train_loss = 1.0761258049751632, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 316, train_loss = 1.0741231851279736, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 317, train_loss = 1.0728387832641602, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 318, train_loss = 1.0723821365390904, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 319, train_loss = 1.0708947262610309, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 320, train_loss = 1.069778786972165, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 321, train_loss = 1.0682706224615686, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 322, train_loss = 1.0673797720228322, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 323, train_loss = 1.0666146011208184, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 324, train_loss = 1.0645922378753312, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 325, train_loss = 1.064055871218443, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 326, train_loss = 1.0626680285786279, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 327, train_loss = 1.061592950776685, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 328, train_loss = 1.0609724639798515, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 329, train_loss = 1.0585827653412707, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 330, train_loss = 1.0581221859902143, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 331, train_loss = 1.0568179904366843, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 332, train_loss = 1.05600224371301, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 333, train_loss = 1.0547845189576037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 334, train_loss = 1.0538535912637599, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 335, train_loss = 1.0524551402777433, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 336, train_loss = 1.0516797111486085, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 337, train_loss = 1.0499973806436174, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 338, train_loss = 1.0496174308354966, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 339, train_loss = 1.0484398466651328, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 340, train_loss = 1.0473891900037415, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 341, train_loss = 1.0462043031002395, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 342, train_loss = 1.045287894725334, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 343, train_loss = 1.0436872417922132, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 344, train_loss = 1.04233126033796, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 345, train_loss = 1.0419191885739565, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 346, train_loss = 1.0405427906662226, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 347, train_loss = 1.0398580245673656, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 348, train_loss = 1.03838724270463, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 349, train_loss = 1.0373447220772505, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 350, train_loss = 1.0370236591843423, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 351, train_loss = 1.035853752255207, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 352, train_loss = 1.0344049943087157, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 353, train_loss = 1.0333537539991084, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 354, train_loss = 1.0324150541273411, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 355, train_loss = 1.0313876904547215, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 356, train_loss = 1.0309524325130042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 357, train_loss = 1.0297358706593513, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 358, train_loss = 1.028360073134536, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 359, train_loss = 1.0271359936741646, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 360, train_loss = 1.027034660190111, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 361, train_loss = 1.026151541620493, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 362, train_loss = 1.0243192768248264, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 363, train_loss = 1.0242271752504166, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 364, train_loss = 1.022782715037465, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 365, train_loss = 1.022046505153412, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 366, train_loss = 1.020738578721648, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 367, train_loss = 1.0196905452758074, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 368, train_loss = 1.0196106949297246, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 369, train_loss = 1.0191913383605424, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 370, train_loss = 1.0175798498094082, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 371, train_loss = 1.0160741402360145, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 372, train_loss = 1.0156870329228695, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 373, train_loss = 1.0143951301870402, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 374, train_loss = 1.0132105884549674, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 375, train_loss = 1.0130238812416792, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 376, train_loss = 1.0117312303336803, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 377, train_loss = 1.0109714083373547, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 378, train_loss = 1.0101498340663966, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 379, train_loss = 1.009233457967639, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 380, train_loss = 1.008329113945365, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 381, train_loss = 1.0076425398292486, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 382, train_loss = 1.006787004560465, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 383, train_loss = 1.0052757778612431, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 384, train_loss = 1.0055786576122046, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 385, train_loss = 1.0041445350798313, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 386, train_loss = 1.0035778967139777, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 387, train_loss = 1.0026808232069016, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 388, train_loss = 1.0014055998472031, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 389, train_loss = 1.0005649694649037, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 390, train_loss = 0.9998600942490157, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 391, train_loss = 0.9989260584115982, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 392, train_loss = 0.9978606222721282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 393, train_loss = 0.996998139336938, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 394, train_loss = 0.9964911006391048, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 395, train_loss = 0.9961120883526746, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 396, train_loss = 0.9946117258223239, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 397, train_loss = 0.9937670839426573, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 398, train_loss = 0.9931376650929451, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 399, train_loss = 0.9927125716058072, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 400, train_loss = 0.9911374393850565, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 401, train_loss = 0.9905230638978537, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 402, train_loss = 0.9901942213473376, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 403, train_loss = 0.9890709115716163, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 404, train_loss = 0.9885504314152058, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 405, train_loss = 0.987824055046076, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 406, train_loss = 0.986641059309477, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 407, train_loss = 0.9860593732446432, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 408, train_loss = 0.9852942023426294, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 409, train_loss = 0.9844384131429251, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 410, train_loss = 0.9837231797573622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 411, train_loss = 0.9824078362435102, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 412, train_loss = 0.982914388179779, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 413, train_loss = 0.980774392694002, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 414, train_loss = 0.9808006162347738, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 415, train_loss = 0.9800148910435382, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 416, train_loss = 0.978708716109395, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 417, train_loss = 0.9783547632396221, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 418, train_loss = 0.9776399731636047, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 419, train_loss = 0.9767964339407627, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 420, train_loss = 0.9758555423468351, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 421, train_loss = 0.9761375561356544, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 422, train_loss = 0.974603395909071, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 423, train_loss = 0.9741291707905475, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 424, train_loss = 0.9731353651732206, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 425, train_loss = 0.972648741066223, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 426, train_loss = 0.9721625062229577, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 427, train_loss = 0.9709424879401922, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 428, train_loss = 0.9706061227770988, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 429, train_loss = 0.9695192513463553, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 430, train_loss = 0.9690802308323327, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 431, train_loss = 0.9687163339403924, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 432, train_loss = 0.9676048215478659, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 433, train_loss = 0.9663387549517211, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 434, train_loss = 0.9662788262066897, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 435, train_loss = 0.9656040519475937, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 436, train_loss = 0.9648049877432641, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 437, train_loss = 0.9644676440802868, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 438, train_loss = 0.9634213820099831, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 439, train_loss = 0.9627816304564476, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 440, train_loss = 0.9619853266922291, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 441, train_loss = 0.9621638326498214, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 442, train_loss = 0.9609716609120369, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 443, train_loss = 0.9597138166427612, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 444, train_loss = 0.959719459846383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 445, train_loss = 0.9592681719514076, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 446, train_loss = 0.9584043603390455, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 447, train_loss = 0.957698181271553, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 448, train_loss = 0.9570976986142341, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 449, train_loss = 0.9561103911546525, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 450, train_loss = 0.9556847407075111, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 451, train_loss = 0.955239367991453, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 452, train_loss = 0.9547544071974698, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 453, train_loss = 0.953622056171298, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 454, train_loss = 0.9527457039803267, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 455, train_loss = 0.9534210550191347, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 456, train_loss = 0.9519380107522011, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 457, train_loss = 0.9517714958637953, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 458, train_loss = 0.9515398995426949, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 459, train_loss = 0.9502573286590632, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 460, train_loss = 0.9496485094132368, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 461, train_loss = 0.9489289354532957, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 462, train_loss = 0.948444507404929, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 463, train_loss = 0.9479533346893732, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 464, train_loss = 0.94665807732963, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 465, train_loss = 0.9469192115066107, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 466, train_loss = 0.9461253266781569, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 467, train_loss = 0.9448064149764832, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 468, train_loss = 0.9447706254723016, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 469, train_loss = 0.943515924125677, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 470, train_loss = 0.9434955859032925, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 471, train_loss = 0.9426341696234886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 472, train_loss = 0.9424107484519482, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 473, train_loss = 0.9415596587059554, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 474, train_loss = 0.9412240156379994, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 475, train_loss = 0.9410448502749205, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 476, train_loss = 0.939729830250144, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 477, train_loss = 0.9394516050815582, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 478, train_loss = 0.9385956314799841, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 479, train_loss = 0.9383956311794464, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 480, train_loss = 0.9380682253686246, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 481, train_loss = 0.9366728303430136, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 482, train_loss = 0.9362836554646492, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 483, train_loss = 0.9361905474215746, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 484, train_loss = 0.9351577181369066, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 485, train_loss = 0.9349743463099003, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 486, train_loss = 0.9342032087442931, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 487, train_loss = 0.9337397882190999, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 488, train_loss = 0.9329454830440227, train_acc = 0.9980204937121565\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 489, train_loss = 0.9330095326004084, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 490, train_loss = 0.9318150517938193, train_acc = 0.9980204937121565\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 491, train_loss = 0.9311947803944349, train_acc = 0.9980204937121565\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 492, train_loss = 0.9312805092486087, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 493, train_loss = 0.9301316626369953, train_acc = 0.9980204937121565\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 494, train_loss = 0.9297004106047098, train_acc = 0.9980204937121565\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 495, train_loss = 0.9292189627885818, train_acc = 0.9980204937121565\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 496, train_loss = 0.9288084053841885, train_acc = 0.9980204937121565\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 497, train_loss = 0.9283780647965614, train_acc = 0.9980204937121565\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 498, train_loss = 0.9268835348484572, train_acc = 0.9980204937121565\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 499, train_loss = 0.9269152531924192, train_acc = 0.9980204937121565\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▊                                                                    | 2/30 [19:25<4:28:59, 576.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "3th- epoch: 0, train_loss = 119.46971649676561, train_acc = 0.7706101537028411\n",
      "test Acc 0.8747672253258846:\n",
      "3th- epoch: 1, train_loss = 43.75456079095602, train_acc = 0.9110386585933862\n",
      "test Acc 0.9106145251396648:\n",
      "3th- epoch: 2, train_loss = 31.91010744869709, train_acc = 0.9349091755938519\n",
      "test Acc 0.9259776536312849:\n",
      "3th- epoch: 3, train_loss = 25.69590152800083, train_acc = 0.9457382394038193\n",
      "test Acc 0.9394785847299814:\n",
      "3th- epoch: 4, train_loss = 21.596347901970148, train_acc = 0.9543549138332557\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 5, train_loss = 18.67721415311098, train_acc = 0.9618071727992548\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 6, train_loss = 16.50638397783041, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "3th- epoch: 7, train_loss = 14.816208520904183, train_acc = 0.9706567303213787\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 8, train_loss = 13.46745977178216, train_acc = 0.9728691197019096\n",
      "test Acc 0.9548417132216015:\n",
      "3th- epoch: 9, train_loss = 12.35886355675757, train_acc = 0.9760130414531905\n",
      "test Acc 0.9567039106145251:\n",
      "3th- epoch: 10, train_loss = 11.431145368143916, train_acc = 0.977992547741034\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 11, train_loss = 10.644404644146562, train_acc = 0.97973917093619\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 12, train_loss = 9.955058418214321, train_acc = 0.9813693525850024\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 13, train_loss = 9.353590296581388, train_acc = 0.9827666511411272\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 14, train_loss = 8.824559564702213, train_acc = 0.9846297158826269\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 15, train_loss = 8.35520517360419, train_acc = 0.9848625989753144\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 16, train_loss = 7.932616461999714, train_acc = 0.9855612482533768\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 17, train_loss = 7.556235029362142, train_acc = 0.9864927806241267\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 18, train_loss = 7.208115334622562, train_acc = 0.9873078714485328\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 19, train_loss = 6.890840853564441, train_acc = 0.9877736376339078\n",
      "test Acc 0.9674115456238361:\n",
      "3th- epoch: 20, train_loss = 6.600691053085029, train_acc = 0.9885887284583139\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 21, train_loss = 6.330577806569636, train_acc = 0.9889380530973452\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 22, train_loss = 6.085973503999412, train_acc = 0.9890544946436889\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 23, train_loss = 5.857372443191707, train_acc = 0.98940381928272\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 24, train_loss = 5.647172536700964, train_acc = 0.989869585468095\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 25, train_loss = 5.449260115623474, train_acc = 0.99033535165347\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 26, train_loss = 5.266062547452748, train_acc = 0.9906846762925011\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 27, train_loss = 5.098401918075979, train_acc = 0.9909175593851887\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 28, train_loss = 4.939743656665087, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 29, train_loss = 4.795625914819539, train_acc = 0.9916162086632511\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 30, train_loss = 4.659223756752908, train_acc = 0.9916162086632511\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 31, train_loss = 4.5336086275056005, train_acc = 0.9918490917559385\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 32, train_loss = 4.414442089851946, train_acc = 0.992081974848626\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 33, train_loss = 4.302790407091379, train_acc = 0.9926641825803446\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 34, train_loss = 4.1951520456932485, train_acc = 0.9930135072193759\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 35, train_loss = 4.096386031713337, train_acc = 0.9932463903120633\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 36, train_loss = 4.001511403825134, train_acc = 0.9933628318584071\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 37, train_loss = 3.9131884039379656, train_acc = 0.9935957149510946\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 38, train_loss = 3.8288871035911143, train_acc = 0.9937121564974383\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 39, train_loss = 3.747834739740938, train_acc = 0.9939450395901258\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 40, train_loss = 3.6721966601908207, train_acc = 0.9940614811364695\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 41, train_loss = 3.598756545688957, train_acc = 0.9941779226828132\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 42, train_loss = 3.52950332313776, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 43, train_loss = 3.4629687829874456, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 44, train_loss = 3.3999251686036587, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 45, train_loss = 3.3397377631627023, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 46, train_loss = 3.2830217271111906, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 47, train_loss = 3.226470851805061, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 48, train_loss = 3.1732418588362634, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 49, train_loss = 3.122753360774368, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 50, train_loss = 3.0729456855915487, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 51, train_loss = 3.026985871139914, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 52, train_loss = 2.9812919734977186, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 53, train_loss = 2.937856152653694, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 54, train_loss = 2.8944469853304327, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 55, train_loss = 2.853630182798952, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 56, train_loss = 2.8145380788482726, train_acc = 0.9954587796925943\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 57, train_loss = 2.7760517224669456, train_acc = 0.9954587796925943\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 58, train_loss = 2.739288000855595, train_acc = 0.9959245458779693\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 59, train_loss = 2.704632794018835, train_acc = 0.9959245458779693\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 60, train_loss = 2.668568105669692, train_acc = 0.9959245458779693\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 61, train_loss = 2.6358231890480965, train_acc = 0.9959245458779693\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 62, train_loss = 2.603306873468682, train_acc = 0.9959245458779693\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 63, train_loss = 2.5718040578067303, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 64, train_loss = 2.5416309509892017, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 65, train_loss = 2.5115649315994233, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 66, train_loss = 2.4839840792119503, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 67, train_loss = 2.4571165193337947, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 68, train_loss = 2.429756094934419, train_acc = 0.9962738705170004\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 69, train_loss = 2.4043487298768014, train_acc = 0.9962738705170004\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 70, train_loss = 2.379343006759882, train_acc = 0.9963903120633442\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 71, train_loss = 2.3554713788907975, train_acc = 0.9963903120633442\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 72, train_loss = 2.3315537001471967, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 73, train_loss = 2.3086650781333447, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 74, train_loss = 2.286200414178893, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 75, train_loss = 2.264411059441045, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 76, train_loss = 2.2436366777401417, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 77, train_loss = 2.2237658388912678, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 78, train_loss = 2.203667877940461, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 79, train_loss = 2.184994437964633, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 80, train_loss = 2.1662829990964383, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 81, train_loss = 2.148258003173396, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 82, train_loss = 2.130685194162652, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 83, train_loss = 2.1134468007367104, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 84, train_loss = 2.096228151349351, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 85, train_loss = 2.0811245527584106, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 86, train_loss = 2.064769174903631, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 87, train_loss = 2.048389334231615, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 88, train_loss = 2.0346866447944194, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 89, train_loss = 2.0189190916717052, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 90, train_loss = 2.004655133932829, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 91, train_loss = 1.99081985023804, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 92, train_loss = 1.9765108909923583, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 93, train_loss = 1.963077784748748, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 94, train_loss = 1.950660874368623, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 95, train_loss = 1.9373215474188328, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 96, train_loss = 1.924420841038227, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 97, train_loss = 1.9118483315687627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 98, train_loss = 1.9001018006820232, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 99, train_loss = 1.8884956240653992, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 100, train_loss = 1.8765186045784503, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 101, train_loss = 1.8644601441919804, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 102, train_loss = 1.8541922954609618, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 103, train_loss = 1.8431619430193678, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 104, train_loss = 1.832895390689373, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 105, train_loss = 1.8226014003157616, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 106, train_loss = 1.8118233369896188, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 107, train_loss = 1.8026643296470866, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 108, train_loss = 1.792903434485197, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 109, train_loss = 1.78335292392876, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 110, train_loss = 1.7740854769945145, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 111, train_loss = 1.7648816840955988, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 112, train_loss = 1.755525030195713, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 113, train_loss = 1.7466742979595438, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 114, train_loss = 1.7380103567847982, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 115, train_loss = 1.7297495380043983, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 116, train_loss = 1.7209352714708075, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 117, train_loss = 1.712671579211019, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 118, train_loss = 1.704395268112421, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 119, train_loss = 1.697099070996046, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 120, train_loss = 1.6896910605719313, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 121, train_loss = 1.6814486794173717, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 122, train_loss = 1.6735400134930387, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 123, train_loss = 1.6669047363102436, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 124, train_loss = 1.6590825319290161, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 125, train_loss = 1.6525506315520033, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 126, train_loss = 1.6447804732015356, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 127, train_loss = 1.6381443614372984, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 128, train_loss = 1.6305084774503484, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 129, train_loss = 1.6238968732068315, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 130, train_loss = 1.6170333040645346, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 131, train_loss = 1.6104918221244588, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 132, train_loss = 1.6039596224436536, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 133, train_loss = 1.5979215676197782, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 134, train_loss = 1.590977450250648, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 135, train_loss = 1.585070390254259, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 136, train_loss = 1.5792736547300592, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 137, train_loss = 1.5734611041843891, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 138, train_loss = 1.567820223630406, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 139, train_loss = 1.5619564453372732, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 140, train_loss = 1.5556833297014236, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 141, train_loss = 1.5503357239067554, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 142, train_loss = 1.5438473088433966, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 143, train_loss = 1.5392938839504495, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 144, train_loss = 1.5337637489428744, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 145, train_loss = 1.528461200534366, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 146, train_loss = 1.5226319035282359, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 147, train_loss = 1.5180489482590929, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 148, train_loss = 1.5127525416901335, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 149, train_loss = 1.5074668899178505, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 150, train_loss = 1.5022411743411794, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 151, train_loss = 1.4978771470487118, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 152, train_loss = 1.4924706431338564, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 153, train_loss = 1.4886355685302988, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 154, train_loss = 1.4825722947716713, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 155, train_loss = 1.4789129184791818, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 156, train_loss = 1.4732306711375713, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 157, train_loss = 1.469834870309569, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 158, train_loss = 1.4649281539022923, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 159, train_loss = 1.4601840364048257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 160, train_loss = 1.4563248915364966, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 161, train_loss = 1.4520194059005007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 162, train_loss = 1.4472025111317635, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 163, train_loss = 1.4436266819830053, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 164, train_loss = 1.4389930317993276, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 165, train_loss = 1.4352588293259032, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 166, train_loss = 1.4309105674619786, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 167, train_loss = 1.4269949036533944, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 168, train_loss = 1.4232053073938005, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 169, train_loss = 1.4192692289943807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 170, train_loss = 1.415136483788956, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 171, train_loss = 1.4119903917307965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 172, train_loss = 1.4077020275290124, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 173, train_loss = 1.4039877988398075, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 174, train_loss = 1.4000047904555686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 175, train_loss = 1.395322609692812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 176, train_loss = 1.392398439347744, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 177, train_loss = 1.3885103265638463, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 178, train_loss = 1.3844002795522101, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 179, train_loss = 1.3810236652498133, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 180, train_loss = 1.3781555841560476, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 181, train_loss = 1.3738676967914216, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 182, train_loss = 1.3699750837986358, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 183, train_loss = 1.3667976136202924, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 184, train_loss = 1.3634939131443389, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 185, train_loss = 1.3607352164690383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 186, train_loss = 1.3572834258084185, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 187, train_loss = 1.3534856413607486, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 188, train_loss = 1.3503464311361313, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 189, train_loss = 1.3474583153729327, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 190, train_loss = 1.3442533276975155, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 191, train_loss = 1.3402313962578773, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 192, train_loss = 1.3382474035024643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 193, train_loss = 1.3346217200160027, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 194, train_loss = 1.332264584780205, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 195, train_loss = 1.3286030267481692, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 196, train_loss = 1.3259371009771712, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 197, train_loss = 1.323449061543215, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 198, train_loss = 1.3202098731999286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 199, train_loss = 1.3170630696113221, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 200, train_loss = 1.3144963371451013, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 201, train_loss = 1.31129814311862, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 202, train_loss = 1.3080680184066296, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 203, train_loss = 1.3060010423068888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 204, train_loss = 1.3034058709745295, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 205, train_loss = 1.3002825801377185, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 206, train_loss = 1.2977126550977118, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 207, train_loss = 1.2950783993001096, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 208, train_loss = 1.292357066005934, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 209, train_loss = 1.289437508850824, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 210, train_loss = 1.2869277496938594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 211, train_loss = 1.2842783008818515, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 212, train_loss = 1.2819675542414188, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 213, train_loss = 1.2798197269439697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 214, train_loss = 1.2766179616446607, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 215, train_loss = 1.2743899102206342, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 216, train_loss = 1.2715107028489, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 217, train_loss = 1.2693525862996466, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 218, train_loss = 1.2671642650966533, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 219, train_loss = 1.2644384130835533, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 220, train_loss = 1.261853278905619, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 221, train_loss = 1.2599456931347959, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 222, train_loss = 1.256750235974323, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 223, train_loss = 1.255240086466074, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 224, train_loss = 1.2529737750883214, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 225, train_loss = 1.2496795381302945, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 226, train_loss = 1.2485926213557832, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 227, train_loss = 1.2459545520250686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 228, train_loss = 1.2435543673927896, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 229, train_loss = 1.2411451551015489, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 230, train_loss = 1.239447046071291, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 231, train_loss = 1.23718959587859, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 232, train_loss = 1.2347123722429387, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 233, train_loss = 1.2324896926875226, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 234, train_loss = 1.2309957134420983, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 235, train_loss = 1.2282446511089802, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 236, train_loss = 1.2263030757312663, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 237, train_loss = 1.2242912650108337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 238, train_loss = 1.2227754145860672, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 239, train_loss = 1.2195066772401333, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 240, train_loss = 1.218538114160765, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 241, train_loss = 1.2166930735111237, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 242, train_loss = 1.2143988472525962, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 243, train_loss = 1.2122606461052783, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 244, train_loss = 1.2106977365911007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 245, train_loss = 1.2078172166948207, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 246, train_loss = 1.2064976245164871, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 247, train_loss = 1.204859472811222, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 248, train_loss = 1.2028719547088258, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 249, train_loss = 1.20049549639225, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 250, train_loss = 1.1986967946286313, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 251, train_loss = 1.196518737822771, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 252, train_loss = 1.1940351289813407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 253, train_loss = 1.1930525762145407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 254, train_loss = 1.1909823727910407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 255, train_loss = 1.1885389424860477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 256, train_loss = 1.1868365059490316, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 257, train_loss = 1.185678752779495, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 258, train_loss = 1.183799805759918, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 259, train_loss = 1.1808763009612449, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 260, train_loss = 1.179431984841358, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 261, train_loss = 1.177169771224726, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 262, train_loss = 1.175623840332264, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 263, train_loss = 1.1736360279319342, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 264, train_loss = 1.1724254339933395, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 265, train_loss = 1.1705204136669636, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 266, train_loss = 1.169090768933529, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 267, train_loss = 1.1666993287799414, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 268, train_loss = 1.165749410778517, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 269, train_loss = 1.163958022982115, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 270, train_loss = 1.1612893293204252, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 271, train_loss = 1.1608387231826782, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 272, train_loss = 1.1589933298528194, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 273, train_loss = 1.1567311075923499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 274, train_loss = 1.1558386137185153, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 275, train_loss = 1.154177794844145, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 276, train_loss = 1.152028209209675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 277, train_loss = 1.1512912561593112, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 278, train_loss = 1.1485139032301959, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 279, train_loss = 1.147929459810257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 280, train_loss = 1.1456906410458032, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 281, train_loss = 1.1444612654449884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 282, train_loss = 1.1431678707303945, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 283, train_loss = 1.1410446377994958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 284, train_loss = 1.1404280761780683, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 285, train_loss = 1.1378168736991938, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 286, train_loss = 1.137106642127037, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 287, train_loss = 1.1357915786502417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 288, train_loss = 1.1332772423920687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 289, train_loss = 1.1327069898543414, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 290, train_loss = 1.1305364705622196, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 291, train_loss = 1.1296237707138062, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 292, train_loss = 1.1280645628867205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 293, train_loss = 1.1257944740355015, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 294, train_loss = 1.1251334150729235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 295, train_loss = 1.1231861089763697, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 296, train_loss = 1.1222776249051094, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 297, train_loss = 1.120208709180588, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 298, train_loss = 1.120110278337961, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 299, train_loss = 1.1178648968634661, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 300, train_loss = 1.1162026934325695, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 301, train_loss = 1.115136024862295, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 302, train_loss = 1.1138508146104869, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 303, train_loss = 1.112479748815531, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 304, train_loss = 1.1110635697841644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 305, train_loss = 1.109702712536091, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 306, train_loss = 1.10812259465456, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 307, train_loss = 1.1069077737629414, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 308, train_loss = 1.1059970756468829, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 309, train_loss = 1.1037282571196556, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 310, train_loss = 1.1035423812863883, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 311, train_loss = 1.1019415520131588, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 312, train_loss = 1.1001343876123428, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 313, train_loss = 1.0990242063999176, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 314, train_loss = 1.097599654138321, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 315, train_loss = 1.0963420843181666, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 316, train_loss = 1.094766065478325, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 317, train_loss = 1.0941384260950144, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 318, train_loss = 1.092880267649889, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 319, train_loss = 1.0910990623233374, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 320, train_loss = 1.0903186289069708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 321, train_loss = 1.0887108755705412, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 322, train_loss = 1.087836742401123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 323, train_loss = 1.0859201165440027, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 324, train_loss = 1.085304665059084, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 325, train_loss = 1.0843360846338328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 326, train_loss = 1.0819928459823132, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 327, train_loss = 1.0818502393958624, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 328, train_loss = 1.0799188700912055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 329, train_loss = 1.0789668584766332, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 330, train_loss = 1.0779349083604757, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 331, train_loss = 1.076442789286375, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 332, train_loss = 1.0757825411856174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 333, train_loss = 1.0733776303532068, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 334, train_loss = 1.0729833965597209, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 335, train_loss = 1.0717853369715158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 336, train_loss = 1.0703952064213809, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 337, train_loss = 1.0696608635189477, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 338, train_loss = 1.0682160072028637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 339, train_loss = 1.0670468943717424, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 340, train_loss = 1.0660769591631833, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 341, train_loss = 1.0649098468420561, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 342, train_loss = 1.0637896048428956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 343, train_loss = 1.062636104732519, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 344, train_loss = 1.0612523990275804, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 345, train_loss = 1.0603728306887206, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 346, train_loss = 1.0592199998500291, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 347, train_loss = 1.058107528835535, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 348, train_loss = 1.0569307394325733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 349, train_loss = 1.055846631526947, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 350, train_loss = 1.0548321790993214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 351, train_loss = 1.0533980714681093, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 352, train_loss = 1.052674168109661, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 353, train_loss = 1.0516059460642282, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 354, train_loss = 1.0504727003572043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 355, train_loss = 1.0495370427670423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 356, train_loss = 1.0483641015889589, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 357, train_loss = 1.047128056496149, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 358, train_loss = 1.046398221194977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 359, train_loss = 1.0449405312538147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 360, train_loss = 1.0445262181165162, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 361, train_loss = 1.0436462511715945, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 362, train_loss = 1.0420183626411017, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 363, train_loss = 1.041027163475519, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 364, train_loss = 1.0402080416679382, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 365, train_loss = 1.0390876730380114, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 366, train_loss = 1.038367599248886, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 367, train_loss = 1.0371753560903016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 368, train_loss = 1.0357890029845294, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 369, train_loss = 1.0352291452290956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 370, train_loss = 1.0344661213457584, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 371, train_loss = 1.0325419642031193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 372, train_loss = 1.032372571527958, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 373, train_loss = 1.0312707511184271, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 374, train_loss = 1.0300053978862707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 375, train_loss = 1.0294610696437303, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 376, train_loss = 1.0284016144869383, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 377, train_loss = 1.0272255713643972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 378, train_loss = 1.0266052807273809, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 379, train_loss = 1.025783949851757, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 380, train_loss = 1.023984676838154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 381, train_loss = 1.0234420858323574, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 382, train_loss = 1.0229200112225953, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 383, train_loss = 1.0212156660854816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 384, train_loss = 1.02123879516148, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 385, train_loss = 1.020197539270157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 386, train_loss = 1.0187577828764915, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 387, train_loss = 1.0183846441505011, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 388, train_loss = 1.0171148255467415, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 389, train_loss = 1.016127947717905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 390, train_loss = 1.0151661708950996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 391, train_loss = 1.0145172215998173, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 392, train_loss = 1.0134596154093742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 393, train_loss = 1.012341166526312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 394, train_loss = 1.0123037385346834, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 395, train_loss = 1.0110269697906915, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 396, train_loss = 1.009536617755657, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 397, train_loss = 1.0091441397962626, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 398, train_loss = 1.0087930671870708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 399, train_loss = 1.0071424854395445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 400, train_loss = 1.0066570242343005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 401, train_loss = 1.0055707531573717, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 402, train_loss = 1.0046603865921497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 403, train_loss = 1.004114589333767, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 404, train_loss = 1.0031955800950527, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 405, train_loss = 1.0021217999455985, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 406, train_loss = 1.0015086705388967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 407, train_loss = 1.0006398670375347, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 408, train_loss = 0.9996277441678103, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 409, train_loss = 0.9988728711905424, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 410, train_loss = 0.9984582029283047, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 411, train_loss = 0.9969280548393726, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 412, train_loss = 0.9965775795280933, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 413, train_loss = 0.995468582957983, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 414, train_loss = 0.9948499140737113, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 415, train_loss = 0.9946328414080199, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 416, train_loss = 0.9925788640975952, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 417, train_loss = 0.9928621140570613, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 418, train_loss = 0.9919701144099236, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 419, train_loss = 0.9901657539157895, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 420, train_loss = 0.9899059918971034, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 421, train_loss = 0.9889992537646322, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 422, train_loss = 0.9877429616899462, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 423, train_loss = 0.9872076685278444, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 424, train_loss = 0.9867637803108664, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 425, train_loss = 0.985762033611536, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 426, train_loss = 0.984557165458682, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 427, train_loss = 0.9843715553433867, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 428, train_loss = 0.9832144180982141, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 429, train_loss = 0.9825646852405043, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 430, train_loss = 0.9819701773376437, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 431, train_loss = 0.981233574450016, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 432, train_loss = 0.9799006668181391, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 433, train_loss = 0.979748509824276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 434, train_loss = 0.9784914466290502, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 435, train_loss = 0.9781515002250671, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 436, train_loss = 0.9766445110290078, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 437, train_loss = 0.9768776707351208, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 438, train_loss = 0.9752540327608585, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 439, train_loss = 0.9749311382620363, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 440, train_loss = 0.9737603863031836, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 441, train_loss = 0.973781747117755, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 442, train_loss = 0.9728223346173763, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 443, train_loss = 0.9718640881328611, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 444, train_loss = 0.9709956087172031, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 445, train_loss = 0.9713909377605887, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 446, train_loss = 0.970090489834547, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 447, train_loss = 0.9695296324789524, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 448, train_loss = 0.9686901730747195, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 449, train_loss = 0.9674152284860611, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 450, train_loss = 0.9664823263883591, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 451, train_loss = 0.9662686809897423, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 452, train_loss = 0.9657681708486052, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 453, train_loss = 0.9643139106483432, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 454, train_loss = 0.9638254096062155, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 455, train_loss = 0.963845373436925, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 456, train_loss = 0.9626417135150405, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 457, train_loss = 0.962379701435566, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 458, train_loss = 0.9611475231795339, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 459, train_loss = 0.9601892580540152, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 460, train_loss = 0.9593263355345698, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 461, train_loss = 0.9592381678521633, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 462, train_loss = 0.9577483211905928, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 463, train_loss = 0.9579130560159683, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 464, train_loss = 0.9565765832812758, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 465, train_loss = 0.9564110115170479, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 466, train_loss = 0.9552595093846321, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 467, train_loss = 0.954750519245863, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 468, train_loss = 0.954208626106265, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 469, train_loss = 0.9532699001283618, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 470, train_loss = 0.9527978040277958, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 471, train_loss = 0.9526765954942675, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 472, train_loss = 0.9511845856904984, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 473, train_loss = 0.9513551580457715, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 474, train_loss = 0.9500649881811114, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 475, train_loss = 0.949677628770587, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 476, train_loss = 0.9488241573126288, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 477, train_loss = 0.9486215114593506, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 478, train_loss = 0.9472133231611224, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 479, train_loss = 0.9473304736166028, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 480, train_loss = 0.9464510828256607, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 481, train_loss = 0.9455804613680812, train_acc = 0.9976711690731253\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 482, train_loss = 0.9451517922134371, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 483, train_loss = 0.944190135851386, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 484, train_loss = 0.9439231790602207, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 485, train_loss = 0.9430905853660079, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 486, train_loss = 0.9426837861537933, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 487, train_loss = 0.9418413775711088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 488, train_loss = 0.9416143310518237, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 489, train_loss = 0.9407287103385897, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 490, train_loss = 0.9403610378503799, train_acc = 0.9976711690731253\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 491, train_loss = 0.9392451668827562, train_acc = 0.9975547275267815\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 492, train_loss = 0.9387700967490673, train_acc = 0.9976711690731253\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 493, train_loss = 0.9381958159356145, train_acc = 0.9976711690731253\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 494, train_loss = 0.9382116372435121, train_acc = 0.9976711690731253\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 495, train_loss = 0.9366908843367128, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 496, train_loss = 0.9367661289870739, train_acc = 0.9976711690731253\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 497, train_loss = 0.9357548082916765, train_acc = 0.9976711690731253\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 498, train_loss = 0.9356118403375149, train_acc = 0.9976711690731253\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 499, train_loss = 0.9343418565840693, train_acc = 0.9976711690731253\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▎                                                                 | 3/30 [29:24<4:22:30, 583.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "4th- epoch: 0, train_loss = 132.0282479673624, train_acc = 0.766301816488123\n",
      "test Acc 0.8649906890130353:\n",
      "4th- epoch: 1, train_loss = 45.407737493515015, train_acc = 0.9063809967396367\n",
      "test Acc 0.9115456238361266:\n",
      "4th- epoch: 2, train_loss = 32.735219053924084, train_acc = 0.9318816953889147\n",
      "test Acc 0.9283054003724395:\n",
      "4th- epoch: 3, train_loss = 26.47483091056347, train_acc = 0.9459711224965067\n",
      "test Acc 0.9338919925512105:\n",
      "4th- epoch: 4, train_loss = 22.551902689039707, train_acc = 0.9550535631113182\n",
      "test Acc 0.9371508379888268:\n",
      "4th- epoch: 5, train_loss = 19.818847365677357, train_acc = 0.9600605496040987\n",
      "test Acc 0.9432029795158287:\n",
      "4th- epoch: 6, train_loss = 17.753145452588797, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 7, train_loss = 16.119262274354696, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 8, train_loss = 14.781088769435883, train_acc = 0.9731020027945971\n",
      "test Acc 0.952513966480447:\n",
      "4th- epoch: 9, train_loss = 13.658796388655901, train_acc = 0.975314392175128\n",
      "test Acc 0.9553072625698324:\n",
      "4th- epoch: 10, train_loss = 12.684521108865738, train_acc = 0.9772938984629715\n",
      "test Acc 0.957635009310987:\n",
      "4th- epoch: 11, train_loss = 11.839728096500039, train_acc = 0.9788076385654402\n",
      "test Acc 0.9585661080074488:\n",
      "4th- epoch: 12, train_loss = 11.099097456783056, train_acc = 0.9796227293898463\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 13, train_loss = 10.439520044252276, train_acc = 0.9811364694923148\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 14, train_loss = 9.863285394385457, train_acc = 0.9825337680484397\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 15, train_loss = 9.35095240548253, train_acc = 0.983698183511877\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 16, train_loss = 8.889650039374828, train_acc = 0.9847461574289706\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 17, train_loss = 8.472039902582765, train_acc = 0.9849790405216581\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 18, train_loss = 8.09583830833435, train_acc = 0.9856776897997206\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 19, train_loss = 7.753062538802624, train_acc = 0.9864927806241267\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 20, train_loss = 7.4369293339550495, train_acc = 0.9870749883558454\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 21, train_loss = 7.146692527458072, train_acc = 0.9877736376339078\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 22, train_loss = 6.882706316187978, train_acc = 0.9887051700046576\n",
      "test Acc 0.962756052141527:\n",
      "4th- epoch: 23, train_loss = 6.638545861467719, train_acc = 0.9890544946436889\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 24, train_loss = 6.413779960945249, train_acc = 0.9897531439217513\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 25, train_loss = 6.204127991572022, train_acc = 0.989869585468095\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 26, train_loss = 6.009549748152494, train_acc = 0.9906846762925011\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 27, train_loss = 5.825580706819892, train_acc = 0.9910340009315324\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 28, train_loss = 5.657609490677714, train_acc = 0.9911504424778761\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 29, train_loss = 5.50111844856292, train_acc = 0.9918490917559385\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 30, train_loss = 5.349497940391302, train_acc = 0.9923148579413135\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 31, train_loss = 5.207620793953538, train_acc = 0.9923148579413135\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 32, train_loss = 5.07550376560539, train_acc = 0.9926641825803446\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 33, train_loss = 4.94704716373235, train_acc = 0.9926641825803446\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 34, train_loss = 4.827350030653179, train_acc = 0.9926641825803446\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 35, train_loss = 4.715021204203367, train_acc = 0.9927806241266884\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 36, train_loss = 4.605808179825544, train_acc = 0.9928970656730322\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 37, train_loss = 4.504217394627631, train_acc = 0.9932463903120633\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 38, train_loss = 4.407427790574729, train_acc = 0.9932463903120633\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 39, train_loss = 4.314643708057702, train_acc = 0.9933628318584071\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 40, train_loss = 4.224827144294977, train_acc = 0.9937121564974383\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 41, train_loss = 4.141426547430456, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 42, train_loss = 4.061102622188628, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 43, train_loss = 3.9850472761318088, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "4th- epoch: 44, train_loss = 3.913412774913013, train_acc = 0.9944108057755007\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 45, train_loss = 3.8421769039705396, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 46, train_loss = 3.7755303094163537, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 47, train_loss = 3.7132716476917267, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 48, train_loss = 3.651588749140501, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 49, train_loss = 3.5931376228109, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 50, train_loss = 3.5368809811770916, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 51, train_loss = 3.4818891966715455, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 52, train_loss = 3.4297038512304425, train_acc = 0.9953423381462506\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 53, train_loss = 3.378996138460934, train_acc = 0.9953423381462506\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 54, train_loss = 3.3290299139916897, train_acc = 0.9953423381462506\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 55, train_loss = 3.282422230578959, train_acc = 0.9953423381462506\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 56, train_loss = 3.2378120301291347, train_acc = 0.9954587796925943\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 57, train_loss = 3.1928197080269456, train_acc = 0.9956916627852818\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 58, train_loss = 3.1503910860046744, train_acc = 0.9956916627852818\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 59, train_loss = 3.1080373348668218, train_acc = 0.9959245458779693\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 60, train_loss = 3.067875831387937, train_acc = 0.9959245458779693\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 61, train_loss = 3.029410476796329, train_acc = 0.996040987424313\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 62, train_loss = 2.9904986559413373, train_acc = 0.996040987424313\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 63, train_loss = 2.953908591065556, train_acc = 0.996040987424313\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 64, train_loss = 2.917994609568268, train_acc = 0.9962738705170004\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 65, train_loss = 2.883079739753157, train_acc = 0.9962738705170004\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 66, train_loss = 2.849025697913021, train_acc = 0.9962738705170004\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 67, train_loss = 2.815750523004681, train_acc = 0.9962738705170004\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 68, train_loss = 2.7846438945271075, train_acc = 0.9962738705170004\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 69, train_loss = 2.7531203129328787, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 70, train_loss = 2.7238572076894343, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 71, train_loss = 2.6938020125962794, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 72, train_loss = 2.665089637041092, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 73, train_loss = 2.636878080666065, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 74, train_loss = 2.6107562580145895, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 75, train_loss = 2.5834721885621548, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 76, train_loss = 2.5579831660725176, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 77, train_loss = 2.532853092998266, train_acc = 0.9963903120633442\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 78, train_loss = 2.5075049228034914, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 79, train_loss = 2.4839041768573225, train_acc = 0.9963903120633442\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 80, train_loss = 2.460647214204073, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 81, train_loss = 2.4380587288178504, train_acc = 0.9963903120633442\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 82, train_loss = 2.4149694428779185, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 83, train_loss = 2.393817786127329, train_acc = 0.996506753609688\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 84, train_loss = 2.3722093463875353, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 85, train_loss = 2.352114195469767, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 86, train_loss = 2.3313025175593793, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 87, train_loss = 2.3111972487531602, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 88, train_loss = 2.292363448534161, train_acc = 0.9966231951560317\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 89, train_loss = 2.2728172675706446, train_acc = 0.9967396367023754\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 90, train_loss = 2.254932983312756, train_acc = 0.9967396367023754\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 91, train_loss = 2.236562298145145, train_acc = 0.9967396367023754\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 92, train_loss = 2.219126120209694, train_acc = 0.9967396367023754\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 93, train_loss = 2.202496482525021, train_acc = 0.9967396367023754\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 94, train_loss = 2.1847188412211835, train_acc = 0.9967396367023754\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 95, train_loss = 2.1685409755446017, train_acc = 0.9968560782487191\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 96, train_loss = 2.1531879738904536, train_acc = 0.9968560782487191\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 97, train_loss = 2.1368495910428464, train_acc = 0.9968560782487191\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 98, train_loss = 2.1212908402085304, train_acc = 0.9968560782487191\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 99, train_loss = 2.1062456369400024, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 100, train_loss = 2.091544805560261, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 101, train_loss = 2.0763419694267213, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 102, train_loss = 2.0633763656951487, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 103, train_loss = 2.0489202230237424, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 104, train_loss = 2.0360263264738023, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 105, train_loss = 2.0233044722117484, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 106, train_loss = 2.0095559605397284, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 107, train_loss = 1.9981134035624564, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 108, train_loss = 1.9853390529751778, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 109, train_loss = 1.973650378640741, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 110, train_loss = 1.9614848918281496, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 111, train_loss = 1.9502717703580856, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 112, train_loss = 1.9394374401308596, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 113, train_loss = 1.9271289012394845, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 114, train_loss = 1.9170302017591894, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 115, train_loss = 1.9058509357273579, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 116, train_loss = 1.8957416724879295, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 117, train_loss = 1.885682389140129, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 118, train_loss = 1.8751523196697235, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 119, train_loss = 1.8652725655119866, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 120, train_loss = 1.8557800638955086, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 121, train_loss = 1.8458979378920048, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 122, train_loss = 1.836692550452426, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 123, train_loss = 1.8272461269516498, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 124, train_loss = 1.817774098366499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 125, train_loss = 1.808892694534734, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 126, train_loss = 1.800654924241826, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 127, train_loss = 1.791654471307993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 128, train_loss = 1.7821210350375623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 129, train_loss = 1.7752178125083447, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 130, train_loss = 1.7669655941426754, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 131, train_loss = 1.7580339286942035, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 132, train_loss = 1.7503056016284972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 133, train_loss = 1.7424108360428363, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 134, train_loss = 1.7344006274361163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 135, train_loss = 1.7271991421002895, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 136, train_loss = 1.7193677711766213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 137, train_loss = 1.7119238923769444, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 138, train_loss = 1.7044720973353833, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 139, train_loss = 1.697274224134162, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 140, train_loss = 1.689834526507184, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 141, train_loss = 1.6835041244048625, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 142, train_loss = 1.6759656083304435, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 143, train_loss = 1.6693322334904224, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 144, train_loss = 1.6627883587498218, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 145, train_loss = 1.6560669653117657, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 146, train_loss = 1.6489787374157459, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 147, train_loss = 1.6425629269797355, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 148, train_loss = 1.6362687747459859, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 149, train_loss = 1.6300528210122138, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 150, train_loss = 1.6241581018548459, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 151, train_loss = 1.6180002067703754, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 152, train_loss = 1.611750055104494, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 153, train_loss = 1.6059732895810157, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 154, train_loss = 1.600037505151704, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 155, train_loss = 1.5939322251360863, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 156, train_loss = 1.5885670769494027, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 157, train_loss = 1.5826836999040097, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 158, train_loss = 1.5778894636314362, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 159, train_loss = 1.5721688196063042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 160, train_loss = 1.566666227998212, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 161, train_loss = 1.5613934956490993, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 162, train_loss = 1.5561420943122357, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 163, train_loss = 1.55131575348787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 164, train_loss = 1.5458967462182045, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 165, train_loss = 1.5410499286372215, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 166, train_loss = 1.5352286361157894, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 167, train_loss = 1.5310892041306943, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 168, train_loss = 1.5255282868165523, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 169, train_loss = 1.5213507425505668, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 170, train_loss = 1.516263445140794, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 171, train_loss = 1.5115902237594128, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 172, train_loss = 1.5073376011569053, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 173, train_loss = 1.502071313560009, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 174, train_loss = 1.4980626192409545, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 175, train_loss = 1.4937457938212901, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 176, train_loss = 1.4891290068626404, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 177, train_loss = 1.4849447943270206, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 178, train_loss = 1.4800805274862796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 179, train_loss = 1.4763039276003838, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 180, train_loss = 1.4717366124968976, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 181, train_loss = 1.467847841558978, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 182, train_loss = 1.4634208392817527, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 183, train_loss = 1.459776220144704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 184, train_loss = 1.4551100197713822, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 185, train_loss = 1.451271116733551, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 186, train_loss = 1.447405816288665, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 187, train_loss = 1.443313955096528, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 188, train_loss = 1.4392898220103234, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 189, train_loss = 1.435429894598201, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 190, train_loss = 1.431582611054182, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 191, train_loss = 1.4276014156639576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 192, train_loss = 1.4236739799380302, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 193, train_loss = 1.420428135781549, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 194, train_loss = 1.4164079738548025, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 195, train_loss = 1.4128645384917036, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 196, train_loss = 1.4087844988098368, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 197, train_loss = 1.4057402635226026, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 198, train_loss = 1.4021987915039062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 199, train_loss = 1.3990953551838174, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 200, train_loss = 1.3954891475150362, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 201, train_loss = 1.391968889744021, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 202, train_loss = 1.3883383745560423, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 203, train_loss = 1.3855862083146349, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 204, train_loss = 1.3817546367645264, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 205, train_loss = 1.378446776419878, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 206, train_loss = 1.3754292478552088, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 207, train_loss = 1.372217788011767, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 208, train_loss = 1.3691000317921862, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 209, train_loss = 1.3660367330303416, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 210, train_loss = 1.362782427459024, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 211, train_loss = 1.359611721127294, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 212, train_loss = 1.3569153249263763, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 213, train_loss = 1.3535297960042953, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 214, train_loss = 1.3507687064120546, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 215, train_loss = 1.3473764372756705, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 216, train_loss = 1.3451694088289514, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 217, train_loss = 1.3418346171965823, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 218, train_loss = 1.3382436769315973, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 219, train_loss = 1.3361226990818977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 220, train_loss = 1.3327526189386845, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 221, train_loss = 1.3303357226541266, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 222, train_loss = 1.327510250150226, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 223, train_loss = 1.324792013852857, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 224, train_loss = 1.3222315907478333, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 225, train_loss = 1.3191511208424345, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 226, train_loss = 1.3165598461637273, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 227, train_loss = 1.3141590630402789, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 228, train_loss = 1.3112996047129855, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 229, train_loss = 1.3089575916528702, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 230, train_loss = 1.30581885331776, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 231, train_loss = 1.3035316752502695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 232, train_loss = 1.301037379889749, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 233, train_loss = 1.2980329158017412, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 234, train_loss = 1.2963136434555054, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 235, train_loss = 1.2931723954388872, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 236, train_loss = 1.2911537798354402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 237, train_loss = 1.2886167293181643, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 238, train_loss = 1.285911982296966, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 239, train_loss = 1.2841000693151727, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 240, train_loss = 1.2802712073316798, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 241, train_loss = 1.277076330035925, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 242, train_loss = 1.2746958633651957, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 243, train_loss = 1.2713610790669918, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 244, train_loss = 1.270070381462574, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 245, train_loss = 1.266874031512998, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 246, train_loss = 1.2647801575949416, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 247, train_loss = 1.2624105475842953, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 248, train_loss = 1.2598955457797274, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 249, train_loss = 1.2572228288045153, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 250, train_loss = 1.2556660895934328, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 251, train_loss = 1.2528613408794627, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 252, train_loss = 1.2508924454450607, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 253, train_loss = 1.248235514969565, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 254, train_loss = 1.2470170358428732, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 255, train_loss = 1.2443816363811493, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 256, train_loss = 1.2427717708051205, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 257, train_loss = 1.2401229465613142, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 258, train_loss = 1.2382093941560015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 259, train_loss = 1.2352548415074125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 260, train_loss = 1.2333327854285017, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 261, train_loss = 1.2319147773087025, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 262, train_loss = 1.229685322730802, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 263, train_loss = 1.2277840772876516, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 264, train_loss = 1.2250615805387497, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 265, train_loss = 1.2234937734901905, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 266, train_loss = 1.222085545421578, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 267, train_loss = 1.2196687510004267, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 268, train_loss = 1.2182893404969946, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 269, train_loss = 1.2154761850833893, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 270, train_loss = 1.2135692313313484, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 271, train_loss = 1.2120585478842258, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 272, train_loss = 1.2102162191877142, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 273, train_loss = 1.2081040801713243, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 274, train_loss = 1.205974274664186, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 275, train_loss = 1.2041833760449663, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 276, train_loss = 1.202799410908483, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 277, train_loss = 1.2009705851087347, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 278, train_loss = 1.1984003545949236, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 279, train_loss = 1.1972086677560583, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 280, train_loss = 1.1954942606389523, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 281, train_loss = 1.1932707900414243, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 282, train_loss = 1.1910021615913138, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 283, train_loss = 1.1898767290404066, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 284, train_loss = 1.188345288275741, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 285, train_loss = 1.186335202306509, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 286, train_loss = 1.1844148201635107, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 287, train_loss = 1.183125497191213, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 288, train_loss = 1.1812797436723486, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 289, train_loss = 1.1789278822252527, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 290, train_loss = 1.1775077556958422, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 291, train_loss = 1.1758872556383722, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 292, train_loss = 1.174099872529041, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 293, train_loss = 1.1717419400811195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 294, train_loss = 1.1702666183118708, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 295, train_loss = 1.1689189647440799, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 296, train_loss = 1.1664185698027723, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 297, train_loss = 1.1653962594573386, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 298, train_loss = 1.1638178589637391, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 299, train_loss = 1.1619459477369674, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 300, train_loss = 1.160173210024368, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 301, train_loss = 1.158909862220753, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 302, train_loss = 1.1568304039537907, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 303, train_loss = 1.155631959438324, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 304, train_loss = 1.1538093946874142, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 305, train_loss = 1.152557437599171, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 306, train_loss = 1.150793083012104, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 307, train_loss = 1.1497614768450148, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 308, train_loss = 1.147800501435995, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 309, train_loss = 1.1468258301611058, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 310, train_loss = 1.144662330567371, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 311, train_loss = 1.143300851166714, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 312, train_loss = 1.1420876421034336, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 313, train_loss = 1.1403420865535736, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 314, train_loss = 1.1393659003078938, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 315, train_loss = 1.1377691340749152, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 316, train_loss = 1.135973206430208, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 317, train_loss = 1.1351111407275312, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 318, train_loss = 1.134002186357975, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 319, train_loss = 1.131925641268026, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 320, train_loss = 1.1301439975504763, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 321, train_loss = 1.1294863385264762, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 322, train_loss = 1.1281077290768735, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 323, train_loss = 1.1265766297583468, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 324, train_loss = 1.1250774475629441, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 325, train_loss = 1.1232797342236154, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 326, train_loss = 1.1222299535875209, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 327, train_loss = 1.1208605256979354, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 328, train_loss = 1.1195607967674732, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 329, train_loss = 1.1187096287612803, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 330, train_loss = 1.1167940187151544, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 331, train_loss = 1.11530553054763, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 332, train_loss = 1.1145846582949162, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 333, train_loss = 1.1128534798626788, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 334, train_loss = 1.1117584246094339, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 335, train_loss = 1.1099455555086024, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 336, train_loss = 1.1091229927842505, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 337, train_loss = 1.107517511874903, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 338, train_loss = 1.1068142354488373, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 339, train_loss = 1.105207022279501, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 340, train_loss = 1.1040866374969482, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 341, train_loss = 1.1024191193282604, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 342, train_loss = 1.1014003629679792, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 343, train_loss = 1.1002232320606709, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 344, train_loss = 1.0989926804904826, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 345, train_loss = 1.0978178692166694, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 346, train_loss = 1.0961778064374812, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 347, train_loss = 1.0955021021072753, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 348, train_loss = 1.0943629530374892, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 349, train_loss = 1.093013759702444, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 350, train_loss = 1.0916517401929013, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 351, train_loss = 1.0905784207279794, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 352, train_loss = 1.0894361734390259, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 353, train_loss = 1.0887472082977183, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 354, train_loss = 1.087120634794701, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 355, train_loss = 1.0864205558900721, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 356, train_loss = 1.0845662641222589, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 357, train_loss = 1.0837614499032497, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 358, train_loss = 1.0818984508514404, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 359, train_loss = 1.0814832125906833, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 360, train_loss = 1.0800076338346116, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 361, train_loss = 1.079117938876152, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 362, train_loss = 1.0780858757789247, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 363, train_loss = 1.0773647365276702, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 364, train_loss = 1.0749272418324836, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 365, train_loss = 1.074966698884964, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 366, train_loss = 1.0740359649062157, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 367, train_loss = 1.0725605276529677, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 368, train_loss = 1.071461835235823, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 369, train_loss = 1.0704243766958825, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 370, train_loss = 1.0691246750648133, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 371, train_loss = 1.067867239296902, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 372, train_loss = 1.067141193896532, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 373, train_loss = 1.0659392538364045, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 374, train_loss = 1.0647995956242085, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 375, train_loss = 1.064042876183521, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 376, train_loss = 1.063064083456993, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 377, train_loss = 1.0618408657610416, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 378, train_loss = 1.0605939229135402, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 379, train_loss = 1.0599351885612123, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 380, train_loss = 1.0584681530599482, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 381, train_loss = 1.0577862175996415, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 382, train_loss = 1.0562743159825914, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 383, train_loss = 1.0555538348853588, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 384, train_loss = 1.0545730504090898, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 385, train_loss = 1.0536920527811162, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 386, train_loss = 1.0522830188274384, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 387, train_loss = 1.0517135088448413, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 388, train_loss = 1.050993635028135, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 389, train_loss = 1.0493128920788877, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 390, train_loss = 1.0484026956255548, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 391, train_loss = 1.0475111876730807, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 392, train_loss = 1.0470163809950463, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 393, train_loss = 1.0455610404605977, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 394, train_loss = 1.0450137394363992, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 395, train_loss = 1.043780283362139, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 396, train_loss = 1.042669903486967, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 397, train_loss = 1.0417383636231534, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 398, train_loss = 1.0412148597533815, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 399, train_loss = 1.0393913934822194, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 400, train_loss = 1.039327334612608, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 401, train_loss = 1.0372365626390092, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 402, train_loss = 1.0377226993441582, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 403, train_loss = 1.0359089821577072, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 404, train_loss = 1.0354396266047843, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 405, train_loss = 1.0343097001314163, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 406, train_loss = 1.033765997737646, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 407, train_loss = 1.0322799061541446, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 408, train_loss = 1.0317579545080662, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 409, train_loss = 1.0304138325154781, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 410, train_loss = 1.0302191426162608, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 411, train_loss = 1.0284325554966927, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 412, train_loss = 1.0278762504458427, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 413, train_loss = 1.0271599814295769, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 414, train_loss = 1.0260565641219728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 415, train_loss = 1.0255035807495005, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 416, train_loss = 1.0241457397933118, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 417, train_loss = 1.024158048152458, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 418, train_loss = 1.0225557424128056, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 419, train_loss = 1.0219569119508378, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 420, train_loss = 1.0206043633515947, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 421, train_loss = 1.0202052506501786, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 422, train_loss = 1.0191158701782115, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 423, train_loss = 1.0187427115743048, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 424, train_loss = 1.0170258941943757, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 425, train_loss = 1.0171662109787576, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 426, train_loss = 1.0155339688062668, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 427, train_loss = 1.0146800155634992, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 428, train_loss = 1.0137516905670054, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 429, train_loss = 1.013269857794512, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 430, train_loss = 1.0126098816399463, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 431, train_loss = 1.0114890784025192, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 432, train_loss = 1.0109725805814378, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 433, train_loss = 1.0101789732580073, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 434, train_loss = 1.009192667901516, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 435, train_loss = 1.007956734567415, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 436, train_loss = 1.007897175848484, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 437, train_loss = 1.0066355876624584, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 438, train_loss = 1.0060681464965455, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 439, train_loss = 1.005238237499725, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 440, train_loss = 1.0046376660466194, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 441, train_loss = 1.0037906442885287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 442, train_loss = 1.0031177451019175, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 443, train_loss = 1.002180077135563, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 444, train_loss = 1.0015684142708778, train_acc = 0.9979040521658128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 445, train_loss = 1.0005488879978657, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 446, train_loss = 0.9996634560229722, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 447, train_loss = 0.9989920891821384, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 448, train_loss = 0.9987231107952539, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 449, train_loss = 0.9972934847173747, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 450, train_loss = 0.9970836937427521, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 451, train_loss = 0.995519890129799, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 452, train_loss = 0.9954028291103896, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 453, train_loss = 0.9947239682078362, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 454, train_loss = 0.9935010944900569, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 455, train_loss = 0.9932118691504002, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 456, train_loss = 0.9922260778548662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 457, train_loss = 0.9913176062109414, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 458, train_loss = 0.9906587488949299, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 459, train_loss = 0.9907500073313713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 460, train_loss = 0.9893511893751565, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 461, train_loss = 0.9881781203148421, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 462, train_loss = 0.9879765212535858, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 463, train_loss = 0.9869253995420877, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 464, train_loss = 0.9869415486755315, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 465, train_loss = 0.9856986714003142, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 466, train_loss = 0.9851615490915719, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 467, train_loss = 0.983703793346649, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 468, train_loss = 0.983714334666729, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 469, train_loss = 0.9827207388880197, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 470, train_loss = 0.982484190404648, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 471, train_loss = 0.9807657686469611, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 472, train_loss = 0.9809581389126834, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 473, train_loss = 0.9802347955701407, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 474, train_loss = 0.9790280374290887, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 475, train_loss = 0.978784399718279, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 476, train_loss = 0.9778471775352955, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 477, train_loss = 0.9771024385991041, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 478, train_loss = 0.9769188749196474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 479, train_loss = 0.9755056997237261, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 480, train_loss = 0.9755742934939917, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 481, train_loss = 0.9746077433228493, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 482, train_loss = 0.9737456800939981, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 483, train_loss = 0.9729907078144606, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 484, train_loss = 0.9724274886248168, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 485, train_loss = 0.9723126006720122, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 486, train_loss = 0.9708008728921413, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 487, train_loss = 0.9705121157167014, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 488, train_loss = 0.9699540672299918, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 489, train_loss = 0.9692215410468634, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 490, train_loss = 0.9688264317810535, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 491, train_loss = 0.9677571381034795, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 492, train_loss = 0.9674392864108086, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 493, train_loss = 0.9666299136879388, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 494, train_loss = 0.9663217341003474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 495, train_loss = 0.9655527559516486, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 496, train_loss = 0.9648302979767323, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 497, train_loss = 0.9639611033198889, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 498, train_loss = 0.9632688226702157, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 499, train_loss = 0.9626721652748529, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████▋                                                               | 4/30 [39:25<4:14:57, 588.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "5th- epoch: 0, train_loss = 120.55677610635757, train_acc = 0.7828365160689333\n",
      "test Acc 0.8901303538175046:\n",
      "5th- epoch: 1, train_loss = 45.66316147148609, train_acc = 0.9098742431299488\n",
      "test Acc 0.930633147113594:\n",
      "5th- epoch: 2, train_loss = 33.25825983658433, train_acc = 0.9364229156963204\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 3, train_loss = 26.978147331625223, train_acc = 0.946786213320913\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 4, train_loss = 22.876254690811038, train_acc = 0.9540055891942245\n",
      "test Acc 0.9548417132216015:\n",
      "5th- epoch: 5, train_loss = 19.890782237052917, train_acc = 0.9597112249650676\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 6, train_loss = 17.58805935829878, train_acc = 0.9643688868188169\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 7, train_loss = 15.766941495239735, train_acc = 0.9686772240335352\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 8, train_loss = 14.30711404234171, train_acc = 0.9727526781555659\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 9, train_loss = 13.092780763283372, train_acc = 0.9749650675360969\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 10, train_loss = 12.075532376766205, train_acc = 0.9770610153702841\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 11, train_loss = 11.207222201861441, train_acc = 0.9782254308337215\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 12, train_loss = 10.440081452950835, train_acc = 0.9793898462971589\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 13, train_loss = 9.764676630496979, train_acc = 0.9811364694923148\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 14, train_loss = 9.163297130726278, train_acc = 0.9825337680484397\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 15, train_loss = 8.628464591689408, train_acc = 0.9832324173265021\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 16, train_loss = 8.150092068128288, train_acc = 0.9849790405216581\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 17, train_loss = 7.717003186233342, train_acc = 0.9856776897997206\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 18, train_loss = 7.326333596371114, train_acc = 0.9862598975314392\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 19, train_loss = 6.97519938275218, train_acc = 0.9873078714485328\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 20, train_loss = 6.657370827160776, train_acc = 0.9878900791802515\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 21, train_loss = 6.368571010418236, train_acc = 0.9884722869119702\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 22, train_loss = 6.105454138480127, train_acc = 0.9891709361900326\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 23, train_loss = 5.863650499843061, train_acc = 0.9901024685607824\n",
      "test Acc 0.972998137802607:\n",
      "5th- epoch: 24, train_loss = 5.642379589378834, train_acc = 0.9909175593851887\n",
      "test Acc 0.972998137802607:\n",
      "5th- epoch: 25, train_loss = 5.4398878971114755, train_acc = 0.9912668840242198\n",
      "test Acc 0.972998137802607:\n",
      "5th- epoch: 26, train_loss = 5.251166488043964, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "5th- epoch: 27, train_loss = 5.079829161521047, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "5th- epoch: 28, train_loss = 4.921440048608929, train_acc = 0.9926641825803446\n",
      "test Acc 0.973463687150838:\n",
      "5th- epoch: 29, train_loss = 4.774234296288341, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "5th- epoch: 30, train_loss = 4.638485376257449, train_acc = 0.9934792734047508\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 31, train_loss = 4.5116584757342935, train_acc = 0.9934792734047508\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 32, train_loss = 4.393148021772504, train_acc = 0.9935957149510946\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 33, train_loss = 4.280854053329676, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 34, train_loss = 4.1775744506157935, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 35, train_loss = 4.079184429720044, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 36, train_loss = 3.9875027360394597, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 37, train_loss = 3.8999791792593896, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 38, train_loss = 3.8183486559428275, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 39, train_loss = 3.7395218103192747, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 40, train_loss = 3.6661716792732477, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 41, train_loss = 3.594281711615622, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 42, train_loss = 3.526266790460795, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 43, train_loss = 3.462380120996386, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 44, train_loss = 3.400724598672241, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 45, train_loss = 3.3423971817828715, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 46, train_loss = 3.284638159442693, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 47, train_loss = 3.2320895534940064, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 48, train_loss = 3.1787138897925615, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 49, train_loss = 3.1284901117905974, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 50, train_loss = 3.081120627466589, train_acc = 0.9958081043316255\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 51, train_loss = 3.035230358596891, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 52, train_loss = 2.989818172995001, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 53, train_loss = 2.9477763713803142, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 54, train_loss = 2.9062405682634562, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 55, train_loss = 2.866986237699166, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 56, train_loss = 2.8284912810195237, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 57, train_loss = 2.7910339143127203, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 58, train_loss = 2.7553987067658454, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 59, train_loss = 2.719745255773887, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 60, train_loss = 2.687392085790634, train_acc = 0.9958081043316255\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 61, train_loss = 2.6532341002020985, train_acc = 0.9958081043316255\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 62, train_loss = 2.6219139576423913, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 63, train_loss = 2.590665034716949, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 64, train_loss = 2.5611980070825666, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 65, train_loss = 2.531271544052288, train_acc = 0.9961574289706567\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 66, train_loss = 2.5039430742617697, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 67, train_loss = 2.4763145726174116, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 68, train_loss = 2.448823118582368, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 69, train_loss = 2.424188582925126, train_acc = 0.9961574289706567\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 70, train_loss = 2.398045503301546, train_acc = 0.9962738705170004\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 71, train_loss = 2.373839913867414, train_acc = 0.9962738705170004\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 72, train_loss = 2.3498802471440285, train_acc = 0.9962738705170004\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 73, train_loss = 2.326875339495018, train_acc = 0.9963903120633442\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 74, train_loss = 2.3050003533717245, train_acc = 0.9962738705170004\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 75, train_loss = 2.280857792356983, train_acc = 0.9962738705170004\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 76, train_loss = 2.2594158686697483, train_acc = 0.9962738705170004\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 77, train_loss = 2.2393628084100783, train_acc = 0.9962738705170004\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 78, train_loss = 2.218533559469506, train_acc = 0.9963903120633442\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 79, train_loss = 2.1988392868079245, train_acc = 0.996506753609688\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 80, train_loss = 2.1781634024810046, train_acc = 0.996506753609688\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 81, train_loss = 2.1599383607972413, train_acc = 0.996506753609688\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 82, train_loss = 2.141268448671326, train_acc = 0.996506753609688\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 83, train_loss = 2.123319354839623, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 84, train_loss = 2.105482682120055, train_acc = 0.996506753609688\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 85, train_loss = 2.088770916685462, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 86, train_loss = 2.071530145825818, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 87, train_loss = 2.055515939835459, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 88, train_loss = 2.0393617937806994, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 89, train_loss = 2.0237294391263276, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 90, train_loss = 2.0088436328805983, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 91, train_loss = 1.9940031205769628, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 92, train_loss = 1.979714517481625, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 93, train_loss = 1.96629432705231, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 94, train_loss = 1.9524141633883119, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 95, train_loss = 1.9384162913775072, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 96, train_loss = 1.925732466042973, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 97, train_loss = 1.9132534140953794, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 98, train_loss = 1.9010568348458037, train_acc = 0.9967396367023754\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 99, train_loss = 1.8878481648862362, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 100, train_loss = 1.8771755443885922, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 101, train_loss = 1.864488197141327, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 102, train_loss = 1.8537746733054519, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 103, train_loss = 1.8414268518099561, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 104, train_loss = 1.83075670117978, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 105, train_loss = 1.8196774553507566, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 106, train_loss = 1.8095208943122998, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 107, train_loss = 1.7993176560848951, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 108, train_loss = 1.7895568773383275, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 109, train_loss = 1.7799741234630346, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 110, train_loss = 1.7706659454852343, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 111, train_loss = 1.7605382967740297, train_acc = 0.9969725197950629\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 112, train_loss = 1.751938253059052, train_acc = 0.9969725197950629\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 113, train_loss = 1.7431698717409745, train_acc = 0.9969725197950629\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 114, train_loss = 1.7336984887951985, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 115, train_loss = 1.7251790059963241, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 116, train_loss = 1.7163230212172493, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 117, train_loss = 1.7082160012796521, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 118, train_loss = 1.70053986646235, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 119, train_loss = 1.692013967433013, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 120, train_loss = 1.6838483415776864, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 121, train_loss = 1.676884670741856, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 122, train_loss = 1.668644777033478, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 123, train_loss = 1.661648502922617, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 124, train_loss = 1.6538360718404874, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 125, train_loss = 1.6468612680910155, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 126, train_loss = 1.6396358021302149, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 127, train_loss = 1.6324720316333696, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 128, train_loss = 1.6258861968526617, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 129, train_loss = 1.6190821930067614, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 130, train_loss = 1.6119707549223676, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 131, train_loss = 1.6063759312964976, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 132, train_loss = 1.5990795966936275, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 133, train_loss = 1.5924403318203986, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 134, train_loss = 1.5857323189266026, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 135, train_loss = 1.5798597465036437, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 136, train_loss = 1.5732663992093876, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 137, train_loss = 1.5673606214113533, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 138, train_loss = 1.5613088394748047, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 139, train_loss = 1.55505462072324, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 140, train_loss = 1.5496810540789738, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 141, train_loss = 1.5439970195293427, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 142, train_loss = 1.5385836631758139, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 143, train_loss = 1.5326178093673661, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 144, train_loss = 1.5274370205588639, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 145, train_loss = 1.5223089834908023, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 146, train_loss = 1.5172885538777336, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 147, train_loss = 1.5116535763954744, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 148, train_loss = 1.5071857917355374, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 149, train_loss = 1.502219513640739, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 150, train_loss = 1.496840976178646, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 151, train_loss = 1.4922748301178217, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 152, train_loss = 1.4876926908036694, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 153, train_loss = 1.4832032913109288, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 154, train_loss = 1.478418285609223, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 155, train_loss = 1.4737028687959537, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 156, train_loss = 1.468877122097183, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 157, train_loss = 1.4646448551793583, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 158, train_loss = 1.4601973363314755, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 159, train_loss = 1.4554523170809262, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 160, train_loss = 1.4520682611619122, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 161, train_loss = 1.447711409709882, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 162, train_loss = 1.4431216508965008, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 163, train_loss = 1.4394523671944626, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 164, train_loss = 1.4346646151388995, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 165, train_loss = 1.4314294839277864, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 166, train_loss = 1.42738577228738, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 167, train_loss = 1.423299951478839, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 168, train_loss = 1.4194957303698175, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 169, train_loss = 1.4151633009314537, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 170, train_loss = 1.4116950767929666, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 171, train_loss = 1.407783713832032, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 172, train_loss = 1.4042060968349688, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 173, train_loss = 1.400229453749489, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 174, train_loss = 1.397154641977977, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 175, train_loss = 1.392694127454888, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 176, train_loss = 1.3889435632154346, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 177, train_loss = 1.3852690933272243, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 178, train_loss = 1.382100590504706, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 179, train_loss = 1.3787472965195775, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 180, train_loss = 1.3747629346325994, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 181, train_loss = 1.370862115174532, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 182, train_loss = 1.3682402046397328, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 183, train_loss = 1.36477223347174, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 184, train_loss = 1.3618527275393717, train_acc = 0.9970889613414066\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 185, train_loss = 1.3579652765765786, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 186, train_loss = 1.3546903195674531, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 187, train_loss = 1.3517978588934056, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 188, train_loss = 1.3490403098985553, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 189, train_loss = 1.3456322206184268, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 190, train_loss = 1.3425405003945343, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 191, train_loss = 1.3397829411551356, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 192, train_loss = 1.3369278752361424, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 193, train_loss = 1.3336237566545606, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 194, train_loss = 1.330908466130495, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 195, train_loss = 1.3270337118883617, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 196, train_loss = 1.324846236675512, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 197, train_loss = 1.3223849681089632, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 198, train_loss = 1.319738902442623, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 199, train_loss = 1.316106944985222, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 200, train_loss = 1.3139324790681712, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 201, train_loss = 1.3108123457059264, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 202, train_loss = 1.308705580420792, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 203, train_loss = 1.3051577263395302, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 204, train_loss = 1.3023511478677392, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 205, train_loss = 1.300152807496488, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 206, train_loss = 1.2981130694970489, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 207, train_loss = 1.2947034149547108, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 208, train_loss = 1.292129332490731, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 209, train_loss = 1.2889984876965173, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 210, train_loss = 1.2870402336120605, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 211, train_loss = 1.284363241866231, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 212, train_loss = 1.2818677580798976, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 213, train_loss = 1.2797492137178779, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 214, train_loss = 1.276634634763468, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 215, train_loss = 1.2743457074393518, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 216, train_loss = 1.2722474529291503, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 217, train_loss = 1.2696495211566798, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 218, train_loss = 1.2669773831148632, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 219, train_loss = 1.264565505378414, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 220, train_loss = 1.262190194800496, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 221, train_loss = 1.260104136832524, train_acc = 0.9970889613414066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 222, train_loss = 1.2572603880544193, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 223, train_loss = 1.2551434173365124, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 224, train_loss = 1.2539149979129434, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 225, train_loss = 1.2507347312639467, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 226, train_loss = 1.2484599354793318, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 227, train_loss = 1.2460043877363205, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 228, train_loss = 1.24354271433549, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 229, train_loss = 1.2416538776014931, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 230, train_loss = 1.239103616506327, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 231, train_loss = 1.2377483304589987, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 232, train_loss = 1.2351584201678634, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 233, train_loss = 1.2329277973622084, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 234, train_loss = 1.2303583768079989, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 235, train_loss = 1.2286928445100784, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 236, train_loss = 1.2266115645761602, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 237, train_loss = 1.2238262997125275, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 238, train_loss = 1.2226615734398365, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 239, train_loss = 1.2204084523837082, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 240, train_loss = 1.2190513592213392, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 241, train_loss = 1.2161686662584543, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 242, train_loss = 1.214070372923743, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 243, train_loss = 1.2125791522557847, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 244, train_loss = 1.210650543391239, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 245, train_loss = 1.2089610963012092, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 246, train_loss = 1.2065465860068798, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 247, train_loss = 1.204744643822778, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 248, train_loss = 1.2032003669883125, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 249, train_loss = 1.201301593973767, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 250, train_loss = 1.1990142476861365, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 251, train_loss = 1.1974956716003362, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 252, train_loss = 1.196187516063219, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 253, train_loss = 1.1935659516602755, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 254, train_loss = 1.1917587562056724, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 255, train_loss = 1.1897600808588322, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 256, train_loss = 1.1879464508965611, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 257, train_loss = 1.186935480684042, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 258, train_loss = 1.1847482211887836, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 259, train_loss = 1.182729764841497, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 260, train_loss = 1.1818795166909695, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 261, train_loss = 1.1792990490794182, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 262, train_loss = 1.17753897109651, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 263, train_loss = 1.1760229300707579, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 264, train_loss = 1.1746748195437249, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 265, train_loss = 1.1730524490994867, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 266, train_loss = 1.170817662961781, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 267, train_loss = 1.1691569853574038, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 268, train_loss = 1.1681126529874746, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 269, train_loss = 1.1656701186147984, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 270, train_loss = 1.1641693183628377, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 271, train_loss = 1.1630934033019003, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 272, train_loss = 1.16075040679425, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 273, train_loss = 1.1598174814134836, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 274, train_loss = 1.1578716548683587, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 275, train_loss = 1.1566751288773958, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 276, train_loss = 1.1547469850629568, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 277, train_loss = 1.1530375514703337, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 278, train_loss = 1.1520362570881844, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 279, train_loss = 1.150227403268218, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 280, train_loss = 1.1489050602540374, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 281, train_loss = 1.1472985182481352, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 282, train_loss = 1.1456475291925017, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 283, train_loss = 1.1445405762642622, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 284, train_loss = 1.1422646132705268, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 285, train_loss = 1.1414161622524261, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 286, train_loss = 1.1404367601498961, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 287, train_loss = 1.1379802475275937, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 288, train_loss = 1.136813489109045, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 289, train_loss = 1.135433598101372, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 290, train_loss = 1.1339453989639878, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 291, train_loss = 1.1323552181420382, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 292, train_loss = 1.1313819866627455, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 293, train_loss = 1.1297690191713627, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 294, train_loss = 1.1289159770531114, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 295, train_loss = 1.1271669367852155, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 296, train_loss = 1.1254712051304523, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 297, train_loss = 1.1241895593702793, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 298, train_loss = 1.1233520694077015, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 299, train_loss = 1.1216885074973106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 300, train_loss = 1.1202164596470539, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 301, train_loss = 1.1192198442295194, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 302, train_loss = 1.1175489822926465, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 303, train_loss = 1.1161350086331367, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 304, train_loss = 1.1149525766668376, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 305, train_loss = 1.113872455433011, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 306, train_loss = 1.112489144637948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 307, train_loss = 1.1111783720552921, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 308, train_loss = 1.10966738811112, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 309, train_loss = 1.109010761603713, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 310, train_loss = 1.1072463268938009, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 311, train_loss = 1.1056737356411759, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 312, train_loss = 1.1048312947677914, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 313, train_loss = 1.1035363739356399, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 314, train_loss = 1.102209061384201, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 315, train_loss = 1.1009953481552657, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 316, train_loss = 1.0999937498418149, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 317, train_loss = 1.0983266016992275, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 318, train_loss = 1.09722019979381, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 319, train_loss = 1.096446326613659, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 320, train_loss = 1.0944115109741688, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 321, train_loss = 1.0939598524419125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 322, train_loss = 1.092886165395612, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 323, train_loss = 1.0915145687758923, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 324, train_loss = 1.0898348881455604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 325, train_loss = 1.0891469909402076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 326, train_loss = 1.087330967799062, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 327, train_loss = 1.087265940994257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 328, train_loss = 1.0856432119908277, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 329, train_loss = 1.0842200797051191, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 330, train_loss = 1.083101412281394, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 331, train_loss = 1.0818905097839888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 332, train_loss = 1.0804426403192338, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 333, train_loss = 1.0800051645783242, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 334, train_loss = 1.078715088457102, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 335, train_loss = 1.0777002827671822, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 336, train_loss = 1.0764696238038596, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 337, train_loss = 1.075119562447071, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 338, train_loss = 1.074514094128972, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 339, train_loss = 1.0727905308303889, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 340, train_loss = 1.0716720558702946, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 341, train_loss = 1.0712353748676833, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 342, train_loss = 1.0696021324547473, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 343, train_loss = 1.0683181087078992, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 344, train_loss = 1.0670803108660039, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 345, train_loss = 1.066471385449404, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 346, train_loss = 1.0653081623313483, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 347, train_loss = 1.0640853804943617, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 348, train_loss = 1.0626228737237398, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 349, train_loss = 1.0620482619851828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 350, train_loss = 1.0605036808701698, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 351, train_loss = 1.060170757904416, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 352, train_loss = 1.0585989877581596, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 353, train_loss = 1.057579296961194, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 354, train_loss = 1.0569619486632291, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 355, train_loss = 1.0552106325922068, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 356, train_loss = 1.055083150655264, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 357, train_loss = 1.0538007101567928, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 358, train_loss = 1.0524217107740697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 359, train_loss = 1.0520886747690383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 360, train_loss = 1.0510578832181636, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 361, train_loss = 1.0494864502397832, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 362, train_loss = 1.0484018356946763, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 363, train_loss = 1.0480862738040742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 364, train_loss = 1.0465516801923513, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 365, train_loss = 1.0455062451364938, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 366, train_loss = 1.0450139412132557, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 367, train_loss = 1.044581309572095, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 368, train_loss = 1.0430779947491828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 369, train_loss = 1.0416167564690113, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 370, train_loss = 1.0412256438285112, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 371, train_loss = 1.039876138791442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 372, train_loss = 1.039012599736452, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 373, train_loss = 1.0381059050559998, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 374, train_loss = 1.0375091824680567, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 375, train_loss = 1.036661963298684, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 376, train_loss = 1.0355917209235486, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 377, train_loss = 1.0343724756094161, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 378, train_loss = 1.0337021270242985, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 379, train_loss = 1.0326644070446491, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 380, train_loss = 1.0318920016288757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 381, train_loss = 1.0311376179161016, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 382, train_loss = 1.0301982586679514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 383, train_loss = 1.0290366150438786, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 384, train_loss = 1.028442815557355, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 385, train_loss = 1.027396878838772, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 386, train_loss = 1.026096365734702, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 387, train_loss = 1.0256880627421197, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 388, train_loss = 1.024960652604932, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 389, train_loss = 1.0239891471865121, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 390, train_loss = 1.0231942062673625, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 391, train_loss = 1.021770248800749, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 392, train_loss = 1.0217549744993448, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 393, train_loss = 1.0204149273631629, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 394, train_loss = 1.0194997253420297, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 395, train_loss = 1.0187459053995553, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 396, train_loss = 1.0185337203147355, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 397, train_loss = 1.0168466201575939, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 398, train_loss = 1.016033881023759, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 399, train_loss = 1.015961946293828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 400, train_loss = 1.0147424427123042, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 401, train_loss = 1.0142232794314623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 402, train_loss = 1.0129563268274069, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 403, train_loss = 1.0124141816049814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 404, train_loss = 1.0115785890520783, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 405, train_loss = 1.0106619372963905, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 406, train_loss = 1.0094764325767756, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 407, train_loss = 1.0092867432831554, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 408, train_loss = 1.0079741304070922, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 409, train_loss = 1.007483771070838, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 410, train_loss = 1.0069638664572267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 411, train_loss = 1.0060596230177907, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 412, train_loss = 1.005159520849702, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 413, train_loss = 1.004523731142399, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 414, train_loss = 1.0033122102468042, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 415, train_loss = 1.0025250681937905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 416, train_loss = 1.001879778385046, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 417, train_loss = 1.0014701802283525, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 418, train_loss = 1.0002443194389343, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 419, train_loss = 1.00002180908632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 420, train_loss = 0.998694397509098, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 421, train_loss = 0.9978372287005186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 422, train_loss = 0.9972286957054166, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 423, train_loss = 0.9963772166520357, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 424, train_loss = 0.9963492614479037, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 425, train_loss = 0.9950743553490611, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 426, train_loss = 0.9945393304078607, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 427, train_loss = 0.993546836078167, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 428, train_loss = 0.9929023968725232, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 429, train_loss = 0.9924004189670086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 430, train_loss = 0.9913825926632853, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 431, train_loss = 0.9906946153641911, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 432, train_loss = 0.9895565503538819, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 433, train_loss = 0.989168036103365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 434, train_loss = 0.9882412587030558, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 435, train_loss = 0.9877605885267258, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 436, train_loss = 0.987128044173005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 437, train_loss = 0.9860190482140752, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 438, train_loss = 0.9855933266953798, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 439, train_loss = 0.9849544571043225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 440, train_loss = 0.9840926000179024, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 441, train_loss = 0.9829932594002457, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 442, train_loss = 0.9828254130407004, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 443, train_loss = 0.9824524900614051, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 444, train_loss = 0.9817171633912949, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 445, train_loss = 0.9801804476155667, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 446, train_loss = 0.979659545540926, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 447, train_loss = 0.9795287838205695, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 448, train_loss = 0.9789769453927875, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 449, train_loss = 0.9777187568397494, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 450, train_loss = 0.9770246197731467, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 451, train_loss = 0.976478806391242, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 452, train_loss = 0.9759776138962479, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 453, train_loss = 0.9749321791605325, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 454, train_loss = 0.9743398372083902, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 455, train_loss = 0.9740675268694758, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 456, train_loss = 0.9727178728207946, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 457, train_loss = 0.9720207514910726, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 458, train_loss = 0.9721853161900071, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 459, train_loss = 0.9710779367014766, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 460, train_loss = 0.9703429688961478, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 461, train_loss = 0.9696562765166163, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 462, train_loss = 0.968948139809072, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 463, train_loss = 0.9685324535967084, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 464, train_loss = 0.967743522793171, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 465, train_loss = 0.9668567103071837, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 466, train_loss = 0.966364630497992, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 467, train_loss = 0.9662121894507436, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 468, train_loss = 0.9656813349574804, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 469, train_loss = 0.9643571085034637, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 470, train_loss = 0.9636829405353637, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 471, train_loss = 0.963726525194943, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 472, train_loss = 0.9626581308693858, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 473, train_loss = 0.9619181149901124, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 474, train_loss = 0.9611358198599191, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 475, train_loss = 0.9609864363446832, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 476, train_loss = 0.9600353731511859, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 477, train_loss = 0.9594971261249157, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 478, train_loss = 0.9591257150023011, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 479, train_loss = 0.9587106977851363, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 480, train_loss = 0.957502472519991, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 481, train_loss = 0.9570357960910769, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 482, train_loss = 0.9568555559962988, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 483, train_loss = 0.9559983511717292, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 484, train_loss = 0.955082078158739, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 485, train_loss = 0.9547002073377371, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 486, train_loss = 0.9541159880609484, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 487, train_loss = 0.9533640307636233, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 488, train_loss = 0.9532133682369022, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 489, train_loss = 0.9519848252384691, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 490, train_loss = 0.9519799097179202, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 491, train_loss = 0.9513281720428495, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 492, train_loss = 0.9511710343213053, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 493, train_loss = 0.9502276722341776, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 494, train_loss = 0.9494678514747648, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 495, train_loss = 0.9491325120179681, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 496, train_loss = 0.9482269461004762, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 497, train_loss = 0.9477313862444134, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 498, train_loss = 0.9471366982907057, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 499, train_loss = 0.9468121894897195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▏                                                            | 5/30 [49:26<4:06:44, 592.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "6th- epoch: 0, train_loss = 137.3917533159256, train_acc = 0.7617605961807172\n",
      "test Acc 0.8677839851024208:\n",
      "6th- epoch: 1, train_loss = 44.395061656832695, train_acc = 0.9110386585933862\n",
      "test Acc 0.9068901303538175:\n",
      "6th- epoch: 2, train_loss = 31.72097035497427, train_acc = 0.9381695388914765\n",
      "test Acc 0.9287709497206704:\n",
      "6th- epoch: 3, train_loss = 25.49173191189766, train_acc = 0.9486492780624126\n",
      "test Acc 0.9399441340782123:\n",
      "6th- epoch: 4, train_loss = 21.56215450912714, train_acc = 0.955519329296693\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 5, train_loss = 18.77768489345908, train_acc = 0.9613414066138798\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 6, train_loss = 16.6730733551085, train_acc = 0.965649743828598\n",
      "test Acc 0.9543761638733705:\n",
      "6th- epoch: 7, train_loss = 15.031607698649168, train_acc = 0.9692594317652539\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 8, train_loss = 13.70541276410222, train_acc = 0.9726362366092222\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 9, train_loss = 12.624756544828415, train_acc = 0.9750815090824406\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 10, train_loss = 11.708472788333893, train_acc = 0.9770610153702841\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 11, train_loss = 10.917395846918225, train_acc = 0.9788076385654402\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 12, train_loss = 10.229958010837436, train_acc = 0.9800884955752213\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 13, train_loss = 9.632456570863724, train_acc = 0.981951560316721\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 14, train_loss = 9.099347656592727, train_acc = 0.9828830926874709\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 15, train_loss = 8.626838903874159, train_acc = 0.983698183511877\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 16, train_loss = 8.192925525829196, train_acc = 0.9843968327899395\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 17, train_loss = 7.807210633531213, train_acc = 0.9847461574289706\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 18, train_loss = 7.4482437036931515, train_acc = 0.985910572892408\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 19, train_loss = 7.1279451623559, train_acc = 0.9866092221704704\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 20, train_loss = 6.833143716678023, train_acc = 0.9874243129948765\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 21, train_loss = 6.563281761482358, train_acc = 0.9883558453656265\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 22, train_loss = 6.313099013641477, train_acc = 0.9887051700046576\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 23, train_loss = 6.07923555187881, train_acc = 0.9892873777363763\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 24, train_loss = 5.864201497286558, train_acc = 0.9896367023754076\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 25, train_loss = 5.668294087983668, train_acc = 0.9902189101071263\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 26, train_loss = 5.481493935920298, train_acc = 0.990801117838845\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 27, train_loss = 5.3137280801311135, train_acc = 0.9911504424778761\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 28, train_loss = 5.153054713271558, train_acc = 0.9914997671169073\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 29, train_loss = 5.004584722220898, train_acc = 0.9914997671169073\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 30, train_loss = 4.8597034038975835, train_acc = 0.992081974848626\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 31, train_loss = 4.728885255753994, train_acc = 0.992081974848626\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 32, train_loss = 4.603223281912506, train_acc = 0.9921984163949698\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 33, train_loss = 4.48694219160825, train_acc = 0.9923148579413135\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 34, train_loss = 4.372995697893202, train_acc = 0.9925477410340009\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 35, train_loss = 4.26656150072813, train_acc = 0.9927806241266884\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 36, train_loss = 4.165694748051465, train_acc = 0.9928970656730322\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 37, train_loss = 4.0694080060347915, train_acc = 0.9928970656730322\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 38, train_loss = 3.9772697500884533, train_acc = 0.9930135072193759\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 39, train_loss = 3.892005108296871, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 40, train_loss = 3.8080978421494365, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 41, train_loss = 3.728924971073866, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 42, train_loss = 3.654176573269069, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 43, train_loss = 3.5826698802411556, train_acc = 0.9941779226828132\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 44, train_loss = 3.5146084474399686, train_acc = 0.9941779226828132\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 45, train_loss = 3.449815634638071, train_acc = 0.994294364229157\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 46, train_loss = 3.3867090730927885, train_acc = 0.9944108057755007\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 47, train_loss = 3.3267596983350813, train_acc = 0.9944108057755007\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 48, train_loss = 3.270237820688635, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 49, train_loss = 3.213729473296553, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 50, train_loss = 3.1596790202893317, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 51, train_loss = 3.1113132438622415, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 52, train_loss = 3.0627953014336526, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 53, train_loss = 3.0151078775525093, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 54, train_loss = 2.9691815064288676, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 55, train_loss = 2.9266836368478835, train_acc = 0.996040987424313\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 56, train_loss = 2.88538626069203, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 57, train_loss = 2.8440286084078252, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 58, train_loss = 2.805310983210802, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 59, train_loss = 2.7670357264578342, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 60, train_loss = 2.730709297116846, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 61, train_loss = 2.6959757008589804, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 62, train_loss = 2.6618797914125025, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 63, train_loss = 2.6284646815620363, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 64, train_loss = 2.5975181669928133, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 65, train_loss = 2.566712375730276, train_acc = 0.996506753609688\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 66, train_loss = 2.5369589552283287, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 67, train_loss = 2.507458206266165, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 68, train_loss = 2.4795691431500018, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 69, train_loss = 2.4531279080547392, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 70, train_loss = 2.4265368268825114, train_acc = 0.9966231951560317\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 71, train_loss = 2.4021517424844205, train_acc = 0.9966231951560317\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 72, train_loss = 2.3775628209114075, train_acc = 0.9966231951560317\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 73, train_loss = 2.3542441823519766, train_acc = 0.9968560782487191\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 74, train_loss = 2.330721451435238, train_acc = 0.9968560782487191\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 75, train_loss = 2.3085801475681365, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 76, train_loss = 2.287115427199751, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 77, train_loss = 2.2655105516314507, train_acc = 0.9968560782487191\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 78, train_loss = 2.244541183114052, train_acc = 0.9968560782487191\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 79, train_loss = 2.2236839211545885, train_acc = 0.9968560782487191\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 80, train_loss = 2.2039899367373437, train_acc = 0.9968560782487191\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 81, train_loss = 2.1864782150369138, train_acc = 0.9968560782487191\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 82, train_loss = 2.16713934764266, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 83, train_loss = 2.1496905486565083, train_acc = 0.9968560782487191\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 84, train_loss = 2.132267516106367, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 85, train_loss = 2.1151471089106053, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 86, train_loss = 2.0987911608535796, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 87, train_loss = 2.0833572559058666, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 88, train_loss = 2.0670601204037666, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 89, train_loss = 2.0514387029688805, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 90, train_loss = 2.036951294867322, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 91, train_loss = 2.0228267770726234, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 92, train_loss = 2.008894598810002, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 93, train_loss = 1.9950070369523019, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 94, train_loss = 1.9813710402231663, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 95, train_loss = 1.9679183315020055, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 96, train_loss = 1.955128100933507, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 97, train_loss = 1.943227796582505, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 98, train_loss = 1.9308962747454643, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 99, train_loss = 1.9189443390350789, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 100, train_loss = 1.906781944213435, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 101, train_loss = 1.895193489966914, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 102, train_loss = 1.884191072313115, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 103, train_loss = 1.8724845324177295, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 104, train_loss = 1.862319553969428, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 105, train_loss = 1.8522055123466998, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 106, train_loss = 1.841337489662692, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 107, train_loss = 1.8305763378739357, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 108, train_loss = 1.8206851992290467, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 109, train_loss = 1.810943853110075, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 110, train_loss = 1.8008999302983284, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 111, train_loss = 1.7917289163451642, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 112, train_loss = 1.782246722606942, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 113, train_loss = 1.7731019258499146, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 114, train_loss = 1.7647247090935707, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 115, train_loss = 1.755966155556962, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 116, train_loss = 1.7472358532249928, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 117, train_loss = 1.7389118175487965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 118, train_loss = 1.7303317089099437, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 119, train_loss = 1.7222610462922603, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 120, train_loss = 1.714206463424489, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 121, train_loss = 1.706821384606883, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 122, train_loss = 1.6986646577715874, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 123, train_loss = 1.6911671869456768, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 124, train_loss = 1.6837415769696236, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 125, train_loss = 1.6764391846954823, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 126, train_loss = 1.6690540921408683, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 127, train_loss = 1.6617085437756032, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 128, train_loss = 1.6552104093134403, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 129, train_loss = 1.6470789201557636, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 130, train_loss = 1.6411833849269897, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 131, train_loss = 1.6337951608002186, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 132, train_loss = 1.6276926088612527, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 133, train_loss = 1.6209962356369942, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 134, train_loss = 1.6152385349851102, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 135, train_loss = 1.6087142825126648, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 136, train_loss = 1.6017936307471246, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 137, train_loss = 1.5960163101553917, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 138, train_loss = 1.5904516268055886, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 139, train_loss = 1.5841365531086922, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 140, train_loss = 1.5783386379480362, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 141, train_loss = 1.5728425856214017, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 142, train_loss = 1.5668346993625164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 143, train_loss = 1.5616304638097063, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 144, train_loss = 1.5558945139637217, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 145, train_loss = 1.550924530834891, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 146, train_loss = 1.5460765585303307, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 147, train_loss = 1.540387307642959, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 148, train_loss = 1.535784162580967, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 149, train_loss = 1.530431634397246, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 150, train_loss = 1.5259656546404585, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 151, train_loss = 1.520800276310183, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 152, train_loss = 1.51568803191185, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 153, train_loss = 1.511133585125208, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 154, train_loss = 1.5063350523123518, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 155, train_loss = 1.5018850540509447, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 156, train_loss = 1.496923861443065, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 157, train_loss = 1.492634283960797, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 158, train_loss = 1.4878858687588945, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 159, train_loss = 1.4830796519527212, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 160, train_loss = 1.478777146548964, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 161, train_loss = 1.4741641990840435, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 162, train_loss = 1.46961587050464, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 163, train_loss = 1.4649443799862638, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 164, train_loss = 1.4612041587242857, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 165, train_loss = 1.4563404495129362, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 166, train_loss = 1.4521031255135313, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 167, train_loss = 1.4480510018765926, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 168, train_loss = 1.444122756482102, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 169, train_loss = 1.4402373569319025, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 170, train_loss = 1.4364607060560957, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 171, train_loss = 1.4319760762155056, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 172, train_loss = 1.4285094240913168, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 173, train_loss = 1.4245488805463538, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 174, train_loss = 1.4207967408001423, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 175, train_loss = 1.4177476527402177, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 176, train_loss = 1.4138066470623016, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 177, train_loss = 1.410064708441496, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 178, train_loss = 1.406397214741446, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 179, train_loss = 1.4025963358581066, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 180, train_loss = 1.3996835140278563, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 181, train_loss = 1.3963239217409864, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 182, train_loss = 1.392750540166162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 183, train_loss = 1.3894749408354983, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 184, train_loss = 1.3865354843437672, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 185, train_loss = 1.3828083537518978, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 186, train_loss = 1.3797597313532606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 187, train_loss = 1.3762273961910978, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 188, train_loss = 1.3729609474539757, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 189, train_loss = 1.3698480129241943, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 190, train_loss = 1.3668304992606863, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 191, train_loss = 1.3635786151280627, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 192, train_loss = 1.3605427047004923, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 193, train_loss = 1.3573521660873666, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 194, train_loss = 1.3543547404697165, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 195, train_loss = 1.3515330230584368, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 196, train_loss = 1.3489406431326643, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 197, train_loss = 1.3452103721210733, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 198, train_loss = 1.3426329778740183, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 199, train_loss = 1.34026413038373, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 200, train_loss = 1.3364355005323887, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 201, train_loss = 1.3342323960969225, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 202, train_loss = 1.3312209881842136, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 203, train_loss = 1.3292364986846223, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 204, train_loss = 1.325551995425485, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 205, train_loss = 1.323069660575129, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 206, train_loss = 1.3202936860034242, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 207, train_loss = 1.3174469111254439, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 208, train_loss = 1.3151125746080652, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 209, train_loss = 1.3122954368591309, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 210, train_loss = 1.3099121736595407, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 211, train_loss = 1.3066358926007524, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 212, train_loss = 1.304468970745802, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 213, train_loss = 1.3017078241100535, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 214, train_loss = 1.2995788442203775, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 215, train_loss = 1.2968563698232174, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 216, train_loss = 1.2944801151752472, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 217, train_loss = 1.291532122879289, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 218, train_loss = 1.2893864599755034, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 219, train_loss = 1.286259358166717, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 220, train_loss = 1.2843704981496558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 221, train_loss = 1.2818203618517146, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 222, train_loss = 1.2793288504472002, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 223, train_loss = 1.277326655923389, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 224, train_loss = 1.2746563939144835, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 225, train_loss = 1.2723386524012312, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 226, train_loss = 1.2700055552413687, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 227, train_loss = 1.2672794436803088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 228, train_loss = 1.2652617072453722, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 229, train_loss = 1.2628152556717396, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 230, train_loss = 1.2604675380280241, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 231, train_loss = 1.2581098029622808, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 232, train_loss = 1.2559163768892176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 233, train_loss = 1.2534760597045533, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 234, train_loss = 1.251056730747223, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 235, train_loss = 1.2483387899701484, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 236, train_loss = 1.246422243595589, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 237, train_loss = 1.2445175920729525, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 238, train_loss = 1.2418791726231575, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 239, train_loss = 1.2401128262281418, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 240, train_loss = 1.2372462811763398, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 241, train_loss = 1.235718420415651, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 242, train_loss = 1.2331277641351335, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 243, train_loss = 1.2307839443092234, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 244, train_loss = 1.228835515677929, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 245, train_loss = 1.2266714051365852, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 246, train_loss = 1.224685990542639, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 247, train_loss = 1.222981243103277, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 248, train_loss = 1.2212367716128938, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 249, train_loss = 1.2190803959965706, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 250, train_loss = 1.2172177471220493, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 251, train_loss = 1.214757965237368, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 252, train_loss = 1.2138574595446698, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 253, train_loss = 1.2111734722857364, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 254, train_loss = 1.2095265078241937, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 255, train_loss = 1.2071534755523317, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 256, train_loss = 1.2062785290181637, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 257, train_loss = 1.2040250512654893, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 258, train_loss = 1.2020453971927054, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 259, train_loss = 1.2001870051026344, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 260, train_loss = 1.1983942948281765, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 261, train_loss = 1.1969565898180008, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 262, train_loss = 1.194282352924347, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 263, train_loss = 1.1931351460516453, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 264, train_loss = 1.1913290632073767, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 265, train_loss = 1.1892938862438314, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 266, train_loss = 1.187775267928373, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 267, train_loss = 1.1862931375508197, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 268, train_loss = 1.1842850099201314, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 269, train_loss = 1.182909204333555, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 270, train_loss = 1.1809592805802822, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 271, train_loss = 1.178866297006607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 272, train_loss = 1.1778812445700169, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 273, train_loss = 1.1761095362599008, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 274, train_loss = 1.17422578856349, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 275, train_loss = 1.1728221513330936, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 276, train_loss = 1.1714205642347224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 277, train_loss = 1.1694581645424478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 278, train_loss = 1.167892925441265, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 279, train_loss = 1.1660615764558315, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 280, train_loss = 1.1650722858612426, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 281, train_loss = 1.1625975146889687, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 282, train_loss = 1.1617431205813773, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 283, train_loss = 1.1598718712921254, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 284, train_loss = 1.158289159357082, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 285, train_loss = 1.1569320348207839, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 286, train_loss = 1.1549277107114904, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 287, train_loss = 1.1533231027424335, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 288, train_loss = 1.152080589265097, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 289, train_loss = 1.1510163347120397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 290, train_loss = 1.148680254817009, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 291, train_loss = 1.1476397079532035, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 292, train_loss = 1.1460728533565998, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 293, train_loss = 1.1449576790328138, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 294, train_loss = 1.1435340332682244, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 295, train_loss = 1.142023955762852, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 296, train_loss = 1.1404526121914387, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 297, train_loss = 1.138512123376131, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 298, train_loss = 1.1377410925924778, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 299, train_loss = 1.1358772056992166, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 300, train_loss = 1.1340477739577182, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 301, train_loss = 1.1334104153211229, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 302, train_loss = 1.1316519665415399, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 303, train_loss = 1.1304403890972026, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 304, train_loss = 1.1291432802681811, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 305, train_loss = 1.1273877036874183, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 306, train_loss = 1.1260170464520343, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 307, train_loss = 1.1250109635293484, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 308, train_loss = 1.1234355606138706, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 309, train_loss = 1.1220803794567473, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 310, train_loss = 1.120502398640383, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 311, train_loss = 1.1194406561553478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 312, train_loss = 1.1184274206752889, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 313, train_loss = 1.1168233056669123, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 314, train_loss = 1.1151444924180396, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 315, train_loss = 1.1142404948477633, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 316, train_loss = 1.1124040919239633, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 317, train_loss = 1.1115718334913254, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 318, train_loss = 1.1102233305573463, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 319, train_loss = 1.1087831308250315, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 320, train_loss = 1.107777465134859, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 321, train_loss = 1.105789701163303, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 322, train_loss = 1.1051590691204183, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 323, train_loss = 1.103642750531435, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 324, train_loss = 1.102661254524719, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 325, train_loss = 1.1012427930836566, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 326, train_loss = 1.1002727883751504, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 327, train_loss = 1.0984652911429293, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 328, train_loss = 1.0980591364204884, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 329, train_loss = 1.0965608258848079, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 330, train_loss = 1.0943942703306675, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 331, train_loss = 1.0938647625152953, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 332, train_loss = 1.0922513864934444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 333, train_loss = 1.0916047456557862, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 334, train_loss = 1.0902992536430247, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 335, train_loss = 1.0894060755963437, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 336, train_loss = 1.0881363985245116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 337, train_loss = 1.0866986513137817, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 338, train_loss = 1.0850770100951195, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 339, train_loss = 1.0845062409644015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 340, train_loss = 1.0838131134514697, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 341, train_loss = 1.0815887724165805, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 342, train_loss = 1.0811269171535969, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 343, train_loss = 1.0799313026363961, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 344, train_loss = 1.0780165393953212, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 345, train_loss = 1.0778675240580924, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 346, train_loss = 1.0765183965559117, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 347, train_loss = 1.075556484342087, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 348, train_loss = 1.0740064841811545, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 349, train_loss = 1.073244656145107, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 350, train_loss = 1.0719325405661948, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 351, train_loss = 1.0699072505231015, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 352, train_loss = 1.07019703584956, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 353, train_loss = 1.0685409146244638, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 354, train_loss = 1.0674684109981172, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 355, train_loss = 1.066427522629965, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 356, train_loss = 1.0650965521926992, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 357, train_loss = 1.064389929175377, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 358, train_loss = 1.0631760868127458, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 359, train_loss = 1.0622324831783772, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 360, train_loss = 1.060223416716326, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 361, train_loss = 1.0600018091499805, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 362, train_loss = 1.0586742523009889, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 363, train_loss = 1.0576173302833922, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 364, train_loss = 1.0566041941638105, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 365, train_loss = 1.056012409448158, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 366, train_loss = 1.0544656862621196, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 367, train_loss = 1.0533911250531673, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 368, train_loss = 1.0522971277241595, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 369, train_loss = 1.0511018398101442, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 370, train_loss = 1.050195234536659, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 371, train_loss = 1.0500145207042806, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 372, train_loss = 1.0484964810311794, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 373, train_loss = 1.04710029438138, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 374, train_loss = 1.0462484794552438, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 375, train_loss = 1.0456819087266922, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 376, train_loss = 1.0442124915425666, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 377, train_loss = 1.0434171929955482, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 378, train_loss = 1.042634192854166, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 379, train_loss = 1.0415013047750108, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 380, train_loss = 1.0404417601821478, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 381, train_loss = 1.039360719412798, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 382, train_loss = 1.0387031758727971, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 383, train_loss = 1.037495774537092, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 384, train_loss = 1.0368302700517233, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 385, train_loss = 1.0353285533783492, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 386, train_loss = 1.034700881689787, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 387, train_loss = 1.0333003091218416, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 388, train_loss = 1.0326910192670766, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 389, train_loss = 1.0319113358855247, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 390, train_loss = 1.0311237312853336, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 391, train_loss = 1.030053156107897, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 392, train_loss = 1.029261545598274, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 393, train_loss = 1.0281427515146788, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 394, train_loss = 1.0273297342064325, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 395, train_loss = 1.0263114137051161, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 396, train_loss = 1.025556094944477, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 397, train_loss = 1.024467084556818, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 398, train_loss = 1.0237722334859427, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 399, train_loss = 1.0218233155610505, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 400, train_loss = 1.0221572580339853, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 401, train_loss = 1.020856138318777, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 402, train_loss = 1.0201113993825857, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 403, train_loss = 1.0190928106603678, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 404, train_loss = 1.0178174711763859, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 405, train_loss = 1.0179228459892329, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 406, train_loss = 1.0163613682088908, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 407, train_loss = 1.0156845127639826, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 408, train_loss = 1.0145959295332432, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 409, train_loss = 1.0149263305065688, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 410, train_loss = 1.0133189347980078, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 411, train_loss = 1.0121873021125793, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 412, train_loss = 1.0109630214574281, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 413, train_loss = 1.0106606607732829, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 414, train_loss = 1.0097912698984146, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 415, train_loss = 1.008967563509941, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 416, train_loss = 1.0082052697835024, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 417, train_loss = 1.0070947421190795, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 418, train_loss = 1.006172675639391, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 419, train_loss = 1.0054973140358925, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 420, train_loss = 1.0047433786094189, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 421, train_loss = 1.0034376978874207, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 422, train_loss = 1.002900704741478, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 423, train_loss = 1.002529756486183, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 424, train_loss = 1.0012392811477184, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 425, train_loss = 1.0002807465789374, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 426, train_loss = 0.999626636505127, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 427, train_loss = 0.9989741022291128, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 428, train_loss = 0.9978771594760474, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 429, train_loss = 0.997551749140257, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 430, train_loss = 0.9955705230531748, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 431, train_loss = 0.9958154385385569, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 432, train_loss = 0.9944968832132872, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 433, train_loss = 0.9943161085247993, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 434, train_loss = 0.9932397579250392, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 435, train_loss = 0.9925081357359886, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 436, train_loss = 0.9923655850288924, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 437, train_loss = 0.9912199204263743, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 438, train_loss = 0.9904931249620859, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 439, train_loss = 0.9895271149871405, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 440, train_loss = 0.9886131075618323, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 441, train_loss = 0.9883624377253, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 442, train_loss = 0.9879261305031832, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 443, train_loss = 0.9866150617599487, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 444, train_loss = 0.9858440297248308, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 445, train_loss = 0.9845953447220381, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 446, train_loss = 0.9845053789613303, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 447, train_loss = 0.9834746060369071, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 448, train_loss = 0.9829739468696062, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 449, train_loss = 0.9815093713405076, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 450, train_loss = 0.9816835038363934, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 451, train_loss = 0.9809615686535835, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 452, train_loss = 0.9796949736773968, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 453, train_loss = 0.9792502112686634, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 454, train_loss = 0.9786851865646895, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 455, train_loss = 0.9782138479349669, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 456, train_loss = 0.9773058270511683, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 457, train_loss = 0.9761261021194514, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 458, train_loss = 0.975275557488203, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 459, train_loss = 0.9746154149470385, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 460, train_loss = 0.9744047323765699, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 461, train_loss = 0.973793546349043, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 462, train_loss = 0.9733706302940845, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 463, train_loss = 0.9719964812102262, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 464, train_loss = 0.9711385903356131, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 465, train_loss = 0.970805070042843, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 466, train_loss = 0.9697972672584001, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 467, train_loss = 0.9694562256336212, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 468, train_loss = 0.9691409903171007, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 469, train_loss = 0.9681282564997673, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 470, train_loss = 0.9673808092775289, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 471, train_loss = 0.9664298767747823, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 472, train_loss = 0.9659702641365584, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 473, train_loss = 0.9646276111307088, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 474, train_loss = 0.965044341981411, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 475, train_loss = 0.9636131686565932, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 476, train_loss = 0.9633213952183723, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 477, train_loss = 0.9627245614829008, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 478, train_loss = 0.962031220406061, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 479, train_loss = 0.9609216116368771, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 480, train_loss = 0.9600120261311531, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 481, train_loss = 0.9600607355532702, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 482, train_loss = 0.959220927208662, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 483, train_loss = 0.9587134892644826, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 484, train_loss = 0.9575948864221573, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 485, train_loss = 0.9573370479047298, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 486, train_loss = 0.9560129642486572, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 487, train_loss = 0.9561352667806204, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 488, train_loss = 0.955541156232357, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 489, train_loss = 0.9543760729429778, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 490, train_loss = 0.9545906893908978, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 491, train_loss = 0.9533069543540478, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 492, train_loss = 0.9533060267567635, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 493, train_loss = 0.9521565412578639, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 494, train_loss = 0.9522651558218058, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 495, train_loss = 0.9513998900947627, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 496, train_loss = 0.9507851923408452, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 497, train_loss = 0.9501392766833305, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 498, train_loss = 0.9491079623403493, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 499, train_loss = 0.9488636292517185, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████▌                                                          | 6/30 [59:28<3:58:06, 595.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "7th- epoch: 0, train_loss = 116.58521346747875, train_acc = 0.7792268281322776\n",
      "test Acc 0.8640595903165735:\n",
      "7th- epoch: 1, train_loss = 43.69835852086544, train_acc = 0.9153469958081043\n",
      "test Acc 0.9031657355679702:\n",
      "7th- epoch: 2, train_loss = 31.73815283179283, train_acc = 0.9373544480670704\n",
      "test Acc 0.925512104283054:\n",
      "7th- epoch: 3, train_loss = 25.724874954670668, train_acc = 0.948067070330694\n",
      "test Acc 0.9338919925512105:\n",
      "7th- epoch: 4, train_loss = 21.860715355724096, train_acc = 0.9568001863064741\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 5, train_loss = 19.114923752844334, train_acc = 0.9614578481602236\n",
      "test Acc 0.952048417132216:\n",
      "7th- epoch: 6, train_loss = 17.047544825822115, train_acc = 0.9664648346530041\n",
      "test Acc 0.9548417132216015:\n",
      "7th- epoch: 7, train_loss = 15.43266874179244, train_acc = 0.9690265486725663\n",
      "test Acc 0.9585661080074488:\n",
      "7th- epoch: 8, train_loss = 14.100802514702082, train_acc = 0.9720540288775035\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 9, train_loss = 12.993599308654666, train_acc = 0.974033535165347\n",
      "test Acc 0.9618249534450651:\n",
      "7th- epoch: 10, train_loss = 12.050229599699378, train_acc = 0.9755472752678156\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 11, train_loss = 11.238663256168365, train_acc = 0.9771774569166278\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 12, train_loss = 10.526090569794178, train_acc = 0.9793898462971589\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 13, train_loss = 9.900374848395586, train_acc = 0.9803213786679087\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 14, train_loss = 9.346058351919055, train_acc = 0.9824173265020959\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 15, train_loss = 8.852551558986306, train_acc = 0.9835817419655333\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 16, train_loss = 8.40899789892137, train_acc = 0.9845132743362832\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 17, train_loss = 8.0087994877249, train_acc = 0.9852119236143456\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 18, train_loss = 7.6494133453816175, train_acc = 0.9862598975314392\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 19, train_loss = 7.318614462390542, train_acc = 0.9868421052631579\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 20, train_loss = 7.018492678180337, train_acc = 0.9869585468095017\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 21, train_loss = 6.741751130670309, train_acc = 0.9876571960875641\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 22, train_loss = 6.490007434971631, train_acc = 0.9883558453656265\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 23, train_loss = 6.259219706058502, train_acc = 0.9890544946436889\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 24, train_loss = 6.04301917552948, train_acc = 0.98940381928272\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 25, train_loss = 5.842803540639579, train_acc = 0.9895202608290639\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 26, train_loss = 5.65654213540256, train_acc = 0.9899860270144387\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 27, train_loss = 5.4784368285909295, train_acc = 0.99033535165347\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 28, train_loss = 5.314033336006105, train_acc = 0.9910340009315324\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 29, train_loss = 5.159027069807053, train_acc = 0.9912668840242198\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 30, train_loss = 5.013356609269977, train_acc = 0.9917326502095948\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 31, train_loss = 4.8737213453277946, train_acc = 0.9917326502095948\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 32, train_loss = 4.744586112909019, train_acc = 0.992081974848626\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 33, train_loss = 4.618024664930999, train_acc = 0.9923148579413135\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 34, train_loss = 4.4997181706130505, train_acc = 0.9923148579413135\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 35, train_loss = 4.388036750257015, train_acc = 0.9927806241266884\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 36, train_loss = 4.281179117970169, train_acc = 0.9927806241266884\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 37, train_loss = 4.1812281515449286, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 38, train_loss = 4.084108694456518, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 39, train_loss = 3.991463640704751, train_acc = 0.9934792734047508\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 40, train_loss = 3.903570955619216, train_acc = 0.9934792734047508\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 41, train_loss = 3.821086773183197, train_acc = 0.9935957149510946\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 42, train_loss = 3.7423735396005213, train_acc = 0.993828598043782\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 43, train_loss = 3.6661701570264995, train_acc = 0.9939450395901258\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 44, train_loss = 3.5961414724588394, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 45, train_loss = 3.5267503992654383, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 46, train_loss = 3.4618186349980533, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 47, train_loss = 3.3989793085493147, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 48, train_loss = 3.3380861654877663, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 49, train_loss = 3.281977688893676, train_acc = 0.9951094550535631\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 50, train_loss = 3.2282397826202214, train_acc = 0.9951094550535631\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 51, train_loss = 3.1759775024838746, train_acc = 0.9951094550535631\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 52, train_loss = 3.1266127582639456, train_acc = 0.9951094550535631\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 53, train_loss = 3.0785903125070035, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 54, train_loss = 3.0327066625468433, train_acc = 0.9951094550535631\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 55, train_loss = 2.9885401423089206, train_acc = 0.9951094550535631\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 56, train_loss = 2.9456378403119743, train_acc = 0.9952258965999069\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 57, train_loss = 2.9042812273837626, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 58, train_loss = 2.864519089460373, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 59, train_loss = 2.8253729455173016, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 60, train_loss = 2.788936914410442, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 61, train_loss = 2.7529189730994403, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 62, train_loss = 2.718624866101891, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 63, train_loss = 2.684637799859047, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 64, train_loss = 2.6511434209533036, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 65, train_loss = 2.620325465220958, train_acc = 0.9956916627852818\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 66, train_loss = 2.589767508674413, train_acc = 0.9958081043316255\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 67, train_loss = 2.5602549966424704, train_acc = 0.9958081043316255\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 68, train_loss = 2.5314372130669653, train_acc = 0.9959245458779693\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 69, train_loss = 2.5047452826984227, train_acc = 0.9959245458779693\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 70, train_loss = 2.4782502949237823, train_acc = 0.996040987424313\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 71, train_loss = 2.4522175029851496, train_acc = 0.996040987424313\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 72, train_loss = 2.426800819579512, train_acc = 0.9961574289706567\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 73, train_loss = 2.4032706413418055, train_acc = 0.9961574289706567\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 74, train_loss = 2.37863787333481, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 75, train_loss = 2.3553924702573568, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 76, train_loss = 2.3333822533022612, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 77, train_loss = 2.312255101976916, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 78, train_loss = 2.290667988359928, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 79, train_loss = 2.2704500071704388, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 80, train_loss = 2.25053319032304, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 81, train_loss = 2.231413597241044, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 82, train_loss = 2.2128849886357784, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 83, train_loss = 2.1941099029500037, train_acc = 0.996506753609688\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 84, train_loss = 2.1763834052253515, train_acc = 0.996506753609688\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 85, train_loss = 2.158731418894604, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 86, train_loss = 2.141984935849905, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 87, train_loss = 2.1246552485972643, train_acc = 0.9967396367023754\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 88, train_loss = 2.1087669506669044, train_acc = 0.9967396367023754\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 89, train_loss = 2.0932643692940474, train_acc = 0.9968560782487191\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 90, train_loss = 2.0774346105754375, train_acc = 0.9968560782487191\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 91, train_loss = 2.0624358486384153, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 92, train_loss = 2.047317157732323, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 93, train_loss = 2.0332705546170473, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 94, train_loss = 2.018951965495944, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 95, train_loss = 2.0043679650407284, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 96, train_loss = 1.9913473196793348, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 97, train_loss = 1.97840740904212, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 98, train_loss = 1.964278468862176, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 99, train_loss = 1.951562563655898, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 100, train_loss = 1.9383033625781536, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 101, train_loss = 1.9256172149907798, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 102, train_loss = 1.9137704148888588, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 103, train_loss = 1.9016623019706458, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 104, train_loss = 1.890307331457734, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 105, train_loss = 1.8787431244272739, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 106, train_loss = 1.868140511913225, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 107, train_loss = 1.8571005451958627, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 108, train_loss = 1.8468551959376782, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 109, train_loss = 1.836476270109415, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 110, train_loss = 1.8266468595247716, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 111, train_loss = 1.8161803726106882, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 112, train_loss = 1.806888309540227, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 113, train_loss = 1.7971906245220453, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 114, train_loss = 1.7874654207844287, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "7th- epoch: 115, train_loss = 1.7784274921286851, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "7th- epoch: 116, train_loss = 1.7699345101136714, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "7th- epoch: 117, train_loss = 1.7606550864875317, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 118, train_loss = 1.752066385699436, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 119, train_loss = 1.7437553443014622, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 120, train_loss = 1.7356252192985266, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 121, train_loss = 1.7266667399089783, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 122, train_loss = 1.7194014110136777, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 123, train_loss = 1.7110088001936674, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 124, train_loss = 1.7032423552591354, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 125, train_loss = 1.6956019878853112, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 126, train_loss = 1.6885977548081428, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 127, train_loss = 1.681078376248479, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 128, train_loss = 1.6732801522593945, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 129, train_loss = 1.6669037851970643, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 130, train_loss = 1.6596302471589297, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 131, train_loss = 1.652443467406556, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 132, train_loss = 1.646148570580408, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 133, train_loss = 1.6392708874773234, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 134, train_loss = 1.6325675150146708, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 135, train_loss = 1.6264468698063865, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 136, train_loss = 1.6198654311010614, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 137, train_loss = 1.6130914272507653, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 138, train_loss = 1.6076582130044699, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 139, train_loss = 1.60116333886981, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 140, train_loss = 1.594923005090095, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 141, train_loss = 1.5894292866578326, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 142, train_loss = 1.5830026045441628, train_acc = 0.9969725197950629\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 143, train_loss = 1.5775087656220421, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 144, train_loss = 1.572078657685779, train_acc = 0.9969725197950629\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 145, train_loss = 1.5664135981351137, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 146, train_loss = 1.5604758827248588, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 147, train_loss = 1.5550116946687922, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 148, train_loss = 1.5497002148767933, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 149, train_loss = 1.544545085518621, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 150, train_loss = 1.5387955643236637, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 151, train_loss = 1.5337493028491735, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 152, train_loss = 1.52871833241079, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 153, train_loss = 1.5235524444142357, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 154, train_loss = 1.5186912877252325, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 155, train_loss = 1.5137978723505512, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 156, train_loss = 1.5090597551316023, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 157, train_loss = 1.5038301075110212, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 158, train_loss = 1.4989483673125505, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 159, train_loss = 1.4946472296724096, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 160, train_loss = 1.4896160470088944, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 161, train_loss = 1.4854559960076585, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 162, train_loss = 1.481233399361372, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 163, train_loss = 1.4764980841428041, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 164, train_loss = 1.471892432658933, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 165, train_loss = 1.4673452470451593, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 166, train_loss = 1.4634091462939978, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 167, train_loss = 1.4590970240533352, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 168, train_loss = 1.455027605756186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 169, train_loss = 1.4503834446659312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 170, train_loss = 1.4465666972100735, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 171, train_loss = 1.4426568826893345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 172, train_loss = 1.4383107783505693, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 173, train_loss = 1.4344879314303398, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 174, train_loss = 1.4309525856515393, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 175, train_loss = 1.4269274225225672, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 176, train_loss = 1.4228789955377579, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 177, train_loss = 1.4193230923265219, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 178, train_loss = 1.415144756436348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 179, train_loss = 1.4115476397564635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 180, train_loss = 1.4084601495414972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 181, train_loss = 1.4045804217457771, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 182, train_loss = 1.4004366608569399, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 183, train_loss = 1.3977892032125965, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 184, train_loss = 1.3938845494994894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 185, train_loss = 1.3907800229499117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 186, train_loss = 1.387476165429689, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 187, train_loss = 1.3840353345731273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 188, train_loss = 1.380361938267015, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 189, train_loss = 1.377091821283102, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 190, train_loss = 1.3744861017912626, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 191, train_loss = 1.3711162991821766, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 192, train_loss = 1.3680571547010913, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 193, train_loss = 1.364785460755229, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 194, train_loss = 1.361566860228777, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 195, train_loss = 1.3582738805562258, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 196, train_loss = 1.3552044139942154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 197, train_loss = 1.3523948608199134, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 198, train_loss = 1.3497984372079372, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 199, train_loss = 1.3461267929524183, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 200, train_loss = 1.3433839473873377, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 201, train_loss = 1.3394716568291187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 202, train_loss = 1.3368969106813893, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 203, train_loss = 1.3339874278753996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 204, train_loss = 1.330973363132216, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 205, train_loss = 1.328303606598638, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 206, train_loss = 1.3251399701694027, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 207, train_loss = 1.322897053672932, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 208, train_loss = 1.3196989558637142, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 209, train_loss = 1.3168862294405699, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 210, train_loss = 1.3143251346191391, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 211, train_loss = 1.311922699213028, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 212, train_loss = 1.3094697184860706, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 213, train_loss = 1.3064636135241017, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 214, train_loss = 1.3040672490606084, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 215, train_loss = 1.3013014321331866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 216, train_loss = 1.2987776665831916, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 217, train_loss = 1.2957707748864777, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 218, train_loss = 1.293974656611681, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 219, train_loss = 1.2907131134415977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 220, train_loss = 1.2892858926206827, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 221, train_loss = 1.2862932446296327, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 222, train_loss = 1.2839263093774207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 223, train_loss = 1.2817921818350442, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 224, train_loss = 1.2787378635257483, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 225, train_loss = 1.276734894781839, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 226, train_loss = 1.2743549005244859, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 227, train_loss = 1.2722279274021275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 228, train_loss = 1.269316129386425, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 229, train_loss = 1.2671869273181073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 230, train_loss = 1.2648425890947692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 231, train_loss = 1.262812778353691, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 232, train_loss = 1.2603348158299923, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 233, train_loss = 1.257916932925582, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 234, train_loss = 1.256397569552064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 235, train_loss = 1.2541996228392236, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 236, train_loss = 1.2511890630121343, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 237, train_loss = 1.2500347662717104, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 238, train_loss = 1.2470667753368616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 239, train_loss = 1.2450596069102176, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 240, train_loss = 1.2430440224707127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 241, train_loss = 1.2410955373197794, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 242, train_loss = 1.238797340542078, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 243, train_loss = 1.23670444637537, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 244, train_loss = 1.2344130731071346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 245, train_loss = 1.2331124525517225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 246, train_loss = 1.230116834223736, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 247, train_loss = 1.2290108930319548, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 248, train_loss = 1.226829741790425, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 249, train_loss = 1.2248720216448419, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 250, train_loss = 1.2228050815756433, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 251, train_loss = 1.2207474404131062, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 252, train_loss = 1.2184812401537783, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 253, train_loss = 1.217022882134188, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 254, train_loss = 1.2148185863043182, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 255, train_loss = 1.2133844687486999, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 256, train_loss = 1.2110672257840633, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 257, train_loss = 1.2097068305010907, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 258, train_loss = 1.2071744880522601, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 259, train_loss = 1.2054684975300916, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 260, train_loss = 1.2036810430581681, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 261, train_loss = 1.2017047591507435, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 262, train_loss = 1.2002265248447657, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 263, train_loss = 1.1978233263944276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 264, train_loss = 1.1963784098625183, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 265, train_loss = 1.194830137596, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 266, train_loss = 1.1927157274330966, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 267, train_loss = 1.1908394359052181, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 268, train_loss = 1.189511924982071, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 269, train_loss = 1.1874614153057337, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 270, train_loss = 1.185569776862394, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 271, train_loss = 1.1845602256362326, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 272, train_loss = 1.1824869513511658, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 273, train_loss = 1.1807139336015098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 274, train_loss = 1.1790841557085514, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 275, train_loss = 1.177846908569336, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 276, train_loss = 1.1757683387841098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 277, train_loss = 1.1741792317479849, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 278, train_loss = 1.1725945000653155, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 279, train_loss = 1.1711898340727203, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 280, train_loss = 1.1694048388744704, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 281, train_loss = 1.1681632014806382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 282, train_loss = 1.166193991259206, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 283, train_loss = 1.164231514558196, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 284, train_loss = 1.1628843508660793, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 285, train_loss = 1.1621650159358978, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 286, train_loss = 1.1595618507708423, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 287, train_loss = 1.158465848013293, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 288, train_loss = 1.156930396973621, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 289, train_loss = 1.1554737978731282, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 290, train_loss = 1.1541003044694662, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 291, train_loss = 1.1527279528672807, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 292, train_loss = 1.1508589765871875, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 293, train_loss = 1.1494815231417306, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 294, train_loss = 1.1476496172253974, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 295, train_loss = 1.1469134303624742, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 296, train_loss = 1.144993242516648, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 297, train_loss = 1.1436302736401558, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 298, train_loss = 1.1421953700482845, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 299, train_loss = 1.1412982549518347, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 300, train_loss = 1.139384986832738, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 301, train_loss = 1.1377281099557877, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 302, train_loss = 1.1364050302654505, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 303, train_loss = 1.1357719544321299, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 304, train_loss = 1.133432250469923, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 305, train_loss = 1.1327111323480494, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 306, train_loss = 1.1311576000298373, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 307, train_loss = 1.129752776294481, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 308, train_loss = 1.1280975143308751, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 309, train_loss = 1.12752885062946, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 310, train_loss = 1.125508847355377, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 311, train_loss = 1.1242558012600057, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 312, train_loss = 1.1233373004943132, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 313, train_loss = 1.1217227063025348, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 314, train_loss = 1.119769976765383, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 315, train_loss = 1.119358914613258, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 316, train_loss = 1.1179937440901995, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 317, train_loss = 1.116420492529869, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 318, train_loss = 1.1153625075821765, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 319, train_loss = 1.1140424491022713, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 320, train_loss = 1.1128213324700482, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 321, train_loss = 1.11118982732296, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 322, train_loss = 1.1104018638725393, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 323, train_loss = 1.1090056306566112, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 324, train_loss = 1.1080595658277161, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 325, train_loss = 1.10596588376211, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 326, train_loss = 1.1053961006109603, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 327, train_loss = 1.1041395353968255, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 328, train_loss = 1.1031172784860246, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 329, train_loss = 1.101593229919672, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 330, train_loss = 1.1006264227326028, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 331, train_loss = 1.0993185974657536, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 332, train_loss = 1.0980390198528767, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 333, train_loss = 1.0966791696846485, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 334, train_loss = 1.0961916011874564, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 335, train_loss = 1.0939949217136018, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 336, train_loss = 1.0936531722545624, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 337, train_loss = 1.091845786839258, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 338, train_loss = 1.0911349691450596, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 339, train_loss = 1.0892060759360902, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 340, train_loss = 1.0887797536852304, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 341, train_loss = 1.0876139191386756, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 342, train_loss = 1.0864243172109127, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 343, train_loss = 1.0852290069160517, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 344, train_loss = 1.0838184617459774, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 345, train_loss = 1.0831143707036972, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 346, train_loss = 1.0817258916795254, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 347, train_loss = 1.0806675714848097, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 348, train_loss = 1.0800384866597597, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 349, train_loss = 1.0785470915434416, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 350, train_loss = 1.077525099128252, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 351, train_loss = 1.0763589640555438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 352, train_loss = 1.0760183495876845, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 353, train_loss = 1.0738846361637115, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 354, train_loss = 1.0738306269049644, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 355, train_loss = 1.071831247449154, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 356, train_loss = 1.0711295517685357, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 357, train_loss = 1.069802107900614, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 358, train_loss = 1.0690479998884257, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 359, train_loss = 1.0679963690636214, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 360, train_loss = 1.0670944452285767, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 361, train_loss = 1.065974044293398, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 362, train_loss = 1.0651071543397848, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 363, train_loss = 1.0636295502481516, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 364, train_loss = 1.063102704792982, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 365, train_loss = 1.0619725733995438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 366, train_loss = 1.0609112853708211, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 367, train_loss = 1.059825169533724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 368, train_loss = 1.0590070908365306, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 369, train_loss = 1.0576277723012026, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 370, train_loss = 1.0568187795579433, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 371, train_loss = 1.0561762116849422, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 372, train_loss = 1.0546462858619634, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 373, train_loss = 1.053938594966894, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 374, train_loss = 1.0532174855470657, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 375, train_loss = 1.0524143477377947, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 376, train_loss = 1.0507760606706142, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 377, train_loss = 1.0500600151717663, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 378, train_loss = 1.0490193428995553, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 379, train_loss = 1.0485213920474052, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 380, train_loss = 1.0471483319997787, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 381, train_loss = 1.0463928120734636, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 382, train_loss = 1.0449105662701186, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 383, train_loss = 1.0446756606397685, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 384, train_loss = 1.043380187213188, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 385, train_loss = 1.043012193083996, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 386, train_loss = 1.0412977772357408, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 387, train_loss = 1.0409062703547534, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 388, train_loss = 1.0397255420684814, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 389, train_loss = 1.0389305464923382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 390, train_loss = 1.038180941104656, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 391, train_loss = 1.036901906132698, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 392, train_loss = 1.0365762884321157, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 393, train_loss = 1.0351878690125886, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 394, train_loss = 1.034795232117176, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 395, train_loss = 1.033549269050127, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 396, train_loss = 1.0327054858207703, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 397, train_loss = 1.0320132175984327, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 398, train_loss = 1.0306834491493646, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 399, train_loss = 1.0303634939191397, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 400, train_loss = 1.0290080395934638, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 401, train_loss = 1.0283123912813608, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 402, train_loss = 1.0274451983568724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 403, train_loss = 1.025994131952757, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 404, train_loss = 1.0258042191562708, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 405, train_loss = 1.0250674659910146, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 406, train_loss = 1.0239513677952345, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 407, train_loss = 1.0232169243099634, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 408, train_loss = 1.0223514549434185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 409, train_loss = 1.021273917198414, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 410, train_loss = 1.0208612407150213, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 411, train_loss = 1.0196049561200198, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 412, train_loss = 1.0190948036906775, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 413, train_loss = 1.0183337231574114, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 414, train_loss = 1.0175719050166663, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 415, train_loss = 1.0164862697420176, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 416, train_loss = 1.015850947558647, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 417, train_loss = 1.0147662895324174, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 418, train_loss = 1.0145061438379344, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 419, train_loss = 1.0132069500687066, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 420, train_loss = 1.0128025151789188, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 421, train_loss = 1.0119971508684102, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 422, train_loss = 1.0108758583664894, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 423, train_loss = 1.0102588683366776, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 424, train_loss = 1.009329585969681, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 425, train_loss = 1.008614362537628, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 426, train_loss = 1.0085070965287741, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 427, train_loss = 1.0069375870225485, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 428, train_loss = 1.0064224811794702, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 429, train_loss = 1.0051658588054124, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 430, train_loss = 1.004953363299137, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 431, train_loss = 1.0042783742246684, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 432, train_loss = 1.0032014014723245, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 433, train_loss = 1.0025690408947412, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 434, train_loss = 1.0019719414412975, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 435, train_loss = 1.000981416553259, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 436, train_loss = 1.0005175806581974, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 437, train_loss = 0.9995372655394021, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 438, train_loss = 0.9989390572009142, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 439, train_loss = 0.998034125805134, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 440, train_loss = 0.9973183708789293, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 441, train_loss = 0.9965472084877547, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 442, train_loss = 0.9955797158181667, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 443, train_loss = 0.995130897819763, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 444, train_loss = 0.9945893312396947, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 445, train_loss = 0.9937426410615444, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 446, train_loss = 0.9926066882908344, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 447, train_loss = 0.9921171540918294, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 448, train_loss = 0.9916330873966217, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 449, train_loss = 0.990760109067196, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 450, train_loss = 0.990170419216156, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 451, train_loss = 0.9892978419957217, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 452, train_loss = 0.9885254986584187, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 453, train_loss = 0.9882369811239187, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 454, train_loss = 0.9872801428136881, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 455, train_loss = 0.9865862441656645, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 456, train_loss = 0.9860447160899639, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 457, train_loss = 0.9854805991053581, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 458, train_loss = 0.9842001236975193, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 459, train_loss = 0.9839049701986369, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 460, train_loss = 0.9836282382311765, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 461, train_loss = 0.9825657034816686, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 462, train_loss = 0.9817906344833318, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 463, train_loss = 0.9812635766866151, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 464, train_loss = 0.980261222779518, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 465, train_loss = 0.9796633260848466, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 466, train_loss = 0.9791400047542993, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 467, train_loss = 0.9786626175045967, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 468, train_loss = 0.9775109626352787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 469, train_loss = 0.9773129336535931, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 470, train_loss = 0.976584579795599, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 471, train_loss = 0.976126636058325, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 472, train_loss = 0.9749423079192638, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 473, train_loss = 0.9747550562024117, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 474, train_loss = 0.9740018559095915, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 475, train_loss = 0.9730241559445858, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 476, train_loss = 0.9730075113475323, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 477, train_loss = 0.972087567060953, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 478, train_loss = 0.9716150350868702, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 479, train_loss = 0.9707148050365504, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 480, train_loss = 0.9704376645386219, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 481, train_loss = 0.9695664519967977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 482, train_loss = 0.9687996456923429, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 483, train_loss = 0.9682666634616908, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 484, train_loss = 0.9678810872137547, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 485, train_loss = 0.9668728100659791, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 486, train_loss = 0.966323229164118, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 487, train_loss = 0.9659017200174276, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 488, train_loss = 0.9650091628136579, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 489, train_loss = 0.9643184766173363, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 490, train_loss = 0.9639750632049982, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 491, train_loss = 0.963066503405571, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 492, train_loss = 0.9626282552781049, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 493, train_loss = 0.9618997623620089, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 494, train_loss = 0.9612099280057009, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 495, train_loss = 0.9607762061059475, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 496, train_loss = 0.959766431391472, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 497, train_loss = 0.9598957411944866, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 498, train_loss = 0.9589561559259892, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 499, train_loss = 0.9584846509096678, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|████████████████▌                                                      | 7/30 [1:09:30<3:49:00, 597.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "8th- epoch: 0, train_loss = 124.84038951992989, train_acc = 0.7748020493712157\n",
      "test Acc 0.8719739292364991:\n",
      "8th- epoch: 1, train_loss = 45.046216666698456, train_acc = 0.9094084769445738\n",
      "test Acc 0.9152700186219739:\n",
      "8th- epoch: 2, train_loss = 32.58322702720761, train_acc = 0.9350256171401956\n",
      "test Acc 0.9283054003724395:\n",
      "8th- epoch: 3, train_loss = 26.379041235893965, train_acc = 0.9487657196087564\n",
      "test Acc 0.936219739292365:\n",
      "8th- epoch: 4, train_loss = 22.445093885064125, train_acc = 0.955985095482068\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 5, train_loss = 19.68724923208356, train_acc = 0.9632044713553796\n",
      "test Acc 0.9427374301675978:\n",
      "8th- epoch: 6, train_loss = 17.62331165187061, train_acc = 0.9673963670237541\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 7, train_loss = 15.97809985280037, train_acc = 0.9706567303213787\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 8, train_loss = 14.613548509776592, train_acc = 0.9734513274336283\n",
      "test Acc 0.952513966480447:\n",
      "8th- epoch: 9, train_loss = 13.469369927421212, train_acc = 0.9751979506287843\n",
      "test Acc 0.9581005586592178:\n",
      "8th- epoch: 10, train_loss = 12.490685915574431, train_acc = 0.9769445738239404\n",
      "test Acc 0.9590316573556797:\n",
      "8th- epoch: 11, train_loss = 11.640586521476507, train_acc = 0.9785747554727526\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 12, train_loss = 10.894095787778497, train_acc = 0.9795062878435026\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 13, train_loss = 10.242348657920957, train_acc = 0.9805542617605962\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 14, train_loss = 9.663974806666374, train_acc = 0.9814857941313461\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 15, train_loss = 9.144007271155715, train_acc = 0.9825337680484397\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 16, train_loss = 8.676169767975807, train_acc = 0.984163949697252\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 17, train_loss = 8.2514517782256, train_acc = 0.9847461574289706\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 18, train_loss = 7.866637294180691, train_acc = 0.9853283651606893\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 19, train_loss = 7.515296835452318, train_acc = 0.9860270144387517\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 20, train_loss = 7.1936083640903234, train_acc = 0.9862598975314392\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 21, train_loss = 6.897699796594679, train_acc = 0.9875407545412203\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 22, train_loss = 6.62497752904892, train_acc = 0.9882394038192828\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 23, train_loss = 6.37064603716135, train_acc = 0.9883558453656265\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 24, train_loss = 6.134042488411069, train_acc = 0.9888216115510013\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 25, train_loss = 5.910668600350618, train_acc = 0.9891709361900326\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 26, train_loss = 5.707646012306213, train_acc = 0.98940381928272\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 27, train_loss = 5.518094045110047, train_acc = 0.9896367023754076\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 28, train_loss = 5.338202781975269, train_acc = 0.9905682347461574\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 29, train_loss = 5.170121020637453, train_acc = 0.9912668840242198\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 30, train_loss = 5.012190122157335, train_acc = 0.9913833255705635\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 31, train_loss = 4.864325961098075, train_acc = 0.9917326502095948\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 32, train_loss = 4.7243956765159965, train_acc = 0.992081974848626\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 33, train_loss = 4.594073531217873, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 34, train_loss = 4.471644453704357, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 35, train_loss = 4.356029449030757, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 36, train_loss = 4.246223880909383, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 37, train_loss = 4.143288532271981, train_acc = 0.9937121564974383\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 38, train_loss = 4.045629828236997, train_acc = 0.9939450395901258\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 39, train_loss = 3.951755807735026, train_acc = 0.9940614811364695\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 40, train_loss = 3.8631477802991867, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 41, train_loss = 3.779009516350925, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 42, train_loss = 3.697960127145052, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 43, train_loss = 3.6210325555875897, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 44, train_loss = 3.5489263515919447, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 45, train_loss = 3.479073179885745, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 46, train_loss = 3.413018574938178, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 47, train_loss = 3.349361346103251, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 48, train_loss = 3.288148450665176, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 49, train_loss = 3.2309062741696835, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 50, train_loss = 3.174867916852236, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 51, train_loss = 3.1237236419692636, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 52, train_loss = 3.0727723548188806, train_acc = 0.995575221238938\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 53, train_loss = 3.0234210193157196, train_acc = 0.995575221238938\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 54, train_loss = 2.9767543030902743, train_acc = 0.9956916627852818\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 55, train_loss = 2.9318451937288046, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 56, train_loss = 2.8883890230208635, train_acc = 0.9956916627852818\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 57, train_loss = 2.847109831869602, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 58, train_loss = 2.807175984606147, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 59, train_loss = 2.768362040631473, train_acc = 0.9959245458779693\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 60, train_loss = 2.731227931100875, train_acc = 0.9959245458779693\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 61, train_loss = 2.695540518499911, train_acc = 0.9958081043316255\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 62, train_loss = 2.660252974834293, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 63, train_loss = 2.626997683662921, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 64, train_loss = 2.594519132282585, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 65, train_loss = 2.5633676135912538, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 66, train_loss = 2.5328912804834545, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 67, train_loss = 2.5036577288992703, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 68, train_loss = 2.476222981698811, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 69, train_loss = 2.4481165814213455, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 70, train_loss = 2.4219311950728297, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 71, train_loss = 2.397006490267813, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 72, train_loss = 2.3720759875141084, train_acc = 0.996506753609688\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 73, train_loss = 2.347972380463034, train_acc = 0.996506753609688\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 74, train_loss = 2.325289885047823, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 75, train_loss = 2.3030463536269963, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 76, train_loss = 2.2809172477573156, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 77, train_loss = 2.260127972345799, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 78, train_loss = 2.238692465238273, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 79, train_loss = 2.2195383268408477, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 80, train_loss = 2.200246599968523, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 81, train_loss = 2.181477121543139, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 82, train_loss = 2.1630340139381588, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 83, train_loss = 2.1449040598236024, train_acc = 0.9968560782487191\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 84, train_loss = 2.127221549395472, train_acc = 0.9968560782487191\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 85, train_loss = 2.110849025659263, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 86, train_loss = 2.0941938371397555, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 87, train_loss = 2.0777088524773717, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 88, train_loss = 2.062115019187331, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 89, train_loss = 2.0469314716756344, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 90, train_loss = 2.032345689833164, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 91, train_loss = 2.0180947026237845, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 92, train_loss = 2.0035723824985325, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 93, train_loss = 1.9886076883412898, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 94, train_loss = 1.9751593731343746, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 95, train_loss = 1.9609327432699502, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 96, train_loss = 1.9487703484483063, train_acc = 0.9968560782487191\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 97, train_loss = 1.9359410163015127, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 98, train_loss = 1.9238370803650469, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 99, train_loss = 1.9117972953245044, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 100, train_loss = 1.9003620112780482, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 101, train_loss = 1.8882856715936214, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 102, train_loss = 1.876797111472115, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 103, train_loss = 1.8667680909857154, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 104, train_loss = 1.8556815150659531, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 105, train_loss = 1.8452836305368692, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 106, train_loss = 1.8347107600420713, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 107, train_loss = 1.8247560251038522, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 108, train_loss = 1.8143856702372432, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 109, train_loss = 1.8051582460757345, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 110, train_loss = 1.7954033275600523, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 111, train_loss = 1.786636286182329, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 112, train_loss = 1.7766795114148408, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 113, train_loss = 1.7679835287854075, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 114, train_loss = 1.759260382503271, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 115, train_loss = 1.7504323075991124, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 116, train_loss = 1.741801449097693, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 117, train_loss = 1.7325684016104788, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 118, train_loss = 1.7251908502075821, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 119, train_loss = 1.7165287083480507, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 120, train_loss = 1.7084214256610721, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 121, train_loss = 1.7003811514005065, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 122, train_loss = 1.6927571098785847, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 123, train_loss = 1.6854509701952338, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 124, train_loss = 1.6779909587930888, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 125, train_loss = 1.670384437777102, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 126, train_loss = 1.6634296693373471, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 127, train_loss = 1.6555938050150871, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 128, train_loss = 1.6491184260230511, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 129, train_loss = 1.64164535026066, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 130, train_loss = 1.635384818771854, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 131, train_loss = 1.627392597263679, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 132, train_loss = 1.6214013798162341, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 133, train_loss = 1.6144266680348665, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 134, train_loss = 1.6078956841956824, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 135, train_loss = 1.6015247202012688, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 136, train_loss = 1.5949535891413689, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 137, train_loss = 1.5894936386030167, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 138, train_loss = 1.5831263409927487, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 139, train_loss = 1.576885887188837, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 140, train_loss = 1.570981671800837, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 141, train_loss = 1.5657482652459294, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 142, train_loss = 1.5595653045456856, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 143, train_loss = 1.5544866856653243, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 144, train_loss = 1.5484839715063572, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 145, train_loss = 1.5432095548603684, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 146, train_loss = 1.5385084098670632, train_acc = 0.9970889613414066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 147, train_loss = 1.5332045510876924, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 148, train_loss = 1.5276825150940567, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 149, train_loss = 1.5222638335544616, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 150, train_loss = 1.5177340728696436, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 151, train_loss = 1.512447243789211, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 152, train_loss = 1.507624718011357, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 153, train_loss = 1.502605739980936, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 154, train_loss = 1.4977565376320854, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 155, train_loss = 1.4936082946369424, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 156, train_loss = 1.4884977118344977, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 157, train_loss = 1.483593360055238, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 158, train_loss = 1.4803317193873227, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 159, train_loss = 1.4750939826481044, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 160, train_loss = 1.4706593891605735, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 161, train_loss = 1.4667009696131572, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 162, train_loss = 1.4623115351423621, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 163, train_loss = 1.45803719421383, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 164, train_loss = 1.4542797962203622, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 165, train_loss = 1.4500098914140835, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 166, train_loss = 1.4453282578615472, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 167, train_loss = 1.441801437176764, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 168, train_loss = 1.4379964402178302, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 169, train_loss = 1.4340806639520451, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 170, train_loss = 1.429917587316595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 171, train_loss = 1.4259963989024982, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 172, train_loss = 1.4222774481168017, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 173, train_loss = 1.4191893112147227, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 174, train_loss = 1.415051816846244, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 175, train_loss = 1.4116269699297845, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 176, train_loss = 1.40714714769274, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 177, train_loss = 1.4048986709676683, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 178, train_loss = 1.4008965427055955, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 179, train_loss = 1.3970481205033138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 180, train_loss = 1.393894357723184, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 181, train_loss = 1.389917929074727, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 182, train_loss = 1.386701830313541, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 183, train_loss = 1.383581508998759, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 184, train_loss = 1.380340097937733, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 185, train_loss = 1.3775221250252798, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 186, train_loss = 1.3739636187674478, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 187, train_loss = 1.37058163236361, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 188, train_loss = 1.368081548716873, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 189, train_loss = 1.3637653840705752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 190, train_loss = 1.3618463352322578, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 191, train_loss = 1.3574363143416122, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 192, train_loss = 1.3557244990952313, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 193, train_loss = 1.350706484168768, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 194, train_loss = 1.3493721634149551, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 195, train_loss = 1.345987102133222, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 196, train_loss = 1.3431430893251672, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 197, train_loss = 1.3405829773982987, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 198, train_loss = 1.337051501381211, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 199, train_loss = 1.3347396593308076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 200, train_loss = 1.3319244218291715, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 201, train_loss = 1.329195488593541, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 202, train_loss = 1.325567886698991, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 203, train_loss = 1.3234158746199682, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 204, train_loss = 1.3202006849460304, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 205, train_loss = 1.3183433905942366, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 206, train_loss = 1.3143993392586708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 207, train_loss = 1.3130267090164125, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 208, train_loss = 1.3096342141507193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 209, train_loss = 1.3073406199691817, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 210, train_loss = 1.304837720002979, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 211, train_loss = 1.3015318900579587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 212, train_loss = 1.2999482215382159, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 213, train_loss = 1.2967456561746076, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 214, train_loss = 1.2945688428590074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 215, train_loss = 1.2925246845697984, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 216, train_loss = 1.2901936215348542, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 217, train_loss = 1.2867795223137364, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 218, train_loss = 1.2851337344618514, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 219, train_loss = 1.2829723175382242, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 220, train_loss = 1.2806296393973753, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 221, train_loss = 1.2777962564723566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 222, train_loss = 1.275687993504107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 223, train_loss = 1.2723264881642535, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 224, train_loss = 1.2716033030301332, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 225, train_loss = 1.2677057309774682, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 226, train_loss = 1.2663490502163768, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 227, train_loss = 1.2640550747746602, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 228, train_loss = 1.2627035351470113, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 229, train_loss = 1.2593128682347015, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 230, train_loss = 1.258214070345275, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 231, train_loss = 1.255715168081224, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 232, train_loss = 1.2532864097738639, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 233, train_loss = 1.2511910903267562, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 234, train_loss = 1.2493675231235102, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 235, train_loss = 1.2471508315065876, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 236, train_loss = 1.2442939248867333, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 237, train_loss = 1.2430042237974703, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 238, train_loss = 1.2414546385407448, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 239, train_loss = 1.2385103208944201, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 240, train_loss = 1.2371181771159172, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 241, train_loss = 1.2345918685896322, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 242, train_loss = 1.233012594631873, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 243, train_loss = 1.2306356425397098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 244, train_loss = 1.2286096159368753, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 245, train_loss = 1.2264168037218042, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 246, train_loss = 1.2257750928401947, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 247, train_loss = 1.2232750402763486, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 248, train_loss = 1.2218721502576955, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 249, train_loss = 1.21922285790788, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 250, train_loss = 1.2173241793061607, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 251, train_loss = 1.2158800617908128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 252, train_loss = 1.2138956796261482, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 253, train_loss = 1.2122166527551599, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 254, train_loss = 1.2106448888662271, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 255, train_loss = 1.2082504064892419, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 256, train_loss = 1.2068310186150484, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 257, train_loss = 1.2053038307349198, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 258, train_loss = 1.2037397688254714, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 259, train_loss = 1.2019361667335033, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 260, train_loss = 1.1989903077483177, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 261, train_loss = 1.1974500892683864, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 262, train_loss = 1.1959799111937173, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 263, train_loss = 1.193674690730404, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 264, train_loss = 1.1922040099161677, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 265, train_loss = 1.1898126917076297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 266, train_loss = 1.1882762204040773, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 267, train_loss = 1.186173627153039, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 268, train_loss = 1.1843663331237622, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 269, train_loss = 1.1841167759266682, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 270, train_loss = 1.1818473230232485, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 271, train_loss = 1.1803039237856865, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 272, train_loss = 1.178666735359002, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 273, train_loss = 1.1771291554905474, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 274, train_loss = 1.1752598411403596, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 275, train_loss = 1.1740573978167959, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 276, train_loss = 1.172452811151743, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 277, train_loss = 1.171126592613291, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 278, train_loss = 1.168677291367203, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 279, train_loss = 1.1669252181309275, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 280, train_loss = 1.1660044236923568, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 281, train_loss = 1.1640182472765446, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 282, train_loss = 1.163456715468783, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 283, train_loss = 1.1613069467130117, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 284, train_loss = 1.160018281720113, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 285, train_loss = 1.1581524691428058, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 286, train_loss = 1.157238026324194, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 287, train_loss = 1.1557397918659262, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 288, train_loss = 1.1536364685744047, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 289, train_loss = 1.152754689741414, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 290, train_loss = 1.1513962200842798, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 291, train_loss = 1.1490189347532578, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 292, train_loss = 1.148065713699907, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 293, train_loss = 1.146705609105993, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 294, train_loss = 1.1458025124738924, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 295, train_loss = 1.1447055502794683, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 296, train_loss = 1.142617895558942, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 297, train_loss = 1.1410697055980563, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 298, train_loss = 1.1395544344559312, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 299, train_loss = 1.1382589644636028, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 300, train_loss = 1.1377139004762284, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 301, train_loss = 1.1355569924344309, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 302, train_loss = 1.1339731633779593, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 303, train_loss = 1.1330771284992807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 304, train_loss = 1.131468196574133, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 305, train_loss = 1.130282377358526, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 306, train_loss = 1.1290195644833148, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 307, train_loss = 1.1272697509266436, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 308, train_loss = 1.126499306410551, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 309, train_loss = 1.1250873235985637, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 310, train_loss = 1.1237774975597858, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 311, train_loss = 1.1223916481249034, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 312, train_loss = 1.1215771762654185, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 313, train_loss = 1.1198842117446475, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 314, train_loss = 1.1180674815550447, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 315, train_loss = 1.117249812639784, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 316, train_loss = 1.1160939664696343, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 317, train_loss = 1.1141709039802663, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 318, train_loss = 1.1137696746736765, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 319, train_loss = 1.113135252147913, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 320, train_loss = 1.1106496891006827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 321, train_loss = 1.109904188371729, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 322, train_loss = 1.1085479787434451, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 323, train_loss = 1.1073814944247715, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 324, train_loss = 1.1065754086594097, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 325, train_loss = 1.1057565690134652, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 326, train_loss = 1.1038531810045242, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 327, train_loss = 1.1029712480376475, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 328, train_loss = 1.101807159371674, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 329, train_loss = 1.1007684106007218, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 330, train_loss = 1.0999117400497198, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 331, train_loss = 1.0978590799495578, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 332, train_loss = 1.0969019373878837, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 333, train_loss = 1.096200828149449, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 334, train_loss = 1.0945187167380936, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 335, train_loss = 1.0935486030648462, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 336, train_loss = 1.092683895782102, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 337, train_loss = 1.0916076258872636, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 338, train_loss = 1.0903286440297961, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 339, train_loss = 1.08906432549702, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 340, train_loss = 1.088102322712075, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 341, train_loss = 1.0876199209014885, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 342, train_loss = 1.0854699835181236, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 343, train_loss = 1.085441294417251, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 344, train_loss = 1.0836066820775159, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 345, train_loss = 1.0828944630920887, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 346, train_loss = 1.0817144177854061, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 347, train_loss = 1.0803363037412055, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 348, train_loss = 1.0795613434165716, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 349, train_loss = 1.0786492126062512, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 350, train_loss = 1.0774313174188137, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 351, train_loss = 1.0761256885598414, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 352, train_loss = 1.0747976300190203, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 353, train_loss = 1.0748523476650007, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 354, train_loss = 1.0731518026441336, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 355, train_loss = 1.0717570185661316, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 356, train_loss = 1.0710702228243463, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 357, train_loss = 1.069729448587168, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 358, train_loss = 1.0685200651059859, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 359, train_loss = 1.0684470608830452, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 360, train_loss = 1.0665836918051355, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 361, train_loss = 1.065454384952318, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 362, train_loss = 1.0654505363781936, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 363, train_loss = 1.0640354181523435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 364, train_loss = 1.0629681255668402, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 365, train_loss = 1.0624344699899666, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 366, train_loss = 1.0611747587099671, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 367, train_loss = 1.0596684906631708, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 368, train_loss = 1.0589163266122341, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 369, train_loss = 1.0583026471431367, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 370, train_loss = 1.0572851744364016, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 371, train_loss = 1.056078505993355, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 372, train_loss = 1.0551086086779833, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 373, train_loss = 1.0542347859591246, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 374, train_loss = 1.0535053545609117, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 375, train_loss = 1.0522103803232312, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 376, train_loss = 1.0519537326763384, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 377, train_loss = 1.0504513407940976, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 378, train_loss = 1.049306391098071, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 379, train_loss = 1.0489671643008478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 380, train_loss = 1.0478101003100164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 381, train_loss = 1.046979836479295, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 382, train_loss = 1.045964252203703, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 383, train_loss = 1.0453668578411452, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 384, train_loss = 1.0443362003716175, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 385, train_loss = 1.0435899946314748, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 386, train_loss = 1.0423551285639405, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 387, train_loss = 1.0416782035899814, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 388, train_loss = 1.040183572418755, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 389, train_loss = 1.0399993651953992, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 390, train_loss = 1.0385046862065792, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 391, train_loss = 1.0385710739938077, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 392, train_loss = 1.0368049979733769, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 393, train_loss = 1.036251733690733, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 394, train_loss = 1.035468552261591, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 395, train_loss = 1.0345941418781877, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 396, train_loss = 1.0338280256837606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 397, train_loss = 1.0329435014573392, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 398, train_loss = 1.0317764300853014, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 399, train_loss = 1.030838704056805, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 400, train_loss = 1.030803482979536, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 401, train_loss = 1.0292717969568912, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 402, train_loss = 1.028676704823738, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 403, train_loss = 1.0280125457793474, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 404, train_loss = 1.0267487401142716, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 405, train_loss = 1.0265509122982621, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 406, train_loss = 1.0245301183313131, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 407, train_loss = 1.0250469359161798, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 408, train_loss = 1.0234585159050766, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 409, train_loss = 1.0232309146376792, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 410, train_loss = 1.0221211717871483, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 411, train_loss = 1.0217133658006787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 412, train_loss = 1.0205614088627044, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 413, train_loss = 1.0198393162863795, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 414, train_loss = 1.0187593586742878, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 415, train_loss = 1.0183629145321902, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 416, train_loss = 1.0172965958190616, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 417, train_loss = 1.0165251813305076, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 418, train_loss = 1.0161888503062073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 419, train_loss = 1.0150097139703576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 420, train_loss = 1.0143252570705954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 421, train_loss = 1.0132865126652177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 422, train_loss = 1.0131848907622043, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 423, train_loss = 1.011727114819223, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 424, train_loss = 1.011678697541356, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 425, train_loss = 1.0107616301102098, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 426, train_loss = 1.0094470980984624, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 427, train_loss = 1.0090361215698067, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 428, train_loss = 1.0084269167855382, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 429, train_loss = 1.007358313538134, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 430, train_loss = 1.0069506155850831, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 431, train_loss = 1.006334067642456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 432, train_loss = 1.005535434000194, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 433, train_loss = 1.0048215854912996, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 434, train_loss = 1.0036995684204157, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 435, train_loss = 1.0033115927653853, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 436, train_loss = 1.0023150841298047, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 437, train_loss = 1.0018622701463755, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 438, train_loss = 1.0004950358124916, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 439, train_loss = 1.0006606448441744, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 440, train_loss = 0.9994361068529543, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 441, train_loss = 0.9989778005110566, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 442, train_loss = 0.9984029711631592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 443, train_loss = 0.9981163768097758, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 444, train_loss = 0.9963118002342526, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 445, train_loss = 0.9962806062249001, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 446, train_loss = 0.9951154372247402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 447, train_loss = 0.9946034019812942, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 448, train_loss = 0.9939277718367521, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 449, train_loss = 0.9935151130484883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 450, train_loss = 0.99194104471826, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 451, train_loss = 0.9922349012049381, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 452, train_loss = 0.991086987167364, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 453, train_loss = 0.9905236059275921, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 454, train_loss = 0.9902872663515154, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 455, train_loss = 0.9890068430977408, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 456, train_loss = 0.9887656066566706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 457, train_loss = 0.9874724457040429, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 458, train_loss = 0.9875536278414074, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 459, train_loss = 0.9864079408871476, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 460, train_loss = 0.9858463720011059, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 461, train_loss = 0.9850736353546381, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 462, train_loss = 0.9853581581264734, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 463, train_loss = 0.9836476979253348, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 464, train_loss = 0.9833594647643622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 465, train_loss = 0.9822770087048411, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 466, train_loss = 0.9827117730455939, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 467, train_loss = 0.9809940342383925, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 468, train_loss = 0.9803461063129362, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 469, train_loss = 0.9798138734477106, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 470, train_loss = 0.9799453479645308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 471, train_loss = 0.9788100461883005, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 472, train_loss = 0.9779711548762862, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 473, train_loss = 0.9782112818211317, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 474, train_loss = 0.9769947901368141, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 475, train_loss = 0.9757513847725932, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 476, train_loss = 0.9763865886779968, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 477, train_loss = 0.9750407645478845, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 478, train_loss = 0.9738453260215465, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 479, train_loss = 0.9740139143541455, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 480, train_loss = 0.9727693162858486, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 481, train_loss = 0.9730377501400653, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 482, train_loss = 0.9716917928308249, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 483, train_loss = 0.9713154661876615, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 484, train_loss = 0.9697171474399511, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 485, train_loss = 0.970965632237494, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 486, train_loss = 0.9697068221867085, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 487, train_loss = 0.9682626888679806, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 488, train_loss = 0.9683227414789144, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 489, train_loss = 0.9673054075392429, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 490, train_loss = 0.9674612218514085, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 491, train_loss = 0.9659725089150015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 492, train_loss = 0.9662104581075255, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 493, train_loss = 0.964475049637258, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 494, train_loss = 0.9646925513225142, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 495, train_loss = 0.9634371288120747, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 496, train_loss = 0.9638328583387192, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 497, train_loss = 0.9623122336342931, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 498, train_loss = 0.9630624397250358, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 499, train_loss = 0.961198914796114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████▉                                                    | 8/30 [1:19:32<3:39:27, 598.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "9th- epoch: 0, train_loss = 124.46605522930622, train_acc = 0.7624592454587797\n",
      "test Acc 0.8733705772811918:\n",
      "9th- epoch: 1, train_loss = 44.577378414571285, train_acc = 0.9118537494177923\n",
      "test Acc 0.9162011173184358:\n",
      "9th- epoch: 2, train_loss = 32.38711951673031, train_acc = 0.9386353050768514\n",
      "test Acc 0.9348230912476723:\n",
      "9th- epoch: 3, train_loss = 26.2661728002131, train_acc = 0.9501630181648812\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 4, train_loss = 22.34255894087255, train_acc = 0.9558686539357243\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 5, train_loss = 19.528276009485126, train_acc = 0.9614578481602236\n",
      "test Acc 0.9529795158286778:\n",
      "9th- epoch: 6, train_loss = 17.395698821172118, train_acc = 0.9659990684676293\n",
      "test Acc 0.9539106145251397:\n",
      "9th- epoch: 7, train_loss = 15.709278462454677, train_acc = 0.9693758733115976\n",
      "test Acc 0.957635009310987:\n",
      "9th- epoch: 8, train_loss = 14.32805103622377, train_acc = 0.9724033535165347\n",
      "test Acc 0.9599627560521415:\n",
      "9th- epoch: 9, train_loss = 13.151148302480578, train_acc = 0.9749650675360969\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 10, train_loss = 12.151364244520664, train_acc = 0.9774103400093154\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 11, train_loss = 11.284326551482081, train_acc = 0.9791569632044713\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 12, train_loss = 10.517870254814625, train_acc = 0.9803213786679087\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 13, train_loss = 9.838680031709373, train_acc = 0.9813693525850024\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 14, train_loss = 9.228081900626421, train_acc = 0.9825337680484397\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 15, train_loss = 8.683216478675604, train_acc = 0.9838146250582208\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 16, train_loss = 8.193678689189255, train_acc = 0.9843968327899395\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 17, train_loss = 7.751485128886998, train_acc = 0.9856776897997206\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 18, train_loss = 7.350027066655457, train_acc = 0.9868421052631579\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 19, train_loss = 6.987051345407963, train_acc = 0.9873078714485328\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 20, train_loss = 6.655164767988026, train_acc = 0.9882394038192828\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 21, train_loss = 6.349493335932493, train_acc = 0.9887051700046576\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 22, train_loss = 6.0691431341692805, train_acc = 0.98940381928272\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 23, train_loss = 5.812047444283962, train_acc = 0.9892873777363763\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 24, train_loss = 5.574035081081092, train_acc = 0.9896367023754076\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 25, train_loss = 5.355178028345108, train_acc = 0.9901024685607824\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 26, train_loss = 5.152543153613806, train_acc = 0.9909175593851887\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 27, train_loss = 4.966284752823412, train_acc = 0.9913833255705635\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 28, train_loss = 4.796596714295447, train_acc = 0.9917326502095948\n",
      "test Acc 0.9720670391061452:\n",
      "9th- epoch: 29, train_loss = 4.63821719866246, train_acc = 0.9926641825803446\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 30, train_loss = 4.49420868139714, train_acc = 0.9928970656730322\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 31, train_loss = 4.359853493981063, train_acc = 0.9932463903120633\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 32, train_loss = 4.234106842894107, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 33, train_loss = 4.118758594151586, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 34, train_loss = 4.0100757628679276, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 35, train_loss = 3.908379611093551, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 36, train_loss = 3.8135201721452177, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 37, train_loss = 3.7233437807299197, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 38, train_loss = 3.6378433755598962, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 39, train_loss = 3.555468061938882, train_acc = 0.9951094550535631\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 40, train_loss = 3.4798080255277455, train_acc = 0.9951094550535631\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 41, train_loss = 3.409022802952677, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 42, train_loss = 3.34261984936893, train_acc = 0.9954587796925943\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 43, train_loss = 3.278803421650082, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 44, train_loss = 3.2179272486828268, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 45, train_loss = 3.1591775217093527, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 46, train_loss = 3.104267105460167, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 47, train_loss = 3.0518292323686182, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 48, train_loss = 3.000363455619663, train_acc = 0.9959245458779693\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 49, train_loss = 2.953189379069954, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 50, train_loss = 2.907694350928068, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 51, train_loss = 2.863034561276436, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 52, train_loss = 2.821538237389177, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 53, train_loss = 2.781282062176615, train_acc = 0.996506753609688\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 54, train_loss = 2.7430468746460974, train_acc = 0.9966231951560317\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 55, train_loss = 2.7055723443627357, train_acc = 0.9966231951560317\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 56, train_loss = 2.6700599580071867, train_acc = 0.9966231951560317\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 57, train_loss = 2.636535023804754, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 58, train_loss = 2.602690252009779, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 59, train_loss = 2.571237973868847, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "9th- epoch: 60, train_loss = 2.539254279108718, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "9th- epoch: 61, train_loss = 2.5095186084508896, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 62, train_loss = 2.480844024568796, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 63, train_loss = 2.452375168679282, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 64, train_loss = 2.4262591165024787, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 65, train_loss = 2.4005893617868423, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 66, train_loss = 2.375195204047486, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 67, train_loss = 2.3518804262857884, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 68, train_loss = 2.3277906489092857, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 69, train_loss = 2.305036274017766, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 70, train_loss = 2.2829409677069634, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 71, train_loss = 2.2617205802816898, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 72, train_loss = 2.2408787049353123, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 73, train_loss = 2.2201556402724236, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 74, train_loss = 2.201140580000356, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 75, train_loss = 2.1814077843446285, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 76, train_loss = 2.1628587197046727, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 77, train_loss = 2.1452240955550224, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 78, train_loss = 2.127482682466507, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 79, train_loss = 2.109493811847642, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 80, train_loss = 2.0929093796294183, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 81, train_loss = 2.0761862595099956, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 82, train_loss = 2.0587725390214473, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 83, train_loss = 2.043436298845336, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 84, train_loss = 2.0271372322458774, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 85, train_loss = 2.0125393148045987, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 86, train_loss = 1.9982785482425243, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 87, train_loss = 1.9845516569912434, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 88, train_loss = 1.9711300556082278, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 89, train_loss = 1.9573473185300827, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 90, train_loss = 1.9447280105669051, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 91, train_loss = 1.9322821411769837, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 92, train_loss = 1.9193021331448108, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 93, train_loss = 1.9076732422690839, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 94, train_loss = 1.8958671540021896, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 95, train_loss = 1.8841603447217494, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 96, train_loss = 1.8729745410382748, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 97, train_loss = 1.8618986457586288, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 98, train_loss = 1.850476970197633, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 99, train_loss = 1.840021972777322, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 100, train_loss = 1.829829167574644, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 101, train_loss = 1.8199326756875962, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 102, train_loss = 1.8096952848136425, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 103, train_loss = 1.8002839908003807, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 104, train_loss = 1.7896596925565973, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 105, train_loss = 1.7807566287228838, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 106, train_loss = 1.771066072047688, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 107, train_loss = 1.7624510625610128, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 108, train_loss = 1.7536759612848982, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 109, train_loss = 1.7457324551651254, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 110, train_loss = 1.7359447503695264, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 111, train_loss = 1.7278790846467018, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 112, train_loss = 1.720261955051683, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 113, train_loss = 1.7114510399987921, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 114, train_loss = 1.7043928107013926, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 115, train_loss = 1.69604864588473, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 116, train_loss = 1.6887838579714298, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 117, train_loss = 1.681455938727595, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 118, train_loss = 1.674625581712462, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 119, train_loss = 1.6665915586054325, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 120, train_loss = 1.660203617066145, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 121, train_loss = 1.6526074968278408, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 122, train_loss = 1.6453831009566784, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 123, train_loss = 1.6393804313847795, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 124, train_loss = 1.632630160660483, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 125, train_loss = 1.6249458777019754, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 126, train_loss = 1.6192083669593558, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 127, train_loss = 1.6129971543559805, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 128, train_loss = 1.6063133627176285, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 129, train_loss = 1.6007988887140527, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 130, train_loss = 1.5943690625717863, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 131, train_loss = 1.588529497385025, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 132, train_loss = 1.582901711226441, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 133, train_loss = 1.576634954661131, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 134, train_loss = 1.5717474991688505, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 135, train_loss = 1.566225577145815, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 136, train_loss = 1.560273057431914, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 137, train_loss = 1.5557668072870001, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 138, train_loss = 1.5501765223452821, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 139, train_loss = 1.5443312004208565, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 140, train_loss = 1.5394949415931478, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 141, train_loss = 1.5345028204610571, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 142, train_loss = 1.5295742539456114, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 143, train_loss = 1.5248320177197456, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 144, train_loss = 1.5199182530632243, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 145, train_loss = 1.5149842550745234, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 146, train_loss = 1.5100203392794356, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 147, train_loss = 1.5053991489112377, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 148, train_loss = 1.5011304741492495, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 149, train_loss = 1.4964932227740064, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 150, train_loss = 1.4924353323876858, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 151, train_loss = 1.487904561101459, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 152, train_loss = 1.4833816947648302, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 153, train_loss = 1.4791512874653563, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 154, train_loss = 1.4750253682723269, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 155, train_loss = 1.4704010114073753, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 156, train_loss = 1.4664219518890604, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 157, train_loss = 1.4620867557823658, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 158, train_loss = 1.4586915709078312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 159, train_loss = 1.4542052360484377, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 160, train_loss = 1.4505097965011373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 161, train_loss = 1.4461586587131023, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 162, train_loss = 1.442050932557322, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 163, train_loss = 1.4389765175292268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 164, train_loss = 1.4342673160135746, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 165, train_loss = 1.4313265731325373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 166, train_loss = 1.427032077102922, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 167, train_loss = 1.4240161353955045, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 168, train_loss = 1.4196190709481016, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 169, train_loss = 1.4165950367460027, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 170, train_loss = 1.4128819158067927, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 171, train_loss = 1.4094680336420424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 172, train_loss = 1.4053518759901635, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 173, train_loss = 1.4023689801688306, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 174, train_loss = 1.3990518935024738, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 175, train_loss = 1.3954992679064162, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 176, train_loss = 1.3924415782094002, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 177, train_loss = 1.3889215191011317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 178, train_loss = 1.3858893476426601, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 179, train_loss = 1.3826110449736007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 180, train_loss = 1.379352091520559, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 181, train_loss = 1.376007477461826, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 182, train_loss = 1.37363813072443, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 183, train_loss = 1.3698030337691307, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 184, train_loss = 1.3673830057377927, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 185, train_loss = 1.363579920202028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 186, train_loss = 1.3616719928686507, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 187, train_loss = 1.3580716376309283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 188, train_loss = 1.355283748358488, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 189, train_loss = 1.3519870080053806, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 190, train_loss = 1.3499469086527824, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 191, train_loss = 1.346274769573938, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 192, train_loss = 1.3435426987707615, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 193, train_loss = 1.3407102736528032, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 194, train_loss = 1.337960311502684, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 195, train_loss = 1.3354038509423845, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 196, train_loss = 1.3329983949661255, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 197, train_loss = 1.3295285589993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 198, train_loss = 1.3275455869734287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 199, train_loss = 1.3245805079932325, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 200, train_loss = 1.3218940223450772, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 201, train_loss = 1.318676296621561, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 202, train_loss = 1.3168925295467488, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 203, train_loss = 1.3140516231651418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 204, train_loss = 1.3117144865100272, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 205, train_loss = 1.3086686407332309, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 206, train_loss = 1.3066936532850377, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 207, train_loss = 1.3035396176273935, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 208, train_loss = 1.301622413098812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 209, train_loss = 1.2988293282687664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 210, train_loss = 1.2965593611006625, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 211, train_loss = 1.2939635254442692, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 212, train_loss = 1.292095762968529, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 213, train_loss = 1.2893082934315316, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 214, train_loss = 1.2871589101850986, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 215, train_loss = 1.2845830011065118, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 216, train_loss = 1.2829681734438054, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 217, train_loss = 1.2797900177538395, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 218, train_loss = 1.2777034230530262, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 219, train_loss = 1.2759300991892815, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 220, train_loss = 1.2737666070461273, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 221, train_loss = 1.2708700734074228, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 222, train_loss = 1.2693488858640194, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 223, train_loss = 1.2668580536847003, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 224, train_loss = 1.2639972033794038, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 225, train_loss = 1.2623823161120526, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 226, train_loss = 1.2602587516303174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 227, train_loss = 1.2586008596117608, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 228, train_loss = 1.2558725476264954, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 229, train_loss = 1.2542371489107609, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 230, train_loss = 1.252056637138594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 231, train_loss = 1.2502438227529638, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 232, train_loss = 1.247680010914337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 233, train_loss = 1.2460171070997603, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 234, train_loss = 1.24331747245742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 235, train_loss = 1.24195747327758, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 236, train_loss = 1.2398543407325633, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 237, train_loss = 1.237968320667278, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 238, train_loss = 1.2359562031924725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 239, train_loss = 1.2341628819704056, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 240, train_loss = 1.2318509717588313, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 241, train_loss = 1.2301150995190255, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 242, train_loss = 1.2284365631639957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 243, train_loss = 1.2263604042236693, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 244, train_loss = 1.2247481855447404, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 245, train_loss = 1.2223238609731197, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 246, train_loss = 1.220981940627098, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 247, train_loss = 1.218769807368517, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 248, train_loss = 1.2170950410072692, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 249, train_loss = 1.2156746188993566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 250, train_loss = 1.2133176016504876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 251, train_loss = 1.21181895211339, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 252, train_loss = 1.209914690523874, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 253, train_loss = 1.208112598687876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 254, train_loss = 1.2067580074071884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 255, train_loss = 1.204369364946615, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 256, train_loss = 1.2032064485247247, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 257, train_loss = 1.2013781294226646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 258, train_loss = 1.19947750371648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 259, train_loss = 1.1974377346341498, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 260, train_loss = 1.196789228648413, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 261, train_loss = 1.1946539345080964, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 262, train_loss = 1.1928591541945934, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 263, train_loss = 1.1910019405186176, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 264, train_loss = 1.189500740438234, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 265, train_loss = 1.1880506724119186, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 266, train_loss = 1.186642384796869, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 267, train_loss = 1.1844727483694442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 268, train_loss = 1.1833542523090728, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 269, train_loss = 1.1817055009305477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 270, train_loss = 1.1795862416620366, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 271, train_loss = 1.178670308261644, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 272, train_loss = 1.1768566854298115, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 273, train_loss = 1.1756418931181543, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 274, train_loss = 1.173263578384649, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 275, train_loss = 1.172114148736, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 276, train_loss = 1.170703829586273, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 277, train_loss = 1.1688612637517508, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 278, train_loss = 1.1674853948352393, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 279, train_loss = 1.1657245618698653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 280, train_loss = 1.1645046534540597, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 281, train_loss = 1.1631861850619316, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 282, train_loss = 1.161677461117506, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 283, train_loss = 1.160013124346733, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 284, train_loss = 1.1589879281818867, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 285, train_loss = 1.1568474595842417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 286, train_loss = 1.1557477178575937, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 287, train_loss = 1.1547321639955044, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 288, train_loss = 1.1529315039515495, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 289, train_loss = 1.1517925088701304, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 290, train_loss = 1.1503576512041036, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 291, train_loss = 1.1491177591087762, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 292, train_loss = 1.147768136113882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 293, train_loss = 1.1463552353379782, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 294, train_loss = 1.1445596404373646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 295, train_loss = 1.1429910746810492, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 296, train_loss = 1.1423275185225066, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 297, train_loss = 1.1404941578803118, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 298, train_loss = 1.1395179728569929, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 299, train_loss = 1.137210233748192, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 300, train_loss = 1.1365772845747415, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 301, train_loss = 1.135952460259432, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 302, train_loss = 1.1336418154241983, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 303, train_loss = 1.1327551504073199, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 304, train_loss = 1.1310968498291913, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 305, train_loss = 1.129410774767166, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 306, train_loss = 1.1290940145554487, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 307, train_loss = 1.1273413822054863, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 308, train_loss = 1.126440729945898, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 309, train_loss = 1.1248516092600767, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 310, train_loss = 1.123491427541012, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 311, train_loss = 1.1221665205957834, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 312, train_loss = 1.1212034026684705, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 313, train_loss = 1.1196049141290132, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 314, train_loss = 1.1190331541001797, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 315, train_loss = 1.1170123082993086, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 316, train_loss = 1.1158001273870468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 317, train_loss = 1.1150068119168282, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 318, train_loss = 1.1136008737084921, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 319, train_loss = 1.1123871691524982, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 320, train_loss = 1.111547057837015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 321, train_loss = 1.1097476805152837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 322, train_loss = 1.1090766924025957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 323, train_loss = 1.1075478568673134, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 324, train_loss = 1.1063120886683464, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 325, train_loss = 1.1054100319743156, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 326, train_loss = 1.1041306729021017, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 327, train_loss = 1.1033139204082545, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 328, train_loss = 1.1020930955710355, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 329, train_loss = 1.1003457965853158, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 330, train_loss = 1.0995623792114202, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 331, train_loss = 1.0987076250312384, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 332, train_loss = 1.0972488733532373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 333, train_loss = 1.0962511127290782, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 334, train_loss = 1.0953710252942983, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 335, train_loss = 1.0938027488591615, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 336, train_loss = 1.092778243124485, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 337, train_loss = 1.0923216082155704, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 338, train_loss = 1.0906975964608137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 339, train_loss = 1.0896660623548087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 340, train_loss = 1.088705317437416, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 341, train_loss = 1.0877009568212088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 342, train_loss = 1.0868104882538319, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 343, train_loss = 1.0851127853093203, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 344, train_loss = 1.084395286947256, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 345, train_loss = 1.0829111536440905, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 346, train_loss = 1.0824022702872753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 347, train_loss = 1.080759584903717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 348, train_loss = 1.0803311057388783, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 349, train_loss = 1.0786879671213683, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 350, train_loss = 1.0783954933285713, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 351, train_loss = 1.0762395014462527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 352, train_loss = 1.0759960400464479, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 353, train_loss = 1.0745945386588573, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 354, train_loss = 1.0740488866867963, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 355, train_loss = 1.0723894672992174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 356, train_loss = 1.0720501306059305, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 357, train_loss = 1.0699646932480391, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 358, train_loss = 1.070291625946993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 359, train_loss = 1.068792181700701, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 360, train_loss = 1.0679741837084293, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 361, train_loss = 1.0665059002640191, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 362, train_loss = 1.0659336695971433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 363, train_loss = 1.0650561042129993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 364, train_loss = 1.0636793027224485, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 365, train_loss = 1.0629603937268257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 366, train_loss = 1.0611616311070975, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 367, train_loss = 1.0613912269473076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 368, train_loss = 1.0603291007282678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 369, train_loss = 1.0595033131539822, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 370, train_loss = 1.0578440738318022, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 371, train_loss = 1.0575249530375004, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 372, train_loss = 1.0559406330285128, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 373, train_loss = 1.0550960662367288, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 374, train_loss = 1.0543715742824133, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 375, train_loss = 1.0531269113125745, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 376, train_loss = 1.052553929388523, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 377, train_loss = 1.0516526574792806, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 378, train_loss = 1.0497217712400015, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 379, train_loss = 1.0498604737222195, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 380, train_loss = 1.049010987073416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 381, train_loss = 1.0477206284704152, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 382, train_loss = 1.0469051972031593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 383, train_loss = 1.0460183160903398, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 384, train_loss = 1.044824082404375, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 385, train_loss = 1.0439631268382072, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 386, train_loss = 1.0438978833553847, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 387, train_loss = 1.0424740798771381, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 388, train_loss = 1.0413268556294497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 389, train_loss = 1.0401459944841918, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 390, train_loss = 1.0386649357678834, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 391, train_loss = 1.0374936101434287, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 392, train_loss = 1.036966998130083, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 393, train_loss = 1.035670535027748, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 394, train_loss = 1.0343036241829395, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 395, train_loss = 1.033290440827841, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 396, train_loss = 1.0328494211134966, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 397, train_loss = 1.0317644154129084, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 398, train_loss = 1.0307985035178717, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 399, train_loss = 1.030148042977089, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 400, train_loss = 1.028909853339428, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 401, train_loss = 1.0281291281280573, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 402, train_loss = 1.027999742567772, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 403, train_loss = 1.0263759978115559, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 404, train_loss = 1.0263017167744692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 405, train_loss = 1.0248948894441128, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 406, train_loss = 1.0240487208066043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 407, train_loss = 1.0236517041921616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 408, train_loss = 1.0229640901088715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 409, train_loss = 1.021898616105318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 410, train_loss = 1.0216598535480443, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 411, train_loss = 1.0202131643891335, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 412, train_loss = 1.019283402711153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 413, train_loss = 1.0186645574867725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 414, train_loss = 1.0179723861219827, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 415, train_loss = 1.017363482475048, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 416, train_loss = 1.0161256206629332, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 417, train_loss = 1.0155863116087858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 418, train_loss = 1.0150126554071903, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 419, train_loss = 1.0140596739947796, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 420, train_loss = 1.0130040707590524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 421, train_loss = 1.0127599239349365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 422, train_loss = 1.0116311783494893, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 423, train_loss = 1.0113022389414255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 424, train_loss = 1.0096604848804418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 425, train_loss = 1.0092713398189517, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 426, train_loss = 1.0095418405981036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 427, train_loss = 1.0079488803894492, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 428, train_loss = 1.0074663733394118, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 429, train_loss = 1.0061981193721294, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 430, train_loss = 1.006216935813427, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 431, train_loss = 1.00512308254838, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 432, train_loss = 1.004845264062169, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 433, train_loss = 1.003610106810811, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 434, train_loss = 1.002570018172264, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 435, train_loss = 1.0024640783667564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 436, train_loss = 1.000496389970067, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 437, train_loss = 1.0007693419902353, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 438, train_loss = 1.000550590455532, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 439, train_loss = 0.9993966941983672, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 440, train_loss = 0.9982721010892419, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 441, train_loss = 0.9977488120348426, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 442, train_loss = 0.997293350592372, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 443, train_loss = 0.9962318278849125, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 444, train_loss = 0.9956749330012826, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 445, train_loss = 0.9953843553812476, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 446, train_loss = 0.9942541569471359, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 447, train_loss = 0.9937723974435357, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 448, train_loss = 0.992881428450346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 449, train_loss = 0.9919777723698644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 450, train_loss = 0.9923651901335688, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 451, train_loss = 0.9912487541587325, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 452, train_loss = 0.9903742944152327, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 453, train_loss = 0.9895671419799328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 454, train_loss = 0.9888306607754203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 455, train_loss = 0.9880375402717618, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 456, train_loss = 0.9878382869064808, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 457, train_loss = 0.9861620018928079, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 458, train_loss = 0.986137580126524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 459, train_loss = 0.9854968450963497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 460, train_loss = 0.9848293003888102, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 461, train_loss = 0.9839110101311235, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 462, train_loss = 0.9840381356625585, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 463, train_loss = 0.9823952702136012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 464, train_loss = 0.9824047250003787, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 465, train_loss = 0.9816552400588989, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 466, train_loss = 0.9811644926667213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 467, train_loss = 0.9800846402795287, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 468, train_loss = 0.9797622784972191, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 469, train_loss = 0.9789742231369019, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 470, train_loss = 0.9782691200525733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 471, train_loss = 0.9777842114417581, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 472, train_loss = 0.9768886466772528, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 473, train_loss = 0.9764965747745009, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 474, train_loss = 0.9761423977761297, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 475, train_loss = 0.9743710296897916, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 476, train_loss = 0.9752088623790769, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 477, train_loss = 0.9735137435345678, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 478, train_loss = 0.973516737416503, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 479, train_loss = 0.9729739079921274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 480, train_loss = 0.9719143845140934, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 481, train_loss = 0.9710043085069628, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 482, train_loss = 0.9708435907959938, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 483, train_loss = 0.9701217549591092, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 484, train_loss = 0.9699826997966738, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 485, train_loss = 0.9685796859412221, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 486, train_loss = 0.9684021448047133, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 487, train_loss = 0.9680592864751816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 488, train_loss = 0.9671678344457177, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 489, train_loss = 0.9666087801306276, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 490, train_loss = 0.9657088567764731, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 491, train_loss = 0.9653829547314672, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 492, train_loss = 0.9648513942956924, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 493, train_loss = 0.9643345437943935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 494, train_loss = 0.9630869204847841, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 495, train_loss = 0.9632659579365281, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 496, train_loss = 0.9620553379209014, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 497, train_loss = 0.9617557997553376, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 498, train_loss = 0.9612711779773235, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 499, train_loss = 0.9606420646159677, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████████████▎                                                 | 9/30 [1:29:32<3:29:43, 599.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "10th- epoch: 0, train_loss = 129.98318174481392, train_acc = 0.7706101537028411\n",
      "test Acc 0.88268156424581:\n",
      "10th- epoch: 1, train_loss = 42.20667303353548, train_acc = 0.9153469958081043\n",
      "test Acc 0.9241154562383612:\n",
      "10th- epoch: 2, train_loss = 30.88708208873868, train_acc = 0.9420121099208197\n",
      "test Acc 0.9357541899441341:\n",
      "10th- epoch: 3, train_loss = 25.17395945265889, train_acc = 0.9512109920819748\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 4, train_loss = 21.47044638544321, train_acc = 0.9572659524918491\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 5, train_loss = 18.809588346630335, train_acc = 0.9630880298090359\n",
      "test Acc 0.9548417132216015:\n",
      "10th- epoch: 6, train_loss = 16.808982230722904, train_acc = 0.9663483931066604\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 7, train_loss = 15.213304933160543, train_acc = 0.9706567303213787\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 8, train_loss = 13.89226171001792, train_acc = 0.9729855612482534\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 9, train_loss = 12.767418898642063, train_acc = 0.9747321844434094\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 10, train_loss = 11.806328278034925, train_acc = 0.9763623660922217\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 11, train_loss = 10.975242428481579, train_acc = 0.9782254308337215\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 12, train_loss = 10.243176961317658, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 13, train_loss = 9.59986768476665, train_acc = 0.9799720540288775\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 14, train_loss = 9.033981608226895, train_acc = 0.9826502095947834\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 15, train_loss = 8.528771037235856, train_acc = 0.9831159757801584\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 16, train_loss = 8.082441693171859, train_acc = 0.984163949697252\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 17, train_loss = 7.684840241447091, train_acc = 0.9848625989753144\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 18, train_loss = 7.332757947966456, train_acc = 0.985444806707033\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 19, train_loss = 7.007587289437652, train_acc = 0.9867256637168141\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 20, train_loss = 6.712547143921256, train_acc = 0.9873078714485328\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 21, train_loss = 6.4433486722409725, train_acc = 0.9880065207265952\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 22, train_loss = 6.192488884553313, train_acc = 0.9889380530973452\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 23, train_loss = 5.963138286955655, train_acc = 0.9890544946436889\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 24, train_loss = 5.752217759378254, train_acc = 0.9896367023754076\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 25, train_loss = 5.555444766767323, train_acc = 0.9899860270144387\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 26, train_loss = 5.376458128914237, train_acc = 0.9906846762925011\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 27, train_loss = 5.210895720869303, train_acc = 0.9914997671169073\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 28, train_loss = 5.054337691515684, train_acc = 0.9917326502095948\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 29, train_loss = 4.909331482835114, train_acc = 0.9919655333022822\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 30, train_loss = 4.775811254046857, train_acc = 0.9923148579413135\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 31, train_loss = 4.650596145540476, train_acc = 0.9924312994876572\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 32, train_loss = 4.530533327721059, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 33, train_loss = 4.42059797141701, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 34, train_loss = 4.316746805794537, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 35, train_loss = 4.2188547337427735, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 36, train_loss = 4.1267115250229836, train_acc = 0.9933628318584071\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 37, train_loss = 4.037483189254999, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 38, train_loss = 3.954139650799334, train_acc = 0.9933628318584071\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 39, train_loss = 3.8745086453855038, train_acc = 0.9934792734047508\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 40, train_loss = 3.7973707048222423, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 41, train_loss = 3.7245127744972706, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 42, train_loss = 3.656102213077247, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 43, train_loss = 3.5885760076344013, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 44, train_loss = 3.524355229921639, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 45, train_loss = 3.4638983197510242, train_acc = 0.9945272473218444\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 46, train_loss = 3.4050825545564294, train_acc = 0.9945272473218444\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 47, train_loss = 3.349467727355659, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 48, train_loss = 3.294603764079511, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 49, train_loss = 3.2442124993540347, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 50, train_loss = 3.193177028093487, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 51, train_loss = 3.1451045810244977, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 52, train_loss = 3.0996605255641043, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 53, train_loss = 3.054798858705908, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 54, train_loss = 3.0098648578859866, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 55, train_loss = 2.968550252262503, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 56, train_loss = 2.9278707057237625, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 57, train_loss = 2.8890809789299965, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 58, train_loss = 2.8504767827689648, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 59, train_loss = 2.813432302325964, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 60, train_loss = 2.777669684495777, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 61, train_loss = 2.743386012967676, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 62, train_loss = 2.709286832716316, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 63, train_loss = 2.6751402989029884, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 64, train_loss = 2.6435631960630417, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 65, train_loss = 2.611930664628744, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 66, train_loss = 2.58141628280282, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 67, train_loss = 2.5531145646236837, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 68, train_loss = 2.5235756039619446, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 69, train_loss = 2.4960146485827863, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 70, train_loss = 2.467034538742155, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 71, train_loss = 2.442070881370455, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 72, train_loss = 2.414711785968393, train_acc = 0.9962738705170004\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 73, train_loss = 2.389263430144638, train_acc = 0.9962738705170004\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 74, train_loss = 2.364739516284317, train_acc = 0.9962738705170004\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 75, train_loss = 2.341017706785351, train_acc = 0.9962738705170004\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 76, train_loss = 2.318180178757757, train_acc = 0.9962738705170004\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 77, train_loss = 2.295047140214592, train_acc = 0.9962738705170004\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 78, train_loss = 2.2727544545195997, train_acc = 0.9962738705170004\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 79, train_loss = 2.2508099526166916, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 80, train_loss = 2.230806874576956, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 81, train_loss = 2.2104334733448923, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 82, train_loss = 2.191224770154804, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 83, train_loss = 2.1707881740294397, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 84, train_loss = 2.152730909641832, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 85, train_loss = 2.1340398737229407, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 86, train_loss = 2.1158948303200305, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 87, train_loss = 2.097700806800276, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 88, train_loss = 2.080278264824301, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 89, train_loss = 2.062948008533567, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 90, train_loss = 2.047432833816856, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 91, train_loss = 2.0309454649686813, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 92, train_loss = 2.0160972415469587, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 93, train_loss = 2.000228135380894, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 94, train_loss = 1.9850877474527806, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 95, train_loss = 1.9711064212024212, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 96, train_loss = 1.9571707036811858, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 97, train_loss = 1.9441780459601432, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 98, train_loss = 1.9300445679109544, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 99, train_loss = 1.9168600365519524, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 100, train_loss = 1.9036588233429939, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 101, train_loss = 1.8922719918191433, train_acc = 0.9967396367023754\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 102, train_loss = 1.8787154231686145, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 103, train_loss = 1.867610701592639, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 104, train_loss = 1.855979472398758, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 105, train_loss = 1.8438151727896184, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 106, train_loss = 1.833462328882888, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 107, train_loss = 1.8217354479711503, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 108, train_loss = 1.8113853123504668, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 109, train_loss = 1.8005410816986114, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 110, train_loss = 1.7895356118679047, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 111, train_loss = 1.7800681155640632, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 112, train_loss = 1.7697046969551593, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 113, train_loss = 1.7601210412103683, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 114, train_loss = 1.750894858269021, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 115, train_loss = 1.7409542836248875, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 116, train_loss = 1.7318274825811386, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 117, train_loss = 1.7236010804772377, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 118, train_loss = 1.7139886294025928, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 119, train_loss = 1.7061732809524983, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 120, train_loss = 1.6969894245266914, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 121, train_loss = 1.6893363904673606, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 122, train_loss = 1.6809491738677025, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 123, train_loss = 1.673038223059848, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 124, train_loss = 1.6655203513801098, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 125, train_loss = 1.6574778829235584, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 126, train_loss = 1.6494158927816898, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 127, train_loss = 1.6427556823473424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 128, train_loss = 1.6356899428647012, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 129, train_loss = 1.6281142570078373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 130, train_loss = 1.6215636394917965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 131, train_loss = 1.6138886425178498, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 132, train_loss = 1.6074745010118932, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 133, train_loss = 1.600621810881421, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 134, train_loss = 1.5937564224004745, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 135, train_loss = 1.5874592512845993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 136, train_loss = 1.5805965960025787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 137, train_loss = 1.574079666286707, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 138, train_loss = 1.5687081080395728, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 139, train_loss = 1.5620428409893066, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 140, train_loss = 1.55616320297122, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 141, train_loss = 1.5498870834708214, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 142, train_loss = 1.5440800997894257, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 143, train_loss = 1.538551801117137, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 144, train_loss = 1.5329295087140054, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 145, train_loss = 1.5271255436819047, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 146, train_loss = 1.5217109012883157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 147, train_loss = 1.5161171555519104, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 148, train_loss = 1.5106922325212508, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 149, train_loss = 1.5048814564943314, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 150, train_loss = 1.4997709307353944, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 151, train_loss = 1.4945253592450172, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 152, train_loss = 1.4896274183411151, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 153, train_loss = 1.4843153145629913, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 154, train_loss = 1.4796044763643295, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 155, train_loss = 1.4744116750080138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 156, train_loss = 1.4695548478048295, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 157, train_loss = 1.4648838080465794, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 158, train_loss = 1.4603447664994746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 159, train_loss = 1.4555052418727428, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 160, train_loss = 1.4506913770455867, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 161, train_loss = 1.4466869730968028, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 162, train_loss = 1.4419063677778468, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 163, train_loss = 1.4375645531108603, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 164, train_loss = 1.4332784762373194, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 165, train_loss = 1.4288391867885366, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 166, train_loss = 1.4248830737778917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 167, train_loss = 1.4191944934427738, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 168, train_loss = 1.4160886481404305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 169, train_loss = 1.4115628289291635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 170, train_loss = 1.4072773432126269, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 171, train_loss = 1.4036228632321581, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 172, train_loss = 1.3996649967739359, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 173, train_loss = 1.395869949250482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 174, train_loss = 1.3912463895976543, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 175, train_loss = 1.3877334147691727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 176, train_loss = 1.3839406942715868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 177, train_loss = 1.3797378154704347, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 178, train_loss = 1.376129113137722, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 179, train_loss = 1.3727192766964436, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 180, train_loss = 1.369314574985765, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 181, train_loss = 1.3651140531292185, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 182, train_loss = 1.3617109855404124, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 183, train_loss = 1.3584287129342556, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 184, train_loss = 1.3546327663352713, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 185, train_loss = 1.3510919908294454, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 186, train_loss = 1.348219928680919, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 187, train_loss = 1.3445093469927087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 188, train_loss = 1.3412838442018256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 189, train_loss = 1.3380351675441489, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 190, train_loss = 1.3350627111503854, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 191, train_loss = 1.3318758060922846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 192, train_loss = 1.328026389121078, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 193, train_loss = 1.3256534598767757, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 194, train_loss = 1.322047850699164, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 195, train_loss = 1.3192556723952293, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 196, train_loss = 1.3155011497437954, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 197, train_loss = 1.3128171985736117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 198, train_loss = 1.3087862419197336, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 199, train_loss = 1.3063228353857994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 200, train_loss = 1.3030882192542776, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 201, train_loss = 1.3002132015535608, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 202, train_loss = 1.2977231442928314, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 203, train_loss = 1.2945872830459848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 204, train_loss = 1.2917998606571928, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 205, train_loss = 1.2889675808837637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 206, train_loss = 1.2862248407909647, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 207, train_loss = 1.2838919907808304, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 208, train_loss = 1.2805994724621996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 209, train_loss = 1.2784028500318527, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 210, train_loss = 1.276013688533567, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 211, train_loss = 1.2730658315122128, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 212, train_loss = 1.2705446829786524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 213, train_loss = 1.2677243935177103, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 214, train_loss = 1.265839242725633, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 215, train_loss = 1.2628449760377407, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 216, train_loss = 1.2603958087274805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 217, train_loss = 1.2576330974698067, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 218, train_loss = 1.255776796489954, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 219, train_loss = 1.2530679939081892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 220, train_loss = 1.2505183467874303, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 221, train_loss = 1.24854177236557, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 222, train_loss = 1.246033894480206, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 223, train_loss = 1.2433387202909216, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 224, train_loss = 1.2414324519922957, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 225, train_loss = 1.2392211245605722, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 226, train_loss = 1.2366596969077364, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 227, train_loss = 1.234586057602428, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 228, train_loss = 1.2323635393986478, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 229, train_loss = 1.2299373149871826, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 230, train_loss = 1.2282596627483144, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 231, train_loss = 1.2259756190469489, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 232, train_loss = 1.223583921790123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 233, train_loss = 1.2207800758769736, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 234, train_loss = 1.2192967360606417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 235, train_loss = 1.2174842519452795, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 236, train_loss = 1.2150924516608939, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 237, train_loss = 1.2129465466132388, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 238, train_loss = 1.2110688710818067, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 239, train_loss = 1.2087067837128416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 240, train_loss = 1.2071698009967804, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 241, train_loss = 1.2049639634788036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 242, train_loss = 1.203123316168785, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 243, train_loss = 1.2008226501056924, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 244, train_loss = 1.1989824076881632, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 245, train_loss = 1.1973566698143259, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 246, train_loss = 1.1950315149733797, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 247, train_loss = 1.1933178380131721, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 248, train_loss = 1.1910297274589539, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 249, train_loss = 1.1895281808683649, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 250, train_loss = 1.1875302555272356, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 251, train_loss = 1.1857661543181166, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 252, train_loss = 1.1840617445996031, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 253, train_loss = 1.1821410892298445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 254, train_loss = 1.1804938837885857, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 255, train_loss = 1.1785943992435932, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 256, train_loss = 1.1766100252280012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 257, train_loss = 1.175029324949719, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 258, train_loss = 1.1731196977198124, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 259, train_loss = 1.1722599007189274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 260, train_loss = 1.1694607535609975, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 261, train_loss = 1.1687093501677737, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 262, train_loss = 1.166036001057364, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 263, train_loss = 1.1645954549312592, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 264, train_loss = 1.1631180109689012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 265, train_loss = 1.1611047895858064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 266, train_loss = 1.159845918416977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 267, train_loss = 1.158279417664744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 268, train_loss = 1.1562236385652795, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 269, train_loss = 1.1547162595088594, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 270, train_loss = 1.1536800389294513, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 271, train_loss = 1.1513653720612638, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 272, train_loss = 1.1505824985797517, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 273, train_loss = 1.1484216526150703, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 274, train_loss = 1.1466137903626077, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 275, train_loss = 1.1457575907115825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 276, train_loss = 1.1430305913090706, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 277, train_loss = 1.1426992217893712, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 278, train_loss = 1.1403457770938985, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 279, train_loss = 1.1396402629907243, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 280, train_loss = 1.1379949773545377, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 281, train_loss = 1.1355649853940122, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 282, train_loss = 1.13490828871727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 283, train_loss = 1.1328860980574973, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 284, train_loss = 1.1311241437797435, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 285, train_loss = 1.13054758310318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 286, train_loss = 1.1286300607025623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 287, train_loss = 1.1273208297789097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 288, train_loss = 1.1252803827519529, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 289, train_loss = 1.1245631985366344, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 290, train_loss = 1.123230542987585, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 291, train_loss = 1.1212991041247733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 292, train_loss = 1.1195999358897097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 293, train_loss = 1.1191360999946482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 294, train_loss = 1.117806640744675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 295, train_loss = 1.1159077249467373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 296, train_loss = 1.1137818644638173, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 297, train_loss = 1.113015465438366, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 298, train_loss = 1.1120287254452705, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 299, train_loss = 1.1105277240276337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 300, train_loss = 1.1090664826333523, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 301, train_loss = 1.1077298745512962, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 302, train_loss = 1.105996826023329, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 303, train_loss = 1.1052295503322966, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 304, train_loss = 1.1034238139982335, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 305, train_loss = 1.1019625961780548, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 306, train_loss = 1.1010078340768814, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 307, train_loss = 1.0995368150179274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 308, train_loss = 1.0975208369200118, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 309, train_loss = 1.0969517454504967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 310, train_loss = 1.0958792020683177, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 311, train_loss = 1.094240415841341, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 312, train_loss = 1.0933992328937165, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 313, train_loss = 1.0912842266261578, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 314, train_loss = 1.0907091945409775, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 315, train_loss = 1.0893669575452805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 316, train_loss = 1.087711428583134, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 317, train_loss = 1.0870712871546857, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 318, train_loss = 1.0851943530142307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 319, train_loss = 1.0848201562766917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 320, train_loss = 1.0834958106279373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 321, train_loss = 1.0820733942091465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 322, train_loss = 1.081131361424923, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 323, train_loss = 1.0798373743891716, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 324, train_loss = 1.0783188070054166, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 325, train_loss = 1.0777596297557466, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 326, train_loss = 1.0762277928297408, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 327, train_loss = 1.0754107807879336, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 328, train_loss = 1.0736643833224662, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 329, train_loss = 1.0732754940981977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 330, train_loss = 1.0717593990266323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 331, train_loss = 1.0701972643728368, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 332, train_loss = 1.0689001989667304, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 333, train_loss = 1.0685500614345074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 334, train_loss = 1.0666433473234065, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 335, train_loss = 1.0661868837778457, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 336, train_loss = 1.0650064945220947, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 337, train_loss = 1.0633221790194511, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 338, train_loss = 1.0629739140276797, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 339, train_loss = 1.0615335789625533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 340, train_loss = 1.0598563204403035, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 341, train_loss = 1.0596141964197159, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 342, train_loss = 1.0579445188050158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 343, train_loss = 1.0575511517818086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 344, train_loss = 1.0563755395705812, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 345, train_loss = 1.0541446159477346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 346, train_loss = 1.054440513253212, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 347, train_loss = 1.0527824747259729, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 348, train_loss = 1.0516612653736956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 349, train_loss = 1.0510820808704011, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 350, train_loss = 1.0491223844583146, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 351, train_loss = 1.0491819816525094, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 352, train_loss = 1.047677197784651, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 353, train_loss = 1.0472368535702117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 354, train_loss = 1.04545546323061, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 355, train_loss = 1.0454213010962121, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 356, train_loss = 1.0437729519908316, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 357, train_loss = 1.042178266972769, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 358, train_loss = 1.0419268694822676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 359, train_loss = 1.0403569390182383, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 360, train_loss = 1.040227498859167, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 361, train_loss = 1.0382430888712406, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 362, train_loss = 1.0380061529576778, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 363, train_loss = 1.0364453221554868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 364, train_loss = 1.0364630396361463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 365, train_loss = 1.0347918843035586, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 366, train_loss = 1.034244964539539, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 367, train_loss = 1.033502735197544, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 368, train_loss = 1.0312846613232978, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 369, train_loss = 1.031556073576212, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 370, train_loss = 1.029514092952013, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 371, train_loss = 1.0297795832157135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 372, train_loss = 1.0281150017981417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 373, train_loss = 1.0274783459608443, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 374, train_loss = 1.0261466316878796, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 375, train_loss = 1.0261747713084333, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 376, train_loss = 1.024224728345871, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 377, train_loss = 1.0242073200643063, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 378, train_loss = 1.0224143887753598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 379, train_loss = 1.0224137243931182, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 380, train_loss = 1.0205685086548328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 381, train_loss = 1.020835168659687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 382, train_loss = 1.0194167482550256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 383, train_loss = 1.0180814750492573, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 384, train_loss = 1.0181953820283525, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 385, train_loss = 1.0164307343657129, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 386, train_loss = 1.0160956270992756, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 387, train_loss = 1.0144284616108052, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 388, train_loss = 1.0146756867761724, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 389, train_loss = 1.0127344764769077, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 390, train_loss = 1.012567921250593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 391, train_loss = 1.0118816022877581, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 392, train_loss = 1.0108701102435589, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 393, train_loss = 1.0097428622539155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 394, train_loss = 1.0088746485416777, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 395, train_loss = 1.008514877408743, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 396, train_loss = 1.007009553431999, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 397, train_loss = 1.006567321717739, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 398, train_loss = 1.0053814363782294, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 399, train_loss = 1.005361354618799, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 400, train_loss = 1.0037683050031774, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 401, train_loss = 1.0034966046805494, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 402, train_loss = 1.0019887226517312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 403, train_loss = 1.0021695233881474, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 404, train_loss = 1.0007007594103925, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 405, train_loss = 0.9996233184938319, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 406, train_loss = 0.9995661278371699, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 407, train_loss = 0.9987302335794084, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 408, train_loss = 0.997461189806927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 409, train_loss = 0.9973159842193127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 410, train_loss = 0.995950875163544, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 411, train_loss = 0.9958883027429692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 412, train_loss = 0.9949328961665742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 413, train_loss = 0.9941887234454043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 414, train_loss = 0.9925681203603745, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 415, train_loss = 0.9927090133423917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 416, train_loss = 0.9916237915749662, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 417, train_loss = 0.9901826294953935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 418, train_loss = 0.9898139263386838, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 419, train_loss = 0.9888927564024925, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 420, train_loss = 0.9886433047358878, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 421, train_loss = 0.9872676121885888, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 422, train_loss = 0.9872992274467833, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 423, train_loss = 0.9857984793488868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 424, train_loss = 0.9857674539089203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 425, train_loss = 0.9845040303771384, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 426, train_loss = 0.9835740092094056, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 427, train_loss = 0.9830084455315955, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 428, train_loss = 0.9830090391333215, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 429, train_loss = 0.9820058929617517, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 430, train_loss = 0.9807013235986233, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 431, train_loss = 0.9803769041900523, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 432, train_loss = 0.9792602050001733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 433, train_loss = 0.978818831325043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 434, train_loss = 0.9783583879470825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 435, train_loss = 0.977613527327776, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 436, train_loss = 0.9769649244844913, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 437, train_loss = 0.9758434146642685, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 438, train_loss = 0.975294191390276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 439, train_loss = 0.9749838647549041, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 440, train_loss = 0.9742522425949574, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 441, train_loss = 0.9727211606805213, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 442, train_loss = 0.9727393413777463, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 443, train_loss = 0.9715255250339396, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 444, train_loss = 0.9710085627739318, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 445, train_loss = 0.9706318626995198, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 446, train_loss = 0.9700878386502154, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 447, train_loss = 0.9686894938349724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 448, train_loss = 0.9686368592083454, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 449, train_loss = 0.967520662874449, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 450, train_loss = 0.9673293034429662, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 451, train_loss = 0.9657753693754785, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 452, train_loss = 0.9664005003869534, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 453, train_loss = 0.9651266410946846, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 454, train_loss = 0.9638936631381512, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 455, train_loss = 0.9636759857530706, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 456, train_loss = 0.9628360892238561, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 457, train_loss = 0.9625881513056811, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 458, train_loss = 0.9616188779473305, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 459, train_loss = 0.9608660563826561, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 460, train_loss = 0.9598332593741361, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 461, train_loss = 0.9600710446538869, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 462, train_loss = 0.9592102542519569, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 463, train_loss = 0.9579666393401567, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 464, train_loss = 0.9580401678977069, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 465, train_loss = 0.9574335130455438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 466, train_loss = 0.9559769307670649, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 467, train_loss = 0.9562199761567172, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 468, train_loss = 0.9545408686099108, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 469, train_loss = 0.9543520770967007, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 470, train_loss = 0.9535046244564, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 471, train_loss = 0.953318497777218, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 472, train_loss = 0.9522277539072093, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 473, train_loss = 0.9519100437464658, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 474, train_loss = 0.9509231212141458, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 475, train_loss = 0.9508713446557522, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 476, train_loss = 0.9495040426554624, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 477, train_loss = 0.9494906589388847, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 478, train_loss = 0.9489339801075403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 479, train_loss = 0.9484360801579896, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 480, train_loss = 0.9472365950641688, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 481, train_loss = 0.9473253140749875, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 482, train_loss = 0.9465059625508729, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 483, train_loss = 0.9455780995485839, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 484, train_loss = 0.944996066391468, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 485, train_loss = 0.9444253047404345, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 486, train_loss = 0.9441399735806044, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 487, train_loss = 0.9435326581296977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 488, train_loss = 0.9424310090544168, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 489, train_loss = 0.9423319560883101, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 490, train_loss = 0.9410814978182316, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 491, train_loss = 0.9410449204442557, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 492, train_loss = 0.9401602658035699, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 493, train_loss = 0.940020644426113, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 494, train_loss = 0.9386638117430266, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 495, train_loss = 0.9385075283644255, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 496, train_loss = 0.9379801501927432, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 497, train_loss = 0.9371006985602435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 498, train_loss = 0.9372358533146325, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 499, train_loss = 0.9365609151718672, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████▎                                              | 10/30 [1:39:30<3:19:34, 598.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "11th- epoch: 0, train_loss = 116.08354974538088, train_acc = 0.7735211923614346\n",
      "test Acc 0.87243947858473:\n",
      "11th- epoch: 1, train_loss = 45.43683683872223, train_acc = 0.905798789007918\n",
      "test Acc 0.909683426443203:\n",
      "11th- epoch: 2, train_loss = 32.18170055747032, train_acc = 0.9314159292035398\n",
      "test Acc 0.9241154562383612:\n",
      "11th- epoch: 3, train_loss = 25.45407424867153, train_acc = 0.9432929669306008\n",
      "test Acc 0.9348230912476723:\n",
      "11th- epoch: 4, train_loss = 21.190470848232508, train_acc = 0.9542384722869119\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 5, train_loss = 18.288129083812237, train_acc = 0.9598276665114113\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 6, train_loss = 16.182588728144765, train_acc = 0.9668141592920354\n",
      "test Acc 0.9534450651769087:\n",
      "11th- epoch: 7, train_loss = 14.56192073225975, train_acc = 0.972286911970191\n",
      "test Acc 0.9548417132216015:\n",
      "11th- epoch: 8, train_loss = 13.287379613146186, train_acc = 0.9755472752678156\n",
      "test Acc 0.9567039106145251:\n",
      "11th- epoch: 9, train_loss = 12.234757775440812, train_acc = 0.9784583139264089\n",
      "test Acc 0.9585661080074488:\n",
      "11th- epoch: 10, train_loss = 11.349490558728576, train_acc = 0.980204937121565\n",
      "test Acc 0.9604283054003724:\n",
      "11th- epoch: 11, train_loss = 10.585114896297455, train_acc = 0.9813693525850024\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 12, train_loss = 9.918784828856587, train_acc = 0.9829995342338146\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 13, train_loss = 9.333273772150278, train_acc = 0.984163949697252\n",
      "test Acc 0.962756052141527:\n",
      "11th- epoch: 14, train_loss = 8.815489687025547, train_acc = 0.9848625989753144\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 15, train_loss = 8.348083589226007, train_acc = 0.9857941313460643\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 16, train_loss = 7.929675800725818, train_acc = 0.9861434559850955\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 17, train_loss = 7.544396443292499, train_acc = 0.9874243129948765\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 18, train_loss = 7.195068079978228, train_acc = 0.9881229622729389\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 19, train_loss = 6.88128412887454, train_acc = 0.9883558453656265\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 20, train_loss = 6.597077831625938, train_acc = 0.9890544946436889\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 21, train_loss = 6.33310866355896, train_acc = 0.9897531439217513\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 22, train_loss = 6.092686107382178, train_acc = 0.9902189101071263\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 23, train_loss = 5.869094045832753, train_acc = 0.9902189101071263\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 24, train_loss = 5.660652222111821, train_acc = 0.990801117838845\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 25, train_loss = 5.471358509734273, train_acc = 0.9912668840242198\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 26, train_loss = 5.289340926334262, train_acc = 0.9917326502095948\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 27, train_loss = 5.122360717505217, train_acc = 0.9918490917559385\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 28, train_loss = 4.963325082324445, train_acc = 0.9918490917559385\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 29, train_loss = 4.819600624032319, train_acc = 0.992081974848626\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 30, train_loss = 4.681581270880997, train_acc = 0.9924312994876572\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 31, train_loss = 4.5521388510242105, train_acc = 0.9925477410340009\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 32, train_loss = 4.431104015558958, train_acc = 0.9926641825803446\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 33, train_loss = 4.3167686788365245, train_acc = 0.9928970656730322\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 34, train_loss = 4.208806577138603, train_acc = 0.9930135072193759\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 35, train_loss = 4.107594415545464, train_acc = 0.9931299487657196\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 36, train_loss = 4.0097263576462865, train_acc = 0.9934792734047508\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 37, train_loss = 3.9183124201372266, train_acc = 0.9934792734047508\n",
      "test Acc 0.9716014897579144:\n",
      "11th- epoch: 38, train_loss = 3.8331939689815044, train_acc = 0.9937121564974383\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 39, train_loss = 3.750435155816376, train_acc = 0.993828598043782\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 40, train_loss = 3.6733299354091287, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 41, train_loss = 3.597736448980868, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 42, train_loss = 3.528715874068439, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 43, train_loss = 3.4604391073808074, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 44, train_loss = 3.396022468805313, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 45, train_loss = 3.333424120210111, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 46, train_loss = 3.276507940143347, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 47, train_loss = 3.2182391276583076, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 48, train_loss = 3.1653122007846832, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 49, train_loss = 3.113696047104895, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 50, train_loss = 3.0640721330419183, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 51, train_loss = 3.017680429853499, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 52, train_loss = 2.971399943344295, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 53, train_loss = 2.9278009636327624, train_acc = 0.9951094550535631\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 54, train_loss = 2.884270142763853, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 55, train_loss = 2.845280316658318, train_acc = 0.9954587796925943\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 56, train_loss = 2.805641137994826, train_acc = 0.9954587796925943\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 57, train_loss = 2.7670256150886416, train_acc = 0.9954587796925943\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 58, train_loss = 2.730385643430054, train_acc = 0.995575221238938\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 59, train_loss = 2.6961466623470187, train_acc = 0.9958081043316255\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 60, train_loss = 2.6623459667898715, train_acc = 0.9959245458779693\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 61, train_loss = 2.6288925274275243, train_acc = 0.9959245458779693\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 62, train_loss = 2.596732944250107, train_acc = 0.9959245458779693\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 63, train_loss = 2.5664990805089474, train_acc = 0.9959245458779693\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 64, train_loss = 2.5365752042271197, train_acc = 0.9959245458779693\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 65, train_loss = 2.5080894217826426, train_acc = 0.9959245458779693\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 66, train_loss = 2.4792233631014824, train_acc = 0.9959245458779693\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 67, train_loss = 2.452204378787428, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 68, train_loss = 2.4268633015453815, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 69, train_loss = 2.400497884955257, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 70, train_loss = 2.3755149715580046, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 71, train_loss = 2.351185249630362, train_acc = 0.996040987424313\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 72, train_loss = 2.3274525180459023, train_acc = 0.996040987424313\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 73, train_loss = 2.3044469729065895, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 74, train_loss = 2.2820424623787403, train_acc = 0.996040987424313\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 75, train_loss = 2.2603754461742938, train_acc = 0.9961574289706567\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 76, train_loss = 2.239383425563574, train_acc = 0.9961574289706567\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 77, train_loss = 2.218256441410631, train_acc = 0.9962738705170004\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 78, train_loss = 2.1982357315719128, train_acc = 0.9962738705170004\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 79, train_loss = 2.1792396656237543, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 80, train_loss = 2.160279180854559, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 81, train_loss = 2.1437090164981782, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 82, train_loss = 2.1248963312245905, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 83, train_loss = 2.1086128503084183, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 84, train_loss = 2.0913196317851543, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 85, train_loss = 2.0757438144646585, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 86, train_loss = 2.059784641955048, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 87, train_loss = 2.045576711650938, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 88, train_loss = 2.0288569503463805, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 89, train_loss = 2.014646759722382, train_acc = 0.996506753609688\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 90, train_loss = 2.001787055283785, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 91, train_loss = 1.9868039428256452, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 92, train_loss = 1.9737966619431973, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 93, train_loss = 1.9605722553096712, train_acc = 0.9963903120633442\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 94, train_loss = 1.9479827880859375, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 95, train_loss = 1.9355154819786549, train_acc = 0.9966231951560317\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 96, train_loss = 1.9225168242119253, train_acc = 0.9966231951560317\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 97, train_loss = 1.9109326587058604, train_acc = 0.9966231951560317\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 98, train_loss = 1.8987872428260744, train_acc = 0.9966231951560317\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 99, train_loss = 1.8869288265705109, train_acc = 0.9966231951560317\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 100, train_loss = 1.8758062557317317, train_acc = 0.9966231951560317\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 101, train_loss = 1.8646021061576903, train_acc = 0.9966231951560317\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 102, train_loss = 1.8549896054901183, train_acc = 0.9966231951560317\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 103, train_loss = 1.8432807042263448, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 104, train_loss = 1.8337080315686762, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 105, train_loss = 1.8224243323784322, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 106, train_loss = 1.8130921013653278, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 107, train_loss = 1.8035898220259696, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 108, train_loss = 1.7939024257939309, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 109, train_loss = 1.7851392354350537, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 110, train_loss = 1.7754276283085346, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 111, train_loss = 1.766617201268673, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 112, train_loss = 1.7579390369355679, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 113, train_loss = 1.7489877368789166, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 114, train_loss = 1.7407819430809468, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 115, train_loss = 1.7321605682373047, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 116, train_loss = 1.7251341443043202, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 117, train_loss = 1.715664440067485, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 118, train_loss = 1.708052872447297, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 119, train_loss = 1.7000887740869075, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 120, train_loss = 1.693052577553317, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 121, train_loss = 1.6852190110366791, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 122, train_loss = 1.678279175190255, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 123, train_loss = 1.670747424243018, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 124, train_loss = 1.6635024845600128, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 125, train_loss = 1.6562341961544007, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 126, train_loss = 1.6503197874408215, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 127, train_loss = 1.6425385784823447, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 128, train_loss = 1.6365176525432616, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 129, train_loss = 1.62970769405365, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 130, train_loss = 1.623776527820155, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 131, train_loss = 1.6162428099196404, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 132, train_loss = 1.610872769029811, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 133, train_loss = 1.6040752592962235, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 134, train_loss = 1.5982179951388389, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 135, train_loss = 1.5917408254463226, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 136, train_loss = 1.5857646788936108, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 137, train_loss = 1.5800582368392497, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 138, train_loss = 1.5750930856447667, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 139, train_loss = 1.5686849940102547, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 140, train_loss = 1.5632696524262428, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 141, train_loss = 1.5582551981788129, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 142, train_loss = 1.5525838893372566, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 143, train_loss = 1.5466848437208682, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 144, train_loss = 1.5414250653702766, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 145, train_loss = 1.5370998706202954, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 146, train_loss = 1.5313376064877957, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 147, train_loss = 1.5268585681915283, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 148, train_loss = 1.521308058174327, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 149, train_loss = 1.5167378846090287, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 150, train_loss = 1.5115491386968642, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 151, train_loss = 1.5070372931659222, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 152, train_loss = 1.502131012501195, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 153, train_loss = 1.4974979311227798, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 154, train_loss = 1.4927655197679996, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 155, train_loss = 1.4888075292110443, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 156, train_loss = 1.483940253732726, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 157, train_loss = 1.4792324516456574, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 158, train_loss = 1.4746315653901547, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 159, train_loss = 1.4702967058401555, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 160, train_loss = 1.4658738374710083, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 161, train_loss = 1.4618206955492496, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 162, train_loss = 1.4572224367875606, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 163, train_loss = 1.4533080160617828, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 164, train_loss = 1.4493778098840266, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 165, train_loss = 1.4453061174135655, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 166, train_loss = 1.441026397049427, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 167, train_loss = 1.4372156485915184, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 168, train_loss = 1.4332383137661964, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 169, train_loss = 1.429389012278989, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 170, train_loss = 1.4252062676241621, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 171, train_loss = 1.4215421415865421, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 172, train_loss = 1.418058259994723, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 173, train_loss = 1.4140849398681894, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 174, train_loss = 1.4105455303797498, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 175, train_loss = 1.4068584280321375, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 176, train_loss = 1.4031689936527982, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 177, train_loss = 1.3995583156356588, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 178, train_loss = 1.3960746502270922, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 179, train_loss = 1.392756924033165, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 180, train_loss = 1.3888752410421148, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 181, train_loss = 1.385973908007145, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 182, train_loss = 1.3828427953412756, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 183, train_loss = 1.379230409860611, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 184, train_loss = 1.375499989837408, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 185, train_loss = 1.3722388421883807, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 186, train_loss = 1.3690320601454005, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 187, train_loss = 1.3657848039874807, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 188, train_loss = 1.3624224861850962, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 189, train_loss = 1.3594749420881271, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 190, train_loss = 1.3567934347083792, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 191, train_loss = 1.3530884087085724, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 192, train_loss = 1.3499998053302988, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 193, train_loss = 1.3473824398824945, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 194, train_loss = 1.3439278764417395, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 195, train_loss = 1.3415814526379108, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 196, train_loss = 1.3377961479127407, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 197, train_loss = 1.335835199803114, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 198, train_loss = 1.3318320227554068, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 199, train_loss = 1.329725492745638, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 200, train_loss = 1.3268367672571912, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 201, train_loss = 1.3236243141582236, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 202, train_loss = 1.3208522101631388, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 203, train_loss = 1.3183710699668154, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 204, train_loss = 1.3157328056404367, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 205, train_loss = 1.312830933718942, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 206, train_loss = 1.310657225549221, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 207, train_loss = 1.3074949035653844, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 208, train_loss = 1.304846397251822, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 209, train_loss = 1.302242106408812, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 210, train_loss = 1.299449140788056, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 211, train_loss = 1.2974613545229658, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 212, train_loss = 1.2946771023562178, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 213, train_loss = 1.291634721099399, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 214, train_loss = 1.28905139118433, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 215, train_loss = 1.287079755216837, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 216, train_loss = 1.28448559215758, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 217, train_loss = 1.2820428274571896, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 218, train_loss = 1.2794168666005135, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 219, train_loss = 1.277135127573274, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 220, train_loss = 1.2746610889444128, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 221, train_loss = 1.2723925238242373, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 222, train_loss = 1.2698233450064436, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 223, train_loss = 1.2672906728694215, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 224, train_loss = 1.2654091318836436, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 225, train_loss = 1.262745339423418, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 226, train_loss = 1.2609601207077503, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 227, train_loss = 1.2578946190187708, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 228, train_loss = 1.2562818204751238, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 229, train_loss = 1.253668217570521, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 230, train_loss = 1.2518277590861544, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 231, train_loss = 1.2494653599569574, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 232, train_loss = 1.2471062988042831, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 233, train_loss = 1.2453661734471098, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 234, train_loss = 1.2431057119974867, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 235, train_loss = 1.2407863115658984, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 236, train_loss = 1.239072684198618, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 237, train_loss = 1.236655087559484, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 238, train_loss = 1.2347660064697266, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 239, train_loss = 1.2327233714750037, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 240, train_loss = 1.2302834751317278, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 241, train_loss = 1.2281213961541653, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 242, train_loss = 1.2269486300647259, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 243, train_loss = 1.2247822309145704, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 244, train_loss = 1.2224692838499323, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 245, train_loss = 1.220532115548849, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 246, train_loss = 1.2183619178831577, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 247, train_loss = 1.216864861547947, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 248, train_loss = 1.2148829785874113, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 249, train_loss = 1.2131513146450743, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 250, train_loss = 1.2101682076463476, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 251, train_loss = 1.2092431634664536, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 252, train_loss = 1.2074459294090047, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 253, train_loss = 1.2053437096765265, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 254, train_loss = 1.2034287179121748, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 255, train_loss = 1.2013096722075716, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 256, train_loss = 1.199791356921196, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 257, train_loss = 1.1979911277303472, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 258, train_loss = 1.1957978693535551, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 259, train_loss = 1.194599449634552, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 260, train_loss = 1.1924961097538471, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 261, train_loss = 1.1907907389104366, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 262, train_loss = 1.1885273741791025, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 263, train_loss = 1.1879186742007732, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 264, train_loss = 1.1853873083600774, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 265, train_loss = 1.1842301562428474, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 266, train_loss = 1.1819536549737677, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 267, train_loss = 1.181126105308067, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 268, train_loss = 1.1784132681787014, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 269, train_loss = 1.1771115039591677, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 270, train_loss = 1.175695400685072, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 271, train_loss = 1.1735403947532177, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 272, train_loss = 1.1720217603142373, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 273, train_loss = 1.1706254184246063, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 274, train_loss = 1.1690222422475927, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 275, train_loss = 1.1675772840972058, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 276, train_loss = 1.1655475559527986, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 277, train_loss = 1.1646459723706357, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 278, train_loss = 1.1620540780131705, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 279, train_loss = 1.1608329862356186, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 280, train_loss = 1.1589639906887896, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 281, train_loss = 1.1579137829248793, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 282, train_loss = 1.1563529509003274, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 283, train_loss = 1.1543675350840203, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 284, train_loss = 1.1528491961653344, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 285, train_loss = 1.1519205309450626, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 286, train_loss = 1.1500388297135942, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 287, train_loss = 1.1486490232055075, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 288, train_loss = 1.1463077937369235, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 289, train_loss = 1.1452980637550354, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 290, train_loss = 1.1438893675804138, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 291, train_loss = 1.1422762162983418, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 292, train_loss = 1.1408256466384046, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 293, train_loss = 1.1395549960434437, train_acc = 0.9970889613414066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 294, train_loss = 1.1376741913263686, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 295, train_loss = 1.1361291433568113, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 296, train_loss = 1.1345575277809985, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 297, train_loss = 1.1341680635814555, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 298, train_loss = 1.132237157493364, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 299, train_loss = 1.130894597619772, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 300, train_loss = 1.128915208100807, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 301, train_loss = 1.128024107485544, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 302, train_loss = 1.1267249013180844, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 303, train_loss = 1.12526885420084, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 304, train_loss = 1.1237092862720601, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 305, train_loss = 1.1220955128665082, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 306, train_loss = 1.1210657345945947, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 307, train_loss = 1.1196737550199032, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 308, train_loss = 1.117945310950745, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 309, train_loss = 1.1169061449472792, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 310, train_loss = 1.1157643024926074, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 311, train_loss = 1.1139996945858002, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 312, train_loss = 1.1127395654912107, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 313, train_loss = 1.1121540454332717, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 314, train_loss = 1.1103655261103995, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 315, train_loss = 1.1089696797425859, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 316, train_loss = 1.107098278880585, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 317, train_loss = 1.1062918503885157, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 318, train_loss = 1.1055953378672712, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 319, train_loss = 1.1038726717233658, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 320, train_loss = 1.102411309897434, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 321, train_loss = 1.1009038065676577, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 322, train_loss = 1.1003080382943153, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 323, train_loss = 1.0989202025230043, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 324, train_loss = 1.097875151783228, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 325, train_loss = 1.0967254203860648, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 326, train_loss = 1.0956267602741718, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 327, train_loss = 1.0934150467510335, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 328, train_loss = 1.092299333482515, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 329, train_loss = 1.0912406754796393, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 330, train_loss = 1.090180589526426, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 331, train_loss = 1.0887433688039891, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 332, train_loss = 1.0873837868566625, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 333, train_loss = 1.0870022736489773, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 334, train_loss = 1.0855412160162814, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 335, train_loss = 1.0842302280361764, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 336, train_loss = 1.0830426886677742, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 337, train_loss = 1.0824503538315184, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 338, train_loss = 1.080700961232651, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 339, train_loss = 1.079772736877203, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 340, train_loss = 1.0787041137809865, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 341, train_loss = 1.077428713440895, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 342, train_loss = 1.0768303250079043, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 343, train_loss = 1.0754414213006385, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 344, train_loss = 1.0742869625682943, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 345, train_loss = 1.0733987291459925, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 346, train_loss = 1.0720780951087363, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 347, train_loss = 1.0710099178249948, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 348, train_loss = 1.0695634012226947, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 349, train_loss = 1.0683730766177177, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 350, train_loss = 1.068059476732742, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 351, train_loss = 1.066189891367685, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 352, train_loss = 1.0653226412832737, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 353, train_loss = 1.0650086936657317, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 354, train_loss = 1.0633930787444115, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 355, train_loss = 1.0618185736238956, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 356, train_loss = 1.0611271013622172, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 357, train_loss = 1.0605705070192926, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 358, train_loss = 1.0590558077092282, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 359, train_loss = 1.0580638200044632, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 360, train_loss = 1.0570498469169252, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 361, train_loss = 1.0561896202270873, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 362, train_loss = 1.0546672095661052, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 363, train_loss = 1.0537480513448827, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 364, train_loss = 1.053359754383564, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 365, train_loss = 1.0518153582816012, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 366, train_loss = 1.050644863396883, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 367, train_loss = 1.04986971616745, train_acc = 0.9972054028877504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 368, train_loss = 1.0490705805714242, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 369, train_loss = 1.047900925099384, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 370, train_loss = 1.0471853365306742, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 371, train_loss = 1.045552792667877, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 372, train_loss = 1.0452379721100442, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 373, train_loss = 1.0436295072431676, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 374, train_loss = 1.0429055604035966, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 375, train_loss = 1.0421574314241298, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 376, train_loss = 1.0407302342355251, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 377, train_loss = 1.0398223213851452, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 378, train_loss = 1.039353592961561, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 379, train_loss = 1.037828166037798, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 380, train_loss = 1.037520160258282, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 381, train_loss = 1.0359008920495398, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 382, train_loss = 1.0351027809083462, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 383, train_loss = 1.0343852043151855, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 384, train_loss = 1.0338126693968661, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 385, train_loss = 1.0327120919828303, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 386, train_loss = 1.0319052239065059, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 387, train_loss = 1.030517949431669, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 388, train_loss = 1.0296840704977512, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 389, train_loss = 1.0295017038588412, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 390, train_loss = 1.0279413151438348, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 391, train_loss = 1.0269980505108833, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 392, train_loss = 1.025806974619627, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 393, train_loss = 1.0251057569985278, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 394, train_loss = 1.0244980019633658, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 395, train_loss = 1.0232975234393962, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 396, train_loss = 1.0223801446263678, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 397, train_loss = 1.021471481770277, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 398, train_loss = 1.0208156717126258, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 399, train_loss = 1.020181030035019, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 400, train_loss = 1.0194358825683594, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 401, train_loss = 1.0184710274334066, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 402, train_loss = 1.017284529923927, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 403, train_loss = 1.0164345440571196, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 404, train_loss = 1.0165043150191195, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 405, train_loss = 1.014902374416124, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 406, train_loss = 1.0136668272316456, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 407, train_loss = 1.0136969834566116, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 408, train_loss = 1.01261318475008, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 409, train_loss = 1.011764279275667, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 410, train_loss = 1.0099825586075895, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 411, train_loss = 1.0095105071668513, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 412, train_loss = 1.009122823656071, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 413, train_loss = 1.0079340797965415, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 414, train_loss = 1.0069244094192982, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 415, train_loss = 1.0058247869019397, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 416, train_loss = 1.0054736398160458, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 417, train_loss = 1.0049313989584334, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 418, train_loss = 1.003868681669701, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 419, train_loss = 1.0025508217513561, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 420, train_loss = 1.0027142229373567, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 421, train_loss = 1.0015407192404382, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 422, train_loss = 1.000643067061901, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 423, train_loss = 0.9998263095621951, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 424, train_loss = 0.9993022022244986, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 425, train_loss = 0.9980307469668332, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 426, train_loss = 0.9976470259425696, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 427, train_loss = 0.9963860673306044, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 428, train_loss = 0.9952995603380259, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 429, train_loss = 0.9955835180880968, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 430, train_loss = 0.9948646264674608, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 431, train_loss = 0.9934302307665348, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 432, train_loss = 0.9930021191539709, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 433, train_loss = 0.9925429026188795, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 434, train_loss = 0.9914999678730965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 435, train_loss = 0.9907497627136763, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 436, train_loss = 0.989879277854925, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 437, train_loss = 0.9888418726623058, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 438, train_loss = 0.9886330726149026, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 439, train_loss = 0.9873461499810219, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 440, train_loss = 0.9869779770669993, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 441, train_loss = 0.9861238623561803, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 442, train_loss = 0.985022926091915, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 443, train_loss = 0.9848879960773047, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 444, train_loss = 0.9839464152755681, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 445, train_loss = 0.9828681896033231, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 446, train_loss = 0.9825997787120286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 447, train_loss = 0.981597688049078, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 448, train_loss = 0.9808522810635623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 449, train_loss = 0.9805088751018047, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 450, train_loss = 0.9794831598701421, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 451, train_loss = 0.9787734088895377, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 452, train_loss = 0.97764446461224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 453, train_loss = 0.9772578701376915, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 454, train_loss = 0.9765534115431365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 455, train_loss = 0.9756319063308183, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 456, train_loss = 0.9752511369588319, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 457, train_loss = 0.9745176571013872, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 458, train_loss = 0.9739171030523721, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 459, train_loss = 0.9728396609425545, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 460, train_loss = 0.9723220877349377, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 461, train_loss = 0.9717676043510437, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 462, train_loss = 0.9712229867873248, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 463, train_loss = 0.9707167682645377, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 464, train_loss = 0.9695523381233215, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 465, train_loss = 0.9693521745502949, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 466, train_loss = 0.9685301942226943, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 467, train_loss = 0.9675758158264216, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 468, train_loss = 0.9671081391570624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 469, train_loss = 0.9665307501854841, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 470, train_loss = 0.9654318243265152, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 471, train_loss = 0.9649215129611548, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 472, train_loss = 0.9644805788993835, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 473, train_loss = 0.9641298949718475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 474, train_loss = 0.9626133392157499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 475, train_loss = 0.962969321757555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 476, train_loss = 0.961142722517252, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 477, train_loss = 0.9617485677299555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 478, train_loss = 0.9601985663175583, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 479, train_loss = 0.9601220116019249, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 480, train_loss = 0.9586924786271993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 481, train_loss = 0.9587781615555286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 482, train_loss = 0.9577198165061418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 483, train_loss = 0.9571392610669136, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 484, train_loss = 0.9563217299582902, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 485, train_loss = 0.9559076043369714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 486, train_loss = 0.9548206850886345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 487, train_loss = 0.9550528712570667, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 488, train_loss = 0.9544369205832481, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 489, train_loss = 0.9535342268645763, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 490, train_loss = 0.9530093607900199, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 491, train_loss = 0.9521587131021079, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 492, train_loss = 0.9525902060267981, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 493, train_loss = 0.9507252387702465, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 494, train_loss = 0.9503940393624362, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 495, train_loss = 0.9497997673752252, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 496, train_loss = 0.9492661865951959, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 497, train_loss = 0.9485509842634201, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 498, train_loss = 0.9477243696746882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 499, train_loss = 0.9470307926239911, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████▋                                            | 11/30 [1:49:29<3:09:35, 598.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "12th- epoch: 0, train_loss = 128.7874104976654, train_acc = 0.7685142058686539\n",
      "test Acc 0.8691806331471136:\n",
      "12th- epoch: 1, train_loss = 43.30498591810465, train_acc = 0.9061481136469492\n",
      "test Acc 0.9073556797020484:\n",
      "12th- epoch: 2, train_loss = 31.07407159730792, train_acc = 0.9323474615742897\n",
      "test Acc 0.9292364990689013:\n",
      "12th- epoch: 3, train_loss = 25.206489384174347, train_acc = 0.945854680950163\n",
      "test Acc 0.9357541899441341:\n",
      "12th- epoch: 4, train_loss = 21.505670428276062, train_acc = 0.955985095482068\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 5, train_loss = 18.85269165970385, train_acc = 0.9608756404285049\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 6, train_loss = 16.830067424103618, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 7, train_loss = 15.212648287415504, train_acc = 0.9689101071262226\n",
      "test Acc 0.9534450651769087:\n",
      "12th- epoch: 8, train_loss = 13.872164856642485, train_acc = 0.9720540288775035\n",
      "test Acc 0.9553072625698324:\n",
      "12th- epoch: 9, train_loss = 12.736537819728255, train_acc = 0.9738006520726595\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 10, train_loss = 11.767637742683291, train_acc = 0.9763623660922217\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 11, train_loss = 10.941880436614156, train_acc = 0.9776432231020028\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 12, train_loss = 10.223616495728493, train_acc = 0.9789240801117839\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 13, train_loss = 9.592308942228556, train_acc = 0.9805542617605962\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 14, train_loss = 9.032044514082372, train_acc = 0.9812529110386586\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 15, train_loss = 8.537687971256673, train_acc = 0.9823008849557522\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 16, train_loss = 8.09967484511435, train_acc = 0.9832324173265021\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 17, train_loss = 7.710980364121497, train_acc = 0.9845132743362832\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 18, train_loss = 7.357165730558336, train_acc = 0.9855612482533768\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 19, train_loss = 7.037856761366129, train_acc = 0.9867256637168141\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 20, train_loss = 6.748153534717858, train_acc = 0.9870749883558454\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 21, train_loss = 6.484837921336293, train_acc = 0.9880065207265952\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 22, train_loss = 6.243930350057781, train_acc = 0.9887051700046576\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 23, train_loss = 6.01964879501611, train_acc = 0.9891709361900326\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 24, train_loss = 5.81430269498378, train_acc = 0.9899860270144387\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 25, train_loss = 5.624689982272685, train_acc = 0.9902189101071263\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 26, train_loss = 5.44861719571054, train_acc = 0.9902189101071263\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 27, train_loss = 5.288624970242381, train_acc = 0.9909175593851887\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 28, train_loss = 5.13446590770036, train_acc = 0.9913833255705635\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 29, train_loss = 4.992143033072352, train_acc = 0.9917326502095948\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 30, train_loss = 4.858360229060054, train_acc = 0.9917326502095948\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 31, train_loss = 4.733309078961611, train_acc = 0.9918490917559385\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 32, train_loss = 4.6147368545643985, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 33, train_loss = 4.502884563524276, train_acc = 0.9928970656730322\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 34, train_loss = 4.397919326554984, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 35, train_loss = 4.2981182667426765, train_acc = 0.9931299487657196\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 36, train_loss = 4.203769009560347, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 37, train_loss = 4.113967495504767, train_acc = 0.9933628318584071\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 38, train_loss = 4.029758134391159, train_acc = 0.9939450395901258\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 39, train_loss = 3.9468683903105557, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 40, train_loss = 3.87069098232314, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 41, train_loss = 3.798889507073909, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 42, train_loss = 3.7291164095513523, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 43, train_loss = 3.6619155653752387, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 44, train_loss = 3.597424044739455, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 45, train_loss = 3.537358161062002, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 46, train_loss = 3.4778508548624814, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 47, train_loss = 3.422066070139408, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 48, train_loss = 3.368881281465292, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 49, train_loss = 3.3180647850967944, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 50, train_loss = 3.2686808593571186, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 51, train_loss = 3.221448970492929, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 52, train_loss = 3.1747951544821262, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 53, train_loss = 3.130072555039078, train_acc = 0.9951094550535631\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 54, train_loss = 3.0880223102867603, train_acc = 0.9951094550535631\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 55, train_loss = 3.0441584517247975, train_acc = 0.9952258965999069\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 56, train_loss = 3.0014960188418627, train_acc = 0.9952258965999069\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 57, train_loss = 2.9635583427734673, train_acc = 0.9952258965999069\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 58, train_loss = 2.925095358164981, train_acc = 0.9952258965999069\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 59, train_loss = 2.8892187371384352, train_acc = 0.9952258965999069\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 60, train_loss = 2.8553396482020617, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 61, train_loss = 2.8211300037801266, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 62, train_loss = 2.788319354876876, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 63, train_loss = 2.7565431215334684, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 64, train_loss = 2.725161110982299, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 65, train_loss = 2.693741937400773, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 66, train_loss = 2.6647403489332646, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 67, train_loss = 2.6359150744974613, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 68, train_loss = 2.608473151922226, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 69, train_loss = 2.580652604578063, train_acc = 0.995575221238938\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 70, train_loss = 2.554613748565316, train_acc = 0.9956916627852818\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 71, train_loss = 2.5296020589303225, train_acc = 0.9956916627852818\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 72, train_loss = 2.5045374054461718, train_acc = 0.9956916627852818\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 73, train_loss = 2.480619001435116, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 74, train_loss = 2.457670209230855, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 75, train_loss = 2.4351436265278608, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 76, train_loss = 2.4126105948816985, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 77, train_loss = 2.391455388860777, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 78, train_loss = 2.369985057739541, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 79, train_loss = 2.3487930956762284, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 80, train_loss = 2.3296585746575147, train_acc = 0.9959245458779693\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 81, train_loss = 2.3097734830807894, train_acc = 0.996040987424313\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 82, train_loss = 2.289805023698136, train_acc = 0.9961574289706567\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 83, train_loss = 2.271381936268881, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 84, train_loss = 2.253412650898099, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 85, train_loss = 2.2352063085418195, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 86, train_loss = 2.217311505926773, train_acc = 0.9963903120633442\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 87, train_loss = 2.2004938647150993, train_acc = 0.9963903120633442\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 88, train_loss = 2.182899609906599, train_acc = 0.9963903120633442\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 89, train_loss = 2.166268914239481, train_acc = 0.9963903120633442\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 90, train_loss = 2.149890535278246, train_acc = 0.996506753609688\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 91, train_loss = 2.133780039148405, train_acc = 0.9963903120633442\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 92, train_loss = 2.1176945597399026, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 93, train_loss = 2.102136592613533, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 94, train_loss = 2.0874744702596217, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 95, train_loss = 2.0720625955145806, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 96, train_loss = 2.0581029560416937, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 97, train_loss = 2.0433166183065623, train_acc = 0.9967396367023754\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 98, train_loss = 2.028952119871974, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 99, train_loss = 2.0158600583672523, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 100, train_loss = 2.0021756751229987, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 101, train_loss = 1.989260459318757, train_acc = 0.9967396367023754\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 102, train_loss = 1.975926419137977, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 103, train_loss = 1.9631428426364437, train_acc = 0.9967396367023754\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 104, train_loss = 1.9506846821168438, train_acc = 0.9967396367023754\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 105, train_loss = 1.937690505757928, train_acc = 0.9967396367023754\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 106, train_loss = 1.9261286513647065, train_acc = 0.9967396367023754\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 107, train_loss = 1.9139522953191772, train_acc = 0.9967396367023754\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 108, train_loss = 1.9028866160660982, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 109, train_loss = 1.8913067741086707, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 110, train_loss = 1.8797567629953846, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 111, train_loss = 1.8690771920373663, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 112, train_loss = 1.8579218896338716, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 113, train_loss = 1.8474345753202215, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 114, train_loss = 1.8373018266865984, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 115, train_loss = 1.826520906179212, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 116, train_loss = 1.8172818335006014, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 117, train_loss = 1.807445157901384, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 118, train_loss = 1.7981353892246261, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 119, train_loss = 1.7886467619100586, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 120, train_loss = 1.7799079628894106, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 121, train_loss = 1.7705751322209835, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 122, train_loss = 1.7620260653784499, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 123, train_loss = 1.7530958825955167, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 124, train_loss = 1.7450270988047123, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 125, train_loss = 1.7361731050768867, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 126, train_loss = 1.7285606818040833, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 127, train_loss = 1.7202279152115807, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 128, train_loss = 1.7122325176605955, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 129, train_loss = 1.7044588178396225, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 130, train_loss = 1.6969949180493131, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 131, train_loss = 1.6893103079637513, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 132, train_loss = 1.682241172180511, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 133, train_loss = 1.6747085998067632, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 134, train_loss = 1.6671962613472715, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 135, train_loss = 1.6604001944651827, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 136, train_loss = 1.6532211117446423, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 137, train_loss = 1.6470728106796741, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 138, train_loss = 1.6400245142867789, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 139, train_loss = 1.6338272243738174, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 140, train_loss = 1.6266556332120672, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 141, train_loss = 1.620749415247701, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 142, train_loss = 1.614582015783526, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 143, train_loss = 1.6083115848014131, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 144, train_loss = 1.6020648293197155, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 145, train_loss = 1.5959025224437937, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 146, train_loss = 1.5896528909215704, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 147, train_loss = 1.5845670414855704, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 148, train_loss = 1.5784171981504187, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 149, train_loss = 1.572647655964829, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 150, train_loss = 1.5671529608080164, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 151, train_loss = 1.5612160650780424, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 152, train_loss = 1.5559454299509525, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 153, train_loss = 1.5509436912834644, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 154, train_loss = 1.5452530793845654, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 155, train_loss = 1.5398870235076174, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 156, train_loss = 1.535099626868032, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 157, train_loss = 1.5299657173454762, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 158, train_loss = 1.5245812175562605, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 159, train_loss = 1.5197770781815052, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 160, train_loss = 1.5142118955845945, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 161, train_loss = 1.5098148782853968, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 162, train_loss = 1.5053296660189517, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 163, train_loss = 1.4998550601303577, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 164, train_loss = 1.495578573376406, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 165, train_loss = 1.4909552944009192, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 166, train_loss = 1.4861819259822369, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 167, train_loss = 1.4813560743932612, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 168, train_loss = 1.477439230948221, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 169, train_loss = 1.4725545905530453, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 170, train_loss = 1.4686171126668341, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 171, train_loss = 1.4642455875873566, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 172, train_loss = 1.4597911002929322, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 173, train_loss = 1.4554940412635915, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 174, train_loss = 1.4512964934110641, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 175, train_loss = 1.4469045735895634, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 176, train_loss = 1.4427515367860906, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 177, train_loss = 1.4387212209403515, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 178, train_loss = 1.4348402147297747, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 179, train_loss = 1.4304464273154736, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 180, train_loss = 1.4265149533748627, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 181, train_loss = 1.423094168305397, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 182, train_loss = 1.4192430091206916, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 183, train_loss = 1.415335938334465, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 184, train_loss = 1.4118527409736998, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 185, train_loss = 1.4083180825109594, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 186, train_loss = 1.4045159916277044, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 187, train_loss = 1.4011227401788346, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 188, train_loss = 1.3975521884858608, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 189, train_loss = 1.3941917667980306, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 190, train_loss = 1.3905710652470589, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 191, train_loss = 1.387149038433563, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 192, train_loss = 1.3837149925529957, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 193, train_loss = 1.3806945085525513, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 194, train_loss = 1.3770654387772083, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 195, train_loss = 1.3741316671366803, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 196, train_loss = 1.371116812049877, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 197, train_loss = 1.3674631143803708, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 198, train_loss = 1.3643809407949448, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 199, train_loss = 1.361376777291298, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 200, train_loss = 1.35796968388604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 201, train_loss = 1.3552001267671585, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 202, train_loss = 1.3521528120036237, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 203, train_loss = 1.349260735034477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 204, train_loss = 1.3461823190446012, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 205, train_loss = 1.342938361049164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 206, train_loss = 1.3396895490586758, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 207, train_loss = 1.337605791806709, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 208, train_loss = 1.334565966099035, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 209, train_loss = 1.331535963981878, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 210, train_loss = 1.3280462722177617, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 211, train_loss = 1.3253191386465915, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 212, train_loss = 1.322821505367756, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 213, train_loss = 1.3194656160776503, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 214, train_loss = 1.3168633629684336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 215, train_loss = 1.3141303472220898, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 216, train_loss = 1.3115784178371541, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 217, train_loss = 1.3090424674446695, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 218, train_loss = 1.305939697951544, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 219, train_loss = 1.3037046156823635, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 220, train_loss = 1.3009670215542428, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 221, train_loss = 1.298580213158857, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 222, train_loss = 1.2956027686595917, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 223, train_loss = 1.2932478015427478, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 224, train_loss = 1.2908970316057093, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 225, train_loss = 1.2884914713795297, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 226, train_loss = 1.2858544613118283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 227, train_loss = 1.2839469996397384, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 228, train_loss = 1.2811350238625892, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 229, train_loss = 1.2787654126877896, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 230, train_loss = 1.2765275326673873, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 231, train_loss = 1.2738180980086327, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 232, train_loss = 1.2718686771695502, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 233, train_loss = 1.2690794740919955, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 234, train_loss = 1.2671435910160653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 235, train_loss = 1.2650085389614105, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 236, train_loss = 1.2625601962208748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 237, train_loss = 1.2606140089337714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 238, train_loss = 1.257599338889122, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 239, train_loss = 1.2558019894058816, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 240, train_loss = 1.2536914857919328, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 241, train_loss = 1.2512926422059536, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 242, train_loss = 1.2492589242756367, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 243, train_loss = 1.2473113536834717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 244, train_loss = 1.2447086349129677, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 245, train_loss = 1.2427146968839224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 246, train_loss = 1.2407365838589612, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 247, train_loss = 1.2387291342020035, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 248, train_loss = 1.236494205892086, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 249, train_loss = 1.2343953785893973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 250, train_loss = 1.2325857331452426, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 251, train_loss = 1.2304050450620707, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 252, train_loss = 1.228254221379757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 253, train_loss = 1.226495193928713, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 254, train_loss = 1.224084564804798, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 255, train_loss = 1.222567622869974, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 256, train_loss = 1.2205581441521645, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 257, train_loss = 1.217979583889246, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 258, train_loss = 1.216458988696104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 259, train_loss = 1.2143976464867592, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 260, train_loss = 1.2123835807142314, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 261, train_loss = 1.210282808780903, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 262, train_loss = 1.2083820340631064, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 263, train_loss = 1.2060691701772157, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 264, train_loss = 1.2045161513087805, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 265, train_loss = 1.2028262143430766, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 266, train_loss = 1.2007516461017076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 267, train_loss = 1.1984669528901577, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 268, train_loss = 1.1970006451010704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 269, train_loss = 1.1949047856032848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 270, train_loss = 1.1931855815055314, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 271, train_loss = 1.191103234887123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 272, train_loss = 1.1888134131731931, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 273, train_loss = 1.187607786298031, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 274, train_loss = 1.1856784013507422, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 275, train_loss = 1.1835845708847046, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 276, train_loss = 1.1821622103452682, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 277, train_loss = 1.180478136986494, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 278, train_loss = 1.1786522033216897, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 279, train_loss = 1.1767995034751948, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 280, train_loss = 1.1749647743999958, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 281, train_loss = 1.173364674061304, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 282, train_loss = 1.1716925414802972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 283, train_loss = 1.1700409054756165, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 284, train_loss = 1.168266454100376, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 285, train_loss = 1.166504622757202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 286, train_loss = 1.165144612401491, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 287, train_loss = 1.1632951560022775, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 288, train_loss = 1.1617434099316597, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 289, train_loss = 1.1605762864055578, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 290, train_loss = 1.1587309601309244, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 291, train_loss = 1.1568021265265997, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 292, train_loss = 1.155977226793766, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 293, train_loss = 1.1539480748178903, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 294, train_loss = 1.1525027553143445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 295, train_loss = 1.1505305307509843, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 296, train_loss = 1.1493821491894778, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 297, train_loss = 1.1478216188552324, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 298, train_loss = 1.1464150746760424, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 299, train_loss = 1.1446694744226988, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 300, train_loss = 1.1432122377154883, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 301, train_loss = 1.1421244454977568, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 302, train_loss = 1.1400728039443493, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 303, train_loss = 1.139026716351509, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 304, train_loss = 1.137544327735668, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 305, train_loss = 1.1358958346245345, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 306, train_loss = 1.1347210419771727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 307, train_loss = 1.133173686772352, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 308, train_loss = 1.1316535199584905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 309, train_loss = 1.13027342906571, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 310, train_loss = 1.1289573696849402, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 311, train_loss = 1.1275996255280916, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 312, train_loss = 1.1262401305139065, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 313, train_loss = 1.124721523374319, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 314, train_loss = 1.1233310997486115, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 315, train_loss = 1.122166713088518, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 316, train_loss = 1.1208868622779846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 317, train_loss = 1.1194418942031916, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 318, train_loss = 1.1178868474962655, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 319, train_loss = 1.116935638099676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 320, train_loss = 1.115685378521448, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 321, train_loss = 1.1136655285954475, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 322, train_loss = 1.1129608986375388, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 323, train_loss = 1.1113582464458887, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 324, train_loss = 1.1102646216750145, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 325, train_loss = 1.1090207931993064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 326, train_loss = 1.1075886885228101, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 327, train_loss = 1.1059070142509881, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 328, train_loss = 1.1052635995147284, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 329, train_loss = 1.10359450802207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 330, train_loss = 1.1027463836071547, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 331, train_loss = 1.1011828482151031, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 332, train_loss = 1.099930082767969, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 333, train_loss = 1.0988585663435515, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 334, train_loss = 1.097722521662945, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 335, train_loss = 1.0962060491146985, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 336, train_loss = 1.0951699279248714, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 337, train_loss = 1.0935749920608941, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 338, train_loss = 1.092968076467514, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 339, train_loss = 1.0915463641285896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 340, train_loss = 1.090039680391783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 341, train_loss = 1.088960093766218, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 342, train_loss = 1.0878644113836344, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 343, train_loss = 1.087047337234253, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 344, train_loss = 1.0855558713374194, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 345, train_loss = 1.0841212210652884, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 346, train_loss = 1.0828775515255984, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 347, train_loss = 1.0820740349590778, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 348, train_loss = 1.0809487886726856, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 349, train_loss = 1.0794171430170536, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 350, train_loss = 1.0785216925141867, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 351, train_loss = 1.0772920424642507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 352, train_loss = 1.076576398074394, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 353, train_loss = 1.0751481279730797, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 354, train_loss = 1.0742660549876746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 355, train_loss = 1.072820421308279, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 356, train_loss = 1.071808934211731, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 357, train_loss = 1.0706603949365672, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 358, train_loss = 1.0699230010213796, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 359, train_loss = 1.0682199895381927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 360, train_loss = 1.067521413177019, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 361, train_loss = 1.0662172747252043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 362, train_loss = 1.065383680164814, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 363, train_loss = 1.0640976801514626, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 364, train_loss = 1.0634240967629012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 365, train_loss = 1.0619338303804398, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 366, train_loss = 1.0612305787799414, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 367, train_loss = 1.05985751375556, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 368, train_loss = 1.0587908625602722, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 369, train_loss = 1.0577308299543802, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 370, train_loss = 1.0568821815249976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 371, train_loss = 1.0555862908659037, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 372, train_loss = 1.0547984341683332, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 373, train_loss = 1.0536723211407661, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 374, train_loss = 1.0525117181241512, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 375, train_loss = 1.0519465009419946, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 376, train_loss = 1.0504863622336416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 377, train_loss = 1.0496896468102932, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 378, train_loss = 1.0489526763558388, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 379, train_loss = 1.0477377896459075, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 380, train_loss = 1.0465692728757858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 381, train_loss = 1.0458514081983594, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 382, train_loss = 1.0447301492094994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 383, train_loss = 1.0435937556176214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 384, train_loss = 1.0429834797978401, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 385, train_loss = 1.041879404336214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 386, train_loss = 1.0404959569423227, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 387, train_loss = 1.0399974770843983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 388, train_loss = 1.0393160308449296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 389, train_loss = 1.0376716194004985, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 390, train_loss = 1.0372776426374912, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 391, train_loss = 1.0358907344489126, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 392, train_loss = 1.0349646496324567, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 393, train_loss = 1.0340539254248142, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 394, train_loss = 1.0332412744610338, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 395, train_loss = 1.032240108892438, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 396, train_loss = 1.031196982905385, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 397, train_loss = 1.0299738173634978, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 398, train_loss = 1.0292667324392824, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 399, train_loss = 1.0282229284493951, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 400, train_loss = 1.0273393231182126, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 401, train_loss = 1.0256724866776494, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 402, train_loss = 1.0251250080764294, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 403, train_loss = 1.0241758326737909, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 404, train_loss = 1.0235007206647424, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 405, train_loss = 1.0222840942442417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 406, train_loss = 1.0218957575707464, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 407, train_loss = 1.0205454677343369, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 408, train_loss = 1.0200293796806363, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 409, train_loss = 1.019099809229374, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 410, train_loss = 1.0181905416102381, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 411, train_loss = 1.01663355033088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 412, train_loss = 1.0167776197195053, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 413, train_loss = 1.015464706972125, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 414, train_loss = 1.0145305655896664, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 415, train_loss = 1.0140549652278423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 416, train_loss = 1.012820404022932, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 417, train_loss = 1.0123367135674926, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 418, train_loss = 1.011281505227089, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 419, train_loss = 1.0105833907873603, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 420, train_loss = 1.0095273740589619, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 421, train_loss = 1.0086212058813544, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 422, train_loss = 1.0082167883665534, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 423, train_loss = 1.0071502216160297, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 424, train_loss = 1.006567656993866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 425, train_loss = 1.005622487515211, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 426, train_loss = 1.0048044882714748, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 427, train_loss = 1.0035638039262267, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 428, train_loss = 1.0031175849289866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 429, train_loss = 1.0023184642195702, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 430, train_loss = 1.0011971704661846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 431, train_loss = 1.0007475316524506, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 432, train_loss = 0.9999018621892901, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 433, train_loss = 0.9992959946393967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 434, train_loss = 0.9978092436940642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 435, train_loss = 0.9976084853260545, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 436, train_loss = 0.9967427874653367, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 437, train_loss = 0.9957149003894301, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 438, train_loss = 0.9953182972967625, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 439, train_loss = 0.9942214166076155, train_acc = 0.9974382859804378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 440, train_loss = 0.993607897311449, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 441, train_loss = 0.9923699274659157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 442, train_loss = 0.9920802600681782, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 443, train_loss = 0.9915941345243482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 444, train_loss = 0.9904482550919056, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 445, train_loss = 0.9897538187651662, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 446, train_loss = 0.9891448567359475, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 447, train_loss = 0.9885800816118717, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 448, train_loss = 0.987176138907671, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 449, train_loss = 0.9871272134332685, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 450, train_loss = 0.986086942255497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 451, train_loss = 0.9854592556803254, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 452, train_loss = 0.9848573903291253, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 453, train_loss = 0.9836714689881774, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 454, train_loss = 0.9832069724798203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 455, train_loss = 0.9826389191002818, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 456, train_loss = 0.9818752383143874, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 457, train_loss = 0.9808785505592823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 458, train_loss = 0.9802185582666425, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 459, train_loss = 0.9796631137578515, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 460, train_loss = 0.978769393012044, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 461, train_loss = 0.9783567078411579, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 462, train_loss = 0.9776868261396885, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 463, train_loss = 0.976989592119935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 464, train_loss = 0.9763155058026314, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 465, train_loss = 0.9757604685873957, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 466, train_loss = 0.9749090857803822, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 467, train_loss = 0.9740219414234161, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 468, train_loss = 0.9731280145497294, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 469, train_loss = 0.9729991778731346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 470, train_loss = 0.9720894992351532, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 471, train_loss = 0.971492854252574, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 472, train_loss = 0.9708985251636477, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 473, train_loss = 0.9700498556048842, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 474, train_loss = 0.9690830844192533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 475, train_loss = 0.9690563095064135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 476, train_loss = 0.9678998552262783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 477, train_loss = 0.9674727457313566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 478, train_loss = 0.9664917141199112, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 479, train_loss = 0.966254690036294, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 480, train_loss = 0.9653646685183048, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 481, train_loss = 0.9647920839488506, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 482, train_loss = 0.9641922066657571, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 483, train_loss = 0.9636619786469964, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 484, train_loss = 0.9628278166055679, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 485, train_loss = 0.9623838551342487, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 486, train_loss = 0.9611812618823024, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 487, train_loss = 0.9609957151114941, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 488, train_loss = 0.9603236690163612, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 489, train_loss = 0.9596871063113213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 490, train_loss = 0.9591818948538275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 491, train_loss = 0.958383480712655, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 492, train_loss = 0.958004912987235, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 493, train_loss = 0.9569987418799428, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 494, train_loss = 0.9565859151334735, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 495, train_loss = 0.9557604516594438, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 496, train_loss = 0.9550230378954438, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 497, train_loss = 0.9548304577620002, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 498, train_loss = 0.9543049782514572, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 499, train_loss = 0.9534258991479874, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████                                          | 12/30 [1:59:28<2:59:37, 598.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "13th- epoch: 0, train_loss = 108.92297939956188, train_acc = 0.7805076851420587\n",
      "test Acc 0.8691806331471136:\n",
      "13th- epoch: 1, train_loss = 40.389610439538956, train_acc = 0.9158127619934793\n",
      "test Acc 0.9068901303538175:\n",
      "13th- epoch: 2, train_loss = 29.37217888981104, train_acc = 0.94014904517932\n",
      "test Acc 0.9278398510242085:\n",
      "13th- epoch: 3, train_loss = 23.99834307655692, train_acc = 0.952491849091756\n",
      "test Acc 0.9380819366852886:\n",
      "13th- epoch: 4, train_loss = 20.61295384913683, train_acc = 0.9613414066138798\n",
      "test Acc 0.9441340782122905:\n",
      "13th- epoch: 5, train_loss = 18.212854601442814, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 6, train_loss = 16.371179431676865, train_acc = 0.9698416394969726\n",
      "test Acc 0.9539106145251397:\n",
      "13th- epoch: 7, train_loss = 14.883021719753742, train_acc = 0.971821145784816\n",
      "test Acc 0.9562383612662942:\n",
      "13th- epoch: 8, train_loss = 13.649787586182356, train_acc = 0.9739170936190032\n",
      "test Acc 0.9581005586592178:\n",
      "13th- epoch: 9, train_loss = 12.59989363513887, train_acc = 0.9755472752678156\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 10, train_loss = 11.69929632730782, train_acc = 0.9772938984629715\n",
      "test Acc 0.9618249534450651:\n",
      "13th- epoch: 11, train_loss = 10.912455281242728, train_acc = 0.9788076385654402\n",
      "test Acc 0.9641527001862198:\n",
      "13th- epoch: 12, train_loss = 10.226746214553714, train_acc = 0.9796227293898463\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 13, train_loss = 9.616198567673564, train_acc = 0.9805542617605962\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 14, train_loss = 9.06792863085866, train_acc = 0.9823008849557522\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 15, train_loss = 8.582619967870414, train_acc = 0.9832324173265021\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 16, train_loss = 8.148286005482078, train_acc = 0.9845132743362832\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 17, train_loss = 7.757386575452983, train_acc = 0.9853283651606893\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 18, train_loss = 7.401809103786945, train_acc = 0.9860270144387517\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 19, train_loss = 7.078800983726978, train_acc = 0.9868421052631579\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 20, train_loss = 6.785634000785649, train_acc = 0.9875407545412203\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 21, train_loss = 6.518753076903522, train_acc = 0.9880065207265952\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 22, train_loss = 6.269806684926152, train_acc = 0.9885887284583139\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 23, train_loss = 6.041925366036594, train_acc = 0.9887051700046576\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 24, train_loss = 5.832170651294291, train_acc = 0.98940381928272\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 25, train_loss = 5.637644192203879, train_acc = 0.9897531439217513\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 26, train_loss = 5.457376635633409, train_acc = 0.9902189101071263\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 27, train_loss = 5.290014232508838, train_acc = 0.9902189101071263\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 28, train_loss = 5.134565026499331, train_acc = 0.9906846762925011\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 29, train_loss = 4.991175093688071, train_acc = 0.9910340009315324\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 30, train_loss = 4.8561217822134495, train_acc = 0.9913833255705635\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 31, train_loss = 4.731255046091974, train_acc = 0.9916162086632511\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 32, train_loss = 4.612389988265932, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 33, train_loss = 4.501305481418967, train_acc = 0.9921984163949698\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 34, train_loss = 4.397183292079717, train_acc = 0.9923148579413135\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 35, train_loss = 4.297363739460707, train_acc = 0.9924312994876572\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 36, train_loss = 4.202625501900911, train_acc = 0.9927806241266884\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 37, train_loss = 4.112525226548314, train_acc = 0.9930135072193759\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 38, train_loss = 4.029095867648721, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 39, train_loss = 3.9490031502209604, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 40, train_loss = 3.8729412108659744, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 41, train_loss = 3.7991187213920057, train_acc = 0.9933628318584071\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 42, train_loss = 3.730769712012261, train_acc = 0.9939450395901258\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 43, train_loss = 3.664603326935321, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 44, train_loss = 3.600097194314003, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 45, train_loss = 3.539887411519885, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 46, train_loss = 3.4812083053402603, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 47, train_loss = 3.424658364150673, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 48, train_loss = 3.3709243764169514, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 49, train_loss = 3.3179611819796264, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 50, train_loss = 3.268659034278244, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 51, train_loss = 3.2195821260102093, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 52, train_loss = 3.173637807369232, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 53, train_loss = 3.1279266346246004, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 54, train_loss = 3.0852779024280608, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 55, train_loss = 3.0431858147494495, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 56, train_loss = 3.002486664801836, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 57, train_loss = 2.9642586447298527, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 58, train_loss = 2.9256359678693116, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 59, train_loss = 2.8891739775426686, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 60, train_loss = 2.8526502046734095, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 61, train_loss = 2.8183482815511525, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 62, train_loss = 2.784471824299544, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 63, train_loss = 2.7521837460808456, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 64, train_loss = 2.719851127360016, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 65, train_loss = 2.6904312253464013, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 66, train_loss = 2.6593620243947953, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 67, train_loss = 2.631612441269681, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 68, train_loss = 2.6033981379587203, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 69, train_loss = 2.5763400334399194, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 70, train_loss = 2.54990327055566, train_acc = 0.996040987424313\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 71, train_loss = 2.524419656721875, train_acc = 0.996040987424313\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 72, train_loss = 2.4995320320595056, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 73, train_loss = 2.4751342616509646, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 74, train_loss = 2.4506052751094103, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 75, train_loss = 2.4292631552089006, train_acc = 0.996040987424313\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 76, train_loss = 2.4056116957217455, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 77, train_loss = 2.3844199168961495, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 78, train_loss = 2.362420305609703, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 79, train_loss = 2.342226092936471, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 80, train_loss = 2.321045383810997, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 81, train_loss = 2.30161841516383, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 82, train_loss = 2.281595015898347, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 83, train_loss = 2.2628159646410495, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 84, train_loss = 2.244098670082167, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 85, train_loss = 2.2253047339618206, train_acc = 0.9962738705170004\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 86, train_loss = 2.207964586094022, train_acc = 0.9962738705170004\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 87, train_loss = 2.1903147276025265, train_acc = 0.9962738705170004\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 88, train_loss = 2.1728747424203902, train_acc = 0.9962738705170004\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 89, train_loss = 2.1557870488613844, train_acc = 0.9962738705170004\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 90, train_loss = 2.139952939702198, train_acc = 0.9963903120633442\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 91, train_loss = 2.1235323909204453, train_acc = 0.9963903120633442\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 92, train_loss = 2.107416146202013, train_acc = 0.9963903120633442\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 93, train_loss = 2.0918167363852262, train_acc = 0.9963903120633442\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 94, train_loss = 2.077202631160617, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 95, train_loss = 2.0613452072720975, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 96, train_loss = 2.0477404743433, train_acc = 0.996506753609688\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 97, train_loss = 2.0329068892169744, train_acc = 0.996506753609688\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 98, train_loss = 2.0197268966585398, train_acc = 0.996506753609688\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 99, train_loss = 2.0052631583530456, train_acc = 0.9966231951560317\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 100, train_loss = 1.9924429256934673, train_acc = 0.9966231951560317\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 101, train_loss = 1.9789214425254613, train_acc = 0.9966231951560317\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 102, train_loss = 1.9654973589349538, train_acc = 0.9966231951560317\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 103, train_loss = 1.952837223187089, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 104, train_loss = 1.9410761538892984, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 105, train_loss = 1.928454039618373, train_acc = 0.9966231951560317\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 106, train_loss = 1.9157031748909503, train_acc = 0.9966231951560317\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 107, train_loss = 1.904754315270111, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 108, train_loss = 1.8931158550549299, train_acc = 0.9966231951560317\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 109, train_loss = 1.8816284351050854, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 110, train_loss = 1.8699378359597176, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 111, train_loss = 1.8594888604711741, train_acc = 0.9966231951560317\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 112, train_loss = 1.8483027431648225, train_acc = 0.9966231951560317\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 113, train_loss = 1.8383579291403294, train_acc = 0.9967396367023754\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 114, train_loss = 1.8276905168313533, train_acc = 0.9968560782487191\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 115, train_loss = 1.8175530638545752, train_acc = 0.9968560782487191\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 116, train_loss = 1.8077063007513061, train_acc = 0.9968560782487191\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 117, train_loss = 1.7980314890155569, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 118, train_loss = 1.7879211585968733, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 119, train_loss = 1.7790466081351042, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 120, train_loss = 1.769362029270269, train_acc = 0.9967396367023754\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 121, train_loss = 1.7601817591348663, train_acc = 0.9967396367023754\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 122, train_loss = 1.7514570318162441, train_acc = 0.9967396367023754\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 123, train_loss = 1.742060304270126, train_acc = 0.9967396367023754\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 124, train_loss = 1.7334788454463705, train_acc = 0.9967396367023754\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 125, train_loss = 1.725080375908874, train_acc = 0.9967396367023754\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 126, train_loss = 1.716902606189251, train_acc = 0.9967396367023754\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 127, train_loss = 1.7080679325154051, train_acc = 0.9967396367023754\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 128, train_loss = 1.7013799907872453, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 129, train_loss = 1.6927222026279196, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 130, train_loss = 1.6851803660392761, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 131, train_loss = 1.6776180304586887, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 132, train_loss = 1.67050624510739, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 133, train_loss = 1.6626147404313087, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 134, train_loss = 1.6560358591377735, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 135, train_loss = 1.6490116082131863, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 136, train_loss = 1.6422024728963152, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 137, train_loss = 1.6354835219681263, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 138, train_loss = 1.6288025429239497, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 139, train_loss = 1.6220510266721249, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 140, train_loss = 1.6159488931298256, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 141, train_loss = 1.609129186719656, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 142, train_loss = 1.6028281711041927, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 143, train_loss = 1.5965588837862015, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 144, train_loss = 1.5907939448952675, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 145, train_loss = 1.5844788948306814, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 146, train_loss = 1.5789760574698448, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 147, train_loss = 1.5731544382870197, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 148, train_loss = 1.5676388057181612, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 149, train_loss = 1.5617284575710073, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 150, train_loss = 1.5565433166921139, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 151, train_loss = 1.5507009712746367, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 152, train_loss = 1.545859932899475, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 153, train_loss = 1.5403962507843971, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 154, train_loss = 1.5356408394873142, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 155, train_loss = 1.5297189628472552, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 156, train_loss = 1.5253645876655355, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 157, train_loss = 1.5204631251981482, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 158, train_loss = 1.5151928787818179, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 159, train_loss = 1.5104992277920246, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 160, train_loss = 1.5056489867856726, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 161, train_loss = 1.5011033801129088, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 162, train_loss = 1.4961868189275265, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 163, train_loss = 1.4915210691979155, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 164, train_loss = 1.4869033048162237, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 165, train_loss = 1.482431523501873, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 166, train_loss = 1.4780177982756868, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 167, train_loss = 1.473231186508201, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 168, train_loss = 1.469065579236485, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 169, train_loss = 1.4643149400362745, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 170, train_loss = 1.4603478275239468, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 171, train_loss = 1.4560896953335032, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 172, train_loss = 1.4518084997544065, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 173, train_loss = 1.4476701654493809, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 174, train_loss = 1.4439290054142475, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 175, train_loss = 1.4397870674729347, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 176, train_loss = 1.4358983300626278, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 177, train_loss = 1.4318876005709171, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 178, train_loss = 1.4278370229294524, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 179, train_loss = 1.424331821501255, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 180, train_loss = 1.42068537697196, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 181, train_loss = 1.4164439750602469, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 182, train_loss = 1.4132325239479542, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 183, train_loss = 1.4096263783285394, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 184, train_loss = 1.4054816775023937, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 185, train_loss = 1.4024628537008539, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 186, train_loss = 1.3985994271934032, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 187, train_loss = 1.3950906991958618, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 188, train_loss = 1.3918041462311521, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 189, train_loss = 1.388179276138544, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 190, train_loss = 1.384722139686346, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 191, train_loss = 1.3816048875451088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 192, train_loss = 1.3780464641749859, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 193, train_loss = 1.3750823736190796, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 194, train_loss = 1.371377808332909, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 195, train_loss = 1.368785034865141, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 196, train_loss = 1.3652639873325825, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 197, train_loss = 1.3621816870872863, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 198, train_loss = 1.3592621075804345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 199, train_loss = 1.3561589668388478, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 200, train_loss = 1.3524239274556749, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 201, train_loss = 1.3497720621526241, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 202, train_loss = 1.3467227220535278, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 203, train_loss = 1.3441438439185731, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 204, train_loss = 1.3407484131748788, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 205, train_loss = 1.3378785264794715, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 206, train_loss = 1.3350674013490789, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 207, train_loss = 1.3319349686498754, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 208, train_loss = 1.3292975562508218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 209, train_loss = 1.3264300140435807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 210, train_loss = 1.3239079688792117, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 211, train_loss = 1.3209749087691307, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 212, train_loss = 1.3178770653903484, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 213, train_loss = 1.3155151928658597, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 214, train_loss = 1.3128582797944546, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 215, train_loss = 1.3101415361161344, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 216, train_loss = 1.3074927553534508, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 217, train_loss = 1.3047736908192746, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 218, train_loss = 1.3022488132119179, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 219, train_loss = 1.2994618664379232, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 220, train_loss = 1.2968855674262159, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 221, train_loss = 1.2948074017767794, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 222, train_loss = 1.292319008440245, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 223, train_loss = 1.2895543363993056, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 224, train_loss = 1.2869833509321325, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 225, train_loss = 1.2842296957969666, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 226, train_loss = 1.2822250190074556, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 227, train_loss = 1.2796277565066703, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 228, train_loss = 1.277318908541929, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 229, train_loss = 1.274923499673605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 230, train_loss = 1.2726788856089115, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 231, train_loss = 1.2702808293397538, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 232, train_loss = 1.2678306524758227, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 233, train_loss = 1.2657176703214645, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 234, train_loss = 1.2636306869680993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 235, train_loss = 1.2613796715741046, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 236, train_loss = 1.259028598666191, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 237, train_loss = 1.256832915067207, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 238, train_loss = 1.2542885541915894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 239, train_loss = 1.252534939616453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 240, train_loss = 1.2502493907813914, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 241, train_loss = 1.2481545992195606, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 242, train_loss = 1.2458751375670545, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 243, train_loss = 1.243891657621134, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 244, train_loss = 1.2416187686030753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 245, train_loss = 1.2395037015085109, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 246, train_loss = 1.2377547758514993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 247, train_loss = 1.2352895848453045, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 248, train_loss = 1.23329420509981, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 249, train_loss = 1.2316524796187878, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 250, train_loss = 1.229286917776335, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 251, train_loss = 1.2273315154016018, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 252, train_loss = 1.2253875111346133, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 253, train_loss = 1.2234773971140385, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 254, train_loss = 1.2214258288149722, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 255, train_loss = 1.2194143694941886, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 256, train_loss = 1.2172715266351588, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 257, train_loss = 1.2156141201849096, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 258, train_loss = 1.2137082343106158, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 259, train_loss = 1.2116766584222205, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 260, train_loss = 1.2096320378477685, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 261, train_loss = 1.2081793621182442, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 262, train_loss = 1.2059823547606356, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 263, train_loss = 1.2041825304622762, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 264, train_loss = 1.2021960454876535, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 265, train_loss = 1.200575893104542, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 266, train_loss = 1.1985004656016827, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 267, train_loss = 1.1967492774128914, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 268, train_loss = 1.1954102106392384, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 269, train_loss = 1.1931293569505215, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 270, train_loss = 1.1915797789697535, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 271, train_loss = 1.1897101886570454, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 272, train_loss = 1.187915654212702, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 273, train_loss = 1.1860164279933088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 274, train_loss = 1.1847499969298951, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 275, train_loss = 1.1825875329668634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 276, train_loss = 1.1809509533341043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 277, train_loss = 1.179193393618334, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 278, train_loss = 1.1775797207956202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 279, train_loss = 1.1761682033538818, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 280, train_loss = 1.174640433222521, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 281, train_loss = 1.1726429511909373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 282, train_loss = 1.1710651405155659, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 283, train_loss = 1.1690884704585187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 284, train_loss = 1.1680128152365796, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 285, train_loss = 1.1661817617714405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 286, train_loss = 1.1648309963638894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 287, train_loss = 1.1628417546744458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 288, train_loss = 1.161590714007616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 289, train_loss = 1.1599355824291706, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 290, train_loss = 1.157923171937, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 291, train_loss = 1.1567926009302028, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 292, train_loss = 1.1553907406632788, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 293, train_loss = 1.1536223205621354, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 294, train_loss = 1.1521571427583694, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 295, train_loss = 1.1506712337140925, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 296, train_loss = 1.1487716932897456, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 297, train_loss = 1.1474685830180533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 298, train_loss = 1.146177978545893, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 299, train_loss = 1.1443348589236848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 300, train_loss = 1.1428366489708424, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 301, train_loss = 1.1416802604799159, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 302, train_loss = 1.140114676207304, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 303, train_loss = 1.1386213973164558, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 304, train_loss = 1.1369830928742886, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 305, train_loss = 1.1354537743027322, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 306, train_loss = 1.134153913706541, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 307, train_loss = 1.1327997135813348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 308, train_loss = 1.1314892309601419, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 309, train_loss = 1.1298346991534345, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 310, train_loss = 1.1281016170978546, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 311, train_loss = 1.1271608521346934, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 312, train_loss = 1.1260915709135588, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 313, train_loss = 1.1241246834397316, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 314, train_loss = 1.1230448683199938, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 315, train_loss = 1.1213575216534082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 316, train_loss = 1.1204402310249861, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 317, train_loss = 1.1190835312008858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 318, train_loss = 1.1175866524281446, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 319, train_loss = 1.1160423780384008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 320, train_loss = 1.1149657567439135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 321, train_loss = 1.11402459940291, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 322, train_loss = 1.1124014059605543, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 323, train_loss = 1.1110893363656942, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 324, train_loss = 1.1100494662823621, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 325, train_loss = 1.1085395850241184, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 326, train_loss = 1.1072119610907976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 327, train_loss = 1.1060777617094573, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 328, train_loss = 1.1045845461485442, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 329, train_loss = 1.103785663843155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 330, train_loss = 1.1024532516894396, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 331, train_loss = 1.1009879037737846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 332, train_loss = 1.0997559217212256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 333, train_loss = 1.0987955133023206, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 334, train_loss = 1.097491937369341, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 335, train_loss = 1.0964529179036617, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 336, train_loss = 1.0946289536950644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 337, train_loss = 1.0937421955168247, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 338, train_loss = 1.0927815822360571, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 339, train_loss = 1.0915229519305285, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 340, train_loss = 1.0899265656771604, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 341, train_loss = 1.0891161424515303, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 342, train_loss = 1.0879160848853644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 343, train_loss = 1.0866627407667693, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 344, train_loss = 1.0853157701494638, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 345, train_loss = 1.0839527758362237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 346, train_loss = 1.0834851587715093, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 347, train_loss = 1.0821419606509153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 348, train_loss = 1.080820923059946, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 349, train_loss = 1.0797905276122037, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 350, train_loss = 1.0783533664944116, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 351, train_loss = 1.0772296922805253, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 352, train_loss = 1.0766786312160548, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 353, train_loss = 1.0751918728055898, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 354, train_loss = 1.0743041150271893, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 355, train_loss = 1.0727682448923588, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 356, train_loss = 1.0721644510922488, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 357, train_loss = 1.070647050946718, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 358, train_loss = 1.069671269506216, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 359, train_loss = 1.0689210034906864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 360, train_loss = 1.0674171509745065, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 361, train_loss = 1.06668895855546, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 362, train_loss = 1.0654902843234595, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 363, train_loss = 1.0642880039813463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 364, train_loss = 1.063077396393055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 365, train_loss = 1.0621058580873068, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 366, train_loss = 1.0611991807818413, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 367, train_loss = 1.0599546196463052, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 368, train_loss = 1.0590872267785016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 369, train_loss = 1.0578346525726374, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 370, train_loss = 1.0572915437223855, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 371, train_loss = 1.0562681978044566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 372, train_loss = 1.0549169542791788, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 373, train_loss = 1.0541932694613934, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 374, train_loss = 1.0526364470424596, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 375, train_loss = 1.052074458450079, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 376, train_loss = 1.050779423356289, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 377, train_loss = 1.0500522715447005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 378, train_loss = 1.0489726054074708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 379, train_loss = 1.0481910867092665, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 380, train_loss = 1.0465585278871004, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 381, train_loss = 1.0463428609073162, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 382, train_loss = 1.0449894964694977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 383, train_loss = 1.044299378991127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 384, train_loss = 1.0429106863739435, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 385, train_loss = 1.042283938586479, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 386, train_loss = 1.0412093338964041, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 387, train_loss = 1.040607431292301, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 388, train_loss = 1.0392736034991685, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 389, train_loss = 1.0384835613367613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 390, train_loss = 1.0373260267078876, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 391, train_loss = 1.036621996521717, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 392, train_loss = 1.0355625599622726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 393, train_loss = 1.0348791368305683, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 394, train_loss = 1.0334612131118774, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 395, train_loss = 1.0330375122430269, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 396, train_loss = 1.031843544304138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 397, train_loss = 1.031220156699419, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 398, train_loss = 1.0300022512674332, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 399, train_loss = 1.0296419809164945, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 400, train_loss = 1.0283330169913825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 401, train_loss = 1.0273503698408604, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 402, train_loss = 1.0267240429820959, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 403, train_loss = 1.025744628161192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 404, train_loss = 1.024944325297838, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 405, train_loss = 1.0235433839261532, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 406, train_loss = 1.022997621446848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 407, train_loss = 1.0221116803586483, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 408, train_loss = 1.0210795762541238, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 409, train_loss = 1.0200945623219013, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 410, train_loss = 1.01976121836924, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 411, train_loss = 1.0185338010487612, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 412, train_loss = 1.0178647066059057, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 413, train_loss = 1.0167235943081323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 414, train_loss = 1.0159538015723228, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 415, train_loss = 1.0155087957682554, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 416, train_loss = 1.0141721343097743, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 417, train_loss = 1.01368198543787, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 418, train_loss = 1.0125662721693516, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 419, train_loss = 1.011954639106989, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 420, train_loss = 1.010984984546667, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 421, train_loss = 1.0102927262487356, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 422, train_loss = 1.0093489748833235, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 423, train_loss = 1.008786916732788, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 424, train_loss = 1.0077937853930052, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 425, train_loss = 1.0075712762773037, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 426, train_loss = 1.0063548535108566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 427, train_loss = 1.0054769193229731, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 428, train_loss = 1.0046641876397189, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 429, train_loss = 1.0041613081994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 430, train_loss = 1.0027731234731618, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 431, train_loss = 1.0022195018827915, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 432, train_loss = 1.0016575592162553, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 433, train_loss = 1.0006191730499268, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 434, train_loss = 0.9997652843594551, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 435, train_loss = 0.9990770431759302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 436, train_loss = 0.9985907661321107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 437, train_loss = 0.9976342978479806, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 438, train_loss = 0.9971955505607184, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 439, train_loss = 0.996243953704834, train_acc = 0.9974382859804378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 440, train_loss = 0.9952123438415583, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 441, train_loss = 0.9948104421200696, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 442, train_loss = 0.9936769815685693, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 443, train_loss = 0.9928094359638635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 444, train_loss = 0.9926367253065109, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 445, train_loss = 0.9917144812643528, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 446, train_loss = 0.9908435357210692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 447, train_loss = 0.9897334910929203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 448, train_loss = 0.9895234940049704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 449, train_loss = 0.9883783000113908, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 450, train_loss = 0.9881294046936091, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 451, train_loss = 0.9872220195829868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 452, train_loss = 0.9866866742668208, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 453, train_loss = 0.9856138514878694, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 454, train_loss = 0.985422787576681, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 455, train_loss = 0.9840951301157475, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 456, train_loss = 0.983795308828121, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 457, train_loss = 0.9829603806138039, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 458, train_loss = 0.9824914236960467, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 459, train_loss = 0.9813162932696287, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 460, train_loss = 0.9807610772550106, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 461, train_loss = 0.9801405233738478, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 462, train_loss = 0.9794599202868994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 463, train_loss = 0.9789875621499959, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 464, train_loss = 0.9784817981126253, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 465, train_loss = 0.9771542536618654, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 466, train_loss = 0.9768695918319281, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 467, train_loss = 0.9759536683559418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 468, train_loss = 0.9751545004546642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 469, train_loss = 0.9748608395457268, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 470, train_loss = 0.9743685325083788, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 471, train_loss = 0.9732989495096263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 472, train_loss = 0.9726458328368608, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 473, train_loss = 0.9719709269702435, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 474, train_loss = 0.9711874363420065, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 475, train_loss = 0.9706754125654697, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 476, train_loss = 0.9700992628931999, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 477, train_loss = 0.9692211411893368, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 478, train_loss = 0.9689328583481256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 479, train_loss = 0.9677737081947271, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 480, train_loss = 0.9676313983800355, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 481, train_loss = 0.9668467020092066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 482, train_loss = 0.9664182066917419, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 483, train_loss = 0.9653021419944707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 484, train_loss = 0.9647007919847965, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 485, train_loss = 0.9641777364013251, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 486, train_loss = 0.9640802405774593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 487, train_loss = 0.9630338102579117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 488, train_loss = 0.9620217829942703, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 489, train_loss = 0.9616890127363149, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 490, train_loss = 0.9610756163892802, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 491, train_loss = 0.9603511095046997, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 492, train_loss = 0.9600602338614408, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 493, train_loss = 0.9588819121418055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 494, train_loss = 0.9589417912065983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 495, train_loss = 0.9579509397444781, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 496, train_loss = 0.9574372234346811, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 497, train_loss = 0.9568273363111075, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 498, train_loss = 0.9563168610038701, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 499, train_loss = 0.9556783685984556, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████▎                                       | 13/30 [2:09:27<2:49:42, 598.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "14th- epoch: 0, train_loss = 131.23634496331215, train_acc = 0.7652538425710294\n",
      "test Acc 0.8594040968342644:\n",
      "14th- epoch: 1, train_loss = 42.364793978631496, train_acc = 0.9092920353982301\n",
      "test Acc 0.9157355679702048:\n",
      "14th- epoch: 2, train_loss = 30.22188837081194, train_acc = 0.9371215649743828\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 3, train_loss = 24.338241264224052, train_acc = 0.9507452258965999\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 4, train_loss = 20.639132395386696, train_acc = 0.9579646017699115\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 5, train_loss = 17.95643488690257, train_acc = 0.9625058220773172\n",
      "test Acc 0.952048417132216:\n",
      "14th- epoch: 6, train_loss = 15.928710166364908, train_acc = 0.9669306008383791\n",
      "test Acc 0.9543761638733705:\n",
      "14th- epoch: 7, train_loss = 14.327216196805239, train_acc = 0.9703074056823474\n",
      "test Acc 0.9553072625698324:\n",
      "14th- epoch: 8, train_loss = 13.038634330034256, train_acc = 0.9742664182580345\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 9, train_loss = 11.986309915781021, train_acc = 0.9769445738239404\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 10, train_loss = 11.101765738800168, train_acc = 0.9788076385654402\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 11, train_loss = 10.347131792455912, train_acc = 0.9795062878435026\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 12, train_loss = 9.699206653982401, train_acc = 0.980204937121565\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 13, train_loss = 9.133715832605958, train_acc = 0.9811364694923148\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 14, train_loss = 8.630931766703725, train_acc = 0.9823008849557522\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 15, train_loss = 8.186350801959634, train_acc = 0.983698183511877\n",
      "test Acc 0.9641527001862198:\n",
      "14th- epoch: 16, train_loss = 7.789540475234389, train_acc = 0.9847461574289706\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 17, train_loss = 7.433194414712489, train_acc = 0.9861434559850955\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 18, train_loss = 7.11219831649214, train_acc = 0.9864927806241267\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 19, train_loss = 6.819919793866575, train_acc = 0.9870749883558454\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 20, train_loss = 6.5529989041388035, train_acc = 0.9874243129948765\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 21, train_loss = 6.308835932053626, train_acc = 0.9880065207265952\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 22, train_loss = 6.084926360286772, train_acc = 0.9884722869119702\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 23, train_loss = 5.879197399131954, train_acc = 0.9889380530973452\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 24, train_loss = 5.688963450491428, train_acc = 0.9892873777363763\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 25, train_loss = 5.512703414075077, train_acc = 0.98940381928272\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 26, train_loss = 5.348458177410066, train_acc = 0.989869585468095\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 27, train_loss = 5.195716298185289, train_acc = 0.990801117838845\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 28, train_loss = 5.053682248108089, train_acc = 0.9911504424778761\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 29, train_loss = 4.9212962398305535, train_acc = 0.9913833255705635\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 30, train_loss = 4.794781122356653, train_acc = 0.9914997671169073\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 31, train_loss = 4.677688308060169, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 32, train_loss = 4.5676471730694175, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 33, train_loss = 4.46334931999445, train_acc = 0.9930135072193759\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 34, train_loss = 4.3635435765609145, train_acc = 0.9933628318584071\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 35, train_loss = 4.271826233714819, train_acc = 0.9934792734047508\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 36, train_loss = 4.1829222440719604, train_acc = 0.9940614811364695\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 37, train_loss = 4.099075087346137, train_acc = 0.9941779226828132\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 38, train_loss = 4.018862575292587, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 39, train_loss = 3.9443688788451254, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 40, train_loss = 3.8718089810572565, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 41, train_loss = 3.8033772320486605, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 42, train_loss = 3.736187268048525, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 43, train_loss = 3.6746719242073596, train_acc = 0.9951094550535631\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 44, train_loss = 3.61364609003067, train_acc = 0.9951094550535631\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 45, train_loss = 3.5569984428584576, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 46, train_loss = 3.5018263100646436, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 47, train_loss = 3.4480596147477627, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 48, train_loss = 3.397475380450487, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 49, train_loss = 3.3480770303867757, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 50, train_loss = 3.2993806079030037, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 51, train_loss = 3.2533363909460604, train_acc = 0.9954587796925943\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 52, train_loss = 3.209457868244499, train_acc = 0.9954587796925943\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 53, train_loss = 3.1658707186579704, train_acc = 0.9954587796925943\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 54, train_loss = 3.125519165303558, train_acc = 0.9954587796925943\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 55, train_loss = 3.08560594310984, train_acc = 0.9954587796925943\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 56, train_loss = 3.0462406016886234, train_acc = 0.995575221238938\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 57, train_loss = 3.0086282291449606, train_acc = 0.9956916627852818\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 58, train_loss = 2.97294889530167, train_acc = 0.9956916627852818\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 59, train_loss = 2.9372652829624712, train_acc = 0.9956916627852818\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 60, train_loss = 2.902247206773609, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 61, train_loss = 2.8696807944215834, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 62, train_loss = 2.8373484103940427, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 63, train_loss = 2.8064228468574584, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 64, train_loss = 2.776264840271324, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 65, train_loss = 2.746760129928589, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 66, train_loss = 2.718264412134886, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 67, train_loss = 2.690361572895199, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 68, train_loss = 2.662531338632107, train_acc = 0.9959245458779693\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 69, train_loss = 2.6362916193902493, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 70, train_loss = 2.610297823790461, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 71, train_loss = 2.585615745279938, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 72, train_loss = 2.5602642237208784, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 73, train_loss = 2.5372516736388206, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 74, train_loss = 2.5137677404563874, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 75, train_loss = 2.490619535325095, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 76, train_loss = 2.4692212890367955, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 77, train_loss = 2.4466175276320428, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 78, train_loss = 2.4258761804085225, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 79, train_loss = 2.4050749738235027, train_acc = 0.9961574289706567\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 80, train_loss = 2.3849432680290192, train_acc = 0.9962738705170004\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 81, train_loss = 2.3646040584426373, train_acc = 0.9962738705170004\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 82, train_loss = 2.3453144542872906, train_acc = 0.9962738705170004\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 83, train_loss = 2.3261915768962353, train_acc = 0.9962738705170004\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 84, train_loss = 2.307254685787484, train_acc = 0.9962738705170004\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 85, train_loss = 2.289484725566581, train_acc = 0.9962738705170004\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 86, train_loss = 2.2713896085042506, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 87, train_loss = 2.2540037867147475, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 88, train_loss = 2.2370983113069087, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 89, train_loss = 2.219968356192112, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 90, train_loss = 2.20330877113156, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 91, train_loss = 2.1870707261841744, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 92, train_loss = 2.171533814398572, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 93, train_loss = 2.155736707150936, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 94, train_loss = 2.1409253391902894, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 95, train_loss = 2.1255453538615257, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 96, train_loss = 2.110889296978712, train_acc = 0.9962738705170004\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 97, train_loss = 2.0963948741555214, train_acc = 0.9962738705170004\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 98, train_loss = 2.0822263148147613, train_acc = 0.9962738705170004\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 99, train_loss = 2.0682196270208806, train_acc = 0.9963903120633442\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 100, train_loss = 2.054789822548628, train_acc = 0.9963903120633442\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 101, train_loss = 2.0414419944863766, train_acc = 0.9963903120633442\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 102, train_loss = 2.0284203614573926, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 103, train_loss = 2.0154119085054845, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 104, train_loss = 2.0031922485213727, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 105, train_loss = 1.9904480141121894, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 106, train_loss = 1.978810641914606, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 107, train_loss = 1.9669797967653722, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 108, train_loss = 1.955699723213911, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 109, train_loss = 1.9436076793354005, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 110, train_loss = 1.9328007448930293, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 111, train_loss = 1.921115030767396, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 112, train_loss = 1.9109442706685513, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 113, train_loss = 1.8997753411531448, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 114, train_loss = 1.8894785169977695, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 115, train_loss = 1.8787983928341419, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 116, train_loss = 1.8688243578653783, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 117, train_loss = 1.8591390252113342, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 118, train_loss = 1.8500838701147586, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 119, train_loss = 1.8395778175909072, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 120, train_loss = 1.8308473255019635, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 121, train_loss = 1.8216384823899716, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 122, train_loss = 1.812326978892088, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 123, train_loss = 1.8037900477647781, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 124, train_loss = 1.794839893700555, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 125, train_loss = 1.786314006894827, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 126, train_loss = 1.7783850457053632, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 127, train_loss = 1.7696806205203757, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 128, train_loss = 1.7618156584212556, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 129, train_loss = 1.7539553679525852, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 130, train_loss = 1.7460152941057459, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 131, train_loss = 1.7382527341833338, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 132, train_loss = 1.7303188195219263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 133, train_loss = 1.722629837691784, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 134, train_loss = 1.7154804170131683, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 135, train_loss = 1.7082690745592117, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 136, train_loss = 1.700505449087359, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 137, train_loss = 1.694630709826015, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 138, train_loss = 1.6868217525770888, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 139, train_loss = 1.6806366307428107, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 140, train_loss = 1.6733610419323668, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 141, train_loss = 1.6673926388612017, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 142, train_loss = 1.6604968929896131, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 143, train_loss = 1.6546826114645228, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 144, train_loss = 1.6473086202749982, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 145, train_loss = 1.6415602192282677, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 146, train_loss = 1.6359527023741975, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 147, train_loss = 1.6294344825437292, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 148, train_loss = 1.6241572486469522, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 149, train_loss = 1.6177516641328111, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 150, train_loss = 1.6121016269316897, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 151, train_loss = 1.6065725249936804, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 152, train_loss = 1.6011579036712646, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 153, train_loss = 1.5954249961068854, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 154, train_loss = 1.5901847580680624, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 155, train_loss = 1.584432166069746, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 156, train_loss = 1.5792026171693578, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 157, train_loss = 1.574229477555491, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 158, train_loss = 1.568769066245295, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 159, train_loss = 1.5634673250606284, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 160, train_loss = 1.5585775673389435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 161, train_loss = 1.5537665138253942, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 162, train_loss = 1.5484360171249136, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 163, train_loss = 1.544070472358726, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 164, train_loss = 1.5387462824583054, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 165, train_loss = 1.5341694541275501, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 166, train_loss = 1.5291436152765527, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 167, train_loss = 1.5249092566082254, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 168, train_loss = 1.5200106339761987, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 169, train_loss = 1.515978122712113, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 170, train_loss = 1.5106220903107896, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 171, train_loss = 1.5064769113669172, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 172, train_loss = 1.5014051446923986, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 173, train_loss = 1.497889573336579, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 174, train_loss = 1.4931551491608843, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 175, train_loss = 1.4890479730674997, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 176, train_loss = 1.4849826780846342, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 177, train_loss = 1.48071266093757, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 178, train_loss = 1.4766647989163175, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 179, train_loss = 1.4723198637366295, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 180, train_loss = 1.4686966190347448, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 181, train_loss = 1.4643507562577724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 182, train_loss = 1.4604827066650614, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 183, train_loss = 1.4563672927906737, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 184, train_loss = 1.4522689232835546, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 185, train_loss = 1.4490392282605171, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 186, train_loss = 1.4452366543700919, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 187, train_loss = 1.4414951665094122, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 188, train_loss = 1.4382372051477432, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 189, train_loss = 1.4338522950420156, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 190, train_loss = 1.4306681603193283, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 191, train_loss = 1.4269155636429787, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 192, train_loss = 1.4233324540546164, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 193, train_loss = 1.420134806423448, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 194, train_loss = 1.416086153476499, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 195, train_loss = 1.4133753204951063, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 196, train_loss = 1.409706972539425, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 197, train_loss = 1.4058942832052708, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 198, train_loss = 1.4025317492778413, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 199, train_loss = 1.4002402077312581, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 200, train_loss = 1.3965544402599335, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 201, train_loss = 1.393006173253525, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 202, train_loss = 1.3896151930093765, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 203, train_loss = 1.387055516242981, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 204, train_loss = 1.3837139991228469, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 205, train_loss = 1.3808156686718576, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 206, train_loss = 1.377257764339447, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 207, train_loss = 1.3745828618411906, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 208, train_loss = 1.3713488007779233, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 209, train_loss = 1.368396324396599, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 210, train_loss = 1.3650549811427481, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 211, train_loss = 1.3618996391887777, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 212, train_loss = 1.3601431312854402, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 213, train_loss = 1.3564347748761065, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 214, train_loss = 1.353465544700157, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 215, train_loss = 1.350986224890221, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 216, train_loss = 1.3476432996685617, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 217, train_loss = 1.3457649946212769, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 218, train_loss = 1.3421385437250137, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 219, train_loss = 1.3396828472614288, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 220, train_loss = 1.3370728504960425, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 221, train_loss = 1.334245974838268, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 222, train_loss = 1.3319246086175554, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 223, train_loss = 1.3288781245355494, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 224, train_loss = 1.3260381606523879, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 225, train_loss = 1.3238463352317922, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 226, train_loss = 1.3212451040744781, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 227, train_loss = 1.3183782671694644, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 228, train_loss = 1.3160442101652734, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 229, train_loss = 1.3135278597474098, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 230, train_loss = 1.31062350171851, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 231, train_loss = 1.3083040975034237, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 232, train_loss = 1.305009201169014, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 233, train_loss = 1.3029636305873282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 234, train_loss = 1.299983395903837, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 235, train_loss = 1.297812591015827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 236, train_loss = 1.2952194822137244, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 237, train_loss = 1.2926898573641665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 238, train_loss = 1.2903026888961904, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 239, train_loss = 1.2876681511406787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 240, train_loss = 1.2857096220250241, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 241, train_loss = 1.2831403724849224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 242, train_loss = 1.2810565319960006, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 243, train_loss = 1.2784405536949635, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 244, train_loss = 1.2766527968342416, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 245, train_loss = 1.2741236562724225, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 246, train_loss = 1.271660057187546, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 247, train_loss = 1.2695677801966667, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 248, train_loss = 1.2674863238935359, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 249, train_loss = 1.2651562628452666, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 250, train_loss = 1.2632945726509206, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 251, train_loss = 1.2610634316806681, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 252, train_loss = 1.2591086800093763, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 253, train_loss = 1.2560676175053231, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 254, train_loss = 1.2549015184049495, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 255, train_loss = 1.2518710059230216, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 256, train_loss = 1.2503536529839039, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 257, train_loss = 1.2477278274600394, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 258, train_loss = 1.246224136382807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 259, train_loss = 1.2443277786369435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 260, train_loss = 1.2418348714709282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 261, train_loss = 1.2400220234994777, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 262, train_loss = 1.2376262371544726, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 263, train_loss = 1.2360892705619335, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 264, train_loss = 1.2335638925433159, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 265, train_loss = 1.2323057912290096, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 266, train_loss = 1.2299757463042624, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 267, train_loss = 1.2279140639002435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 268, train_loss = 1.226654487370979, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 269, train_loss = 1.2239607113297097, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 270, train_loss = 1.2222699995036237, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 271, train_loss = 1.2204406360979192, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 272, train_loss = 1.2185387586359866, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 273, train_loss = 1.2167813020641916, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 274, train_loss = 1.2147208985988982, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 275, train_loss = 1.2126756508951075, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 276, train_loss = 1.2115492410957813, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 277, train_loss = 1.209152893454302, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 278, train_loss = 1.207197682291735, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 279, train_loss = 1.2060637809336185, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 280, train_loss = 1.2036608830094337, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 281, train_loss = 1.2021211422979832, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 282, train_loss = 1.1999266656930558, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 283, train_loss = 1.1984310957486741, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 284, train_loss = 1.1962203060393222, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 285, train_loss = 1.1944626768236049, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 286, train_loss = 1.1932413068716414, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 287, train_loss = 1.1910556268994696, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 288, train_loss = 1.1894943602383137, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 289, train_loss = 1.1881374579970725, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 290, train_loss = 1.186285110830795, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 291, train_loss = 1.1846634969115257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 292, train_loss = 1.1829645931720734, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 293, train_loss = 1.181592758744955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 294, train_loss = 1.179673397273291, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 295, train_loss = 1.1783541962504387, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 296, train_loss = 1.1769226889009587, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 297, train_loss = 1.1749358561937697, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 298, train_loss = 1.1735576465725899, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 299, train_loss = 1.172037957876455, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 300, train_loss = 1.170341829478275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 301, train_loss = 1.1689712864463218, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 302, train_loss = 1.1673238004441373, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 303, train_loss = 1.1656012050807476, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 304, train_loss = 1.1638208155636676, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 305, train_loss = 1.1625515148043633, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 306, train_loss = 1.1614798779191915, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 307, train_loss = 1.1592305029334966, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 308, train_loss = 1.158076960593462, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 309, train_loss = 1.1568336697819177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 310, train_loss = 1.1551720201969147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 311, train_loss = 1.1534556709229946, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 312, train_loss = 1.1521356416342314, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 313, train_loss = 1.1511960662901402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 314, train_loss = 1.1489494865236338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 315, train_loss = 1.1480855718255043, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 316, train_loss = 1.1464777675864752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 317, train_loss = 1.1451510662736837, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 318, train_loss = 1.1437624332902487, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 319, train_loss = 1.1421240791678429, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 320, train_loss = 1.1411187872290611, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 321, train_loss = 1.139175799995428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 322, train_loss = 1.138348039239645, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 323, train_loss = 1.1368200667202473, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 324, train_loss = 1.135161116719246, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 325, train_loss = 1.1345825555326883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 326, train_loss = 1.1328335826692637, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 327, train_loss = 1.1313114253280219, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 328, train_loss = 1.1301544532179832, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 329, train_loss = 1.1290916725993156, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 330, train_loss = 1.1276345861551818, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 331, train_loss = 1.1262130153772887, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 332, train_loss = 1.124827860534424, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 333, train_loss = 1.123908393085003, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 334, train_loss = 1.122506134212017, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 335, train_loss = 1.120967543363804, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 336, train_loss = 1.1199486441910267, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 337, train_loss = 1.1180883472261485, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 338, train_loss = 1.117276036500698, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 339, train_loss = 1.1162423081696033, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 340, train_loss = 1.114767483115429, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 341, train_loss = 1.113489924609894, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 342, train_loss = 1.1123203349707182, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 343, train_loss = 1.110728994011879, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 344, train_loss = 1.1099745916726533, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 345, train_loss = 1.1082717018725816, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 346, train_loss = 1.1074735125002917, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 347, train_loss = 1.1065007597208023, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 348, train_loss = 1.1046532218751963, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 349, train_loss = 1.1039153473975603, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 350, train_loss = 1.1024609133601189, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 351, train_loss = 1.1012860859336797, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 352, train_loss = 1.100454213708872, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 353, train_loss = 1.0983678301272448, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 354, train_loss = 1.0979397371411324, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 355, train_loss = 1.096511042356724, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 356, train_loss = 1.095274635910755, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 357, train_loss = 1.094435320555931, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 358, train_loss = 1.0933914681372698, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 359, train_loss = 1.091841246932745, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 360, train_loss = 1.090755045413971, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 361, train_loss = 1.089878940343624, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 362, train_loss = 1.0886339557764586, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 363, train_loss = 1.0876020205614623, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 364, train_loss = 1.0860435540380422, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 365, train_loss = 1.0852490266261157, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 366, train_loss = 1.084170682966942, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 367, train_loss = 1.083117680012947, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 368, train_loss = 1.0820915003714617, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 369, train_loss = 1.0809400863945484, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 370, train_loss = 1.079521098494297, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 371, train_loss = 1.0787313667533454, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 372, train_loss = 1.077652723848587, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 373, train_loss = 1.076643237232929, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 374, train_loss = 1.0757602105441038, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 375, train_loss = 1.074234197527403, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 376, train_loss = 1.0735981948673725, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 377, train_loss = 1.072393111884594, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 378, train_loss = 1.0713044044969138, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 379, train_loss = 1.0704948653874453, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 380, train_loss = 1.0691985251905862, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 381, train_loss = 1.068145109951729, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 382, train_loss = 1.0670266101660673, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 383, train_loss = 1.066395799309248, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 384, train_loss = 1.064954406261677, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 385, train_loss = 1.06417166441679, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 386, train_loss = 1.0629322404565755, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 387, train_loss = 1.0623977122304495, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 388, train_loss = 1.0613047666847706, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 389, train_loss = 1.0598342083394527, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 390, train_loss = 1.0594648445548955, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 391, train_loss = 1.0582427394983824, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 392, train_loss = 1.0574669018387794, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 393, train_loss = 1.0563031037745532, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 394, train_loss = 1.0554735151526984, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 395, train_loss = 1.054682174086338, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 396, train_loss = 1.0534819612803403, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 397, train_loss = 1.0523775555193424, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 398, train_loss = 1.0517361474630889, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 399, train_loss = 1.0504415718314704, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 400, train_loss = 1.0498801643552724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 401, train_loss = 1.0484213940799236, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 402, train_loss = 1.0477176643908024, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 403, train_loss = 1.0471735571918543, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 404, train_loss = 1.0457710698246956, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 405, train_loss = 1.0451490481791552, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 406, train_loss = 1.04443034902215, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 407, train_loss = 1.0431754129531328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 408, train_loss = 1.0423424529435579, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 409, train_loss = 1.041485995054245, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 410, train_loss = 1.04033967727446, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 411, train_loss = 1.0401136502623558, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 412, train_loss = 1.0384684354066849, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 413, train_loss = 1.0377302219567355, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 414, train_loss = 1.0371759571135044, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 415, train_loss = 1.0360189800558146, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 416, train_loss = 1.0353428162634373, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 417, train_loss = 1.0348524252476636, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 418, train_loss = 1.0332233098743018, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 419, train_loss = 1.0327996487321798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 420, train_loss = 1.031986235320801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 421, train_loss = 1.031309654325014, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 422, train_loss = 1.0301397070288658, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 423, train_loss = 1.029325666517252, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 424, train_loss = 1.028523358196253, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 425, train_loss = 1.0276117237808648, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 426, train_loss = 1.0270360720751341, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 427, train_loss = 1.025698658078909, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 428, train_loss = 1.024962422758108, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 429, train_loss = 1.024352358042961, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 430, train_loss = 1.023530221224064, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 431, train_loss = 1.022963476687437, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 432, train_loss = 1.0219400810601655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 433, train_loss = 1.0213416007754859, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 434, train_loss = 1.0207682450709399, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 435, train_loss = 1.0198242403566837, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 436, train_loss = 1.0188303080794867, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 437, train_loss = 1.0185998678207397, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 438, train_loss = 1.017139599978691, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 439, train_loss = 1.0165491588413715, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 440, train_loss = 1.0164442608656827, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 441, train_loss = 1.0149309436383191, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 442, train_loss = 1.0144816065730993, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 443, train_loss = 1.0138240829110146, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 444, train_loss = 1.0126566824910697, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 445, train_loss = 1.0120658961532172, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 446, train_loss = 1.0109598698618356, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 447, train_loss = 1.0108211636543274, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 448, train_loss = 1.0096729596552905, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 449, train_loss = 1.0086349596676882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 450, train_loss = 1.0082665806112345, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 451, train_loss = 1.0071230543253478, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 452, train_loss = 1.0068123030068818, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 453, train_loss = 1.0058545494975988, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 454, train_loss = 1.0051059213874396, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 455, train_loss = 1.0049620258214418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 456, train_loss = 1.0029318767192308, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 457, train_loss = 1.0031516142189503, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 458, train_loss = 1.0022216799261514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 459, train_loss = 1.001661187663558, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 460, train_loss = 1.0003287121653557, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 461, train_loss = 0.9998247548937798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 462, train_loss = 0.9992903843522072, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 463, train_loss = 0.9981722682714462, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 464, train_loss = 0.9976506171078654, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 465, train_loss = 0.9970377360732527, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 466, train_loss = 0.9961342625319958, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 467, train_loss = 0.9955619710235624, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 468, train_loss = 0.9952333470137091, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 469, train_loss = 0.9938459657132626, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 470, train_loss = 0.9936155353934737, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 471, train_loss = 0.9927650627942057, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 472, train_loss = 0.9921053585858317, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 473, train_loss = 0.9913309824914904, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 474, train_loss = 0.9909955735056428, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 475, train_loss = 0.9896535736770602, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 476, train_loss = 0.989501108721015, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 477, train_loss = 0.9886130280792713, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 478, train_loss = 0.9876475110650063, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 479, train_loss = 0.9868762269616127, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 480, train_loss = 0.9869791430683108, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 481, train_loss = 0.9857907046825858, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 482, train_loss = 0.9851292458624812, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 483, train_loss = 0.9842079505324364, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 484, train_loss = 0.9838934950530529, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 485, train_loss = 0.9828984799532918, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 486, train_loss = 0.9827366322278976, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 487, train_loss = 0.9814293906092644, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 488, train_loss = 0.9814052321016788, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 489, train_loss = 0.9805577360093594, train_acc = 0.9981369352585002\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 490, train_loss = 0.9793967045843601, train_acc = 0.9981369352585002\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 491, train_loss = 0.9789860273449449, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 492, train_loss = 0.9785647913813591, train_acc = 0.9981369352585002\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 493, train_loss = 0.9772070795297623, train_acc = 0.9981369352585002\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 494, train_loss = 0.9774561896920204, train_acc = 0.9981369352585002\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 495, train_loss = 0.976060311004403, train_acc = 0.9981369352585002\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 496, train_loss = 0.9762029560952215, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 497, train_loss = 0.9750440915377112, train_acc = 0.9981369352585002\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 498, train_loss = 0.9740301594138145, train_acc = 0.9981369352585002\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 499, train_loss = 0.9740654416382313, train_acc = 0.9981369352585002\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████████▋                                     | 14/30 [2:19:26<2:39:44, 599.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "15th- epoch: 0, train_loss = 127.47455484420061, train_acc = 0.778178854215184\n",
      "test Acc 0.8794227188081937:\n",
      "15th- epoch: 1, train_loss = 44.195656921714544, train_acc = 0.9101071262226362\n",
      "test Acc 0.9213221601489758:\n",
      "15th- epoch: 2, train_loss = 31.501319527626038, train_acc = 0.9358407079646017\n",
      "test Acc 0.9338919925512105:\n",
      "15th- epoch: 3, train_loss = 25.172774486243725, train_acc = 0.9496972519795063\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 4, train_loss = 21.25533981062472, train_acc = 0.9577317186772241\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 5, train_loss = 18.544415282085538, train_acc = 0.9629715882626921\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 6, train_loss = 16.51555679552257, train_acc = 0.9673963670237541\n",
      "test Acc 0.9539106145251397:\n",
      "15th- epoch: 7, train_loss = 14.912930652499199, train_acc = 0.9706567303213787\n",
      "test Acc 0.9585661080074488:\n",
      "15th- epoch: 8, train_loss = 13.595021532848477, train_acc = 0.9729855612482534\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 9, train_loss = 12.498140715062618, train_acc = 0.9749650675360969\n",
      "test Acc 0.962756052141527:\n",
      "15th- epoch: 10, train_loss = 11.567400988191366, train_acc = 0.9774103400093154\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 11, train_loss = 10.756395604461432, train_acc = 0.9791569632044713\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 12, train_loss = 10.052834069356322, train_acc = 0.9807871448532837\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 13, train_loss = 9.433275269344449, train_acc = 0.9817186772240335\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 14, train_loss = 8.885328210890293, train_acc = 0.9828830926874709\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 15, train_loss = 8.392643905244768, train_acc = 0.9839310666045645\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 16, train_loss = 7.948578276671469, train_acc = 0.985444806707033\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 17, train_loss = 7.549516837112606, train_acc = 0.9866092221704704\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 18, train_loss = 7.188343370333314, train_acc = 0.9878900791802515\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 19, train_loss = 6.863552466966212, train_acc = 0.9885887284583139\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 20, train_loss = 6.5721220606938004, train_acc = 0.9888216115510013\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 21, train_loss = 6.306191827170551, train_acc = 0.9896367023754076\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 22, train_loss = 6.065440903417766, train_acc = 0.9901024685607824\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 23, train_loss = 5.84437504876405, train_acc = 0.9904517931998137\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 24, train_loss = 5.641232187859714, train_acc = 0.9909175593851887\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 25, train_loss = 5.452216754667461, train_acc = 0.9912668840242198\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 26, train_loss = 5.277764809317887, train_acc = 0.9917326502095948\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 27, train_loss = 5.115263741463423, train_acc = 0.9921984163949698\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 28, train_loss = 4.962838253006339, train_acc = 0.9923148579413135\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 29, train_loss = 4.821550026535988, train_acc = 0.9924312994876572\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 30, train_loss = 4.689662957098335, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 31, train_loss = 4.5625505819916725, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 32, train_loss = 4.445261860731989, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 33, train_loss = 4.335271923337132, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 34, train_loss = 4.228227276355028, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 35, train_loss = 4.128258103039116, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 36, train_loss = 4.033734250813723, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 37, train_loss = 3.943953237030655, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 38, train_loss = 3.858479151967913, train_acc = 0.9940614811364695\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 39, train_loss = 3.7771490402519703, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 40, train_loss = 3.6993702524341643, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 41, train_loss = 3.626394484192133, train_acc = 0.9945272473218444\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 42, train_loss = 3.5543750673532486, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 43, train_loss = 3.4881752394139767, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 44, train_loss = 3.4227068894542754, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 45, train_loss = 3.3618793562054634, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 46, train_loss = 3.30315691861324, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 47, train_loss = 3.2460948687512428, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 48, train_loss = 3.192239860771224, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 49, train_loss = 3.1415082637686282, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 50, train_loss = 3.092154597165063, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 51, train_loss = 3.0443357329349965, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 52, train_loss = 2.999332540901378, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 53, train_loss = 2.955585827352479, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 54, train_loss = 2.9125459045171738, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 55, train_loss = 2.871884108753875, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 56, train_loss = 2.832949750125408, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 57, train_loss = 2.79571025329642, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 58, train_loss = 2.758992413757369, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 59, train_loss = 2.7243758377153426, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 60, train_loss = 2.6910739180166274, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 61, train_loss = 2.658600556431338, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 62, train_loss = 2.6265683707315475, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 63, train_loss = 2.5955703146755695, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 64, train_loss = 2.5664985477924347, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 65, train_loss = 2.537669538287446, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 66, train_loss = 2.5093058485072106, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 67, train_loss = 2.4817833937704563, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 68, train_loss = 2.4553396713454276, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 69, train_loss = 2.4297425497788936, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 70, train_loss = 2.4047021369915456, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 71, train_loss = 2.3816021259408444, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 72, train_loss = 2.358285763533786, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 73, train_loss = 2.336325691314414, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 74, train_loss = 2.3148265989730135, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 75, train_loss = 2.294492520391941, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 76, train_loss = 2.2735133121022955, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 77, train_loss = 2.254121777950786, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 78, train_loss = 2.2346051955828443, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 79, train_loss = 2.216460050432943, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 80, train_loss = 2.1992747373878956, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 81, train_loss = 2.181050686747767, train_acc = 0.9961574289706567\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 82, train_loss = 2.1641651591053233, train_acc = 0.9961574289706567\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 83, train_loss = 2.147493038326502, train_acc = 0.9961574289706567\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 84, train_loss = 2.131325134425424, train_acc = 0.9962738705170004\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 85, train_loss = 2.116069335490465, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 86, train_loss = 2.099704516469501, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 87, train_loss = 2.085196184576489, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 88, train_loss = 2.071037055342458, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 89, train_loss = 2.0564218387007713, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 90, train_loss = 2.042233232408762, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 91, train_loss = 2.0292090674629435, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 92, train_loss = 2.015572560369037, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 93, train_loss = 2.0030702762305737, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 94, train_loss = 1.989596363157034, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 95, train_loss = 1.9782967567443848, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 96, train_loss = 1.9651609858265147, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 97, train_loss = 1.953876773477532, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 98, train_loss = 1.941589031368494, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 99, train_loss = 1.9308025985956192, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 100, train_loss = 1.9186421757331118, train_acc = 0.9967396367023754\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 101, train_loss = 1.9083857176592574, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 102, train_loss = 1.8970241732895374, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 103, train_loss = 1.8872833674540743, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 104, train_loss = 1.8761096000671387, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 105, train_loss = 1.8663559159031138, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 106, train_loss = 1.8563001850852743, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 107, train_loss = 1.8466245954623446, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 108, train_loss = 1.836815319955349, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 109, train_loss = 1.8278518443694338, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 110, train_loss = 1.8189190551638603, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 111, train_loss = 1.8096755804726854, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 112, train_loss = 1.8011988997459412, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 113, train_loss = 1.792624820023775, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 114, train_loss = 1.7835384408244863, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 115, train_loss = 1.7756250152597204, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 116, train_loss = 1.7676133587956429, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 117, train_loss = 1.7594011649489403, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 118, train_loss = 1.7517701610922813, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 119, train_loss = 1.7434334059944376, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 120, train_loss = 1.7359607914695516, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 121, train_loss = 1.7282502514426596, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 122, train_loss = 1.720541849732399, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 123, train_loss = 1.7134835571050644, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 124, train_loss = 1.7062860342557542, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 125, train_loss = 1.6979436067049392, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 126, train_loss = 1.6915858089923859, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 127, train_loss = 1.6840294313733466, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 128, train_loss = 1.6770128619973548, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 129, train_loss = 1.6702251732349396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 130, train_loss = 1.6634375117719173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 131, train_loss = 1.6568836867809296, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 132, train_loss = 1.6499914154410362, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 133, train_loss = 1.6441179141402245, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 134, train_loss = 1.638292112678755, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 135, train_loss = 1.6316939828102477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 136, train_loss = 1.626090057194233, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 137, train_loss = 1.619885457039345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 138, train_loss = 1.6141156827216037, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 139, train_loss = 1.6093950060312636, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 140, train_loss = 1.6023952041869052, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 141, train_loss = 1.5974802573327906, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 142, train_loss = 1.5916702908580191, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 143, train_loss = 1.5861491138930432, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 144, train_loss = 1.5806758627295494, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 145, train_loss = 1.5762345679104328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 146, train_loss = 1.5704411529004574, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 147, train_loss = 1.564682848751545, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 148, train_loss = 1.5602754863793962, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 149, train_loss = 1.5554269713466056, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 150, train_loss = 1.549962607503403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 151, train_loss = 1.5453662537038326, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 152, train_loss = 1.54094797372818, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 153, train_loss = 1.535481158643961, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 154, train_loss = 1.531936610757839, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 155, train_loss = 1.5269738460774533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 156, train_loss = 1.521846315532457, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 157, train_loss = 1.5183539167046547, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 158, train_loss = 1.5124227565829642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 159, train_loss = 1.5086166362161748, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 160, train_loss = 1.5043410174548626, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 161, train_loss = 1.499905998527538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 162, train_loss = 1.4954997797613032, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 163, train_loss = 1.4913059584796429, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 164, train_loss = 1.4876450833980925, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 165, train_loss = 1.4831497259438038, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 166, train_loss = 1.479376653849613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 167, train_loss = 1.4751767739653587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 168, train_loss = 1.470897754014004, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 169, train_loss = 1.467399148910772, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 170, train_loss = 1.4631307981908321, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 171, train_loss = 1.4596409412915818, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 172, train_loss = 1.4562225106055848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 173, train_loss = 1.4517835031147115, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 174, train_loss = 1.4484098106622696, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 175, train_loss = 1.4445217016036622, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 176, train_loss = 1.4411704900558107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 177, train_loss = 1.4365837660734542, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 178, train_loss = 1.4331708140671253, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 179, train_loss = 1.4300335210864432, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 180, train_loss = 1.4262616485357285, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 181, train_loss = 1.4234708088333718, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 182, train_loss = 1.4190316945314407, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 183, train_loss = 1.4164672928745858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 184, train_loss = 1.4129474945366383, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 185, train_loss = 1.4084972527925856, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 186, train_loss = 1.4062089510262012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 187, train_loss = 1.4023911692202091, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 188, train_loss = 1.400776818394661, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 189, train_loss = 1.3962335586547852, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 190, train_loss = 1.3937877702119295, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 191, train_loss = 1.3898677875695284, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 192, train_loss = 1.38747133439756, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 193, train_loss = 1.3843484173121396, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 194, train_loss = 1.3799848891794682, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 195, train_loss = 1.3778759936394636, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 196, train_loss = 1.374971712619299, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 197, train_loss = 1.372434930264717, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 198, train_loss = 1.3688471975328866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 199, train_loss = 1.366704379528528, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 200, train_loss = 1.3621644576487597, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 201, train_loss = 1.3604647492466029, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 202, train_loss = 1.3581922464072704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 203, train_loss = 1.3547423109412193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 204, train_loss = 1.3519268184900284, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 205, train_loss = 1.349411804229021, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 206, train_loss = 1.3461187904176768, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 207, train_loss = 1.3441889882087708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 208, train_loss = 1.3407146582903806, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 209, train_loss = 1.3389130110444967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 210, train_loss = 1.3356362084450666, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 211, train_loss = 1.3336918465793133, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 212, train_loss = 1.3300649002194405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 213, train_loss = 1.3277638827858027, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 214, train_loss = 1.3259369296429213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 215, train_loss = 1.322874574601883, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 216, train_loss = 1.3211027470824774, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 217, train_loss = 1.3180676785705145, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 218, train_loss = 1.31524839749909, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 219, train_loss = 1.313286059856182, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 220, train_loss = 1.310592091322178, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 221, train_loss = 1.3080868311226368, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 222, train_loss = 1.30596087500453, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 223, train_loss = 1.3031337919237558, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 224, train_loss = 1.3010740503668785, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 225, train_loss = 1.298603064060444, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 226, train_loss = 1.2961354119179305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 227, train_loss = 1.2943200754525606, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 228, train_loss = 1.29118880131864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 229, train_loss = 1.2894316762685776, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 230, train_loss = 1.2876425745489541, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 231, train_loss = 1.284294717013836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 232, train_loss = 1.2837057026627008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 233, train_loss = 1.2804663653078023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 234, train_loss = 1.2784606901404914, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 235, train_loss = 1.2757321881654207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 236, train_loss = 1.2745362184941769, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 237, train_loss = 1.2716273417172488, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 238, train_loss = 1.270071151346201, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 239, train_loss = 1.2673326060175896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 240, train_loss = 1.2662381579575595, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 241, train_loss = 1.2634207606315613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 242, train_loss = 1.2614011155965272, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 243, train_loss = 1.2598878368735313, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 244, train_loss = 1.2573307355341967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 245, train_loss = 1.2555736191570759, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 246, train_loss = 1.2539961313304957, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 247, train_loss = 1.2510580246744212, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 248, train_loss = 1.2497849203646183, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 249, train_loss = 1.247488940745825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 250, train_loss = 1.2453195340931416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 251, train_loss = 1.2435323186218739, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 252, train_loss = 1.2416312073764857, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 253, train_loss = 1.2395122237503529, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 254, train_loss = 1.2386735466716345, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 255, train_loss = 1.2360828630626202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 256, train_loss = 1.234327240526909, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 257, train_loss = 1.232810441404581, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 258, train_loss = 1.2305069217982236, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 259, train_loss = 1.2284336276352406, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 260, train_loss = 1.2266683889029082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 261, train_loss = 1.2249559524061624, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 262, train_loss = 1.2231428598461207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 263, train_loss = 1.221480200678343, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 264, train_loss = 1.2191219814121723, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 265, train_loss = 1.2180351217684802, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 266, train_loss = 1.2160837886331137, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 267, train_loss = 1.2139615503547247, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 268, train_loss = 1.212157172471052, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 269, train_loss = 1.2113206523063127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 270, train_loss = 1.208596844226122, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 271, train_loss = 1.20679054534412, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 272, train_loss = 1.2057796878216323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 273, train_loss = 1.2039552219212055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 274, train_loss = 1.2022608742117882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 275, train_loss = 1.2010450872185174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 276, train_loss = 1.1990185168979224, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 277, train_loss = 1.1979548384842928, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 278, train_loss = 1.1956831725838128, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 279, train_loss = 1.194029482692713, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 280, train_loss = 1.19309096163488, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 281, train_loss = 1.1910328467783984, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 282, train_loss = 1.1892955725488719, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 283, train_loss = 1.1875493923726026, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 284, train_loss = 1.1866288048622664, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 285, train_loss = 1.184059176594019, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 286, train_loss = 1.1830286172626074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 287, train_loss = 1.1812744761409704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 288, train_loss = 1.1798861871066038, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 289, train_loss = 1.178429083287483, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 290, train_loss = 1.177238771080738, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 291, train_loss = 1.1750860375759657, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 292, train_loss = 1.1739999266865198, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 293, train_loss = 1.172346166029456, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 294, train_loss = 1.1706697406771127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 295, train_loss = 1.1688834950327873, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 296, train_loss = 1.1681394862680463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 297, train_loss = 1.166274480521679, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 298, train_loss = 1.1650251398532419, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 299, train_loss = 1.1631912887096405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 300, train_loss = 1.1625528571457835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 301, train_loss = 1.1605699732899666, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 302, train_loss = 1.1590584379882785, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 303, train_loss = 1.1573348492383957, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 304, train_loss = 1.1562451981008053, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 305, train_loss = 1.154885491981986, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 306, train_loss = 1.1533919448702363, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 307, train_loss = 1.1520488783717155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 308, train_loss = 1.149895956114051, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 309, train_loss = 1.149522660925868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 310, train_loss = 1.1482932927756337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 311, train_loss = 1.146800956383231, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 312, train_loss = 1.1449473102838965, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 313, train_loss = 1.143578169241664, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 314, train_loss = 1.1424739087669877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 315, train_loss = 1.1409196381719084, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 316, train_loss = 1.1392006054520607, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 317, train_loss = 1.1384080201387405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 318, train_loss = 1.1373134603054496, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 319, train_loss = 1.13589720800519, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 320, train_loss = 1.1344179424195318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 321, train_loss = 1.1332611665129662, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 322, train_loss = 1.1324321540741948, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 323, train_loss = 1.131026650473359, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 324, train_loss = 1.1293160642235307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 325, train_loss = 1.1278089433908463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 326, train_loss = 1.127134552851203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 327, train_loss = 1.12528012196708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 328, train_loss = 1.1242979193775682, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 329, train_loss = 1.1230970956385136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 330, train_loss = 1.1219968746154336, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 331, train_loss = 1.1206795548350783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 332, train_loss = 1.1197084759623976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 333, train_loss = 1.1184997074306011, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 334, train_loss = 1.117481268942356, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 335, train_loss = 1.116537040725234, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 336, train_loss = 1.1143443994224072, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 337, train_loss = 1.1134027615189552, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 338, train_loss = 1.1125375355331926, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 339, train_loss = 1.1115175460727187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 340, train_loss = 1.1100597940385342, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 341, train_loss = 1.1089170003979234, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 342, train_loss = 1.1080389233975438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 343, train_loss = 1.1062454382627038, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 344, train_loss = 1.1057272503821878, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 345, train_loss = 1.1043325861246558, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 346, train_loss = 1.1035486521868734, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 347, train_loss = 1.1024860975594493, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 348, train_loss = 1.100826716676238, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 349, train_loss = 1.0994377757160692, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 350, train_loss = 1.0991372503340244, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 351, train_loss = 1.098105921104434, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 352, train_loss = 1.0966713105590316, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 353, train_loss = 1.0956616376788588, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 354, train_loss = 1.0942619418055983, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 355, train_loss = 1.0938908830285072, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 356, train_loss = 1.0920945877878694, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 357, train_loss = 1.0914438081235858, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 358, train_loss = 1.0897509170026751, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 359, train_loss = 1.089266337454319, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 360, train_loss = 1.088247628256795, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 361, train_loss = 1.0870971344411373, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 362, train_loss = 1.0858515712170629, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 363, train_loss = 1.0853625896124868, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 364, train_loss = 1.0839947871863842, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 365, train_loss = 1.0833888215274783, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 366, train_loss = 1.0817943240253953, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 367, train_loss = 1.0806501470506191, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 368, train_loss = 1.0799625950603513, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 369, train_loss = 1.079413949206355, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 370, train_loss = 1.078026931732893, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 371, train_loss = 1.0766596185712842, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 372, train_loss = 1.0757964837102918, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 373, train_loss = 1.0747667265386553, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 374, train_loss = 1.0744802641420392, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 375, train_loss = 1.0730019845068455, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 376, train_loss = 1.0714671934692888, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 377, train_loss = 1.0712749461381463, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 378, train_loss = 1.0702859262673883, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 379, train_loss = 1.0685793844313594, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 380, train_loss = 1.068379717573407, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 381, train_loss = 1.06774968157697, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 382, train_loss = 1.0659667352883844, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 383, train_loss = 1.0654691768140765, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 384, train_loss = 1.0647046938538551, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 385, train_loss = 1.06314271192241, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 386, train_loss = 1.062526848167181, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 387, train_loss = 1.0617385183722945, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 388, train_loss = 1.0602454518229933, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 389, train_loss = 1.0600670389831066, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 390, train_loss = 1.0587474629282951, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 391, train_loss = 1.0578182724566432, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 392, train_loss = 1.0566583387553692, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 393, train_loss = 1.0557219410984544, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 394, train_loss = 1.0558412348182173, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 395, train_loss = 1.0541340212075738, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 396, train_loss = 1.0526953538210364, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 397, train_loss = 1.0527569490222959, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 398, train_loss = 1.0508990945963887, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 399, train_loss = 1.0506336179823847, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 400, train_loss = 1.0499181461782428, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 401, train_loss = 1.0488451644778252, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 402, train_loss = 1.0477745073585538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 403, train_loss = 1.046978452548501, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 404, train_loss = 1.0454034581780434, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 405, train_loss = 1.0455403129308252, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 406, train_loss = 1.0448872496635886, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 407, train_loss = 1.0435447096824646, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 408, train_loss = 1.0426158085465431, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 409, train_loss = 1.0417270585894585, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 410, train_loss = 1.0410998277366161, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 411, train_loss = 1.0399837754666805, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 412, train_loss = 1.0396992899477482, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 413, train_loss = 1.0383676824421855, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 414, train_loss = 1.0374949077813653, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 415, train_loss = 1.0364407325832872, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 416, train_loss = 1.035501146063325, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 417, train_loss = 1.0351631070225267, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 418, train_loss = 1.0345377537159948, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 419, train_loss = 1.0333869767637225, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 420, train_loss = 1.0322974609880475, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 421, train_loss = 1.031508759901044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 422, train_loss = 1.0303666492254706, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 423, train_loss = 1.0298064437956782, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 424, train_loss = 1.0298126104025869, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 425, train_loss = 1.0289776983408956, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 426, train_loss = 1.0280297348945169, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 427, train_loss = 1.026838964477065, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 428, train_loss = 1.0262466507701902, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 429, train_loss = 1.0252104277460603, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 430, train_loss = 1.0244987073092489, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 431, train_loss = 1.024712270751479, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 432, train_loss = 1.0225969888269901, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 433, train_loss = 1.0221510119736195, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 434, train_loss = 1.0214889608323574, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 435, train_loss = 1.0207729215471772, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 436, train_loss = 1.0201625724585028, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 437, train_loss = 1.0192942259236588, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 438, train_loss = 1.0184376475735917, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 439, train_loss = 1.0174534519537701, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 440, train_loss = 1.016891126833798, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 441, train_loss = 1.015742248542665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 442, train_loss = 1.0154926764444099, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 443, train_loss = 1.0149461564942612, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 444, train_loss = 1.013702737785934, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 445, train_loss = 1.0134281391874538, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 446, train_loss = 1.0125953083261265, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 447, train_loss = 1.0115924651399837, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 448, train_loss = 1.010551551975368, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 449, train_loss = 1.0110094683841453, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 450, train_loss = 1.009359189622046, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 451, train_loss = 1.0087733405307517, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 452, train_loss = 1.0079280957579613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 453, train_loss = 1.0075304632409825, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 454, train_loss = 1.0064232001677738, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 455, train_loss = 1.00625417008996, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 456, train_loss = 1.0052451317533269, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 457, train_loss = 1.0048732186332927, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 458, train_loss = 1.0033477904871688, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 459, train_loss = 1.0031397802158608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 460, train_loss = 1.0022830540910945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 461, train_loss = 1.0019353876487003, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 462, train_loss = 1.0013322445229278, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 463, train_loss = 1.0004081378356204, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 464, train_loss = 0.999953955411911, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 465, train_loss = 0.9989113360643387, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 466, train_loss = 0.9979947482570424, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 467, train_loss = 0.9975609655157314, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 468, train_loss = 0.9968686290085316, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 469, train_loss = 0.9964341185986996, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 470, train_loss = 0.9951971260234131, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 471, train_loss = 0.9952204897999763, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 472, train_loss = 0.9937887378036976, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 473, train_loss = 0.9931494146585464, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 474, train_loss = 0.9922503133639111, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 475, train_loss = 0.9921159036457539, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 476, train_loss = 0.991115981094481, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 477, train_loss = 0.9903229996562004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 478, train_loss = 0.9902614653110504, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 479, train_loss = 0.9889484755694866, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 480, train_loss = 0.988342959433794, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 481, train_loss = 0.9883738656862988, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 482, train_loss = 0.9869841299951077, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 483, train_loss = 0.9863320998847485, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 484, train_loss = 0.9854107052087784, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 485, train_loss = 0.9849818435832276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 486, train_loss = 0.9845248634592281, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 487, train_loss = 0.9837901070713997, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 488, train_loss = 0.9838064188734279, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 489, train_loss = 0.982237234711647, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 490, train_loss = 0.9820391113535152, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 491, train_loss = 0.9808946934863343, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 492, train_loss = 0.9808932145460858, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 493, train_loss = 0.9797307985500083, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 494, train_loss = 0.979734559856297, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 495, train_loss = 0.9789958981200471, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 496, train_loss = 0.9780242554843426, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 497, train_loss = 0.9775292128324509, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 498, train_loss = 0.9770011094733491, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 499, train_loss = 0.9757978953421116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████                                   | 15/30 [2:29:26<2:29:47, 599.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "16th- epoch: 0, train_loss = 126.53203892707825, train_acc = 0.7633907778295296\n",
      "test Acc 0.8770949720670391:\n",
      "16th- epoch: 1, train_loss = 43.34786815196276, train_acc = 0.9113879832324173\n",
      "test Acc 0.9129422718808193:\n",
      "16th- epoch: 2, train_loss = 31.128815229982138, train_acc = 0.9386353050768514\n",
      "test Acc 0.9297020484171322:\n",
      "16th- epoch: 3, train_loss = 25.101302661001682, train_acc = 0.9509781089892874\n",
      "test Acc 0.9436685288640596:\n",
      "16th- epoch: 4, train_loss = 21.303765315562487, train_acc = 0.9587796925943176\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 5, train_loss = 18.627039212733507, train_acc = 0.9634373544480671\n",
      "test Acc 0.9553072625698324:\n",
      "16th- epoch: 6, train_loss = 16.628909964114428, train_acc = 0.9672799254774104\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 7, train_loss = 15.045272283256054, train_acc = 0.9707731718677224\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 8, train_loss = 13.756414549425244, train_acc = 0.9731020027945971\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 9, train_loss = 12.693491108715534, train_acc = 0.9754308337214718\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 10, train_loss = 11.787640580907464, train_acc = 0.977992547741034\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 11, train_loss = 11.013259138911963, train_acc = 0.9795062878435026\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 12, train_loss = 10.326849658042192, train_acc = 0.9810200279459711\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 13, train_loss = 9.724006487056613, train_acc = 0.9820680018630648\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 14, train_loss = 9.189965721219778, train_acc = 0.9831159757801584\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 15, train_loss = 8.714729385450482, train_acc = 0.9838146250582208\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 16, train_loss = 8.288846986368299, train_acc = 0.9852119236143456\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 17, train_loss = 7.903145655989647, train_acc = 0.9861434559850955\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 18, train_loss = 7.556780670769513, train_acc = 0.9869585468095017\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 19, train_loss = 7.240000261925161, train_acc = 0.9881229622729389\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 20, train_loss = 6.950539834797382, train_acc = 0.9887051700046576\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 21, train_loss = 6.684188978746533, train_acc = 0.9895202608290639\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 22, train_loss = 6.438718001358211, train_acc = 0.9901024685607824\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 23, train_loss = 6.21104191057384, train_acc = 0.9905682347461574\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 24, train_loss = 6.001850206404924, train_acc = 0.990801117838845\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 25, train_loss = 5.805317969992757, train_acc = 0.9910340009315324\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 26, train_loss = 5.6235978147014976, train_acc = 0.9912668840242198\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 27, train_loss = 5.451781961135566, train_acc = 0.9916162086632511\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 28, train_loss = 5.2902274383232, train_acc = 0.9919655333022822\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 29, train_loss = 5.137817477807403, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 30, train_loss = 4.9985346887260675, train_acc = 0.9925477410340009\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 31, train_loss = 4.86119971703738, train_acc = 0.9925477410340009\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 32, train_loss = 4.732901488430798, train_acc = 0.9927806241266884\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 33, train_loss = 4.60920668579638, train_acc = 0.9930135072193759\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 34, train_loss = 4.49399400036782, train_acc = 0.9933628318584071\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 35, train_loss = 4.386016894131899, train_acc = 0.9933628318584071\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 36, train_loss = 4.283269109670073, train_acc = 0.9934792734047508\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 37, train_loss = 4.184580797329545, train_acc = 0.9935957149510946\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 38, train_loss = 4.091276255901903, train_acc = 0.9937121564974383\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 39, train_loss = 4.00254057534039, train_acc = 0.993828598043782\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 40, train_loss = 3.918048622086644, train_acc = 0.9939450395901258\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 41, train_loss = 3.836850416380912, train_acc = 0.9939450395901258\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 42, train_loss = 3.76018238440156, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 43, train_loss = 3.685984392184764, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 44, train_loss = 3.6144764088094234, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 45, train_loss = 3.5478435419499874, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 46, train_loss = 3.4828510843217373, train_acc = 0.9940614811364695\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 47, train_loss = 3.4217308503575623, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 48, train_loss = 3.3622926915995777, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 49, train_loss = 3.30597128206864, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 50, train_loss = 3.2504911087453365, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 51, train_loss = 3.1974066831171513, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 52, train_loss = 3.147739607375115, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 53, train_loss = 3.098059028852731, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 54, train_loss = 3.051411585882306, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 55, train_loss = 3.006057161372155, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 56, train_loss = 2.9615116622298956, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 57, train_loss = 2.919467252213508, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 58, train_loss = 2.8790612686425447, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 59, train_loss = 2.8384654098190367, train_acc = 0.9954587796925943\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 60, train_loss = 2.8011795822530985, train_acc = 0.9954587796925943\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 61, train_loss = 2.764925205614418, train_acc = 0.9956916627852818\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 62, train_loss = 2.7275874712504447, train_acc = 0.9959245458779693\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 63, train_loss = 2.693850706797093, train_acc = 0.996040987424313\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 64, train_loss = 2.6601784457452595, train_acc = 0.9958081043316255\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 65, train_loss = 2.626951915677637, train_acc = 0.9959245458779693\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 66, train_loss = 2.5960331154055893, train_acc = 0.9959245458779693\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 67, train_loss = 2.564329219982028, train_acc = 0.996040987424313\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 68, train_loss = 2.5346133816055954, train_acc = 0.9959245458779693\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 69, train_loss = 2.5064937942661345, train_acc = 0.996040987424313\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 70, train_loss = 2.478496137307957, train_acc = 0.996040987424313\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 71, train_loss = 2.4512993928510696, train_acc = 0.9961574289706567\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 72, train_loss = 2.4253567177802324, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 73, train_loss = 2.399774395627901, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 74, train_loss = 2.3753288325387985, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 75, train_loss = 2.3511901868041605, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 76, train_loss = 2.3282049826812, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 77, train_loss = 2.305455918656662, train_acc = 0.9962738705170004\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 78, train_loss = 2.284092325018719, train_acc = 0.9963903120633442\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 79, train_loss = 2.262445171130821, train_acc = 0.996506753609688\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 80, train_loss = 2.2421310141216964, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 81, train_loss = 2.2219511922448874, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 82, train_loss = 2.2015857112128288, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 83, train_loss = 2.1829697946086526, train_acc = 0.996506753609688\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 84, train_loss = 2.1637379804160446, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 85, train_loss = 2.1453453314024955, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 86, train_loss = 2.1283374035265297, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 87, train_loss = 2.1092834260780364, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 88, train_loss = 2.0933258088771254, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 89, train_loss = 2.076431749621406, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 90, train_loss = 2.0603830630425364, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 91, train_loss = 2.0444873720407486, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 92, train_loss = 2.0287681736517698, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 93, train_loss = 2.0142382541671395, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 94, train_loss = 1.999072455568239, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 95, train_loss = 1.9848696722183377, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 96, train_loss = 1.9705309476703405, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 97, train_loss = 1.9572742080781609, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 98, train_loss = 1.9432092721108347, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 99, train_loss = 1.9306599721312523, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 100, train_loss = 1.9171748496592045, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 101, train_loss = 1.9049424633849412, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 102, train_loss = 1.893566922051832, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 103, train_loss = 1.8810822207015008, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 104, train_loss = 1.868964247405529, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 105, train_loss = 1.8577833275776356, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 106, train_loss = 1.847368006594479, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 107, train_loss = 1.8350775064900517, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 108, train_loss = 1.8253934308886528, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 109, train_loss = 1.8146649862173945, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 110, train_loss = 1.8031318716239184, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 111, train_loss = 1.7937530502676964, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 112, train_loss = 1.7838858764152974, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 113, train_loss = 1.7744658961892128, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 114, train_loss = 1.7641100503969938, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 115, train_loss = 1.7552840916905552, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 116, train_loss = 1.7460285322740674, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 117, train_loss = 1.736945406300947, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 118, train_loss = 1.7275316996965557, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 119, train_loss = 1.7196952786762267, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 120, train_loss = 1.7111747581511736, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 121, train_loss = 1.7028763068374246, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 122, train_loss = 1.6933823071885854, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 123, train_loss = 1.6861837112810463, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 124, train_loss = 1.6781185374129564, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 125, train_loss = 1.6707691599149257, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 126, train_loss = 1.662321162642911, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 127, train_loss = 1.6546488122548908, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 128, train_loss = 1.647907432867214, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 129, train_loss = 1.6408678237348795, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 130, train_loss = 1.6333996718749404, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 131, train_loss = 1.6259710974991322, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 132, train_loss = 1.6197151724481955, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 133, train_loss = 1.6121316803619266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 134, train_loss = 1.6055418519536033, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 135, train_loss = 1.599723992520012, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 136, train_loss = 1.592162893153727, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 137, train_loss = 1.5844118651002645, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 138, train_loss = 1.5804356510052457, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 139, train_loss = 1.5727058198535815, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 140, train_loss = 1.5674221906811, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 141, train_loss = 1.5610167551785707, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 142, train_loss = 1.5553937343647704, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 143, train_loss = 1.5486463702982292, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 144, train_loss = 1.5439750083023682, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 145, train_loss = 1.5369437547633424, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 146, train_loss = 1.5315838605165482, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 147, train_loss = 1.52669398766011, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 148, train_loss = 1.5209107244154438, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 149, train_loss = 1.5160065429518, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 150, train_loss = 1.5105823893100023, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 151, train_loss = 1.505395925254561, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 152, train_loss = 1.5003123419592157, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 153, train_loss = 1.4945966834202409, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 154, train_loss = 1.4907154511893168, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 155, train_loss = 1.4849060751730576, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 156, train_loss = 1.4805359607562423, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 157, train_loss = 1.4758574031293392, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 158, train_loss = 1.470830999314785, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 159, train_loss = 1.4662787383422256, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 160, train_loss = 1.4620314171770588, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 161, train_loss = 1.4571226726984605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 162, train_loss = 1.4529440011829138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 163, train_loss = 1.4484004086116329, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 164, train_loss = 1.4444628100609407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 165, train_loss = 1.4391088247066364, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 166, train_loss = 1.4356466457247734, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 167, train_loss = 1.431546445353888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 168, train_loss = 1.4268418025458232, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 169, train_loss = 1.423831339343451, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 170, train_loss = 1.4187570757931098, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 171, train_loss = 1.4152745042229071, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 172, train_loss = 1.4104802813380957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 173, train_loss = 1.4070311362156644, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 174, train_loss = 1.4032206801930442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 175, train_loss = 1.3988832632312551, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 176, train_loss = 1.3955656671896577, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 177, train_loss = 1.3917971352348104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 178, train_loss = 1.3877921629464254, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 179, train_loss = 1.3848338344832882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 180, train_loss = 1.3797715920954943, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 181, train_loss = 1.377011769800447, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 182, train_loss = 1.3735187411075458, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 183, train_loss = 1.3702739967266098, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 184, train_loss = 1.3661862419685349, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 185, train_loss = 1.3634808644419536, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 186, train_loss = 1.3600856525590643, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 187, train_loss = 1.3563824280863628, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 188, train_loss = 1.3539106445387006, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 189, train_loss = 1.3491722453618422, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 190, train_loss = 1.3462683040415868, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 191, train_loss = 1.3432719763368368, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 192, train_loss = 1.3392225928837433, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 193, train_loss = 1.336955258040689, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 194, train_loss = 1.333633715286851, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 195, train_loss = 1.330156584852375, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 196, train_loss = 1.3271045600995421, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 197, train_loss = 1.3244785476708785, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 198, train_loss = 1.3204928397899494, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 199, train_loss = 1.3180015552788973, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 200, train_loss = 1.31553380319383, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 201, train_loss = 1.3121872957563028, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 202, train_loss = 1.3088966585928574, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 203, train_loss = 1.306436239159666, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 204, train_loss = 1.3039839249104261, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 205, train_loss = 1.300771601148881, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 206, train_loss = 1.2979215430095792, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 207, train_loss = 1.295759447850287, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 208, train_loss = 1.2924928832799196, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 209, train_loss = 1.2898248803103343, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 210, train_loss = 1.2874073460698128, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 211, train_loss = 1.2840351136401296, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 212, train_loss = 1.2823040038347244, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 213, train_loss = 1.2791991097619757, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 214, train_loss = 1.276954865665175, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 215, train_loss = 1.2738420258974656, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 216, train_loss = 1.2711560977622867, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 217, train_loss = 1.2690990915289149, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 218, train_loss = 1.26593637408223, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 219, train_loss = 1.2638088697567582, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 220, train_loss = 1.2622637763852254, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 221, train_loss = 1.2594620141899213, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 222, train_loss = 1.2569328099489212, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 223, train_loss = 1.2549037777935155, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 224, train_loss = 1.2524330864544027, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 225, train_loss = 1.249549827829469, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 226, train_loss = 1.2473125361721031, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 227, train_loss = 1.2448295897920616, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 228, train_loss = 1.2426703997771256, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 229, train_loss = 1.2400323888286948, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 230, train_loss = 1.2385358652099967, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 231, train_loss = 1.2354437678004615, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 232, train_loss = 1.2345516048371792, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 233, train_loss = 1.2315620764275081, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 234, train_loss = 1.229593644849956, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 235, train_loss = 1.2274179051746614, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 236, train_loss = 1.2244922130485065, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 237, train_loss = 1.2228756972472183, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 238, train_loss = 1.221479516767431, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 239, train_loss = 1.2187786409631371, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 240, train_loss = 1.2158432537689805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 241, train_loss = 1.2147498959675431, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 242, train_loss = 1.2125405833940022, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 243, train_loss = 1.2106394683942199, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 244, train_loss = 1.2075417560408823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 245, train_loss = 1.206419658206869, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 246, train_loss = 1.2053011078387499, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 247, train_loss = 1.2023808092926629, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 248, train_loss = 1.200502731546294, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 249, train_loss = 1.1982410081545822, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 250, train_loss = 1.1965631134808064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 251, train_loss = 1.194609469443094, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 252, train_loss = 1.1929088557953946, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 253, train_loss = 1.1908451958443038, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 254, train_loss = 1.1887966438080184, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 255, train_loss = 1.188147886947263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 256, train_loss = 1.1853315836633556, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 257, train_loss = 1.183739171072375, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 258, train_loss = 1.1813562996685505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 259, train_loss = 1.1804632407729514, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 260, train_loss = 1.1784250916098244, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 261, train_loss = 1.1762394433026202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 262, train_loss = 1.175081746012438, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 263, train_loss = 1.1734981015324593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 264, train_loss = 1.1712336695636623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 265, train_loss = 1.1691074564005248, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 266, train_loss = 1.1679904467309825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 267, train_loss = 1.166003652557265, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 268, train_loss = 1.164860814169515, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 269, train_loss = 1.1622291070525534, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 270, train_loss = 1.1615831957315095, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 271, train_loss = 1.1595760248601437, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 272, train_loss = 1.1585145872086287, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 273, train_loss = 1.1559952783281915, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 274, train_loss = 1.1548049313132651, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 275, train_loss = 1.1531027766759507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 276, train_loss = 1.1514660312677734, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 277, train_loss = 1.150652660697233, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 278, train_loss = 1.1480395123362541, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 279, train_loss = 1.1468219862435944, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 280, train_loss = 1.1444228955660947, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 281, train_loss = 1.1436160026933067, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 282, train_loss = 1.1408185859327205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 283, train_loss = 1.1394210296566598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 284, train_loss = 1.1379840497975238, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 285, train_loss = 1.1358825769275427, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 286, train_loss = 1.135589126497507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 287, train_loss = 1.1338570471853018, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 288, train_loss = 1.1313068382441998, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 289, train_loss = 1.1300317657296546, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 290, train_loss = 1.1285667158663273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 291, train_loss = 1.1277715979958884, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 292, train_loss = 1.1254599162493832, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 293, train_loss = 1.1241378380800597, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 294, train_loss = 1.1228476439719088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 295, train_loss = 1.1217579450458288, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 296, train_loss = 1.1203181675518863, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 297, train_loss = 1.1182552054524422, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 298, train_loss = 1.1168269726331346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 299, train_loss = 1.1154573056846857, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 300, train_loss = 1.1141225583851337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 301, train_loss = 1.1138184436713345, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 302, train_loss = 1.1116379530285485, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 303, train_loss = 1.1098455737228505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 304, train_loss = 1.108993237838149, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 305, train_loss = 1.1070388164371252, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 306, train_loss = 1.1068781092762947, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 307, train_loss = 1.1048547172104008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 308, train_loss = 1.103905335708987, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 309, train_loss = 1.1020190424169414, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 310, train_loss = 1.1011227027629502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 311, train_loss = 1.0998889859765768, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 312, train_loss = 1.0989021714776754, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 313, train_loss = 1.0967229039524682, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 314, train_loss = 1.0958847192232497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 315, train_loss = 1.0945893432945013, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 316, train_loss = 1.0927427113056183, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 317, train_loss = 1.0919730446184985, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 318, train_loss = 1.09153639402939, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 319, train_loss = 1.0894497160916217, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 320, train_loss = 1.0874798794393428, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 321, train_loss = 1.0865821142797358, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 322, train_loss = 1.085378723219037, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 323, train_loss = 1.0841604601591825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 324, train_loss = 1.083001995459199, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 325, train_loss = 1.0817654349957593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 326, train_loss = 1.0804138493840583, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 327, train_loss = 1.0787419292028062, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 328, train_loss = 1.0783014905755408, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 329, train_loss = 1.0775945521891117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 330, train_loss = 1.0757496636360884, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 331, train_loss = 1.0743629802018404, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 332, train_loss = 1.0745206133578904, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 333, train_loss = 1.072689872875344, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 334, train_loss = 1.070837605104316, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 335, train_loss = 1.0702030931715854, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 336, train_loss = 1.0683995485305786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 337, train_loss = 1.068023182451725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 338, train_loss = 1.065800720185507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 339, train_loss = 1.0662099097971804, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 340, train_loss = 1.0643022389267571, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 341, train_loss = 1.0636390701984055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 342, train_loss = 1.0627353439922445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 343, train_loss = 1.0612719400669448, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 344, train_loss = 1.0603549002553336, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 345, train_loss = 1.0586752339149825, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 346, train_loss = 1.0578454199130647, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 347, train_loss = 1.0565413770382293, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 348, train_loss = 1.055898554623127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 349, train_loss = 1.0540868664975278, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 350, train_loss = 1.0535422290558927, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 351, train_loss = 1.0528278592973948, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 352, train_loss = 1.051524953916669, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 353, train_loss = 1.0507826264947653, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 354, train_loss = 1.0496121421456337, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 355, train_loss = 1.0487517820147332, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 356, train_loss = 1.0477856881916523, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 357, train_loss = 1.0465814421477262, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 358, train_loss = 1.0456665915844496, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 359, train_loss = 1.0448200522514526, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 360, train_loss = 1.0430143978446722, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 361, train_loss = 1.0426004193723202, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 362, train_loss = 1.0412185011955444, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 363, train_loss = 1.039707683637971, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 364, train_loss = 1.0387893480656203, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 365, train_loss = 1.037438497558469, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 366, train_loss = 1.036784085124964, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 367, train_loss = 1.0360455332847778, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 368, train_loss = 1.035205098480219, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 369, train_loss = 1.0334705778805073, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 370, train_loss = 1.0323337844165508, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 371, train_loss = 1.0311785818485077, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 372, train_loss = 1.0301604494452477, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 373, train_loss = 1.0297515454294626, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 374, train_loss = 1.0289018955081701, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 375, train_loss = 1.0272870430198964, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 376, train_loss = 1.026211612537736, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 377, train_loss = 1.0259581468999386, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 378, train_loss = 1.0248020024446305, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 379, train_loss = 1.0239929538220167, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 380, train_loss = 1.0226797772047576, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 381, train_loss = 1.0217745738627855, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 382, train_loss = 1.0207217863353435, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 383, train_loss = 1.0201462538389023, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 384, train_loss = 1.0194317921996117, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 385, train_loss = 1.0186059189436492, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 386, train_loss = 1.0166813004761934, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 387, train_loss = 1.0166235212236643, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 388, train_loss = 1.0161183296295349, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 389, train_loss = 1.015537297964329, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 390, train_loss = 1.0140068847686052, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 391, train_loss = 1.0129090771079063, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 392, train_loss = 1.012404436856741, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 393, train_loss = 1.0115533471107483, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 394, train_loss = 1.010658177867299, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 395, train_loss = 1.0104291109892074, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 396, train_loss = 1.0089598800987005, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 397, train_loss = 1.0081196098180953, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 398, train_loss = 1.0067157316952944, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 399, train_loss = 1.0068785908224527, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 400, train_loss = 1.005316316470271, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 401, train_loss = 1.0051804153772537, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 402, train_loss = 1.0040903954359237, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 403, train_loss = 1.0026084370911121, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 404, train_loss = 1.0031138602644205, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 405, train_loss = 1.0017179381102324, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 406, train_loss = 1.0003114634600934, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 407, train_loss = 0.9996903451683465, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 408, train_loss = 0.9988244889827911, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 409, train_loss = 0.9982626295241062, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 410, train_loss = 0.9978704117238522, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 411, train_loss = 0.9973051846027374, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 412, train_loss = 0.9950124944152776, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 413, train_loss = 0.99457267174148, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 414, train_loss = 0.9944924383016769, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 415, train_loss = 0.9929015884699766, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 416, train_loss = 0.9927796181291342, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 417, train_loss = 0.9925475921481848, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 418, train_loss = 0.9912136532366276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 419, train_loss = 0.9906263742595911, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 420, train_loss = 0.9896205707045738, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 421, train_loss = 0.9895013508794364, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 422, train_loss = 0.9883723308739718, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 423, train_loss = 0.9873691145330667, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 424, train_loss = 0.9869836804864462, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 425, train_loss = 0.9860521554946899, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 426, train_loss = 0.9849594999104738, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 427, train_loss = 0.9842037204653025, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 428, train_loss = 0.983225928619504, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 429, train_loss = 0.983216662571067, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 430, train_loss = 0.9816052081587259, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 431, train_loss = 0.9814137065259274, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 432, train_loss = 0.980760650098091, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 433, train_loss = 0.9797912687063217, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 434, train_loss = 0.9790788292884827, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 435, train_loss = 0.9780276194214821, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 436, train_loss = 0.9780966248363256, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 437, train_loss = 0.9775772616267204, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 438, train_loss = 0.9766624414769467, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 439, train_loss = 0.9758244007825851, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 440, train_loss = 0.9751678550092038, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 441, train_loss = 0.9751182440668344, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 442, train_loss = 0.9738943794218358, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 443, train_loss = 0.9731061744096223, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 444, train_loss = 0.9725883460196201, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 445, train_loss = 0.9717762277869042, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 446, train_loss = 0.9701319870946463, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 447, train_loss = 0.9700790401548147, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 448, train_loss = 0.9692693749966566, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 449, train_loss = 0.9688941556960344, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 450, train_loss = 0.9679154666664544, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 451, train_loss = 0.9677483563718852, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 452, train_loss = 0.9664493054151535, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 453, train_loss = 0.9660502659680787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 454, train_loss = 0.9648268042656127, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 455, train_loss = 0.9649160839617252, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 456, train_loss = 0.9636617725191172, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 457, train_loss = 0.9633440443722066, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 458, train_loss = 0.9627754141984042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 459, train_loss = 0.9628299952892121, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 460, train_loss = 0.9616506292077247, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 461, train_loss = 0.9610462095588446, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 462, train_loss = 0.9595435857772827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 463, train_loss = 0.9593513514846563, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 464, train_loss = 0.9585123751312494, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 465, train_loss = 0.957696288212901, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 466, train_loss = 0.9573174963297788, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 467, train_loss = 0.9571230597794056, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 468, train_loss = 0.956313473492628, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 469, train_loss = 0.9552490891364869, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 470, train_loss = 0.9552750500442926, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 471, train_loss = 0.9541190030577127, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 472, train_loss = 0.953595162689453, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 473, train_loss = 0.953213664382929, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 474, train_loss = 0.9525463084282819, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 475, train_loss = 0.9522853145899717, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 476, train_loss = 0.9514089003205299, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 477, train_loss = 0.9508706381020602, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 478, train_loss = 0.9500644709914923, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 479, train_loss = 0.9495485977677163, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 480, train_loss = 0.9491217049362604, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 481, train_loss = 0.9484316501766443, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 482, train_loss = 0.9470741072145756, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 483, train_loss = 0.9466230416146573, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 484, train_loss = 0.9467776237579528, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 485, train_loss = 0.9458425398916006, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 486, train_loss = 0.9453666303306818, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 487, train_loss = 0.9435968486068305, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 488, train_loss = 0.9436022341251373, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 489, train_loss = 0.9431969951838255, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 490, train_loss = 0.9426095137896482, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 491, train_loss = 0.9428668022155762, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 492, train_loss = 0.9415185631660279, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 493, train_loss = 0.9411235681327526, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 494, train_loss = 0.9402258644404355, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 495, train_loss = 0.9395301242766436, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 496, train_loss = 0.9388223520072643, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 497, train_loss = 0.9391030371189117, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 498, train_loss = 0.9377078147081193, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 499, train_loss = 0.9368190541863441, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████▎                                | 16/30 [2:39:23<2:19:41, 598.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "17th- epoch: 0, train_loss = 114.40539652109146, train_acc = 0.7887750349324639\n",
      "test Acc 0.8696461824953445:\n",
      "17th- epoch: 1, train_loss = 43.87324829399586, train_acc = 0.9089427107591989\n",
      "test Acc 0.9194599627560521:\n",
      "17th- epoch: 2, train_loss = 31.612607523798943, train_acc = 0.9365393572426641\n",
      "test Acc 0.931098696461825:\n",
      "17th- epoch: 3, train_loss = 25.25949202850461, train_acc = 0.9470190964136004\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 4, train_loss = 21.158839901909232, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "17th- epoch: 5, train_loss = 18.32203887589276, train_acc = 0.9614578481602236\n",
      "test Acc 0.9459962756052142:\n",
      "17th- epoch: 6, train_loss = 16.197670571506023, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 7, train_loss = 14.552530780434608, train_acc = 0.9711224965067536\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 8, train_loss = 13.2248603887856, train_acc = 0.9738006520726595\n",
      "test Acc 0.9543761638733705:\n",
      "17th- epoch: 9, train_loss = 12.138789283111691, train_acc = 0.975780158360503\n",
      "test Acc 0.9553072625698324:\n",
      "17th- epoch: 10, train_loss = 11.222466710954905, train_acc = 0.9771774569166278\n",
      "test Acc 0.9567039106145251:\n",
      "17th- epoch: 11, train_loss = 10.44037370197475, train_acc = 0.9789240801117839\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 12, train_loss = 9.761116683483124, train_acc = 0.9803213786679087\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 13, train_loss = 9.173495471477509, train_acc = 0.9816022356776898\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 14, train_loss = 8.658297492191195, train_acc = 0.983698183511877\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 15, train_loss = 8.20507787540555, train_acc = 0.9846297158826269\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 16, train_loss = 7.79562715254724, train_acc = 0.9857941313460643\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 17, train_loss = 7.424577297642827, train_acc = 0.9867256637168141\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 18, train_loss = 7.09040860272944, train_acc = 0.9875407545412203\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 19, train_loss = 6.78665111027658, train_acc = 0.9883558453656265\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 20, train_loss = 6.508284395560622, train_acc = 0.9888216115510013\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 21, train_loss = 6.25227521546185, train_acc = 0.9890544946436889\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 22, train_loss = 6.018368473276496, train_acc = 0.9895202608290639\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 23, train_loss = 5.808992672711611, train_acc = 0.9896367023754076\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 24, train_loss = 5.608068235218525, train_acc = 0.9906846762925011\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 25, train_loss = 5.423951058648527, train_acc = 0.9910340009315324\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 26, train_loss = 5.25392319727689, train_acc = 0.9909175593851887\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 27, train_loss = 5.095322902314365, train_acc = 0.9911504424778761\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 28, train_loss = 4.946716486476362, train_acc = 0.9914997671169073\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 29, train_loss = 4.808667495846748, train_acc = 0.9919655333022822\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 30, train_loss = 4.676838232204318, train_acc = 0.9923148579413135\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 31, train_loss = 4.554474299773574, train_acc = 0.9924312994876572\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 32, train_loss = 4.437515811994672, train_acc = 0.9924312994876572\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 33, train_loss = 4.328633812256157, train_acc = 0.9925477410340009\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 34, train_loss = 4.2257835902273655, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 35, train_loss = 4.128486924804747, train_acc = 0.9930135072193759\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 36, train_loss = 4.037174075841904, train_acc = 0.9933628318584071\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 37, train_loss = 3.9488207707181573, train_acc = 0.9934792734047508\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 38, train_loss = 3.8670445075258613, train_acc = 0.993828598043782\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 39, train_loss = 3.788475072942674, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 40, train_loss = 3.712711524218321, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 41, train_loss = 3.6425400599837303, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 42, train_loss = 3.5745396614074707, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 43, train_loss = 3.5097187347710133, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 44, train_loss = 3.4472880056127906, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 45, train_loss = 3.388750028796494, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 46, train_loss = 3.333006382919848, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 47, train_loss = 3.2775737969204783, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 48, train_loss = 3.2269653575494885, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 49, train_loss = 3.176859467290342, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 50, train_loss = 3.12927208840847, train_acc = 0.9951094550535631\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 51, train_loss = 3.0831614937633276, train_acc = 0.9951094550535631\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 52, train_loss = 3.0399665837176144, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 53, train_loss = 2.9965366809628904, train_acc = 0.9954587796925943\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 54, train_loss = 2.9559652055613697, train_acc = 0.995575221238938\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 55, train_loss = 2.9155456512235105, train_acc = 0.9956916627852818\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 56, train_loss = 2.8771793507039547, train_acc = 0.9956916627852818\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 57, train_loss = 2.839495453517884, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 58, train_loss = 2.804453544318676, train_acc = 0.9956916627852818\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 59, train_loss = 2.7686169571243227, train_acc = 0.996040987424313\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 60, train_loss = 2.7364271669648588, train_acc = 0.9959245458779693\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 61, train_loss = 2.7024481729604304, train_acc = 0.996040987424313\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 62, train_loss = 2.671006873715669, train_acc = 0.996040987424313\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 63, train_loss = 2.6408584900200367, train_acc = 0.996040987424313\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 64, train_loss = 2.609619594644755, train_acc = 0.996040987424313\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 65, train_loss = 2.581433893647045, train_acc = 0.9961574289706567\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 66, train_loss = 2.552429635077715, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 67, train_loss = 2.524433748796582, train_acc = 0.9961574289706567\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 68, train_loss = 2.4975784309208393, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 69, train_loss = 2.470478822942823, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 70, train_loss = 2.4452847372740507, train_acc = 0.9961574289706567\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 71, train_loss = 2.4201554488390684, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 72, train_loss = 2.3961841384880245, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 73, train_loss = 2.3730328497476876, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 74, train_loss = 2.3497651549987495, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 75, train_loss = 2.3274074303917587, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 76, train_loss = 2.3059103284031153, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 77, train_loss = 2.2849434870295227, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 78, train_loss = 2.26318691810593, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 79, train_loss = 2.243536768015474, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 80, train_loss = 2.2231822130270302, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 81, train_loss = 2.2036869060248137, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 82, train_loss = 2.184209367260337, train_acc = 0.9963903120633442\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 83, train_loss = 2.1646124622784555, train_acc = 0.9963903120633442\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 84, train_loss = 2.1463935668580234, train_acc = 0.9963903120633442\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 85, train_loss = 2.1282184342853725, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 86, train_loss = 2.109934439882636, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 87, train_loss = 2.0932806376367807, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 88, train_loss = 2.07634805329144, train_acc = 0.9963903120633442\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 89, train_loss = 2.060875914990902, train_acc = 0.996506753609688\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 90, train_loss = 2.0452094059437513, train_acc = 0.996506753609688\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 91, train_loss = 2.029747396009043, train_acc = 0.996506753609688\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 92, train_loss = 2.0148170094471425, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 93, train_loss = 2.000576213700697, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 94, train_loss = 1.9857661116402596, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 95, train_loss = 1.9730506769847125, train_acc = 0.9968560782487191\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 96, train_loss = 1.9592212445568293, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 97, train_loss = 1.9459931459277868, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 98, train_loss = 1.9329010446090251, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 99, train_loss = 1.920507178409025, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 100, train_loss = 1.9073542046826333, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 101, train_loss = 1.8962442420888692, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 102, train_loss = 1.8848322450648993, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 103, train_loss = 1.8733177799731493, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 104, train_loss = 1.8616710063070059, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 105, train_loss = 1.8511398620903492, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 106, train_loss = 1.8397026509046555, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 107, train_loss = 1.8297827076166868, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 108, train_loss = 1.8190034485887736, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 109, train_loss = 1.809234245447442, train_acc = 0.9968560782487191\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 110, train_loss = 1.7991516061592847, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 111, train_loss = 1.7900053628254682, train_acc = 0.9968560782487191\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 112, train_loss = 1.780254737706855, train_acc = 0.9968560782487191\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 113, train_loss = 1.7712837278377265, train_acc = 0.9968560782487191\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 114, train_loss = 1.7618398561608046, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 115, train_loss = 1.7524710812140256, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 116, train_loss = 1.7433555491734296, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 117, train_loss = 1.7353742402046919, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 118, train_loss = 1.7267307310830802, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 119, train_loss = 1.718418026342988, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 120, train_loss = 1.7104791514575481, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 121, train_loss = 1.702185643138364, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 122, train_loss = 1.693930682959035, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 123, train_loss = 1.6868465666193515, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 124, train_loss = 1.6789636549074203, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 125, train_loss = 1.6719055387657136, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 126, train_loss = 1.6642046961933374, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 127, train_loss = 1.6568049110937864, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 128, train_loss = 1.650458488613367, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 129, train_loss = 1.6431169968564063, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 130, train_loss = 1.6362792134750634, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 131, train_loss = 1.6291717905551195, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 132, train_loss = 1.6227872837334871, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 133, train_loss = 1.6158220532815903, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 134, train_loss = 1.610283225774765, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 135, train_loss = 1.6030720912385732, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 136, train_loss = 1.5969128031283617, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 137, train_loss = 1.5907569534610957, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 138, train_loss = 1.5844794169533998, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 139, train_loss = 1.578642002074048, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 140, train_loss = 1.5724950295407325, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 141, train_loss = 1.5666787077207118, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 142, train_loss = 1.5615572140086442, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 143, train_loss = 1.5552942000795156, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 144, train_loss = 1.5499920062720776, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 145, train_loss = 1.544057410210371, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 146, train_loss = 1.5387059536296874, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 147, train_loss = 1.5338269744534045, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 148, train_loss = 1.5282730776816607, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 149, train_loss = 1.5231091224122792, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 150, train_loss = 1.5178906694054604, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 151, train_loss = 1.5129271186888218, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 152, train_loss = 1.5074541978538036, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 153, train_loss = 1.503076716675423, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 154, train_loss = 1.4974065590649843, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 155, train_loss = 1.4921236286172643, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 156, train_loss = 1.4883083464810625, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 157, train_loss = 1.48317002505064, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 158, train_loss = 1.4792731063207611, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 159, train_loss = 1.4741750955581665, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 160, train_loss = 1.4694724790751934, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 161, train_loss = 1.4649722091853619, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 162, train_loss = 1.4614121107151732, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 163, train_loss = 1.4562252685427666, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 164, train_loss = 1.4524469872703776, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 165, train_loss = 1.4478616093983874, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 166, train_loss = 1.4435876918723807, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 167, train_loss = 1.4393142672488466, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 168, train_loss = 1.4357280085096136, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 169, train_loss = 1.4310634806752205, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 170, train_loss = 1.4268818820128217, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 171, train_loss = 1.4237238889327273, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 172, train_loss = 1.418786616413854, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 173, train_loss = 1.4154935715487227, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 174, train_loss = 1.410009173094295, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 175, train_loss = 1.4065797763178125, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 176, train_loss = 1.4030686765909195, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 177, train_loss = 1.3991666907677427, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 178, train_loss = 1.3955844802549109, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 179, train_loss = 1.3916921677300707, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 180, train_loss = 1.3879436030983925, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 181, train_loss = 1.3849603260168806, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 182, train_loss = 1.3808489566436037, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 183, train_loss = 1.3774845749139786, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 184, train_loss = 1.3748218616237864, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 185, train_loss = 1.370666248141788, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 186, train_loss = 1.367743968963623, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 187, train_loss = 1.3644375316798687, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 188, train_loss = 1.3609017418930307, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 189, train_loss = 1.3575985605129972, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 190, train_loss = 1.3541026674211025, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 191, train_loss = 1.3519731797277927, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 192, train_loss = 1.3478296833345667, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 193, train_loss = 1.3450877951690927, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 194, train_loss = 1.341633771895431, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 195, train_loss = 1.3394339866936207, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 196, train_loss = 1.3353596739470959, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 197, train_loss = 1.3328549837460741, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 198, train_loss = 1.3302047388860956, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 199, train_loss = 1.3264034390449524, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 200, train_loss = 1.3238627997925505, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 201, train_loss = 1.3204602003097534, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 202, train_loss = 1.318403486162424, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 203, train_loss = 1.3153334321686998, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 204, train_loss = 1.311650037765503, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 205, train_loss = 1.3094490034272894, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 206, train_loss = 1.306785294204019, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 207, train_loss = 1.3032749643316492, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 208, train_loss = 1.3010317360749468, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 209, train_loss = 1.297928130836226, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 210, train_loss = 1.2952115362277254, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 211, train_loss = 1.2926401732256636, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 212, train_loss = 1.2895360129186884, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 213, train_loss = 1.2870908057084307, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 214, train_loss = 1.284386514336802, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 215, train_loss = 1.2820053746690974, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 216, train_loss = 1.2787265392253175, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 217, train_loss = 1.2763456193497404, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 218, train_loss = 1.2740869434783235, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 219, train_loss = 1.2708052856614813, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 220, train_loss = 1.268943227827549, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 221, train_loss = 1.2663124637911096, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 222, train_loss = 1.264029094367288, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 223, train_loss = 1.2606617137789726, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 224, train_loss = 1.2592558773467317, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 225, train_loss = 1.2567908776691183, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 226, train_loss = 1.2537640059599653, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 227, train_loss = 1.2519436503062025, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 228, train_loss = 1.2494609480490908, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 229, train_loss = 1.24696261563804, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 230, train_loss = 1.2448908885708079, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 231, train_loss = 1.2418006099760532, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 232, train_loss = 1.2405831502983347, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 233, train_loss = 1.2376370715210214, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 234, train_loss = 1.235875797807239, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 235, train_loss = 1.2337663099169731, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 236, train_loss = 1.2313241474330425, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 237, train_loss = 1.2291201812913641, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 238, train_loss = 1.2270833775401115, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 239, train_loss = 1.2253134213387966, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 240, train_loss = 1.2225783182075247, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 241, train_loss = 1.220809031277895, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 242, train_loss = 1.2187266225228086, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 243, train_loss = 1.216566658229567, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 244, train_loss = 1.2146807113895193, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 245, train_loss = 1.2125857969513163, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 246, train_loss = 1.210085300146602, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 247, train_loss = 1.2085022056708112, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 248, train_loss = 1.2068002000451088, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 249, train_loss = 1.204202195047401, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 250, train_loss = 1.20229211950209, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 251, train_loss = 1.2006217004964128, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 252, train_loss = 1.1986255099182017, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 253, train_loss = 1.196298009424936, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 254, train_loss = 1.1951213578577153, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 255, train_loss = 1.192779312550556, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 256, train_loss = 1.19121914106654, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 257, train_loss = 1.1887691083247773, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 258, train_loss = 1.187586071609985, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 259, train_loss = 1.185339083254803, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 260, train_loss = 1.1835545028443448, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 261, train_loss = 1.1814971268177032, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 262, train_loss = 1.1799470546538942, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 263, train_loss = 1.1781629348988645, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 264, train_loss = 1.1763604233856313, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 265, train_loss = 1.174272624135483, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 266, train_loss = 1.1727216616272926, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 267, train_loss = 1.1711703091859818, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 268, train_loss = 1.1694179673795588, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 269, train_loss = 1.1672735649044625, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 270, train_loss = 1.16618986800313, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 271, train_loss = 1.163807888806332, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 272, train_loss = 1.1626808668370359, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 273, train_loss = 1.1610252894461155, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 274, train_loss = 1.1588896724279039, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 275, train_loss = 1.1574029860203154, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 276, train_loss = 1.15547514957143, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 277, train_loss = 1.15376654145075, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 278, train_loss = 1.152438998222351, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 279, train_loss = 1.1508618158404715, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 280, train_loss = 1.1494136328692548, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 281, train_loss = 1.1476656695012935, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 282, train_loss = 1.1463612603838556, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 283, train_loss = 1.1446134112775326, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 284, train_loss = 1.1429422162473202, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 285, train_loss = 1.1416599203948863, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 286, train_loss = 1.1398400577600114, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 287, train_loss = 1.1384925991296768, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 288, train_loss = 1.1368908782606013, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 289, train_loss = 1.1355482526123524, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 290, train_loss = 1.1340878494083881, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 291, train_loss = 1.1325129456818104, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 292, train_loss = 1.1310126893222332, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 293, train_loss = 1.129697321623098, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 294, train_loss = 1.1280643318896182, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 295, train_loss = 1.127035714685917, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 296, train_loss = 1.1253476304118522, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 297, train_loss = 1.1240893540089019, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 298, train_loss = 1.1221339876647107, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 299, train_loss = 1.120490641624201, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 300, train_loss = 1.1194450557231903, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 301, train_loss = 1.1177475092117675, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 302, train_loss = 1.1167524109478109, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 303, train_loss = 1.1149723182315938, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 304, train_loss = 1.1139532960951328, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 305, train_loss = 1.1122406348586082, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 306, train_loss = 1.1113145922427066, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 307, train_loss = 1.109573060006369, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 308, train_loss = 1.1085907096858136, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 309, train_loss = 1.107543057471048, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 310, train_loss = 1.1065483664278872, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 311, train_loss = 1.1042345414753072, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 312, train_loss = 1.1038973008398898, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 313, train_loss = 1.102128092199564, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 314, train_loss = 1.1007670896942727, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 315, train_loss = 1.0997597115929238, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 316, train_loss = 1.098429847508669, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 317, train_loss = 1.0967247299849987, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 318, train_loss = 1.0960502524976619, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 319, train_loss = 1.0947545630042441, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 320, train_loss = 1.0932133756577969, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 321, train_loss = 1.0921392825548537, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 322, train_loss = 1.0907218866050243, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 323, train_loss = 1.089854583144188, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 324, train_loss = 1.0882433379883878, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 325, train_loss = 1.0872264454956166, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 326, train_loss = 1.086160808801651, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 327, train_loss = 1.084497470408678, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 328, train_loss = 1.0836663183872588, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 329, train_loss = 1.0819617708330043, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 330, train_loss = 1.0812113347346894, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 331, train_loss = 1.079802505671978, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 332, train_loss = 1.0788967286353, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 333, train_loss = 1.0775535007123835, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 334, train_loss = 1.0765789759461768, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 335, train_loss = 1.0755254104733467, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 336, train_loss = 1.0738242007791996, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 337, train_loss = 1.072536336898338, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 338, train_loss = 1.0713560382719152, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 339, train_loss = 1.070931299298536, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 340, train_loss = 1.0692042969167233, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 341, train_loss = 1.0682663818006404, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 342, train_loss = 1.0672495712642558, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 343, train_loss = 1.065932237834204, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 344, train_loss = 1.0649826054577716, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 345, train_loss = 1.0641693000798114, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 346, train_loss = 1.062578575045336, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 347, train_loss = 1.0620243201847188, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 348, train_loss = 1.060482431203127, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 349, train_loss = 1.0597897346015088, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 350, train_loss = 1.0583255390520208, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 351, train_loss = 1.057579776912462, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 352, train_loss = 1.055620917410124, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 353, train_loss = 1.0550585140590556, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 354, train_loss = 1.0540518586640246, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 355, train_loss = 1.053006914735306, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 356, train_loss = 1.0521143500809558, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 357, train_loss = 1.0515242504770868, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 358, train_loss = 1.0498224534094334, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 359, train_loss = 1.0492410523002036, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 360, train_loss = 1.0477453631465323, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 361, train_loss = 1.0469584192032926, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 362, train_loss = 1.0454980544745922, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 363, train_loss = 1.0447133767302148, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 364, train_loss = 1.044022586196661, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 365, train_loss = 1.042323925823439, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 366, train_loss = 1.041940110444557, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 367, train_loss = 1.0407662491197698, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 368, train_loss = 1.0396937616169453, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 369, train_loss = 1.039053099870216, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 370, train_loss = 1.038163413584698, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 371, train_loss = 1.0367351335589774, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 372, train_loss = 1.036236287385691, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 373, train_loss = 1.0349209954147227, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 374, train_loss = 1.0338971354067326, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 375, train_loss = 1.0330978706479073, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 376, train_loss = 1.031694286793936, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 377, train_loss = 1.0316334900562651, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 378, train_loss = 1.030347116291523, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 379, train_loss = 1.0296352989971638, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 380, train_loss = 1.02792752411915, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 381, train_loss = 1.0272533086244948, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 382, train_loss = 1.0264928229153156, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 383, train_loss = 1.0255693271756172, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 384, train_loss = 1.0249358427827246, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 385, train_loss = 1.0235603501205333, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 386, train_loss = 1.0233039185404778, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 387, train_loss = 1.0213998506660573, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 388, train_loss = 1.0213502596016042, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 389, train_loss = 1.0200929914717562, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 390, train_loss = 1.0190881341695786, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 391, train_loss = 1.0180894136428833, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 392, train_loss = 1.017535048245918, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 393, train_loss = 1.0165021121501923, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 394, train_loss = 1.0152775620226748, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 395, train_loss = 1.0149605050683022, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 396, train_loss = 1.0138169552083127, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 397, train_loss = 1.0132020699675195, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 398, train_loss = 1.0122315784101374, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 399, train_loss = 1.0112007036805153, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 400, train_loss = 1.0102844933862798, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 401, train_loss = 1.0093362827901728, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 402, train_loss = 1.0089501738548279, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 403, train_loss = 1.008139606565237, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 404, train_loss = 1.007058719813358, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 405, train_loss = 1.0059472036664374, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 406, train_loss = 1.0055195701424964, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 407, train_loss = 1.004709908098448, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 408, train_loss = 1.0039452078635804, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 409, train_loss = 1.0033234916627407, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 410, train_loss = 1.0017597464029677, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 411, train_loss = 1.0016471892595291, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 412, train_loss = 1.000173419713974, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 413, train_loss = 0.9995344703202136, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 414, train_loss = 0.9985890661482699, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 415, train_loss = 0.9982571142609231, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 416, train_loss = 0.9973731015925296, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 417, train_loss = 0.9964942162041552, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 418, train_loss = 0.9955910506541841, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 419, train_loss = 0.9947386520798318, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 420, train_loss = 0.9941593632102013, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 421, train_loss = 0.9934279285371304, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 422, train_loss = 0.9926203253562562, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 423, train_loss = 0.9920477867126465, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 424, train_loss = 0.990837345510954, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 425, train_loss = 0.9901441981492098, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 426, train_loss = 0.9894644642772619, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 427, train_loss = 0.988863038510317, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 428, train_loss = 0.9879851341247559, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 429, train_loss = 0.9877266387047712, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 430, train_loss = 0.986162298679119, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 431, train_loss = 0.9852588487265166, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 432, train_loss = 0.9850891629757825, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 433, train_loss = 0.9843494147062302, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 434, train_loss = 0.9837423264980316, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 435, train_loss = 0.9823832313122693, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 436, train_loss = 0.9820654740033206, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 437, train_loss = 0.9810623079538345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 438, train_loss = 0.9806816788914148, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 439, train_loss = 0.9797988670470659, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 440, train_loss = 0.9788189940154552, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 441, train_loss = 0.9777746597828809, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 442, train_loss = 0.9771646695735399, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 443, train_loss = 0.9766312974097673, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 444, train_loss = 0.9763335722091142, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 445, train_loss = 0.9753889391722623, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 446, train_loss = 0.9745545561017934, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 447, train_loss = 0.9736353854241315, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 448, train_loss = 0.9732190234062728, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 449, train_loss = 0.9722178354859352, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 450, train_loss = 0.9720549868943635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 451, train_loss = 0.9708376588823739, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 452, train_loss = 0.9705265437660273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 453, train_loss = 0.9689959088864271, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 454, train_loss = 0.9678071613016073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 455, train_loss = 0.9673650277254637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 456, train_loss = 0.9667766404745635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 457, train_loss = 0.9656850211322308, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 458, train_loss = 0.965201453625923, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 459, train_loss = 0.9642719042894896, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 460, train_loss = 0.9633209928870201, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 461, train_loss = 0.963203851133585, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 462, train_loss = 0.9619518555700779, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 463, train_loss = 0.961845874786377, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 464, train_loss = 0.9607388836739119, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 465, train_loss = 0.9602445860800799, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 466, train_loss = 0.9593415881099645, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 467, train_loss = 0.9586241344513837, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 468, train_loss = 0.9579968216421548, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 469, train_loss = 0.9574311139585916, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 470, train_loss = 0.9566376022994518, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 471, train_loss = 0.9559412921371404, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 472, train_loss = 0.9553964647057, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 473, train_loss = 0.9546636901795864, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 474, train_loss = 0.95387027785182, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 475, train_loss = 0.9540105226042215, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 476, train_loss = 0.9530778502521571, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 477, train_loss = 0.9521046206355095, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 478, train_loss = 0.9518000607786234, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 479, train_loss = 0.9511829999682959, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 480, train_loss = 0.9502904849650804, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 481, train_loss = 0.9497733128664549, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 482, train_loss = 0.9492387287318707, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 483, train_loss = 0.9480805024504662, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 484, train_loss = 0.94833025088883, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 485, train_loss = 0.9472461988625582, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 486, train_loss = 0.9465632413921412, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 487, train_loss = 0.9459976727666799, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 488, train_loss = 0.9452116824686527, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 489, train_loss = 0.9452122164366301, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 490, train_loss = 0.9438173336384352, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 491, train_loss = 0.9436791191401426, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 492, train_loss = 0.943084600061411, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 493, train_loss = 0.9424517291190568, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 494, train_loss = 0.9420260339975357, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 495, train_loss = 0.9411916360259056, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 496, train_loss = 0.9402930811047554, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 497, train_loss = 0.9399772894976195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 498, train_loss = 0.9397059666516725, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 499, train_loss = 0.9387037518026773, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████▋                              | 17/30 [2:49:23<2:09:45, 598.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "18th- epoch: 0, train_loss = 114.45541493594646, train_acc = 0.7782952957615277\n",
      "test Acc 0.8919925512104283:\n",
      "18th- epoch: 1, train_loss = 44.26167467236519, train_acc = 0.9094084769445738\n",
      "test Acc 0.9236499068901304:\n",
      "18th- epoch: 2, train_loss = 32.07041832059622, train_acc = 0.9335118770377271\n",
      "test Acc 0.9320297951582868:\n",
      "18th- epoch: 3, train_loss = 26.002422146499157, train_acc = 0.9459711224965067\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 4, train_loss = 22.08591390401125, train_acc = 0.9554028877503493\n",
      "test Acc 0.9427374301675978:\n",
      "18th- epoch: 5, train_loss = 19.235760431736708, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 6, train_loss = 17.057102723047137, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "18th- epoch: 7, train_loss = 15.330323847010732, train_acc = 0.970540288775035\n",
      "test Acc 0.9534450651769087:\n",
      "18th- epoch: 8, train_loss = 13.938379341736436, train_acc = 0.9729855612482534\n",
      "test Acc 0.9553072625698324:\n",
      "18th- epoch: 9, train_loss = 12.779331730678678, train_acc = 0.9750815090824406\n",
      "test Acc 0.9557728119180633:\n",
      "18th- epoch: 10, train_loss = 11.805758653208613, train_acc = 0.9768281322775967\n",
      "test Acc 0.9590316573556797:\n",
      "18th- epoch: 11, train_loss = 10.97892296500504, train_acc = 0.9790405216581276\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 12, train_loss = 10.266904836520553, train_acc = 0.9800884955752213\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 13, train_loss = 9.643005177378654, train_acc = 0.9814857941313461\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 14, train_loss = 9.09642993658781, train_acc = 0.9833488588728458\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 15, train_loss = 8.607585476711392, train_acc = 0.9842803912435957\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 16, train_loss = 8.17291303165257, train_acc = 0.9853283651606893\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 17, train_loss = 7.787824712693691, train_acc = 0.9861434559850955\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 18, train_loss = 7.443813499063253, train_acc = 0.9869585468095017\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 19, train_loss = 7.1301977932453156, train_acc = 0.9880065207265952\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 20, train_loss = 6.844750909134746, train_acc = 0.9888216115510013\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 21, train_loss = 6.582928907126188, train_acc = 0.9891709361900326\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 22, train_loss = 6.342825505882502, train_acc = 0.9892873777363763\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 23, train_loss = 6.123347534798086, train_acc = 0.9897531439217513\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 24, train_loss = 5.91653261706233, train_acc = 0.9905682347461574\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 25, train_loss = 5.728491138666868, train_acc = 0.990801117838845\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 26, train_loss = 5.550985736772418, train_acc = 0.9912668840242198\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 27, train_loss = 5.38520902954042, train_acc = 0.9916162086632511\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 28, train_loss = 5.2304394375532866, train_acc = 0.9918490917559385\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 29, train_loss = 5.082127808593214, train_acc = 0.9919655333022822\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 30, train_loss = 4.946364113129675, train_acc = 0.9923148579413135\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 31, train_loss = 4.815311247482896, train_acc = 0.9925477410340009\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 32, train_loss = 4.691595062613487, train_acc = 0.9926641825803446\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 33, train_loss = 4.575572493486106, train_acc = 0.9928970656730322\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 34, train_loss = 4.4644479267299175, train_acc = 0.9932463903120633\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 35, train_loss = 4.360639292746782, train_acc = 0.9933628318584071\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 36, train_loss = 4.261744786053896, train_acc = 0.9935957149510946\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 37, train_loss = 4.168906739912927, train_acc = 0.993828598043782\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 38, train_loss = 4.079855072312057, train_acc = 0.9940614811364695\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 39, train_loss = 3.9958056109026074, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 40, train_loss = 3.9156957641243935, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 41, train_loss = 3.836946649476886, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 42, train_loss = 3.763623588718474, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 43, train_loss = 3.6915273955091834, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 44, train_loss = 3.625323485583067, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 45, train_loss = 3.5593266268260777, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 46, train_loss = 3.495866682380438, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 47, train_loss = 3.4348590094596148, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 48, train_loss = 3.375140043441206, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 49, train_loss = 3.32026382163167, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 50, train_loss = 3.265466762240976, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 51, train_loss = 3.2146189268678427, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 52, train_loss = 3.164192549418658, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 53, train_loss = 3.116262121591717, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 54, train_loss = 3.0687824301421642, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 55, train_loss = 3.0249164081178606, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 56, train_loss = 2.98211058229208, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 57, train_loss = 2.9416725714690983, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 58, train_loss = 2.902491608634591, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 59, train_loss = 2.8627118300646544, train_acc = 0.9954587796925943\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 60, train_loss = 2.825892999768257, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 61, train_loss = 2.7900210614316165, train_acc = 0.9954587796925943\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 62, train_loss = 2.754726927727461, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 63, train_loss = 2.7212672834284604, train_acc = 0.9958081043316255\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 64, train_loss = 2.686500165145844, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 65, train_loss = 2.6548733455128968, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 66, train_loss = 2.6242454941384494, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 67, train_loss = 2.5938601158559322, train_acc = 0.9959245458779693\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 68, train_loss = 2.565037047956139, train_acc = 0.9959245458779693\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 69, train_loss = 2.5357800708152354, train_acc = 0.9958081043316255\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 70, train_loss = 2.509300783276558, train_acc = 0.9959245458779693\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 71, train_loss = 2.4828157648444176, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 72, train_loss = 2.457354837562889, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 73, train_loss = 2.431511343922466, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 74, train_loss = 2.4067712500691414, train_acc = 0.9959245458779693\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 75, train_loss = 2.3834337652660906, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 76, train_loss = 2.360111700836569, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 77, train_loss = 2.3376534071285278, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 78, train_loss = 2.3157849845010787, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 79, train_loss = 2.2943547789473087, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 80, train_loss = 2.274364260258153, train_acc = 0.996040987424313\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 81, train_loss = 2.2537552390713245, train_acc = 0.996040987424313\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 82, train_loss = 2.2342624713201076, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 83, train_loss = 2.215882658958435, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 84, train_loss = 2.196626342833042, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 85, train_loss = 2.1784805320203304, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 86, train_loss = 2.160562767414376, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 87, train_loss = 2.1436560947913677, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 88, train_loss = 2.1255955782253295, train_acc = 0.9963903120633442\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 89, train_loss = 2.1090838175732642, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 90, train_loss = 2.092974938452244, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 91, train_loss = 2.0761351101100445, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 92, train_loss = 2.061513679800555, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 93, train_loss = 2.0457264457363635, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 94, train_loss = 2.0312451149802655, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 95, train_loss = 2.0172352008521557, train_acc = 0.9966231951560317\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 96, train_loss = 2.0030605730134994, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 97, train_loss = 1.9894574161153287, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 98, train_loss = 1.975956813665107, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 99, train_loss = 1.9634489677846432, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 100, train_loss = 1.9504408475477248, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 101, train_loss = 1.9382402140181512, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 102, train_loss = 1.925630411831662, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 103, train_loss = 1.9139631998259574, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 104, train_loss = 1.9019887123722583, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 105, train_loss = 1.8900445613544434, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 106, train_loss = 1.8797657813411206, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 107, train_loss = 1.8679799039382488, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 108, train_loss = 1.856966794701293, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 109, train_loss = 1.8463272117078304, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 110, train_loss = 1.8356233176309615, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 111, train_loss = 1.8258071057498455, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 112, train_loss = 1.8158142503816634, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 113, train_loss = 1.8057762172538787, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 114, train_loss = 1.7961327370721847, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 115, train_loss = 1.7860575828235596, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 116, train_loss = 1.7769073620438576, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 117, train_loss = 1.7677403788547963, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 118, train_loss = 1.7586343449074775, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 119, train_loss = 1.7504040710628033, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 120, train_loss = 1.741646868409589, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 121, train_loss = 1.7332667026203126, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 122, train_loss = 1.7255966600496322, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 123, train_loss = 1.7175865732133389, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 124, train_loss = 1.7094133968930691, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 125, train_loss = 1.7018889274913818, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 126, train_loss = 1.6938815477769822, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 127, train_loss = 1.686706330627203, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 128, train_loss = 1.6787658345419914, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 129, train_loss = 1.6718251158017665, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 130, train_loss = 1.6641596369445324, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 131, train_loss = 1.6571429371833801, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 132, train_loss = 1.6502510035643354, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 133, train_loss = 1.6435636592796072, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 134, train_loss = 1.63722922897432, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 135, train_loss = 1.6308304431149736, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 136, train_loss = 1.6246085179736838, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 137, train_loss = 1.6179223781218752, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 138, train_loss = 1.611739069223404, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 139, train_loss = 1.6052199924597517, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 140, train_loss = 1.5995666148373857, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 141, train_loss = 1.5929818277945742, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 142, train_loss = 1.5871163917472586, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 143, train_loss = 1.5811442857375368, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 144, train_loss = 1.575431284843944, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 145, train_loss = 1.5695761168608442, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 146, train_loss = 1.5636711729457602, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 147, train_loss = 1.5581247558584437, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 148, train_loss = 1.5527813894441351, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 149, train_loss = 1.547506413073279, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 150, train_loss = 1.542655477882363, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 151, train_loss = 1.5368550767889246, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 152, train_loss = 1.5312280046055093, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 153, train_loss = 1.5266831616172567, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 154, train_loss = 1.5215671099722385, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 155, train_loss = 1.5167081145336851, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 156, train_loss = 1.511083555757068, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 157, train_loss = 1.5071907403180376, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 158, train_loss = 1.5017246702918783, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 159, train_loss = 1.4970957599580288, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 160, train_loss = 1.492578960955143, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 161, train_loss = 1.48777938389685, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 162, train_loss = 1.4836698696017265, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 163, train_loss = 1.4788539931178093, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 164, train_loss = 1.474169091670774, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 165, train_loss = 1.4699081033468246, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 166, train_loss = 1.4649435306200758, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 167, train_loss = 1.4609342651674524, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 168, train_loss = 1.4568108282983303, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 169, train_loss = 1.45310914888978, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 170, train_loss = 1.4476218521595001, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 171, train_loss = 1.4415405901381746, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 172, train_loss = 1.438250401406549, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 173, train_loss = 1.4343223050236702, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 174, train_loss = 1.429927010089159, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 175, train_loss = 1.4262415344128385, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 176, train_loss = 1.4213141141226515, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 177, train_loss = 1.4171055579790846, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 178, train_loss = 1.4127260347595438, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 179, train_loss = 1.4089813554892316, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 180, train_loss = 1.4047901021549478, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 181, train_loss = 1.4016206227242947, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 182, train_loss = 1.3977856723358855, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 183, train_loss = 1.3943572429707274, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 184, train_loss = 1.390891496092081, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 185, train_loss = 1.38737351691816, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 186, train_loss = 1.3836367018520832, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 187, train_loss = 1.3798715671291575, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 188, train_loss = 1.3764759203186259, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 189, train_loss = 1.3729224726557732, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 190, train_loss = 1.3698623640229926, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 191, train_loss = 1.3666155288228765, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 192, train_loss = 1.3629341957857832, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 193, train_loss = 1.360084297717549, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 194, train_loss = 1.3562616432318464, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 195, train_loss = 1.352231215685606, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 196, train_loss = 1.3495061993598938, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 197, train_loss = 1.346059750765562, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 198, train_loss = 1.3432512283325195, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 199, train_loss = 1.3394110625376925, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 200, train_loss = 1.3370558036258444, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 201, train_loss = 1.333057434647344, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 202, train_loss = 1.330072912038304, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 203, train_loss = 1.3281607056269422, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 204, train_loss = 1.3248661333927885, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 205, train_loss = 1.321581838070415, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 206, train_loss = 1.3183822942664847, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 207, train_loss = 1.3164112964877859, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 208, train_loss = 1.3140918338904157, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 209, train_loss = 1.3108839256456122, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 210, train_loss = 1.3081840326776728, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 211, train_loss = 1.3054860569536686, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 212, train_loss = 1.3028417093446478, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 213, train_loss = 1.300170342088677, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 214, train_loss = 1.2973305782070383, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 215, train_loss = 1.295284646213986, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 216, train_loss = 1.2924076480558142, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 217, train_loss = 1.2896464802324772, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 218, train_loss = 1.286872067837976, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 219, train_loss = 1.2839359877398238, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 220, train_loss = 1.2822323205764405, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 221, train_loss = 1.2791516967117786, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 222, train_loss = 1.2773610837757587, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 223, train_loss = 1.2746809770469554, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 224, train_loss = 1.2719734807615168, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 225, train_loss = 1.2697877672617324, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 226, train_loss = 1.2675623632967472, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 227, train_loss = 1.2646256759762764, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 228, train_loss = 1.2628887705504894, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 229, train_loss = 1.2605094760656357, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 230, train_loss = 1.2578048159484752, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 231, train_loss = 1.2552652818267234, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 232, train_loss = 1.2539392324979417, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 233, train_loss = 1.2510293151135556, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 234, train_loss = 1.2493567392230034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 235, train_loss = 1.246837196231354, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 236, train_loss = 1.2453683987259865, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 237, train_loss = 1.2423775109346025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 238, train_loss = 1.2402682987158187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 239, train_loss = 1.238253653049469, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 240, train_loss = 1.2359098469023593, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 241, train_loss = 1.2339461135561578, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 242, train_loss = 1.2321497338707559, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 243, train_loss = 1.2291097926790826, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 244, train_loss = 1.227725438773632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 245, train_loss = 1.2259632659261115, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 246, train_loss = 1.223026915162336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 247, train_loss = 1.2214856334030628, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 248, train_loss = 1.2204325559432618, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 249, train_loss = 1.216791772574652, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 250, train_loss = 1.2156191132962704, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 251, train_loss = 1.2134151731734164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 252, train_loss = 1.211696160316933, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 253, train_loss = 1.2095876795356162, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 254, train_loss = 1.207538690418005, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 255, train_loss = 1.2057452996377833, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 256, train_loss = 1.2031063412432559, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 257, train_loss = 1.2023795694112778, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 258, train_loss = 1.1998293424840085, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 259, train_loss = 1.1981394911999814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 260, train_loss = 1.1962696773116477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 261, train_loss = 1.1951761444215663, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 262, train_loss = 1.1926822140812874, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 263, train_loss = 1.1912192690069787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 264, train_loss = 1.1886972176725976, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 265, train_loss = 1.1875014665420167, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 266, train_loss = 1.1850305522675626, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 267, train_loss = 1.1836953063611872, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 268, train_loss = 1.1815353582496755, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 269, train_loss = 1.1800946432049386, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 270, train_loss = 1.1787840078468435, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 271, train_loss = 1.1770228631794453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 272, train_loss = 1.1750280112028122, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 273, train_loss = 1.1730515671079047, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 274, train_loss = 1.1710912163252942, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 275, train_loss = 1.1703373665804975, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 276, train_loss = 1.1682240292429924, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 277, train_loss = 1.1664603998069651, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 278, train_loss = 1.1644704031641595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 279, train_loss = 1.1630714014172554, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 280, train_loss = 1.161716591566801, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 281, train_loss = 1.159662223129999, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 282, train_loss = 1.1586925511364825, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 283, train_loss = 1.1563449539244175, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 284, train_loss = 1.1554456266458146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 285, train_loss = 1.1528924070298672, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 286, train_loss = 1.1521385312080383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 287, train_loss = 1.1498890866641887, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 288, train_loss = 1.148369471251499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 289, train_loss = 1.147423489659559, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 290, train_loss = 1.1457095754449256, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 291, train_loss = 1.1443666729028337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 292, train_loss = 1.1421057122643106, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 293, train_loss = 1.141101115674246, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 294, train_loss = 1.1393364680116065, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 295, train_loss = 1.1378508235211484, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 296, train_loss = 1.1363596506416798, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 297, train_loss = 1.1346702724695206, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 298, train_loss = 1.1326524739270099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 299, train_loss = 1.132029237865936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 300, train_loss = 1.129818458110094, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 301, train_loss = 1.128423682122957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 302, train_loss = 1.1266879364848137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 303, train_loss = 1.1254912788863294, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 304, train_loss = 1.1236827026004903, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 305, train_loss = 1.1227364118094556, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 306, train_loss = 1.1207262898678891, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 307, train_loss = 1.1196257869596593, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 308, train_loss = 1.117764227092266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 309, train_loss = 1.1163458811934106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 310, train_loss = 1.1150540846283548, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 311, train_loss = 1.113980696827639, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 312, train_loss = 1.11263045668602, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 313, train_loss = 1.1105708256363869, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 314, train_loss = 1.1095728501677513, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 315, train_loss = 1.1084202130441554, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 316, train_loss = 1.107787782966625, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 317, train_loss = 1.1056547040934674, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 318, train_loss = 1.1046897359192371, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 319, train_loss = 1.103674203157425, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 320, train_loss = 1.1015874333679676, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 321, train_loss = 1.1014902517199516, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 322, train_loss = 1.0993283043499105, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 323, train_loss = 1.0980743045802228, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 324, train_loss = 1.0966665943269618, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 325, train_loss = 1.0951347115333192, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 326, train_loss = 1.0946794860064983, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 327, train_loss = 1.093380305916071, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 328, train_loss = 1.0914072680170648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 329, train_loss = 1.0906913454527967, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 330, train_loss = 1.0892635497148149, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 331, train_loss = 1.087687882303726, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 332, train_loss = 1.086631151556503, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 333, train_loss = 1.084972960234154, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 334, train_loss = 1.083619873970747, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 335, train_loss = 1.083218180865515, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 336, train_loss = 1.0810642552678473, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 337, train_loss = 1.0807291666860692, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 338, train_loss = 1.0791899387841113, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 339, train_loss = 1.0784351353649981, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 340, train_loss = 1.07717665535165, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 341, train_loss = 1.0755521369283088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 342, train_loss = 1.0742573750321753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 343, train_loss = 1.0738778213853948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 344, train_loss = 1.0722941110725515, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 345, train_loss = 1.0713389478623867, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 346, train_loss = 1.0696984082460403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 347, train_loss = 1.069626626878744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 348, train_loss = 1.0678447174432222, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 349, train_loss = 1.0667010409233626, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 350, train_loss = 1.065642594039673, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 351, train_loss = 1.0635474833252374, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 352, train_loss = 1.0631352228519972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 353, train_loss = 1.0618092007935047, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 354, train_loss = 1.0608878607454244, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 355, train_loss = 1.0595794369874056, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 356, train_loss = 1.0591713277099188, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 357, train_loss = 1.0573119583132211, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 358, train_loss = 1.0569078574480955, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 359, train_loss = 1.055536888539791, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 360, train_loss = 1.0540571933088358, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 361, train_loss = 1.0535638853907585, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 362, train_loss = 1.052490913629299, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 363, train_loss = 1.0514882641436998, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 364, train_loss = 1.049959941447014, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 365, train_loss = 1.0491779235599097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 366, train_loss = 1.0478412210941315, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 367, train_loss = 1.0473239980638027, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 368, train_loss = 1.04574086269713, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 369, train_loss = 1.0449872302415315, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 370, train_loss = 1.0439121102390345, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 371, train_loss = 1.043242378771538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 372, train_loss = 1.042101907223696, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 373, train_loss = 1.0409533803758677, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 374, train_loss = 1.0406339230539743, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 375, train_loss = 1.038859880209202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 376, train_loss = 1.0376649809477385, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 377, train_loss = 1.0374200654623564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 378, train_loss = 1.0355520198645536, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 379, train_loss = 1.0350378578004893, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 380, train_loss = 1.034291248768568, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 381, train_loss = 1.0331533240678255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 382, train_loss = 1.0325646810233593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 383, train_loss = 1.0311849365534727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 384, train_loss = 1.0305799456837121, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 385, train_loss = 1.0294177432951983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 386, train_loss = 1.028580086916918, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 387, train_loss = 1.027891132980585, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 388, train_loss = 1.026534765958786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 389, train_loss = 1.0255629556777421, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 390, train_loss = 1.025352917611599, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 391, train_loss = 1.0238416219654027, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 392, train_loss = 1.0227293483912945, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 393, train_loss = 1.0221234088239726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 394, train_loss = 1.0216293123958167, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 395, train_loss = 1.0203296070394572, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 396, train_loss = 1.019755493849516, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 397, train_loss = 1.0185149498283863, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 398, train_loss = 1.0179175958037376, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 399, train_loss = 1.0169252703490201, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 400, train_loss = 1.0165639258921146, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 401, train_loss = 1.0149829909205437, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 402, train_loss = 1.0144170013663825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 403, train_loss = 1.013687257975107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 404, train_loss = 1.0127031852898654, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 405, train_loss = 1.011430380254751, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 406, train_loss = 1.0108006695809308, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 407, train_loss = 1.010478192329174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 408, train_loss = 1.0094294498267118, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 409, train_loss = 1.0074993607995566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 410, train_loss = 1.0080482053162996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 411, train_loss = 1.0066454162297305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 412, train_loss = 1.0063648459909018, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 413, train_loss = 1.0050443919899408, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 414, train_loss = 1.004493618995184, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 415, train_loss = 1.0040573788282927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 416, train_loss = 1.002705321967369, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 417, train_loss = 1.0021663779916707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 418, train_loss = 1.0011369685234968, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 419, train_loss = 1.0003561191260815, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 420, train_loss = 0.9998538891377393, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 421, train_loss = 0.9990298611519393, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 422, train_loss = 0.9977544719877187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 423, train_loss = 0.9970405002532061, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 424, train_loss = 0.9963289263250772, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 425, train_loss = 0.9957674046454486, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 426, train_loss = 0.9949199246766511, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 427, train_loss = 0.9934884260001127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 428, train_loss = 0.993480517208809, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 429, train_loss = 0.9922509839234408, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 430, train_loss = 0.9919629606010858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 431, train_loss = 0.9911086397769395, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 432, train_loss = 0.9901952569780406, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 433, train_loss = 0.9892107769846916, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 434, train_loss = 0.9880188181996346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 435, train_loss = 0.9881355663237628, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 436, train_loss = 0.9871341573598329, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 437, train_loss = 0.9866088715789374, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 438, train_loss = 0.9852409449813422, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 439, train_loss = 0.985434136033291, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 440, train_loss = 0.9841280865075532, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 441, train_loss = 0.983550414443016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 442, train_loss = 0.9829999369976576, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 443, train_loss = 0.9828201197087765, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 444, train_loss = 0.9809852453472558, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 445, train_loss = 0.9808145612478256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 446, train_loss = 0.9798801305296365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 447, train_loss = 0.9792983370425645, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 448, train_loss = 0.97850633165217, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 449, train_loss = 0.9775249572994653, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 450, train_loss = 0.9771118362841662, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 451, train_loss = 0.9764306992292404, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 452, train_loss = 0.9757083505392075, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 453, train_loss = 0.9747593303618487, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 454, train_loss = 0.9744502914545592, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 455, train_loss = 0.9731003890337888, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 456, train_loss = 0.9727990416286048, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 457, train_loss = 0.9723551807401236, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 458, train_loss = 0.9713685984315816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 459, train_loss = 0.9710159301757812, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 460, train_loss = 0.970444036036497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 461, train_loss = 0.9692450799047947, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 462, train_loss = 0.9689768975076731, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 463, train_loss = 0.9680345530214254, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 464, train_loss = 0.9672686768171843, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 465, train_loss = 0.9663809947669506, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 466, train_loss = 0.9661849066615105, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 467, train_loss = 0.9657588911650237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 468, train_loss = 0.965389646589756, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 469, train_loss = 0.9641570411622524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 470, train_loss = 0.9630752143857535, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 471, train_loss = 0.9625672623515129, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 472, train_loss = 0.9624291074869689, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 473, train_loss = 0.9613009306194726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 474, train_loss = 0.9611455785634462, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 475, train_loss = 0.9602442483010236, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 476, train_loss = 0.9600163636205252, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 477, train_loss = 0.9589872471988201, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 478, train_loss = 0.958454833686119, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 479, train_loss = 0.9576532555220183, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 480, train_loss = 0.9565443197789136, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 481, train_loss = 0.9566704357566778, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 482, train_loss = 0.955815819412237, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 483, train_loss = 0.9553286619484425, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 484, train_loss = 0.9547019240853842, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 485, train_loss = 0.9536263135669287, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 486, train_loss = 0.9533202114107553, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 487, train_loss = 0.952264236897463, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 488, train_loss = 0.9522790288028773, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 489, train_loss = 0.9508064997789916, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 490, train_loss = 0.9511238349077757, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 491, train_loss = 0.949837746709818, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 492, train_loss = 0.9497736245393753, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 493, train_loss = 0.9491001628339291, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 494, train_loss = 0.948064424097538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 495, train_loss = 0.9481081068515778, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 496, train_loss = 0.9471126049757004, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 497, train_loss = 0.946633438259596, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 498, train_loss = 0.9463553490641061, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 499, train_loss = 0.9457550210354384, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████                            | 18/30 [2:59:22<1:59:47, 598.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "19th- epoch: 0, train_loss = 137.81563758850098, train_acc = 0.7649045179319981\n",
      "test Acc 0.8435754189944135:\n",
      "19th- epoch: 1, train_loss = 45.36756218969822, train_acc = 0.9077782952957615\n",
      "test Acc 0.8868715083798883:\n",
      "19th- epoch: 2, train_loss = 33.248519118875265, train_acc = 0.9346762925011645\n",
      "test Acc 0.914804469273743:\n",
      "19th- epoch: 3, train_loss = 27.022679667919874, train_acc = 0.9485328365160689\n",
      "test Acc 0.9315642458100558:\n",
      "19th- epoch: 4, train_loss = 23.01511850208044, train_acc = 0.9561015370284117\n",
      "test Acc 0.9422718808193669:\n",
      "19th- epoch: 5, train_loss = 20.135420406237245, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "19th- epoch: 6, train_loss = 17.918718371540308, train_acc = 0.9646017699115044\n",
      "test Acc 0.9543761638733705:\n",
      "19th- epoch: 7, train_loss = 16.15644185990095, train_acc = 0.9676292501164415\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 8, train_loss = 14.729965249076486, train_acc = 0.9706567303213787\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 9, train_loss = 13.5542809702456, train_acc = 0.9743828598043782\n",
      "test Acc 0.9646182495344506:\n",
      "19th- epoch: 10, train_loss = 12.556495141237974, train_acc = 0.9770610153702841\n",
      "test Acc 0.9655493482309124:\n",
      "19th- epoch: 11, train_loss = 11.694318689405918, train_acc = 0.9785747554727526\n",
      "test Acc 0.9660148975791434:\n",
      "19th- epoch: 12, train_loss = 10.943829119205475, train_acc = 0.9803213786679087\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 13, train_loss = 10.282810809090734, train_acc = 0.981951560316721\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 14, train_loss = 9.7028530780226, train_acc = 0.9834653004191896\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 15, train_loss = 9.188074320554733, train_acc = 0.984163949697252\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 16, train_loss = 8.723854955285788, train_acc = 0.9850954820680019\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 17, train_loss = 8.30676687695086, train_acc = 0.985910572892408\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 18, train_loss = 7.925056758336723, train_acc = 0.9864927806241267\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 19, train_loss = 7.578119896352291, train_acc = 0.9868421052631579\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 20, train_loss = 7.258156788535416, train_acc = 0.9870749883558454\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 21, train_loss = 6.967929231934249, train_acc = 0.9877736376339078\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 22, train_loss = 6.6963841784745455, train_acc = 0.9880065207265952\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 23, train_loss = 6.449796442873776, train_acc = 0.9889380530973452\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 24, train_loss = 6.217378402128816, train_acc = 0.9891709361900326\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 25, train_loss = 6.001872317865491, train_acc = 0.98940381928272\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 26, train_loss = 5.803410714492202, train_acc = 0.9896367023754076\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 27, train_loss = 5.613219873048365, train_acc = 0.9899860270144387\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 28, train_loss = 5.438338441774249, train_acc = 0.99033535165347\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 29, train_loss = 5.273034722544253, train_acc = 0.9906846762925011\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 30, train_loss = 5.11449427343905, train_acc = 0.990801117838845\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 31, train_loss = 4.965692842379212, train_acc = 0.9913833255705635\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 32, train_loss = 4.82784831430763, train_acc = 0.9916162086632511\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 33, train_loss = 4.695772222243249, train_acc = 0.9919655333022822\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 34, train_loss = 4.57008074503392, train_acc = 0.9921984163949698\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 35, train_loss = 4.450617129914463, train_acc = 0.9926641825803446\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 36, train_loss = 4.33780153375119, train_acc = 0.9926641825803446\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 37, train_loss = 4.230593685992062, train_acc = 0.9927806241266884\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 38, train_loss = 4.129935649223626, train_acc = 0.9931299487657196\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 39, train_loss = 4.0337330643087626, train_acc = 0.9931299487657196\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 40, train_loss = 3.9423296516761184, train_acc = 0.9934792734047508\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 41, train_loss = 3.855403544381261, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 42, train_loss = 3.7724044788628817, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 43, train_loss = 3.6932173082605004, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 44, train_loss = 3.618543672375381, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 45, train_loss = 3.5464222617447376, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 46, train_loss = 3.476852781139314, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 47, train_loss = 3.409433706663549, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 48, train_loss = 3.345576978288591, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 49, train_loss = 3.285698287189007, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 50, train_loss = 3.2268418557941914, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 51, train_loss = 3.1716165775433183, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 52, train_loss = 3.1178786139935255, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 53, train_loss = 3.0674560833722353, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 54, train_loss = 3.017330741509795, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 55, train_loss = 2.9711403120309114, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 56, train_loss = 2.9251601668074727, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 57, train_loss = 2.8822648655623198, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 58, train_loss = 2.8403635062277317, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 59, train_loss = 2.800930800382048, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 60, train_loss = 2.761646169703454, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 61, train_loss = 2.7245342754758894, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 62, train_loss = 2.687030835542828, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 63, train_loss = 2.652321068570018, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 64, train_loss = 2.619110562838614, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 65, train_loss = 2.5866120173595846, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 66, train_loss = 2.554625127464533, train_acc = 0.9961574289706567\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 67, train_loss = 2.524941314011812, train_acc = 0.9961574289706567\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 68, train_loss = 2.4940769555978477, train_acc = 0.9961574289706567\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 69, train_loss = 2.465582692530006, train_acc = 0.9961574289706567\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 70, train_loss = 2.438155047595501, train_acc = 0.9962738705170004\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 71, train_loss = 2.4107668665237725, train_acc = 0.9962738705170004\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 72, train_loss = 2.384921132121235, train_acc = 0.9961574289706567\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 73, train_loss = 2.360646974761039, train_acc = 0.9961574289706567\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 74, train_loss = 2.3355268510058522, train_acc = 0.9963903120633442\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 75, train_loss = 2.3127063009887934, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 76, train_loss = 2.2896751426160336, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 77, train_loss = 2.2684989292174578, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 78, train_loss = 2.2471429496072233, train_acc = 0.996506753609688\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 79, train_loss = 2.2260865587741137, train_acc = 0.9966231951560317\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 80, train_loss = 2.2071351348422468, train_acc = 0.9967396367023754\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 81, train_loss = 2.1874241400510073, train_acc = 0.9968560782487191\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 82, train_loss = 2.1687202150933444, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 83, train_loss = 2.1511093587614596, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 84, train_loss = 2.133113401941955, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 85, train_loss = 2.116113326512277, train_acc = 0.9969725197950629\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 86, train_loss = 2.0991508127190173, train_acc = 0.9969725197950629\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 87, train_loss = 2.0836216718889773, train_acc = 0.9969725197950629\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 88, train_loss = 2.0672213514335454, train_acc = 0.9969725197950629\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 89, train_loss = 2.051819617394358, train_acc = 0.9969725197950629\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 90, train_loss = 2.0367928803898394, train_acc = 0.9969725197950629\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 91, train_loss = 2.0226874365471303, train_acc = 0.9969725197950629\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 92, train_loss = 2.008151896763593, train_acc = 0.9969725197950629\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 93, train_loss = 1.9940298185683787, train_acc = 0.9969725197950629\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 94, train_loss = 1.9798461818136275, train_acc = 0.9969725197950629\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 95, train_loss = 1.9670512550510466, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 96, train_loss = 1.9529808587394655, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 97, train_loss = 1.9404129623435438, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 98, train_loss = 1.9263655385002494, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 99, train_loss = 1.9129826449789107, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 100, train_loss = 1.9018814973533154, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 101, train_loss = 1.8900355019140989, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 102, train_loss = 1.8788272552192211, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 103, train_loss = 1.8675422037485987, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 104, train_loss = 1.8569226337131113, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 105, train_loss = 1.8457748328801244, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 106, train_loss = 1.835128704085946, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 107, train_loss = 1.8253908168990165, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 108, train_loss = 1.8155472290236503, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 109, train_loss = 1.8052145114634186, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 110, train_loss = 1.7954936595633626, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 111, train_loss = 1.7860352909192443, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 112, train_loss = 1.7769806559663266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 113, train_loss = 1.7675393756944686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 114, train_loss = 1.7580081701744348, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 115, train_loss = 1.7495266795158386, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 116, train_loss = 1.740697632310912, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 117, train_loss = 1.7323167163413018, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 118, train_loss = 1.7236251719295979, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 119, train_loss = 1.7152298169676214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 120, train_loss = 1.707022295333445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 121, train_loss = 1.6993989709299058, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 122, train_loss = 1.6914214447606355, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 123, train_loss = 1.6839685819577426, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 124, train_loss = 1.6758219718467444, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 125, train_loss = 1.6687088587787002, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 126, train_loss = 1.6609670317266136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 127, train_loss = 1.654948958195746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 128, train_loss = 1.6473053197842091, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 129, train_loss = 1.6410504411906004, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 130, train_loss = 1.6345568848773837, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 131, train_loss = 1.6279146948363632, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 132, train_loss = 1.620847068959847, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 133, train_loss = 1.6155251439195126, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 134, train_loss = 1.60879340977408, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 135, train_loss = 1.6028538970276713, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 136, train_loss = 1.5967861767858267, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 137, train_loss = 1.5910959562752396, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 138, train_loss = 1.5851063504815102, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 139, train_loss = 1.5796408948954195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 140, train_loss = 1.5733444653451443, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 141, train_loss = 1.5679582909215242, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 142, train_loss = 1.5631008176133037, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 143, train_loss = 1.5569624865893275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 144, train_loss = 1.5521844839677215, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 145, train_loss = 1.5471218812745064, train_acc = 0.9974382859804378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 146, train_loss = 1.5414646279532462, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 147, train_loss = 1.536464219680056, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 148, train_loss = 1.5319612396415323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 149, train_loss = 1.5262379811611027, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 150, train_loss = 1.5215948021505028, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 151, train_loss = 1.5163898898754269, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 152, train_loss = 1.5119648359250277, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 153, train_loss = 1.5067537734284997, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 154, train_loss = 1.5024538745637983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 155, train_loss = 1.4974908481817693, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 156, train_loss = 1.4937574323266745, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 157, train_loss = 1.488734176615253, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 158, train_loss = 1.4844775777310133, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 159, train_loss = 1.4803532052319497, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 160, train_loss = 1.4756612302735448, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 161, train_loss = 1.471747930161655, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 162, train_loss = 1.467271629953757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 163, train_loss = 1.4629139963071793, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 164, train_loss = 1.4588413266465068, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 165, train_loss = 1.45516456104815, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 166, train_loss = 1.450845085317269, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 167, train_loss = 1.447139417519793, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 168, train_loss = 1.4429964451119304, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 169, train_loss = 1.439135342137888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 170, train_loss = 1.4355222994927317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 171, train_loss = 1.4317228903528303, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 172, train_loss = 1.427166185923852, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 173, train_loss = 1.4239051941549405, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "19th- epoch: 174, train_loss = 1.4199456475907937, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 175, train_loss = 1.416706827818416, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 176, train_loss = 1.4127566168317571, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 177, train_loss = 1.409911907860078, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 178, train_loss = 1.405967054888606, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 179, train_loss = 1.402670817449689, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 180, train_loss = 1.398647385998629, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 181, train_loss = 1.395825452171266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 182, train_loss = 1.3921856312081218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 183, train_loss = 1.3891784235602245, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 184, train_loss = 1.3858847077935934, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 185, train_loss = 1.3826321819797158, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 186, train_loss = 1.3795025838771835, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 187, train_loss = 1.3758217239519581, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 188, train_loss = 1.37317272182554, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 189, train_loss = 1.3698776023229584, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 190, train_loss = 1.366804343299009, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 191, train_loss = 1.3633985705673695, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 192, train_loss = 1.360821740119718, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 193, train_loss = 1.3573843532940373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 194, train_loss = 1.3549876989563927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 195, train_loss = 1.3515055160969496, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 196, train_loss = 1.3484477885067463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 197, train_loss = 1.3458746429532766, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 198, train_loss = 1.3428323274711147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 199, train_loss = 1.3397113649407402, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 200, train_loss = 1.3372137068072334, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 201, train_loss = 1.3340527974069118, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 202, train_loss = 1.3315367171308026, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 203, train_loss = 1.3284258743515238, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 204, train_loss = 1.3262075992533937, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 205, train_loss = 1.323007047176361, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 206, train_loss = 1.3203511604806408, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 207, train_loss = 1.3179698809981346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 208, train_loss = 1.3154408304253593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 209, train_loss = 1.3125828262418509, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 210, train_loss = 1.3100340435048565, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 211, train_loss = 1.3072074601659551, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 212, train_loss = 1.3046612981706858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 213, train_loss = 1.3019241424044594, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 214, train_loss = 1.2994334833929315, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 215, train_loss = 1.2968244472285733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 216, train_loss = 1.2944718269864097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 217, train_loss = 1.2915728613734245, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 218, train_loss = 1.2897472027689219, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 219, train_loss = 1.2869685180485249, train_acc = 0.9974382859804378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 220, train_loss = 1.2844461239874363, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 221, train_loss = 1.2815198065945879, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 222, train_loss = 1.2796669671079144, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 223, train_loss = 1.2770974524319172, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 224, train_loss = 1.2744972854852676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 225, train_loss = 1.2719718907028437, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 226, train_loss = 1.2701398668577895, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 227, train_loss = 1.2672723165014759, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 228, train_loss = 1.2657101905206218, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 229, train_loss = 1.2629143180092797, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 230, train_loss = 1.2613124208291993, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 231, train_loss = 1.2583609769353643, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 232, train_loss = 1.2567940162261948, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 233, train_loss = 1.2541386540979147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 234, train_loss = 1.2524840632686391, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 235, train_loss = 1.250069199129939, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 236, train_loss = 1.248336854740046, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 237, train_loss = 1.2460211409488693, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 238, train_loss = 1.2434153923531994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 239, train_loss = 1.2423568591475487, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 240, train_loss = 1.2403617507079616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 241, train_loss = 1.237456200644374, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 242, train_loss = 1.2355289062252268, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 243, train_loss = 1.2338746065506712, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 244, train_loss = 1.2321706718066707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 245, train_loss = 1.229569099843502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 246, train_loss = 1.2272158022969961, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 247, train_loss = 1.2259978260844946, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 248, train_loss = 1.2234440272441134, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 249, train_loss = 1.2217841217061505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 250, train_loss = 1.219895327463746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 251, train_loss = 1.2178871867945418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 252, train_loss = 1.215803756727837, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 253, train_loss = 1.2145099068293348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 254, train_loss = 1.2116972537478432, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 255, train_loss = 1.2108458740403876, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 256, train_loss = 1.2088633744278923, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 257, train_loss = 1.2071504214545712, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 258, train_loss = 1.2046667771646753, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 259, train_loss = 1.202898078947328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 260, train_loss = 1.2007933277636766, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 261, train_loss = 1.1997733315220103, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 262, train_loss = 1.1977870693663135, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 263, train_loss = 1.1956985829165205, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 264, train_loss = 1.194102336303331, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 265, train_loss = 1.1921786094317213, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 266, train_loss = 1.1907808376709, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 267, train_loss = 1.189008224173449, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 268, train_loss = 1.1875833123922348, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 269, train_loss = 1.1854396691778675, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 270, train_loss = 1.1842357981950045, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 271, train_loss = 1.1822044855216518, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 272, train_loss = 1.1803397480398417, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 273, train_loss = 1.1790454983711243, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 274, train_loss = 1.1775893972953781, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 275, train_loss = 1.1753145599504933, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 276, train_loss = 1.1737914873519912, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 277, train_loss = 1.1724820273229852, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 278, train_loss = 1.170630389242433, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 279, train_loss = 1.1696480313548818, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 280, train_loss = 1.1674313010880724, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 281, train_loss = 1.1660725710680708, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 282, train_loss = 1.1645151786506176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 283, train_loss = 1.1621970062842593, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 284, train_loss = 1.1613624884048477, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 285, train_loss = 1.159284332767129, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 286, train_loss = 1.1582739682635292, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 287, train_loss = 1.1561188859632239, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 288, train_loss = 1.155330159352161, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 289, train_loss = 1.1537444280693308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 290, train_loss = 1.1524198353290558, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 291, train_loss = 1.1504931753734127, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 292, train_loss = 1.1494989929487929, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 293, train_loss = 1.147568809450604, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 294, train_loss = 1.1461422269931063, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 295, train_loss = 1.144025287940167, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 296, train_loss = 1.143691223114729, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 297, train_loss = 1.1421494477544911, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 298, train_loss = 1.1403095604036935, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 299, train_loss = 1.1387224228237756, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 300, train_loss = 1.1372111265663989, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 301, train_loss = 1.136503615125548, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 302, train_loss = 1.1348597301985137, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 303, train_loss = 1.1329570623929612, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 304, train_loss = 1.1324810565565713, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 305, train_loss = 1.1307035622303374, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 306, train_loss = 1.1286081063444726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 307, train_loss = 1.1276752414996736, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 308, train_loss = 1.1256593602593057, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 309, train_loss = 1.125327990099322, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 310, train_loss = 1.1230965151335113, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 311, train_loss = 1.1224286183714867, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 312, train_loss = 1.1207591432030313, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 313, train_loss = 1.1191839004750364, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 314, train_loss = 1.118369800329674, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 315, train_loss = 1.1169027996365912, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 316, train_loss = 1.1155068408697844, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 317, train_loss = 1.1137940548360348, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 318, train_loss = 1.113011470704805, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 319, train_loss = 1.1115478581632487, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 320, train_loss = 1.110353288531769, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 321, train_loss = 1.1091068740934134, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 322, train_loss = 1.1080769151449203, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 323, train_loss = 1.1063389380578883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 324, train_loss = 1.105169375136029, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 325, train_loss = 1.1038479556445964, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 326, train_loss = 1.1024809132213704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 327, train_loss = 1.1021022833883762, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 328, train_loss = 1.1003806156222709, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 329, train_loss = 1.099345865950454, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 330, train_loss = 1.0977155703003518, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 331, train_loss = 1.097069051116705, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 332, train_loss = 1.0953714183415286, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 333, train_loss = 1.0935059425537474, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 334, train_loss = 1.0930488047306426, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 335, train_loss = 1.0921484399586916, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 336, train_loss = 1.0907250450109132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 337, train_loss = 1.0898500879411586, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 338, train_loss = 1.0881621483713388, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 339, train_loss = 1.0870336393709294, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 340, train_loss = 1.0864426114712842, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 341, train_loss = 1.0841738395392895, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 342, train_loss = 1.0834502496873029, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 343, train_loss = 1.0819038189947605, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 344, train_loss = 1.0819416511803865, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 345, train_loss = 1.0797378700226545, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 346, train_loss = 1.0791586941923015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 347, train_loss = 1.0776914258603938, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 348, train_loss = 1.076381603255868, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 349, train_loss = 1.0756279111956246, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 350, train_loss = 1.0742384288460016, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 351, train_loss = 1.0730643390561454, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 352, train_loss = 1.0721180469845422, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 353, train_loss = 1.0701606919174083, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 354, train_loss = 1.069613317027688, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 355, train_loss = 1.067864652723074, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 356, train_loss = 1.0662574761663564, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 357, train_loss = 1.0656611758167855, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 358, train_loss = 1.0645786269451492, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 359, train_loss = 1.063160514459014, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 360, train_loss = 1.0624946001917124, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 361, train_loss = 1.0608378760516644, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 362, train_loss = 1.060206022753846, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 363, train_loss = 1.0590737232123502, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 364, train_loss = 1.0576978946919553, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 365, train_loss = 1.0570124897058122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 366, train_loss = 1.0551224636728875, train_acc = 0.9977876106194691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 367, train_loss = 1.0550396361504681, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 368, train_loss = 1.0533997646416537, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 369, train_loss = 1.0522582003031857, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 370, train_loss = 1.0511880572885275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 371, train_loss = 1.050571583211422, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 372, train_loss = 1.0488683612202294, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 373, train_loss = 1.0481557585299015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 374, train_loss = 1.046973502903711, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 375, train_loss = 1.046483501791954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 376, train_loss = 1.0451138385687955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 377, train_loss = 1.0439697094261646, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 378, train_loss = 1.043328984931577, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 379, train_loss = 1.0417183333192952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 380, train_loss = 1.0407798302476294, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 381, train_loss = 1.039674950123299, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 382, train_loss = 1.0389353446662426, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 383, train_loss = 1.0380675084888935, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 384, train_loss = 1.0365611768211238, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 385, train_loss = 1.0359519862686284, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 386, train_loss = 1.0349759378586896, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 387, train_loss = 1.0331728886812925, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 388, train_loss = 1.0333285983651876, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 389, train_loss = 1.0317374747246504, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 390, train_loss = 1.0314102433621883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 391, train_loss = 1.0304855567519553, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 392, train_loss = 1.0286795416031964, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 393, train_loss = 1.0288705832208507, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 394, train_loss = 1.0269512124359608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 395, train_loss = 1.0266881355200894, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 396, train_loss = 1.0252867490053177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 397, train_loss = 1.0251371537451632, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 398, train_loss = 1.023272396356333, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 399, train_loss = 1.0226213466376066, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 400, train_loss = 1.02171766635729, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 401, train_loss = 1.0202435925602913, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 402, train_loss = 1.020098065957427, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 403, train_loss = 1.018110886856448, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 404, train_loss = 1.017954085022211, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 405, train_loss = 1.0164605714380741, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 406, train_loss = 1.0162611044943333, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 407, train_loss = 1.0149806129629724, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 408, train_loss = 1.01422045257641, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 409, train_loss = 1.0129884729976766, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 410, train_loss = 1.0120245621656068, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 411, train_loss = 1.0116288978606462, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 412, train_loss = 1.010685982182622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 413, train_loss = 1.009959356219042, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 414, train_loss = 1.0084040984511375, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 415, train_loss = 1.0082261506468058, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 416, train_loss = 1.0069522000849247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 417, train_loss = 1.0065618343651295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 418, train_loss = 1.0055735620553605, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 419, train_loss = 1.004195551679004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 420, train_loss = 1.004018746316433, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 421, train_loss = 1.0030413679778576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 422, train_loss = 1.001749315590132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 423, train_loss = 1.0016016041045077, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 424, train_loss = 1.0003175362944603, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 425, train_loss = 0.9999748710542917, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 426, train_loss = 0.9982517522876151, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 427, train_loss = 0.9980739522725344, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 428, train_loss = 0.9968414095346816, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 429, train_loss = 0.9964182346011512, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 430, train_loss = 0.9950268032844178, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 431, train_loss = 0.9942024337942712, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 432, train_loss = 0.9940649438649416, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 433, train_loss = 0.9931277657742612, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 434, train_loss = 0.9921796942944638, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 435, train_loss = 0.9913987324689515, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 436, train_loss = 0.9907015294884332, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 437, train_loss = 0.9895948357880116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 438, train_loss = 0.9895262774080038, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 439, train_loss = 0.9876564095611684, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 440, train_loss = 0.9875394621049054, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 441, train_loss = 0.9865392160718329, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 442, train_loss = 0.9858747851103544, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 443, train_loss = 0.9851372161065228, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 444, train_loss = 0.9842534922063351, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 445, train_loss = 0.9832950482959859, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 446, train_loss = 0.9832227528095245, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 447, train_loss = 0.9816313392366283, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 448, train_loss = 0.9808330635423772, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 449, train_loss = 0.9807586440001614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 450, train_loss = 0.9792485740035772, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 451, train_loss = 0.9794332670862786, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 452, train_loss = 0.9782223217189312, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 453, train_loss = 0.9774031962151639, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 454, train_loss = 0.9767308700829744, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 455, train_loss = 0.9760276172310114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 456, train_loss = 0.9752492637489922, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 457, train_loss = 0.9743259760434739, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 458, train_loss = 0.9740939631010406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 459, train_loss = 0.9728737616096623, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 460, train_loss = 0.9722108480636962, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 461, train_loss = 0.9723966034944169, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 462, train_loss = 0.9708148036152124, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 463, train_loss = 0.9703101900522597, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 464, train_loss = 0.9702773603494279, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 465, train_loss = 0.968915956094861, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 466, train_loss = 0.9685194038902409, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 467, train_loss = 0.9670541727100499, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 468, train_loss = 0.9666049021179788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 469, train_loss = 0.9661648906767368, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 470, train_loss = 0.9651507015223615, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 471, train_loss = 0.9642217407817952, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 472, train_loss = 0.9641604603384621, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 473, train_loss = 0.9637016449123621, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 474, train_loss = 0.9626968428492546, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 475, train_loss = 0.9613705147057772, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 476, train_loss = 0.9612455945461988, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 477, train_loss = 0.9600942730903625, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 478, train_loss = 0.9591762752388604, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 479, train_loss = 0.9594992634956725, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 480, train_loss = 0.9583849869668484, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 481, train_loss = 0.9577502596075647, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 482, train_loss = 0.9563946227426641, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 483, train_loss = 0.9572076710755937, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 484, train_loss = 0.9552008758182637, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 485, train_loss = 0.9550907388329506, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 486, train_loss = 0.9543667982215993, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 487, train_loss = 0.9535036223824136, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 488, train_loss = 0.9527513149078004, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 489, train_loss = 0.9529850638355128, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 490, train_loss = 0.9515044533764012, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 491, train_loss = 0.9517583915148862, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 492, train_loss = 0.9503254338051192, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 493, train_loss = 0.9498955800081603, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 494, train_loss = 0.9490551048074849, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 495, train_loss = 0.9486131966114044, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 496, train_loss = 0.9484154072706588, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 497, train_loss = 0.9476600463385694, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 498, train_loss = 0.9462383650243282, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 499, train_loss = 0.9462451481376775, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████▎                         | 19/30 [3:09:20<1:49:47, 598.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "20th- epoch: 0, train_loss = 115.24945767223835, train_acc = 0.7869119701909641\n",
      "test Acc 0.8873370577281192:\n",
      "20th- epoch: 1, train_loss = 40.71963457763195, train_acc = 0.9224499301350721\n",
      "test Acc 0.9297020484171322:\n",
      "20th- epoch: 2, train_loss = 29.916068241000175, train_acc = 0.9435258500232883\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 3, train_loss = 24.512979693710804, train_acc = 0.9535398230088495\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 4, train_loss = 20.972793359309435, train_acc = 0.9592454587796926\n",
      "test Acc 0.957169459962756:\n",
      "20th- epoch: 5, train_loss = 18.40068293735385, train_acc = 0.9634373544480671\n",
      "test Acc 0.957635009310987:\n",
      "20th- epoch: 6, train_loss = 16.41215467453003, train_acc = 0.9671634839310667\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 7, train_loss = 14.828518584370613, train_acc = 0.9703074056823474\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 8, train_loss = 13.522272355854511, train_acc = 0.9732184443409408\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 9, train_loss = 12.42068113386631, train_acc = 0.9758965999068467\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 10, train_loss = 11.492876632139087, train_acc = 0.9777596646483465\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 11, train_loss = 10.707382341846824, train_acc = 0.9795062878435026\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 12, train_loss = 10.02920113503933, train_acc = 0.9807871448532837\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 13, train_loss = 9.43733162805438, train_acc = 0.9821844434094085\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 14, train_loss = 8.909060776233673, train_acc = 0.9835817419655333\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 15, train_loss = 8.440604317933321, train_acc = 0.9842803912435957\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 16, train_loss = 8.01971984282136, train_acc = 0.9852119236143456\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 17, train_loss = 7.633984124287963, train_acc = 0.9855612482533768\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 18, train_loss = 7.280273903161287, train_acc = 0.9864927806241267\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 19, train_loss = 6.95644555427134, train_acc = 0.9871914299021891\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 20, train_loss = 6.6632536593824625, train_acc = 0.9881229622729389\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 21, train_loss = 6.39064565487206, train_acc = 0.9884722869119702\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 22, train_loss = 6.139571303501725, train_acc = 0.9890544946436889\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 23, train_loss = 5.90911459736526, train_acc = 0.989869585468095\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 24, train_loss = 5.694331703707576, train_acc = 0.990801117838845\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 25, train_loss = 5.495587058365345, train_acc = 0.9909175593851887\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 26, train_loss = 5.310429243370891, train_acc = 0.9918490917559385\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 27, train_loss = 5.139321373775601, train_acc = 0.9923148579413135\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 28, train_loss = 4.979524277150631, train_acc = 0.9926641825803446\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 29, train_loss = 4.828998958691955, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 30, train_loss = 4.690166280604899, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 31, train_loss = 4.557345037348568, train_acc = 0.9930135072193759\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 32, train_loss = 4.433416147716343, train_acc = 0.9933628318584071\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 33, train_loss = 4.31663085706532, train_acc = 0.9933628318584071\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 34, train_loss = 4.205819588154554, train_acc = 0.9937121564974383\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 35, train_loss = 4.103164347819984, train_acc = 0.9939450395901258\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 36, train_loss = 4.0054740235209465, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 37, train_loss = 3.9116416797041893, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 38, train_loss = 3.8242101073265076, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 39, train_loss = 3.7407862273976207, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 40, train_loss = 3.6616660496219993, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 41, train_loss = 3.585483360104263, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 42, train_loss = 3.513627165928483, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 43, train_loss = 3.445112065412104, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 44, train_loss = 3.379363506101072, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 45, train_loss = 3.316831153817475, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 46, train_loss = 3.2577356565743685, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 47, train_loss = 3.199135855771601, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 48, train_loss = 3.145173286087811, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 49, train_loss = 3.0904231192544103, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 50, train_loss = 3.04027855116874, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 51, train_loss = 2.990862120408565, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 52, train_loss = 2.942680013831705, train_acc = 0.9958081043316255\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 53, train_loss = 2.8984369109384716, train_acc = 0.9961574289706567\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 54, train_loss = 2.8544514179229736, train_acc = 0.9961574289706567\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 55, train_loss = 2.811475066933781, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 56, train_loss = 2.76945561170578, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 57, train_loss = 2.730896299239248, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 58, train_loss = 2.6924476139247417, train_acc = 0.9963903120633442\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 59, train_loss = 2.6553220986388624, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 60, train_loss = 2.6203028061427176, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 61, train_loss = 2.5854200259782374, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 62, train_loss = 2.5530289844609797, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 63, train_loss = 2.51940626045689, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 64, train_loss = 2.4889684966765344, train_acc = 0.996506753609688\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 65, train_loss = 2.4584737070836127, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 66, train_loss = 2.4288130961358547, train_acc = 0.9966231951560317\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 67, train_loss = 2.4008261510170996, train_acc = 0.9966231951560317\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 68, train_loss = 2.3725282386876643, train_acc = 0.9966231951560317\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 69, train_loss = 2.3448872515000403, train_acc = 0.9966231951560317\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 70, train_loss = 2.3187421350739896, train_acc = 0.9966231951560317\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 71, train_loss = 2.2936649709008634, train_acc = 0.996506753609688\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 72, train_loss = 2.2698523425497115, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 73, train_loss = 2.246001528110355, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 74, train_loss = 2.2234794250689447, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 75, train_loss = 2.2012817189097404, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 76, train_loss = 2.180620042141527, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 77, train_loss = 2.159391764551401, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 78, train_loss = 2.139933356549591, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 79, train_loss = 2.1200510836206377, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 80, train_loss = 2.101129875984043, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 81, train_loss = 2.082582503557205, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 82, train_loss = 2.065334400627762, train_acc = 0.996506753609688\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 83, train_loss = 2.0472127883695066, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 84, train_loss = 2.0307440757751465, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 85, train_loss = 2.0140173472464085, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 86, train_loss = 1.9980106898583472, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 87, train_loss = 1.982618202921003, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 88, train_loss = 1.9669393138028681, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 89, train_loss = 1.952468449715525, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 90, train_loss = 1.9373272745870054, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 91, train_loss = 1.9232000671327114, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 92, train_loss = 1.909340626327321, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 93, train_loss = 1.8958557869773358, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 94, train_loss = 1.882671520113945, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 95, train_loss = 1.8697264876682311, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 96, train_loss = 1.8574945591390133, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 97, train_loss = 1.8451861937064677, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 98, train_loss = 1.8334042292553931, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 99, train_loss = 1.8221060533542186, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 100, train_loss = 1.8101662781555206, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 101, train_loss = 1.7996277038473636, train_acc = 0.9969725197950629\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 102, train_loss = 1.7885006554424763, train_acc = 0.9969725197950629\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 103, train_loss = 1.778066658647731, train_acc = 0.9969725197950629\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 104, train_loss = 1.7679660667199641, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 105, train_loss = 1.7580480575561523, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 106, train_loss = 1.7474996570963413, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 107, train_loss = 1.7379302133340389, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 108, train_loss = 1.728480187477544, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 109, train_loss = 1.7188402090687305, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 110, train_loss = 1.7104693986475468, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 111, train_loss = 1.7008375253062695, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 112, train_loss = 1.6928537848871201, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 113, train_loss = 1.6839920096099377, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 114, train_loss = 1.6761536102276295, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 115, train_loss = 1.6677878114860505, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 116, train_loss = 1.6600013163406402, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 117, train_loss = 1.6521795701701194, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 118, train_loss = 1.6443456336855888, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 119, train_loss = 1.6362571355421096, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 120, train_loss = 1.629546919139102, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 121, train_loss = 1.622309197904542, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 122, train_loss = 1.614537574350834, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 123, train_loss = 1.6079042318742722, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 124, train_loss = 1.600726380944252, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 125, train_loss = 1.5943221189081669, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 126, train_loss = 1.586672317236662, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 127, train_loss = 1.5805860497057438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 128, train_loss = 1.5741516016423702, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 129, train_loss = 1.5670957118272781, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 130, train_loss = 1.5610727306921035, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 131, train_loss = 1.5548030957579613, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 132, train_loss = 1.5493928019423038, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 133, train_loss = 1.5430773932021111, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 134, train_loss = 1.536644137231633, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 135, train_loss = 1.5310084025841206, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 136, train_loss = 1.5256089072208852, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 137, train_loss = 1.5198243856430054, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 138, train_loss = 1.514153727563098, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 139, train_loss = 1.50804681959562, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 140, train_loss = 1.5039488475304097, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 141, train_loss = 1.4976759776473045, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 142, train_loss = 1.4929910004138947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 143, train_loss = 1.4876081484835595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 144, train_loss = 1.4817685682792217, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 145, train_loss = 1.4769887949805707, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 146, train_loss = 1.4721976656001061, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 147, train_loss = 1.4673811569809914, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 148, train_loss = 1.4625722442287952, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 149, train_loss = 1.4577567242085934, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 150, train_loss = 1.4533293310087174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 151, train_loss = 1.4481996446847916, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 152, train_loss = 1.4438216488342732, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 153, train_loss = 1.438998925150372, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 154, train_loss = 1.4351504556834698, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 155, train_loss = 1.4308436053106561, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 156, train_loss = 1.4262523105135188, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 157, train_loss = 1.4220477180788293, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 158, train_loss = 1.4173510310938582, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 159, train_loss = 1.4139089323580265, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 160, train_loss = 1.4091488098492846, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 161, train_loss = 1.4055722206830978, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 162, train_loss = 1.4016728227725253, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 163, train_loss = 1.3970779353985563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 164, train_loss = 1.3938346517970785, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 165, train_loss = 1.390048393397592, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 166, train_loss = 1.3861129507422447, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 167, train_loss = 1.382285355241038, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 168, train_loss = 1.3787884352495894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 169, train_loss = 1.3744034556439146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 170, train_loss = 1.371117703616619, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 171, train_loss = 1.3674305094173178, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 172, train_loss = 1.3641802333295345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 173, train_loss = 1.3602331703295931, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 174, train_loss = 1.35719518980477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 175, train_loss = 1.353728175163269, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 176, train_loss = 1.3502814782550558, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 177, train_loss = 1.3468891493976116, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 178, train_loss = 1.3436782272765413, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 179, train_loss = 1.3400767123093829, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 180, train_loss = 1.3374392203986645, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 181, train_loss = 1.3338430747389793, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 182, train_loss = 1.3304464593529701, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 183, train_loss = 1.3277375996112823, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 184, train_loss = 1.3242133582243696, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 185, train_loss = 1.3214128278195858, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 186, train_loss = 1.3181045515229926, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 187, train_loss = 1.315224464982748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 188, train_loss = 1.3124161126324907, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 189, train_loss = 1.3095746437320486, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 190, train_loss = 1.3065363230416551, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 191, train_loss = 1.3033898608991876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 192, train_loss = 1.3009982878575101, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 193, train_loss = 1.297999927191995, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 194, train_loss = 1.295172287733294, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 195, train_loss = 1.2923931343248114, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 196, train_loss = 1.2897810166468844, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 197, train_loss = 1.2869751006364822, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 198, train_loss = 1.2841382758924738, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 199, train_loss = 1.2814141312846914, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 200, train_loss = 1.2791191836586222, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 201, train_loss = 1.2759950110921636, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 202, train_loss = 1.2735865823924541, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 203, train_loss = 1.2710784077644348, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 204, train_loss = 1.268668219447136, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 205, train_loss = 1.2661227621138096, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 206, train_loss = 1.2636742828181013, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 207, train_loss = 1.260760041535832, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 208, train_loss = 1.258108546375297, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 209, train_loss = 1.256040520966053, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 210, train_loss = 1.2539384501287714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 211, train_loss = 1.250970546156168, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 212, train_loss = 1.2486572141060606, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 213, train_loss = 1.2459798008203506, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 214, train_loss = 1.2435665428638458, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 215, train_loss = 1.2407972986111417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 216, train_loss = 1.238387526362203, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 217, train_loss = 1.2363721629371867, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 218, train_loss = 1.2336240969598293, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 219, train_loss = 1.2313577210297808, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 220, train_loss = 1.2290094929048792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 221, train_loss = 1.2264107862720266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 222, train_loss = 1.224016446620226, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 223, train_loss = 1.2223261458566412, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 224, train_loss = 1.2196226380765438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 225, train_loss = 1.2175886357435957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 226, train_loss = 1.2152933863690123, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 227, train_loss = 1.2137313783168793, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 228, train_loss = 1.211296122521162, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 229, train_loss = 1.209371980279684, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 230, train_loss = 1.2075510384747759, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 231, train_loss = 1.2052331814775243, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 232, train_loss = 1.2035061357310042, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 233, train_loss = 1.2016264522681013, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 234, train_loss = 1.1992464499780908, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 235, train_loss = 1.1971700800349936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 236, train_loss = 1.1957652382552624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 237, train_loss = 1.1932366391411051, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 238, train_loss = 1.191939422278665, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 239, train_loss = 1.189527254551649, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 240, train_loss = 1.187763569294475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 241, train_loss = 1.1856964491307735, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 242, train_loss = 1.1840915629873052, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 243, train_loss = 1.1818495715851896, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 244, train_loss = 1.180386946827639, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 245, train_loss = 1.1783160381019115, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 246, train_loss = 1.177165814966429, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 247, train_loss = 1.1748967083985917, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 248, train_loss = 1.1730123038287275, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 249, train_loss = 1.171264547854662, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 250, train_loss = 1.1693749179248698, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 251, train_loss = 1.1674436281318776, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 252, train_loss = 1.16614955291152, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 253, train_loss = 1.1641576550900936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 254, train_loss = 1.1620095185935497, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 255, train_loss = 1.1604659867589362, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 256, train_loss = 1.1591450261767022, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 257, train_loss = 1.1571090060169809, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 258, train_loss = 1.1549067609012127, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 259, train_loss = 1.1537928146426566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 260, train_loss = 1.1515519681270234, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 261, train_loss = 1.1502687918837182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 262, train_loss = 1.148967195302248, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 263, train_loss = 1.1472850094432943, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 264, train_loss = 1.1451261825859547, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 265, train_loss = 1.1442411367897876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 266, train_loss = 1.1423313307459466, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 267, train_loss = 1.1404996514320374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 268, train_loss = 1.1392526986892335, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 269, train_loss = 1.137816606729757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 270, train_loss = 1.1359662115573883, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 271, train_loss = 1.1345763243734837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 272, train_loss = 1.1333995684981346, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 273, train_loss = 1.1316660891170613, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 274, train_loss = 1.1299290396273136, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 275, train_loss = 1.1285553450579755, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 276, train_loss = 1.1270027086138725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 277, train_loss = 1.125672623515129, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 278, train_loss = 1.1239047546987422, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 279, train_loss = 1.122950537770521, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 280, train_loss = 1.1210898607969284, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 281, train_loss = 1.11991323903203, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 282, train_loss = 1.1184546227450483, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 283, train_loss = 1.1169570721685886, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 284, train_loss = 1.1153308090870269, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 285, train_loss = 1.1143149721319787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 286, train_loss = 1.1125282334978692, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 287, train_loss = 1.1114425088162534, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 288, train_loss = 1.1100218345527537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 289, train_loss = 1.108810644596815, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 290, train_loss = 1.106726364523638, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 291, train_loss = 1.1061731589143164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 292, train_loss = 1.1045147478580475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 293, train_loss = 1.1030412974650972, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 294, train_loss = 1.1015741862356663, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 295, train_loss = 1.100625158578623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 296, train_loss = 1.0990572609007359, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 297, train_loss = 1.0981341153383255, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 298, train_loss = 1.0961745877866633, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 299, train_loss = 1.095047913491726, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 300, train_loss = 1.093832179903984, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 301, train_loss = 1.0926806690986268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 302, train_loss = 1.091018685430754, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 303, train_loss = 1.0897179593448527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 304, train_loss = 1.0887170533533208, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 305, train_loss = 1.0872812718153, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 306, train_loss = 1.0858523733913898, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 307, train_loss = 1.085069466382265, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 308, train_loss = 1.083666443824768, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 309, train_loss = 1.0823334802989848, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 310, train_loss = 1.0811722911894321, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 311, train_loss = 1.080035888880957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 312, train_loss = 1.078852105885744, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 313, train_loss = 1.0770477664773352, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 314, train_loss = 1.0762471084599383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 315, train_loss = 1.0756807041470893, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 316, train_loss = 1.073488028079737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 317, train_loss = 1.0726333099300973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 318, train_loss = 1.0713095242972486, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 319, train_loss = 1.070208712189924, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 320, train_loss = 1.068993887573015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 321, train_loss = 1.0681012235581875, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 322, train_loss = 1.0666680857539177, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 323, train_loss = 1.0655444500152953, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 324, train_loss = 1.0647154549951665, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 325, train_loss = 1.0636315469746478, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 326, train_loss = 1.0621196180582047, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 327, train_loss = 1.0609239141340367, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 328, train_loss = 1.060579506040085, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 329, train_loss = 1.0589316946570762, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 330, train_loss = 1.0575531621580012, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 331, train_loss = 1.0566976554691792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 332, train_loss = 1.0557121634483337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 333, train_loss = 1.0547624863684177, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 334, train_loss = 1.0533330825273879, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 335, train_loss = 1.0523986431653611, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 336, train_loss = 1.051510814577341, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 337, train_loss = 1.0500980516080745, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 338, train_loss = 1.0491397716104984, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 339, train_loss = 1.0480455321376212, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 340, train_loss = 1.0471370940213092, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 341, train_loss = 1.046317494183313, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 342, train_loss = 1.0451589934527874, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 343, train_loss = 1.0440557226538658, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 344, train_loss = 1.0429027192294598, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 345, train_loss = 1.0418737108702771, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 346, train_loss = 1.0409931701724418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 347, train_loss = 1.0405575831537135, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 348, train_loss = 1.039166059345007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 349, train_loss = 1.0381436794996262, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 350, train_loss = 1.0369277149438858, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 351, train_loss = 1.0360713116824627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 352, train_loss = 1.0348661194439046, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 353, train_loss = 1.0346470425720327, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 354, train_loss = 1.0333897794480436, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 355, train_loss = 1.0320834505255334, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 356, train_loss = 1.0318621098995209, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 357, train_loss = 1.0306242381338961, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 358, train_loss = 1.0295379646122456, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 359, train_loss = 1.0286677293479443, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 360, train_loss = 1.027454988390673, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 361, train_loss = 1.0271411227877252, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 362, train_loss = 1.025854878127575, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 363, train_loss = 1.0248525838251226, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 364, train_loss = 1.024256696284283, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 365, train_loss = 1.0228442872758023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 366, train_loss = 1.0222908208961599, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 367, train_loss = 1.021250817924738, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 368, train_loss = 1.0204770900309086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 369, train_loss = 1.0198153667151928, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 370, train_loss = 1.0189218285377137, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 371, train_loss = 1.017832839221228, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 372, train_loss = 1.0166849456727505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 373, train_loss = 1.0163638927042484, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 374, train_loss = 1.015044103085529, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 375, train_loss = 1.0147899563307874, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 376, train_loss = 1.0132057145237923, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 377, train_loss = 1.0126891384716146, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 378, train_loss = 1.0124488336150534, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 379, train_loss = 1.0111717146937735, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 380, train_loss = 1.010554461448919, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 381, train_loss = 1.0089293134515174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 382, train_loss = 1.0088497114484198, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 383, train_loss = 1.0078453632886522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 384, train_loss = 1.0068949088454247, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 385, train_loss = 1.0059891802375205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 386, train_loss = 1.0051943113503512, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 387, train_loss = 1.0040092977287713, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 388, train_loss = 1.0034811744990293, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 389, train_loss = 1.0025334817764815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 390, train_loss = 1.0019391899404582, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 391, train_loss = 1.0013459449110087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 392, train_loss = 1.0007047342660371, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 393, train_loss = 0.9995904291572515, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 394, train_loss = 0.9988036453723907, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 395, train_loss = 0.9976705511508044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 396, train_loss = 0.9974147391912993, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 397, train_loss = 0.9960807735624257, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 398, train_loss = 0.9957355360093061, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 399, train_loss = 0.9945084154605865, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 400, train_loss = 0.9943138708767947, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 401, train_loss = 0.9933592453598976, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 402, train_loss = 0.9920370752515737, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 403, train_loss = 0.9920667596161366, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 404, train_loss = 0.9912418512103613, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 405, train_loss = 0.990351714193821, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 406, train_loss = 0.9895044242439326, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 407, train_loss = 0.9885776514711324, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 408, train_loss = 0.9880231581628323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 409, train_loss = 0.9869521049258765, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 410, train_loss = 0.9864288816752378, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 411, train_loss = 0.9854343434271868, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 412, train_loss = 0.9850252196192741, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 413, train_loss = 0.9841816611588001, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 414, train_loss = 0.9833688363432884, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 415, train_loss = 0.9831740160880145, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 416, train_loss = 0.9820295609533787, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 417, train_loss = 0.9811276396212634, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 418, train_loss = 0.9804812011716422, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 419, train_loss = 0.9798408721981104, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 420, train_loss = 0.9793379195034504, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 421, train_loss = 0.9785450734198093, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 422, train_loss = 0.9776712780294474, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 423, train_loss = 0.9769493527710438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 424, train_loss = 0.9759840791521128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 425, train_loss = 0.975267523288494, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 426, train_loss = 0.9747116404178087, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 427, train_loss = 0.9738236802222673, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 428, train_loss = 0.9738311544060707, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 429, train_loss = 0.9727074007096235, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 430, train_loss = 0.9712890734372195, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 431, train_loss = 0.971580939978594, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 432, train_loss = 0.9706622970697936, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 433, train_loss = 0.9697695809009019, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 434, train_loss = 0.9691642435791437, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 435, train_loss = 0.9690282493829727, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 436, train_loss = 0.9674668634834234, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 437, train_loss = 0.9673015897569712, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 438, train_loss = 0.9665704766812269, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 439, train_loss = 0.9657436646521091, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 440, train_loss = 0.9655830475094263, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 441, train_loss = 0.9646474085748196, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 442, train_loss = 0.9641818155942019, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 443, train_loss = 0.9631449741718825, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 444, train_loss = 0.9628140032291412, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 445, train_loss = 0.9617545455694199, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 446, train_loss = 0.9610919716360513, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 447, train_loss = 0.961032393068308, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 448, train_loss = 0.9603504178521689, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 449, train_loss = 0.959283539414173, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 450, train_loss = 0.9584721090795938, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 451, train_loss = 0.9579986048338469, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 452, train_loss = 0.9578472711145878, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 453, train_loss = 0.957017756998539, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 454, train_loss = 0.9566565938293934, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 455, train_loss = 0.9557338754239026, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 456, train_loss = 0.9550252792832907, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 457, train_loss = 0.9542873638274614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 458, train_loss = 0.9538422400655691, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 459, train_loss = 0.9531325064599514, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 460, train_loss = 0.9527749468979891, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 461, train_loss = 0.9521043288114015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 462, train_loss = 0.9515879241225775, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 463, train_loss = 0.950880945980316, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 464, train_loss = 0.9502482737007085, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 465, train_loss = 0.9492173604667187, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 466, train_loss = 0.9493860825896263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 467, train_loss = 0.9487260381283704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 468, train_loss = 0.9482639419438783, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 469, train_loss = 0.9467690239252988, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 470, train_loss = 0.9462422927317675, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 471, train_loss = 0.9464278233645018, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 472, train_loss = 0.9454224544169847, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 473, train_loss = 0.9448021575808525, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 474, train_loss = 0.9440266291203443, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 475, train_loss = 0.9435852679016534, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 476, train_loss = 0.9431657803652342, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 477, train_loss = 0.9426019191741943, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 478, train_loss = 0.941945243626833, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 479, train_loss = 0.9411306666734163, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 480, train_loss = 0.9410845525562763, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 481, train_loss = 0.9400139674544334, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 482, train_loss = 0.9398157075047493, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 483, train_loss = 0.9394670327601489, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 484, train_loss = 0.9383338069019374, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 485, train_loss = 0.9381898256542627, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 486, train_loss = 0.93721273043775, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 487, train_loss = 0.9373499900102615, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 488, train_loss = 0.9364658792910632, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 489, train_loss = 0.9355211642978247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 490, train_loss = 0.9350483516755048, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 491, train_loss = 0.9349213006498758, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 492, train_loss = 0.9337613557872828, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 493, train_loss = 0.9333896140160505, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 494, train_loss = 0.9335794573125895, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 495, train_loss = 0.9325581552984659, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 496, train_loss = 0.9317115222511347, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 497, train_loss = 0.9312774737772997, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 498, train_loss = 0.9310159906744957, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 499, train_loss = 0.930303263157839, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████▋                       | 20/30 [3:19:20<1:39:50, 599.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "21th- epoch: 0, train_loss = 139.0367359444499, train_acc = 0.7524452724732185\n",
      "test Acc 0.8794227188081937:\n",
      "21th- epoch: 1, train_loss = 44.29526772350073, train_acc = 0.9105728924080112\n",
      "test Acc 0.9180633147113594:\n",
      "21th- epoch: 2, train_loss = 31.85752570256591, train_acc = 0.9381695388914765\n",
      "test Acc 0.9269087523277467:\n",
      "21th- epoch: 3, train_loss = 25.609631817787886, train_acc = 0.9493479273404751\n",
      "test Acc 0.9366852886405959:\n",
      "21th- epoch: 4, train_loss = 21.668907333165407, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 5, train_loss = 18.82619269937277, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 6, train_loss = 16.653769241645932, train_acc = 0.9676292501164415\n",
      "test Acc 0.9553072625698324:\n",
      "21th- epoch: 7, train_loss = 14.94860690459609, train_acc = 0.9715882626921285\n",
      "test Acc 0.9567039106145251:\n",
      "21th- epoch: 8, train_loss = 13.564920218661427, train_acc = 0.9741499767116907\n",
      "test Acc 0.9608938547486033:\n",
      "21th- epoch: 9, train_loss = 12.409919273108244, train_acc = 0.9769445738239404\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 10, train_loss = 11.432755999267101, train_acc = 0.9786911970190965\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 11, train_loss = 10.603069027885795, train_acc = 0.9807871448532837\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 12, train_loss = 9.889084466733038, train_acc = 0.9818351187703773\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 13, train_loss = 9.26107710506767, train_acc = 0.9831159757801584\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 14, train_loss = 8.708129291422665, train_acc = 0.9840475081509082\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 15, train_loss = 8.216381874866784, train_acc = 0.9843968327899395\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 16, train_loss = 7.776263780891895, train_acc = 0.9852119236143456\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 17, train_loss = 7.379418122582138, train_acc = 0.9855612482533768\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 18, train_loss = 7.026284788735211, train_acc = 0.9866092221704704\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 19, train_loss = 6.708180322311819, train_acc = 0.9876571960875641\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 20, train_loss = 6.42133214045316, train_acc = 0.9885887284583139\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 21, train_loss = 6.159522652626038, train_acc = 0.9892873777363763\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 22, train_loss = 5.919372316449881, train_acc = 0.9896367023754076\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 23, train_loss = 5.701875510625541, train_acc = 0.9904517931998137\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 24, train_loss = 5.500249277800322, train_acc = 0.9912668840242198\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 25, train_loss = 5.316945267375559, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 26, train_loss = 5.144251658115536, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 27, train_loss = 4.9837242676876485, train_acc = 0.9924312994876572\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 28, train_loss = 4.836188749875873, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 29, train_loss = 4.697498969733715, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 30, train_loss = 4.567466739565134, train_acc = 0.9931299487657196\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 31, train_loss = 4.447827947791666, train_acc = 0.9932463903120633\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 32, train_loss = 4.333702198695391, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 33, train_loss = 4.226933844387531, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 34, train_loss = 4.1250669485889375, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 35, train_loss = 4.031881536822766, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 36, train_loss = 3.9422366791404784, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 37, train_loss = 3.8576270192861557, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 38, train_loss = 3.777300640940666, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 39, train_loss = 3.701275071594864, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "21th- epoch: 40, train_loss = 3.6275789639912546, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 41, train_loss = 3.5576068782247603, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 42, train_loss = 3.4935132251121104, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 43, train_loss = 3.431049683596939, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 44, train_loss = 3.3712572255171835, train_acc = 0.9945272473218444\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 45, train_loss = 3.315342281013727, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 46, train_loss = 3.260220570024103, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 47, train_loss = 3.207134781870991, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 48, train_loss = 3.156529714819044, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 49, train_loss = 3.1077827140688896, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 50, train_loss = 3.0617985613644123, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 51, train_loss = 3.0168156302534044, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 52, train_loss = 2.9732592068612576, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 53, train_loss = 2.930796814383939, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 54, train_loss = 2.891609185608104, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 55, train_loss = 2.851933791069314, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 56, train_loss = 2.815157849341631, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 57, train_loss = 2.7782535168807954, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 58, train_loss = 2.7443443599622697, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 59, train_loss = 2.7105202439706773, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 60, train_loss = 2.677720973966643, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 61, train_loss = 2.6449604891240597, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 62, train_loss = 2.615855287760496, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 63, train_loss = 2.586828328669071, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 64, train_loss = 2.5568008348345757, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 65, train_loss = 2.5295745220500976, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 66, train_loss = 2.501850911648944, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 67, train_loss = 2.4756616938393563, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 68, train_loss = 2.451191559433937, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 69, train_loss = 2.4260451134759933, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 70, train_loss = 2.4017892132978886, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 71, train_loss = 2.3782081629615277, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 72, train_loss = 2.3544096264522523, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 73, train_loss = 2.3331276439130306, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 74, train_loss = 2.311679147183895, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 75, train_loss = 2.289621548028663, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 76, train_loss = 2.269968695938587, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 77, train_loss = 2.249705396592617, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 78, train_loss = 2.230311430990696, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 79, train_loss = 2.2115827451925725, train_acc = 0.9963903120633442\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 80, train_loss = 2.1928208221215755, train_acc = 0.9963903120633442\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 81, train_loss = 2.1750773128587753, train_acc = 0.9963903120633442\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 82, train_loss = 2.1574867095332593, train_acc = 0.9963903120633442\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 83, train_loss = 2.139783203601837, train_acc = 0.9963903120633442\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 84, train_loss = 2.123226337134838, train_acc = 0.9963903120633442\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 85, train_loss = 2.1069256078917533, train_acc = 0.996506753609688\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 86, train_loss = 2.0907550640404224, train_acc = 0.996506753609688\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 87, train_loss = 2.075230586109683, train_acc = 0.996506753609688\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 88, train_loss = 2.059827757300809, train_acc = 0.996506753609688\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 89, train_loss = 2.0439935848116875, train_acc = 0.996506753609688\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 90, train_loss = 2.029290620237589, train_acc = 0.996506753609688\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 91, train_loss = 2.014589749276638, train_acc = 0.996506753609688\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 92, train_loss = 2.001276910305023, train_acc = 0.996506753609688\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 93, train_loss = 1.9865958951413631, train_acc = 0.996506753609688\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 94, train_loss = 1.9733183283824474, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 95, train_loss = 1.9606537234503776, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 96, train_loss = 1.947842925786972, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 97, train_loss = 1.9362048271577805, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 98, train_loss = 1.923299976857379, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 99, train_loss = 1.911894804565236, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 100, train_loss = 1.900475449860096, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 101, train_loss = 1.8884890775661916, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 102, train_loss = 1.8769494805019349, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 103, train_loss = 1.8664472524542361, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 104, train_loss = 1.8555616165976971, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 105, train_loss = 1.8455407458823174, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 106, train_loss = 1.8351228248793632, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 107, train_loss = 1.8244551543612033, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 108, train_loss = 1.8149199783802032, train_acc = 0.9966231951560317\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 109, train_loss = 1.8046606481075287, train_acc = 0.996506753609688\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 110, train_loss = 1.7954773816745728, train_acc = 0.9966231951560317\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 111, train_loss = 1.7859534036833793, train_acc = 0.996506753609688\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 112, train_loss = 1.7771322939079255, train_acc = 0.9966231951560317\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 113, train_loss = 1.7682000051718205, train_acc = 0.9967396367023754\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 114, train_loss = 1.758687175810337, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 115, train_loss = 1.7507175344508141, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 116, train_loss = 1.7416218731086701, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 117, train_loss = 1.7335125382523984, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 118, train_loss = 1.7249112066347152, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 119, train_loss = 1.717560026794672, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 120, train_loss = 1.7089032642543316, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 121, train_loss = 1.700607261271216, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 122, train_loss = 1.6932158706476912, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 123, train_loss = 1.6854745534947142, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 124, train_loss = 1.6781596293440089, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 125, train_loss = 1.6702025892445818, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 126, train_loss = 1.6635149518260732, train_acc = 0.9969725197950629\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 127, train_loss = 1.6559029979398474, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 128, train_loss = 1.6487790122628212, train_acc = 0.9969725197950629\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 129, train_loss = 1.6418541632592678, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 130, train_loss = 1.6347030339529738, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 131, train_loss = 1.628339340328239, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 132, train_loss = 1.6209215136477724, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 133, train_loss = 1.6149710515746847, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 134, train_loss = 1.6077589467167854, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 135, train_loss = 1.6023093946278095, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 136, train_loss = 1.595626244903542, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 137, train_loss = 1.5905014822492376, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 138, train_loss = 1.5836977498838678, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 139, train_loss = 1.5774756856262684, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 140, train_loss = 1.5715288954088464, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 141, train_loss = 1.5663691759109497, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 142, train_loss = 1.560031751752831, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 143, train_loss = 1.555368953733705, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 144, train_loss = 1.548669133335352, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 145, train_loss = 1.5437512969365343, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 146, train_loss = 1.5383742563426495, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 147, train_loss = 1.5335645253071561, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 148, train_loss = 1.5272890975465998, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 149, train_loss = 1.5228893905878067, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 150, train_loss = 1.517749579041265, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 151, train_loss = 1.5128928931662813, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 152, train_loss = 1.5082593919942155, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 153, train_loss = 1.5030267536640167, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 154, train_loss = 1.4976115772733465, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 155, train_loss = 1.493725604028441, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 156, train_loss = 1.4886647363891825, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 157, train_loss = 1.4840142478933558, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 158, train_loss = 1.4794182479381561, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 159, train_loss = 1.4748169953236356, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 160, train_loss = 1.4705150773515925, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 161, train_loss = 1.46623110154178, train_acc = 0.9970889613414066\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 162, train_loss = 1.4619499383261427, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 163, train_loss = 1.457657097489573, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 164, train_loss = 1.453216128051281, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 165, train_loss = 1.4492941871285439, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 166, train_loss = 1.4444701621541753, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 167, train_loss = 1.4407503431430086, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 168, train_loss = 1.436943362117745, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 169, train_loss = 1.4326374182710424, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 170, train_loss = 1.4288712131092325, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 171, train_loss = 1.42489540821407, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 172, train_loss = 1.4212012389907613, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 173, train_loss = 1.4174527252325788, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 174, train_loss = 1.4136491132667288, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 175, train_loss = 1.4094558110227808, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 176, train_loss = 1.406182762235403, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 177, train_loss = 1.4025430493056774, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 178, train_loss = 1.398441482335329, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 179, train_loss = 1.394786505610682, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 180, train_loss = 1.3911562947323546, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 181, train_loss = 1.3882306417217478, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 182, train_loss = 1.383490956039168, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 183, train_loss = 1.3810797581681982, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 184, train_loss = 1.377171877771616, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 185, train_loss = 1.3740034736692905, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 186, train_loss = 1.3709008818259463, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 187, train_loss = 1.3676967857172713, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 188, train_loss = 1.364674144773744, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 189, train_loss = 1.3612172566354275, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 190, train_loss = 1.357378842891194, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 191, train_loss = 1.3554488582303748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 192, train_loss = 1.3518793856492266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 193, train_loss = 1.3487491123378277, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 194, train_loss = 1.3456157991895452, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 195, train_loss = 1.3428532356629148, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 196, train_loss = 1.33975113555789, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 197, train_loss = 1.3367409544298425, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 198, train_loss = 1.3336794214555994, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 199, train_loss = 1.3308199681341648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 200, train_loss = 1.3277699003228918, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 201, train_loss = 1.3249541657278314, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 202, train_loss = 1.3225721282651648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 203, train_loss = 1.3197995660593733, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 204, train_loss = 1.3168288493761793, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 205, train_loss = 1.314744203002192, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 206, train_loss = 1.3111125541618094, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 207, train_loss = 1.309003435075283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 208, train_loss = 1.3055813635583036, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 209, train_loss = 1.3034663498401642, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 210, train_loss = 1.3006157490308397, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 211, train_loss = 1.2977660435135476, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 212, train_loss = 1.2959941389854066, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 213, train_loss = 1.2932911950047128, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 214, train_loss = 1.2905517903272994, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 215, train_loss = 1.2878200386767276, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 216, train_loss = 1.284692534536589, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 217, train_loss = 1.2828895598649979, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 218, train_loss = 1.2808110142941587, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 219, train_loss = 1.2777752950787544, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 220, train_loss = 1.275747346400749, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 221, train_loss = 1.273087517649401, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 222, train_loss = 1.2709169052541256, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 223, train_loss = 1.2688736828858964, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 224, train_loss = 1.2660465960507281, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 225, train_loss = 1.2639687334303744, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 226, train_loss = 1.2614648279850371, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 227, train_loss = 1.2598201123182662, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 228, train_loss = 1.256824292242527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 229, train_loss = 1.255038661241997, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 230, train_loss = 1.2530610275571235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 231, train_loss = 1.2500820122659206, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 232, train_loss = 1.248530849814415, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 233, train_loss = 1.2465503364801407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 234, train_loss = 1.24362414580537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 235, train_loss = 1.242197334766388, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 236, train_loss = 1.2399897922878154, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 237, train_loss = 1.2375248323078267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 238, train_loss = 1.2355707374517806, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 239, train_loss = 1.2334595297579654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 240, train_loss = 1.2316942351753823, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 241, train_loss = 1.2294625602662563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 242, train_loss = 1.228055950254202, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 243, train_loss = 1.2258522771298885, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 244, train_loss = 1.223357071459759, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 245, train_loss = 1.22176293033408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 246, train_loss = 1.2195545907015912, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 247, train_loss = 1.217783908068668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 248, train_loss = 1.2156496358220465, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 249, train_loss = 1.2142665746505372, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 250, train_loss = 1.2119285141234286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 251, train_loss = 1.2100750207901, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 252, train_loss = 1.2082638417487033, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 253, train_loss = 1.2065362657303922, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 254, train_loss = 1.2044203343684785, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 255, train_loss = 1.2025087314541452, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 256, train_loss = 1.2004319690167904, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 257, train_loss = 1.1991536989808083, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 258, train_loss = 1.1969060872797854, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 259, train_loss = 1.1952150029246695, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 260, train_loss = 1.1934762609307654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 261, train_loss = 1.191371740133036, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 262, train_loss = 1.1900764095480554, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 263, train_loss = 1.1875593128497712, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 264, train_loss = 1.1864556309883483, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 265, train_loss = 1.1842078653280623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 266, train_loss = 1.1827761245076545, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 267, train_loss = 1.180963285267353, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 268, train_loss = 1.17934062454151, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 269, train_loss = 1.1773496866226196, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 270, train_loss = 1.1758583560585976, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 271, train_loss = 1.1741035357117653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 272, train_loss = 1.1725124840741046, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 273, train_loss = 1.1711447052657604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 274, train_loss = 1.1687324792146683, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 275, train_loss = 1.167765747755766, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 276, train_loss = 1.1663707929546945, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 277, train_loss = 1.1642165717785247, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 278, train_loss = 1.1628432000870816, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 279, train_loss = 1.1612008449737914, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 280, train_loss = 1.159706701815594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 281, train_loss = 1.1574923507869244, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 282, train_loss = 1.156783523678314, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 283, train_loss = 1.154333992570173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 284, train_loss = 1.1532161149079911, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 285, train_loss = 1.151641181379091, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 286, train_loss = 1.1501632568542846, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 287, train_loss = 1.1487685504253022, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 288, train_loss = 1.1471350006759167, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 289, train_loss = 1.1457128611509688, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 290, train_loss = 1.1441115103662014, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 291, train_loss = 1.142665334045887, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 292, train_loss = 1.1412162370979786, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 293, train_loss = 1.1395421363413334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 294, train_loss = 1.1381687211687677, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 295, train_loss = 1.1363172382116318, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 296, train_loss = 1.1352534480392933, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 297, train_loss = 1.1336969273979776, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 298, train_loss = 1.131807167083025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 299, train_loss = 1.1311411361093633, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 300, train_loss = 1.1289659067988396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 301, train_loss = 1.127701302350033, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 302, train_loss = 1.1268185004591942, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 303, train_loss = 1.1248694024980068, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 304, train_loss = 1.1233379009063356, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 305, train_loss = 1.1218421843950637, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 306, train_loss = 1.1206295627052896, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 307, train_loss = 1.1189945414662361, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 308, train_loss = 1.1172569381888025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 309, train_loss = 1.1159152947366238, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 310, train_loss = 1.114858588844072, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 311, train_loss = 1.1134933928842656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 312, train_loss = 1.111767329275608, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 313, train_loss = 1.1106058023869991, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 314, train_loss = 1.1093927013571374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 315, train_loss = 1.1077865275437944, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 316, train_loss = 1.106347467750311, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 317, train_loss = 1.1051866288180463, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 318, train_loss = 1.1040775080327876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 319, train_loss = 1.1024192522163503, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 320, train_loss = 1.101530808955431, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 321, train_loss = 1.1001207306981087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 322, train_loss = 1.098889182030689, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 323, train_loss = 1.0977627436514013, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 324, train_loss = 1.096410732716322, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 325, train_loss = 1.0945176035165787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 326, train_loss = 1.0942963299457915, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 327, train_loss = 1.0930000146036036, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 328, train_loss = 1.0917611941695213, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 329, train_loss = 1.089951477944851, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 330, train_loss = 1.0893233108217828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 331, train_loss = 1.0877263322472572, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 332, train_loss = 1.086828537285328, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 333, train_loss = 1.0856386398081668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 334, train_loss = 1.0842884021694772, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 335, train_loss = 1.0836701306398027, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 336, train_loss = 1.0817126954789273, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 337, train_loss = 1.0808975026011467, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 338, train_loss = 1.0800149515271187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 339, train_loss = 1.0785415234859101, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 340, train_loss = 1.0776722679729573, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 341, train_loss = 1.0762434738571756, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 342, train_loss = 1.07531182342791, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 343, train_loss = 1.0744987651705742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 344, train_loss = 1.0728410507144872, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 345, train_loss = 1.0723896088602487, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 346, train_loss = 1.0706828820111696, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 347, train_loss = 1.0698568137886468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 348, train_loss = 1.068890710681444, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 349, train_loss = 1.067803017795086, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 350, train_loss = 1.0664847530424595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 351, train_loss = 1.0655034855008125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 352, train_loss = 1.064385786652565, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 353, train_loss = 1.0635490591230337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 354, train_loss = 1.0621969687344972, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 355, train_loss = 1.0615030204353388, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 356, train_loss = 1.060203518718481, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 357, train_loss = 1.0588079430162907, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 358, train_loss = 1.0581961100397166, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 359, train_loss = 1.057214734464651, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 360, train_loss = 1.0561236006615218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 361, train_loss = 1.0548528966901358, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 362, train_loss = 1.0541983967123087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 363, train_loss = 1.0532707882521208, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 364, train_loss = 1.0519590601325035, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 365, train_loss = 1.0512139399943408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 366, train_loss = 1.0503882206976414, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 367, train_loss = 1.04861076301313, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 368, train_loss = 1.048180670797592, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 369, train_loss = 1.0470978766679764, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 370, train_loss = 1.0457127963600215, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 371, train_loss = 1.0446343955991324, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 372, train_loss = 1.0444553308188915, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 373, train_loss = 1.0429761645791586, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 374, train_loss = 1.0422206012008246, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 375, train_loss = 1.040926376968855, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 376, train_loss = 1.0400344605150167, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 377, train_loss = 1.0392027596535627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 378, train_loss = 1.0381385075452272, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 379, train_loss = 1.0377178887429181, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 380, train_loss = 1.0364396547374781, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 381, train_loss = 1.0354610048234463, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 382, train_loss = 1.034454695880413, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 383, train_loss = 1.0330216810107231, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 384, train_loss = 1.0328186303377151, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 385, train_loss = 1.0315825802681502, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 386, train_loss = 1.0311376228928566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 387, train_loss = 1.0299250731768552, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 388, train_loss = 1.0292287146148738, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 389, train_loss = 1.0288083851337433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 390, train_loss = 1.0272611230611801, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 391, train_loss = 1.0262774688599166, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 392, train_loss = 1.025232296437025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 393, train_loss = 1.0244942816498224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 394, train_loss = 1.0234348202648107, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 395, train_loss = 1.0225555934011936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 396, train_loss = 1.0217753586766776, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 397, train_loss = 1.0203788293001708, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 398, train_loss = 1.0197765603661537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 399, train_loss = 1.0193505150673445, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 400, train_loss = 1.0179531624016818, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 401, train_loss = 1.0168212478456553, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 402, train_loss = 1.0162289490399417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 403, train_loss = 1.0153727953729685, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 404, train_loss = 1.0146329961717129, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 405, train_loss = 1.0132754109799862, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 406, train_loss = 1.0124824506638106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 407, train_loss = 1.011769418924814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 408, train_loss = 1.0107030818762723, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 409, train_loss = 1.0103654749691486, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 410, train_loss = 1.009346471488243, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 411, train_loss = 1.0085702078940812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 412, train_loss = 1.008332313358551, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 413, train_loss = 1.007000065088505, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 414, train_loss = 1.0058374181389809, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 415, train_loss = 1.0050733449461404, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 416, train_loss = 1.0043480532767717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 417, train_loss = 1.0034329605696257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 418, train_loss = 1.0030354944465216, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 419, train_loss = 1.001697758823866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 420, train_loss = 1.0008000942470971, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 421, train_loss = 1.000453621149063, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 422, train_loss = 0.9995764158666134, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 423, train_loss = 0.9985606297850609, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 424, train_loss = 0.9979218207299709, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 425, train_loss = 0.997683197259903, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 426, train_loss = 0.9962422338721808, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 427, train_loss = 0.9959055905637797, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 428, train_loss = 0.9949457521142904, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 429, train_loss = 0.9940021609363612, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 430, train_loss = 0.9931213545205537, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 431, train_loss = 0.9925639865396079, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 432, train_loss = 0.9920570068061352, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 433, train_loss = 0.9911300527455751, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 434, train_loss = 0.9902235729095992, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 435, train_loss = 0.989728007465601, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 436, train_loss = 0.9895987647178117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 437, train_loss = 0.9882922867836896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 438, train_loss = 0.9875313242373522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 439, train_loss = 0.9866453769209329, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 440, train_loss = 0.985555467515951, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 441, train_loss = 0.9850747610034887, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 442, train_loss = 0.9849714276788291, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 443, train_loss = 0.9838721988198813, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 444, train_loss = 0.983416805654997, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 445, train_loss = 0.9821067228913307, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 446, train_loss = 0.9812493262288626, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 447, train_loss = 0.980935625731945, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 448, train_loss = 0.9801849164068699, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 449, train_loss = 0.9796226968464907, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 450, train_loss = 0.9789566012623254, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 451, train_loss = 0.978253684937954, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 452, train_loss = 0.9773648642003536, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 453, train_loss = 0.9764233244059142, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 454, train_loss = 0.9764297641813755, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 455, train_loss = 0.9752484137716237, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 456, train_loss = 0.9742981319723185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 457, train_loss = 0.9741817303001881, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 458, train_loss = 0.9733737930655479, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 459, train_loss = 0.9726676804421004, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 460, train_loss = 0.9720555506646633, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 461, train_loss = 0.9711347818374634, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 462, train_loss = 0.9702615030109882, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 463, train_loss = 0.9699934708478395, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 464, train_loss = 0.9694044254720211, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 465, train_loss = 0.9684302111563738, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 466, train_loss = 0.968181349337101, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 467, train_loss = 0.9671922214329243, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 468, train_loss = 0.9668380109069403, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 469, train_loss = 0.9657292055489961, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 470, train_loss = 0.9649848403932992, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 471, train_loss = 0.9650506936013699, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 472, train_loss = 0.9639617316424847, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 473, train_loss = 0.9632662174699362, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 474, train_loss = 0.9627689979970455, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 475, train_loss = 0.9621278196573257, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 476, train_loss = 0.9618289060890675, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 477, train_loss = 0.9606665819883347, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 478, train_loss = 0.9606808809039649, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 479, train_loss = 0.9591366325912531, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 480, train_loss = 0.9585461492242757, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 481, train_loss = 0.9588140733540058, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 482, train_loss = 0.9575375405547675, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 483, train_loss = 0.9571937558648642, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 484, train_loss = 0.9565801173448563, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 485, train_loss = 0.9557585840520915, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 486, train_loss = 0.9555847756564617, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 487, train_loss = 0.9543802663683891, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 488, train_loss = 0.954367453843588, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 489, train_loss = 0.9536732956767082, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 490, train_loss = 0.9526111992599908, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 491, train_loss = 0.9521693003771361, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 492, train_loss = 0.951433565467596, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 493, train_loss = 0.9511517857608851, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 494, train_loss = 0.9502450774016324, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 495, train_loss = 0.9502443236706313, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 496, train_loss = 0.9497878973779734, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 497, train_loss = 0.9485022289154585, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 498, train_loss = 0.948584650963312, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 499, train_loss = 0.9474422348139342, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████                     | 21/30 [3:29:20<1:29:55, 599.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "22th- epoch: 0, train_loss = 139.52416820824146, train_acc = 0.7582673497904052\n",
      "test Acc 0.8710428305400373:\n",
      "22th- epoch: 1, train_loss = 46.42191171646118, train_acc = 0.904052165812762\n",
      "test Acc 0.9129422718808193:\n",
      "22th- epoch: 2, train_loss = 33.00591354072094, train_acc = 0.9329296693060084\n",
      "test Acc 0.9259776536312849:\n",
      "22th- epoch: 3, train_loss = 26.503715604543686, train_acc = 0.9451560316721006\n",
      "test Acc 0.9366852886405959:\n",
      "22th- epoch: 4, train_loss = 22.432009052485228, train_acc = 0.9536562645551933\n",
      "test Acc 0.9450651769087524:\n",
      "22th- epoch: 5, train_loss = 19.57628185302019, train_acc = 0.9612249650675361\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 6, train_loss = 17.44956225529313, train_acc = 0.9663483931066604\n",
      "test Acc 0.9534450651769087:\n",
      "22th- epoch: 7, train_loss = 15.790536120533943, train_acc = 0.970540288775035\n",
      "test Acc 0.9543761638733705:\n",
      "22th- epoch: 8, train_loss = 14.420323222875595, train_acc = 0.9736842105263158\n",
      "test Acc 0.9557728119180633:\n",
      "22th- epoch: 9, train_loss = 13.281659804284573, train_acc = 0.9751979506287843\n",
      "test Acc 0.9567039106145251:\n",
      "22th- epoch: 10, train_loss = 12.33841123059392, train_acc = 0.9769445738239404\n",
      "test Acc 0.9594972067039106:\n",
      "22th- epoch: 11, train_loss = 11.525525480508804, train_acc = 0.9785747554727526\n",
      "test Acc 0.9604283054003724:\n",
      "22th- epoch: 12, train_loss = 10.819743182510138, train_acc = 0.9799720540288775\n",
      "test Acc 0.9608938547486033:\n",
      "22th- epoch: 13, train_loss = 10.195745266973972, train_acc = 0.9809035863996274\n",
      "test Acc 0.9613594040968343:\n",
      "22th- epoch: 14, train_loss = 9.640269212424755, train_acc = 0.9816022356776898\n",
      "test Acc 0.9622905027932961:\n",
      "22th- epoch: 15, train_loss = 9.145864583551884, train_acc = 0.9824173265020959\n",
      "test Acc 0.962756052141527:\n",
      "22th- epoch: 16, train_loss = 8.705977495759726, train_acc = 0.9833488588728458\n",
      "test Acc 0.9636871508379888:\n",
      "22th- epoch: 17, train_loss = 8.3043851274997, train_acc = 0.984163949697252\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 18, train_loss = 7.945050565525889, train_acc = 0.9852119236143456\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 19, train_loss = 7.610827682539821, train_acc = 0.9855612482533768\n",
      "test Acc 0.9646182495344506:\n",
      "22th- epoch: 20, train_loss = 7.312150698155165, train_acc = 0.9861434559850955\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 21, train_loss = 7.0345927067101, train_acc = 0.9869585468095017\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 22, train_loss = 6.7795987483114, train_acc = 0.9877736376339078\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 23, train_loss = 6.546787973493338, train_acc = 0.9882394038192828\n",
      "test Acc 0.9664804469273743:\n",
      "22th- epoch: 24, train_loss = 6.327318735420704, train_acc = 0.9885887284583139\n",
      "test Acc 0.9674115456238361:\n",
      "22th- epoch: 25, train_loss = 6.122058318927884, train_acc = 0.9889380530973452\n",
      "test Acc 0.9674115456238361:\n",
      "22th- epoch: 26, train_loss = 5.934960898011923, train_acc = 0.9890544946436889\n",
      "test Acc 0.9674115456238361:\n",
      "22th- epoch: 27, train_loss = 5.7532880287617445, train_acc = 0.98940381928272\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 28, train_loss = 5.584697589278221, train_acc = 0.9901024685607824\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 29, train_loss = 5.428118636831641, train_acc = 0.9904517931998137\n",
      "test Acc 0.9692737430167597:\n",
      "22th- epoch: 30, train_loss = 5.279177343472838, train_acc = 0.990801117838845\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 31, train_loss = 5.139457939192653, train_acc = 0.9910340009315324\n",
      "test Acc 0.9706703910614525:\n",
      "22th- epoch: 32, train_loss = 5.007808838039637, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 33, train_loss = 4.881567120552063, train_acc = 0.9913833255705635\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 34, train_loss = 4.762577595189214, train_acc = 0.9916162086632511\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 35, train_loss = 4.649777481332421, train_acc = 0.9918490917559385\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 36, train_loss = 4.541896728798747, train_acc = 0.9918490917559385\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 37, train_loss = 4.441658869385719, train_acc = 0.992081974848626\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 38, train_loss = 4.344731329008937, train_acc = 0.9925477410340009\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 39, train_loss = 4.2529893685132265, train_acc = 0.9931299487657196\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 40, train_loss = 4.165446698665619, train_acc = 0.9932463903120633\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 41, train_loss = 4.084418441168964, train_acc = 0.9933628318584071\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 42, train_loss = 4.003644723445177, train_acc = 0.9933628318584071\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 43, train_loss = 3.9281094362959266, train_acc = 0.9937121564974383\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 44, train_loss = 3.8553736275061965, train_acc = 0.9939450395901258\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 45, train_loss = 3.785736055113375, train_acc = 0.9940614811364695\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 46, train_loss = 3.719607154838741, train_acc = 0.9940614811364695\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 47, train_loss = 3.6560444831848145, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 48, train_loss = 3.5943579329177737, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 49, train_loss = 3.5359093956649303, train_acc = 0.9945272473218444\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 50, train_loss = 3.4811125239357352, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 51, train_loss = 3.4265330247581005, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 52, train_loss = 3.37430074904114, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 53, train_loss = 3.326240126043558, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 54, train_loss = 3.2780057387426496, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 55, train_loss = 3.231505782343447, train_acc = 0.9952258965999069\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 56, train_loss = 3.1872494257986546, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 57, train_loss = 3.1449337573722005, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 58, train_loss = 3.103262268938124, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 59, train_loss = 3.0629950016736984, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 60, train_loss = 3.024145352654159, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 61, train_loss = 2.986174188554287, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 62, train_loss = 2.9489158205688, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 63, train_loss = 2.913505886681378, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 64, train_loss = 2.8790428498759866, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 65, train_loss = 2.8454352160915732, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 66, train_loss = 2.8122836956754327, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 67, train_loss = 2.779463735409081, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 68, train_loss = 2.7478372119367123, train_acc = 0.9956916627852818\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 69, train_loss = 2.7185260341502726, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 70, train_loss = 2.6880271113477647, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 71, train_loss = 2.658872100058943, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 72, train_loss = 2.6309538818895817, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 73, train_loss = 2.603723455220461, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 74, train_loss = 2.5770775550045073, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 75, train_loss = 2.550878718495369, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 76, train_loss = 2.525798165705055, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 77, train_loss = 2.500954832881689, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 78, train_loss = 2.4766250401735306, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 79, train_loss = 2.452928327023983, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 80, train_loss = 2.4303057701326907, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 81, train_loss = 2.407583152409643, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 82, train_loss = 2.3849173858761787, train_acc = 0.9956916627852818\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 83, train_loss = 2.3631161064840853, train_acc = 0.9958081043316255\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 84, train_loss = 2.3425995432771742, train_acc = 0.9958081043316255\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 85, train_loss = 2.3218615031801164, train_acc = 0.9959245458779693\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 86, train_loss = 2.300845630466938, train_acc = 0.9959245458779693\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 87, train_loss = 2.281080685555935, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 88, train_loss = 2.261953549925238, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 89, train_loss = 2.2432184093631804, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 90, train_loss = 2.224069833755493, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 91, train_loss = 2.2061263881623745, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 92, train_loss = 2.188859378453344, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 93, train_loss = 2.1710651740431786, train_acc = 0.9959245458779693\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 94, train_loss = 2.1537777483463287, train_acc = 0.996040987424313\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 95, train_loss = 2.13738834252581, train_acc = 0.996040987424313\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 96, train_loss = 2.1205578483641148, train_acc = 0.996040987424313\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 97, train_loss = 2.1049467101693153, train_acc = 0.9962738705170004\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 98, train_loss = 2.0891641252674162, train_acc = 0.9962738705170004\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 99, train_loss = 2.074230416212231, train_acc = 0.9962738705170004\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 100, train_loss = 2.0597171089611948, train_acc = 0.9962738705170004\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 101, train_loss = 2.0455301254987717, train_acc = 0.9962738705170004\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 102, train_loss = 2.030660528689623, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 103, train_loss = 2.0173473856411874, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 104, train_loss = 2.003594318870455, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 105, train_loss = 1.9903163141570985, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 106, train_loss = 1.9771055304445326, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 107, train_loss = 1.9654685594141483, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 108, train_loss = 1.952728773234412, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 109, train_loss = 1.9402528565842658, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 110, train_loss = 1.9283757917582989, train_acc = 0.9963903120633442\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 111, train_loss = 1.9171532068867236, train_acc = 0.9963903120633442\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 112, train_loss = 1.9048330895602703, train_acc = 0.996506753609688\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 113, train_loss = 1.8939488183241338, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 114, train_loss = 1.8828194178640842, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 115, train_loss = 1.8722797136288136, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 116, train_loss = 1.861597879556939, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 117, train_loss = 1.8514152441639453, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 118, train_loss = 1.8411744844634086, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 119, train_loss = 1.831759825348854, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 120, train_loss = 1.8219483904540539, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 121, train_loss = 1.812278863042593, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 122, train_loss = 1.8031321614980698, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 123, train_loss = 1.7939920139033347, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 124, train_loss = 1.7846700884401798, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 125, train_loss = 1.7767824579495937, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 126, train_loss = 1.7671835024375468, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 127, train_loss = 1.7594745580572635, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 128, train_loss = 1.7506911680102348, train_acc = 0.9969725197950629\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 129, train_loss = 1.7427740718703717, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 130, train_loss = 1.734776496887207, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 131, train_loss = 1.7274857014417648, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 132, train_loss = 1.7187212482094765, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 133, train_loss = 1.7119813014287502, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 134, train_loss = 1.7035930391866714, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 135, train_loss = 1.6969863437116146, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 136, train_loss = 1.6891159240622073, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 137, train_loss = 1.6824836283922195, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 138, train_loss = 1.6750828314106911, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 139, train_loss = 1.6684872980695218, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 140, train_loss = 1.6622941121459007, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 141, train_loss = 1.6548440244514495, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 142, train_loss = 1.6480841066222638, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 143, train_loss = 1.6421254810411483, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 144, train_loss = 1.6358825638890266, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 145, train_loss = 1.6293278262019157, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 146, train_loss = 1.6234012295026332, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 147, train_loss = 1.6171724896412343, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 148, train_loss = 1.6110930442810059, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 149, train_loss = 1.6053552452940494, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 150, train_loss = 1.5995257075410336, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 151, train_loss = 1.5941373507957906, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 152, train_loss = 1.5881411533337086, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 153, train_loss = 1.5820312935393304, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 154, train_loss = 1.577406057389453, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 155, train_loss = 1.5712588031310588, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 156, train_loss = 1.5660428691189736, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 157, train_loss = 1.5607399966102093, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 158, train_loss = 1.555628564208746, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 159, train_loss = 1.5502750165760517, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 160, train_loss = 1.5454460196197033, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 161, train_loss = 1.539885665057227, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 162, train_loss = 1.5350559391081333, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 163, train_loss = 1.5302217255812138, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 164, train_loss = 1.5253244265913963, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 165, train_loss = 1.5204369437415153, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 166, train_loss = 1.5157300233840942, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 167, train_loss = 1.5106298725586385, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 168, train_loss = 1.5066266108769923, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 169, train_loss = 1.502295532496646, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 170, train_loss = 1.4973306196043268, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 171, train_loss = 1.492529321461916, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 172, train_loss = 1.4886965142795816, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 173, train_loss = 1.4840692715952173, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 174, train_loss = 1.479933480382897, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 175, train_loss = 1.4752833707025275, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 176, train_loss = 1.470914140343666, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 177, train_loss = 1.4666771764168516, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 178, train_loss = 1.462416522204876, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 179, train_loss = 1.4580170698463917, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 180, train_loss = 1.4536144621670246, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 181, train_loss = 1.4493788331747055, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 182, train_loss = 1.4459193957736716, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 183, train_loss = 1.4418379043927416, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 184, train_loss = 1.4376096738269553, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 185, train_loss = 1.4336790876695886, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 186, train_loss = 1.4297385910758749, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 187, train_loss = 1.426392407505773, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 188, train_loss = 1.4222257608780637, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 189, train_loss = 1.4186005666851997, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 190, train_loss = 1.4152432978153229, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 191, train_loss = 1.411280032247305, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 192, train_loss = 1.4076457308838144, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 193, train_loss = 1.404545901925303, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 194, train_loss = 1.401134910644032, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 195, train_loss = 1.3974072089185938, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 196, train_loss = 1.3942777129122987, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 197, train_loss = 1.3905304273357615, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 198, train_loss = 1.3875856337836012, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 199, train_loss = 1.384448523283936, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 200, train_loss = 1.380803257226944, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 201, train_loss = 1.3779895454645157, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 202, train_loss = 1.3743454379728064, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 203, train_loss = 1.3716921930899844, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 204, train_loss = 1.368555391789414, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 205, train_loss = 1.3649650911102071, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 206, train_loss = 1.362323691486381, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 207, train_loss = 1.3588810389628634, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 208, train_loss = 1.3561355756828561, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 209, train_loss = 1.353573871194385, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 210, train_loss = 1.3502710884204134, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 211, train_loss = 1.347103295265697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 212, train_loss = 1.3446692241122946, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 213, train_loss = 1.3417260808637366, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 214, train_loss = 1.3388641936471686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 215, train_loss = 1.3359908051788807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 216, train_loss = 1.3327267641434446, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 217, train_loss = 1.3307946100831032, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 218, train_loss = 1.3271124474704266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 219, train_loss = 1.3250734470784664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 220, train_loss = 1.3222170496592298, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 221, train_loss = 1.3196070604026318, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 222, train_loss = 1.317294312058948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 223, train_loss = 1.31403336673975, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 224, train_loss = 1.312054151087068, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 225, train_loss = 1.3094598638126627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 226, train_loss = 1.30656548589468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 227, train_loss = 1.3040753776440397, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 228, train_loss = 1.3013336459407583, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 229, train_loss = 1.2988699190318584, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 230, train_loss = 1.296840193332173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 231, train_loss = 1.2941338954260573, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 232, train_loss = 1.291736097424291, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 233, train_loss = 1.289132340461947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 234, train_loss = 1.2868361957371235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 235, train_loss = 1.2846711637685075, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 236, train_loss = 1.2822298543760553, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 237, train_loss = 1.2792480798671022, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 238, train_loss = 1.277804741053842, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 239, train_loss = 1.2753226794302464, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 240, train_loss = 1.2725317118456587, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 241, train_loss = 1.2706119356444106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 242, train_loss = 1.2684163389494643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 243, train_loss = 1.2660845145583153, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 244, train_loss = 1.263674775720574, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 245, train_loss = 1.2620141878724098, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 246, train_loss = 1.259523776709102, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 247, train_loss = 1.2571078030159697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 248, train_loss = 1.2555410960922018, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 249, train_loss = 1.2533003775170073, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 250, train_loss = 1.250980343669653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 251, train_loss = 1.2488965155789629, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 252, train_loss = 1.247409239411354, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 253, train_loss = 1.245307000936009, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 254, train_loss = 1.242819432169199, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 255, train_loss = 1.2408098069718108, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 256, train_loss = 1.2382950596511364, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 257, train_loss = 1.2363902106881142, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 258, train_loss = 1.2345273134997115, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 259, train_loss = 1.232297632843256, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 260, train_loss = 1.2297601228347048, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 261, train_loss = 1.2277321964502335, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 262, train_loss = 1.2253369018435478, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 263, train_loss = 1.2231354750692844, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 264, train_loss = 1.2208000594982877, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 265, train_loss = 1.2203015784616582, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 266, train_loss = 1.2173146270215511, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 267, train_loss = 1.214965246617794, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 268, train_loss = 1.213064304261934, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 269, train_loss = 1.2112514898180962, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 270, train_loss = 1.209577935456764, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 271, train_loss = 1.2071512341499329, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 272, train_loss = 1.205356674909126, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 273, train_loss = 1.203842654824257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 274, train_loss = 1.2026800128514878, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 275, train_loss = 1.2006030033226125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 276, train_loss = 1.1986536706681363, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 277, train_loss = 1.1968245816533454, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 278, train_loss = 1.1947997448151, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 279, train_loss = 1.1932653822004795, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 280, train_loss = 1.1915481761097908, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 281, train_loss = 1.1899664563243277, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 282, train_loss = 1.188213872432243, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 283, train_loss = 1.186140286445152, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 284, train_loss = 1.1845823911135085, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 285, train_loss = 1.1839134742622264, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 286, train_loss = 1.1818166337907314, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 287, train_loss = 1.1799376371200196, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 288, train_loss = 1.1778753635589965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 289, train_loss = 1.1765508241951466, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 290, train_loss = 1.1747482307255268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 291, train_loss = 1.1742519065737724, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 292, train_loss = 1.1715195402503014, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 293, train_loss = 1.1704926950042136, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 294, train_loss = 1.1688553392887115, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 295, train_loss = 1.1672530720825307, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 296, train_loss = 1.1653773399884813, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 297, train_loss = 1.1638780261273496, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 298, train_loss = 1.1624545330996625, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 299, train_loss = 1.1609785370528698, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 300, train_loss = 1.1593738198280334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 301, train_loss = 1.159057229757309, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 302, train_loss = 1.1564142939751036, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 303, train_loss = 1.1543531268835068, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 304, train_loss = 1.1536069624125957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 305, train_loss = 1.1523536394233815, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 306, train_loss = 1.1505007210071199, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 307, train_loss = 1.1487513296306133, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 308, train_loss = 1.1467898388509639, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 309, train_loss = 1.1460106559097767, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 310, train_loss = 1.14458765584277, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 311, train_loss = 1.1440382140572183, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 312, train_loss = 1.141618104011286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 313, train_loss = 1.1400548641686328, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 314, train_loss = 1.1386616292293184, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 315, train_loss = 1.1372631415724754, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 316, train_loss = 1.1367104177479632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 317, train_loss = 1.1347387209534645, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 318, train_loss = 1.1328214593231678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 319, train_loss = 1.1313331288401969, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 320, train_loss = 1.1308051000232808, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 321, train_loss = 1.1291020885109901, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 322, train_loss = 1.1274988278746605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 323, train_loss = 1.1258909341995604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 324, train_loss = 1.124751441180706, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 325, train_loss = 1.1231587429647334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 326, train_loss = 1.1217333699460141, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 327, train_loss = 1.1199107629363425, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 328, train_loss = 1.1196739971637726, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 329, train_loss = 1.1176285718684085, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 330, train_loss = 1.1164015109534375, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 331, train_loss = 1.1149309885804541, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 332, train_loss = 1.1138500508968718, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 333, train_loss = 1.1129121407866478, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 334, train_loss = 1.1113657901878469, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 335, train_loss = 1.1097728933091275, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 336, train_loss = 1.1086773984134197, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 337, train_loss = 1.1082202953402884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 338, train_loss = 1.1062184584443457, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 339, train_loss = 1.1051205818657763, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 340, train_loss = 1.1034226355259307, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 341, train_loss = 1.1022218652069569, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 342, train_loss = 1.1013600093428977, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 343, train_loss = 1.1008346043527126, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 344, train_loss = 1.0983859610860236, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 345, train_loss = 1.0975183422560804, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 346, train_loss = 1.096322959929239, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 347, train_loss = 1.095161933451891, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 348, train_loss = 1.094071148603689, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 349, train_loss = 1.093540741770994, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 350, train_loss = 1.0917921860818751, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 351, train_loss = 1.0911050525610335, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 352, train_loss = 1.0898985912208445, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 353, train_loss = 1.088219239085447, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 354, train_loss = 1.087165976583492, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 355, train_loss = 1.085970448970329, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 356, train_loss = 1.085063875943888, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 357, train_loss = 1.0837438913877122, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 358, train_loss = 1.0824964952771552, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 359, train_loss = 1.0822135719354264, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 360, train_loss = 1.0805629082024097, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 361, train_loss = 1.079410279809963, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 362, train_loss = 1.0782186488504522, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 363, train_loss = 1.0770017678732984, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 364, train_loss = 1.0768393836915493, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 365, train_loss = 1.074688584834803, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 366, train_loss = 1.0737505095894448, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 367, train_loss = 1.0728943049907684, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 368, train_loss = 1.0719402345712297, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 369, train_loss = 1.0706836481695063, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 370, train_loss = 1.0695255932514556, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 371, train_loss = 1.068985513120424, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 372, train_loss = 1.0673937375540845, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 373, train_loss = 1.0661195504362695, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 374, train_loss = 1.0655132618849166, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 375, train_loss = 1.0650665201246738, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 376, train_loss = 1.0633491426706314, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 377, train_loss = 1.0629317934508435, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 378, train_loss = 1.0609675645828247, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 379, train_loss = 1.0612957713310607, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 380, train_loss = 1.059262152761221, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 381, train_loss = 1.0582783582503907, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 382, train_loss = 1.0567967320675962, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 383, train_loss = 1.0573960120673291, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 384, train_loss = 1.0557949468493462, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 385, train_loss = 1.0546440581674688, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 386, train_loss = 1.0532079537515529, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 387, train_loss = 1.0526221208274364, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 388, train_loss = 1.051464966207277, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 389, train_loss = 1.0508325199480169, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 390, train_loss = 1.0501894255285151, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 391, train_loss = 1.0486668783123605, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 392, train_loss = 1.0486527283792384, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 393, train_loss = 1.0464816689491272, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 394, train_loss = 1.0456689397688024, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 395, train_loss = 1.0458879508078098, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 396, train_loss = 1.044169815897476, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 397, train_loss = 1.0430825886433013, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 398, train_loss = 1.0429646906559356, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 399, train_loss = 1.0415609094197862, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 400, train_loss = 1.0410814148490317, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 401, train_loss = 1.0392722698743455, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 402, train_loss = 1.0393627844750881, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 403, train_loss = 1.037399793684017, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 404, train_loss = 1.0366345557267778, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 405, train_loss = 1.036760088056326, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 406, train_loss = 1.0349472450907342, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 407, train_loss = 1.0351048558950424, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 408, train_loss = 1.0330413070623763, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 409, train_loss = 1.0323286416823976, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 410, train_loss = 1.0322002284228802, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 411, train_loss = 1.0308068593440112, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 412, train_loss = 1.0296450356545392, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 413, train_loss = 1.0296505528094713, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 414, train_loss = 1.0281277770700399, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 415, train_loss = 1.0280603840947151, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 416, train_loss = 1.0262221755983774, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 417, train_loss = 1.0261510151030961, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 418, train_loss = 1.0248466705379542, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 419, train_loss = 1.0239496367576066, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 420, train_loss = 1.023594123631483, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 421, train_loss = 1.0219546593725681, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 422, train_loss = 1.0220159789023455, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 423, train_loss = 1.0204636305570602, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 424, train_loss = 1.0195536700484809, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 425, train_loss = 1.0187910174427088, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 426, train_loss = 1.019059892743826, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 427, train_loss = 1.0171677097678185, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 428, train_loss = 1.0172065521182958, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 429, train_loss = 1.015157555550104, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 430, train_loss = 1.0153222220542375, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 431, train_loss = 1.0146086364984512, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 432, train_loss = 1.0138177523913328, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 433, train_loss = 1.0125193347630557, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 434, train_loss = 1.011457664280897, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 435, train_loss = 1.0108319918217603, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 436, train_loss = 1.0112609043717384, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 437, train_loss = 1.0090271557273809, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 438, train_loss = 1.009232621639967, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 439, train_loss = 1.0075822062790394, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 440, train_loss = 1.0076147330401, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 441, train_loss = 1.0059207367303316, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 442, train_loss = 1.0063363760709763, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 443, train_loss = 1.0048061596753541, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 444, train_loss = 1.0047062461671885, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 445, train_loss = 1.0028232298791409, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 446, train_loss = 1.0031251510081347, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 447, train_loss = 1.0018576507864054, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 448, train_loss = 1.0016488606634084, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 449, train_loss = 0.9999815411865711, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 450, train_loss = 1.0002166479825974, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 451, train_loss = 0.998688885330921, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 452, train_loss = 0.999219191580778, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 453, train_loss = 0.9968086294829845, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 454, train_loss = 0.997339623660082, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 455, train_loss = 0.9965918026864529, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 456, train_loss = 0.9946903834643308, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 457, train_loss = 0.9951169515552465, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 458, train_loss = 0.99344502389431, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 459, train_loss = 0.9936321154236794, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 460, train_loss = 0.9921486067178193, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 461, train_loss = 0.9925415379402693, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 462, train_loss = 0.99118896946311, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 463, train_loss = 0.9895198854210321, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 464, train_loss = 0.9900446596147958, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 465, train_loss = 0.988492234289879, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 466, train_loss = 0.9883203344943468, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 467, train_loss = 0.986941513925558, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 468, train_loss = 0.9872603068652097, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 469, train_loss = 0.9858471924962942, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 470, train_loss = 0.9857122525572777, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 471, train_loss = 0.983588207513094, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 472, train_loss = 0.9843903680739459, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 473, train_loss = 0.9826329126954079, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 474, train_loss = 0.9833595032396261, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 475, train_loss = 0.9809451351466123, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 476, train_loss = 0.9816671088337898, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 477, train_loss = 0.9797693329455797, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 478, train_loss = 0.9806636311113834, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 479, train_loss = 0.9784477700886782, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 480, train_loss = 0.9786509200930595, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 481, train_loss = 0.9770523173210677, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 482, train_loss = 0.9774297066032887, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 483, train_loss = 0.9757748121919576, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 484, train_loss = 0.97628023228026, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 485, train_loss = 0.9748885991575662, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 486, train_loss = 0.9749190124275628, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 487, train_loss = 0.9729290107788984, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 488, train_loss = 0.9738020226359367, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 489, train_loss = 0.9725779680011328, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 490, train_loss = 0.972025066614151, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 491, train_loss = 0.970710893481737, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 492, train_loss = 0.9710232304933015, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 493, train_loss = 0.9697360495629255, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 494, train_loss = 0.9695561701955739, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 495, train_loss = 0.9680823559465352, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 496, train_loss = 0.9682256132364273, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 497, train_loss = 0.9664794256386813, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 498, train_loss = 0.9671437852084637, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 499, train_loss = 0.9662377139029559, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████▎                  | 22/30 [3:39:20<1:19:57, 599.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "23th- epoch: 0, train_loss = 126.42875200510025, train_acc = 0.7682813227759665\n",
      "test Acc 0.8822160148975792:\n",
      "23th- epoch: 1, train_loss = 45.097257524728775, train_acc = 0.9095249184909175\n",
      "test Acc 0.9241154562383612:\n",
      "23th- epoch: 2, train_loss = 32.96508913487196, train_acc = 0.9344434094084769\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 3, train_loss = 26.755202628672123, train_acc = 0.9474848625989754\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 4, train_loss = 22.81513339281082, train_acc = 0.9556357708430367\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 5, train_loss = 19.990813095122576, train_acc = 0.9612249650675361\n",
      "test Acc 0.9529795158286778:\n",
      "23th- epoch: 6, train_loss = 17.822268068790436, train_acc = 0.9653004191895669\n",
      "test Acc 0.9590316573556797:\n",
      "23th- epoch: 7, train_loss = 16.057770159095526, train_acc = 0.9673963670237541\n",
      "test Acc 0.9632216014897579:\n",
      "23th- epoch: 8, train_loss = 14.599907293915749, train_acc = 0.9706567303213787\n",
      "test Acc 0.9636871508379888:\n",
      "23th- epoch: 9, train_loss = 13.37617340683937, train_acc = 0.9735677689799721\n",
      "test Acc 0.9660148975791434:\n",
      "23th- epoch: 10, train_loss = 12.33040600642562, train_acc = 0.975780158360503\n",
      "test Acc 0.9669459962756052:\n",
      "23th- epoch: 11, train_loss = 11.428346402943134, train_acc = 0.9778761061946902\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 12, train_loss = 10.637693081051111, train_acc = 0.97973917093619\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 13, train_loss = 9.950749855488539, train_acc = 0.9810200279459711\n",
      "test Acc 0.9697392923649907:\n",
      "23th- epoch: 14, train_loss = 9.33731184899807, train_acc = 0.9825337680484397\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 15, train_loss = 8.793410811573267, train_acc = 0.9833488588728458\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 16, train_loss = 8.308003885671496, train_acc = 0.9845132743362832\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 17, train_loss = 7.872682465240359, train_acc = 0.9849790405216581\n",
      "test Acc 0.9725325884543762:\n",
      "23th- epoch: 18, train_loss = 7.4853582587093115, train_acc = 0.9856776897997206\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 19, train_loss = 7.138724813237786, train_acc = 0.9864927806241267\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 20, train_loss = 6.824479661881924, train_acc = 0.9873078714485328\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 21, train_loss = 6.538553096354008, train_acc = 0.9878900791802515\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 22, train_loss = 6.281912276521325, train_acc = 0.9885887284583139\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 23, train_loss = 6.041329801082611, train_acc = 0.9892873777363763\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 24, train_loss = 5.824077906087041, train_acc = 0.9897531439217513\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 25, train_loss = 5.6260804031044245, train_acc = 0.9904517931998137\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 26, train_loss = 5.438527690246701, train_acc = 0.9913833255705635\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 27, train_loss = 5.267479028552771, train_acc = 0.9918490917559385\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 28, train_loss = 5.108391271904111, train_acc = 0.9921984163949698\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 29, train_loss = 4.959650693461299, train_acc = 0.9923148579413135\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 30, train_loss = 4.819359449669719, train_acc = 0.9924312994876572\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 31, train_loss = 4.689011086709797, train_acc = 0.9925477410340009\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 32, train_loss = 4.567967240698636, train_acc = 0.9928970656730322\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 33, train_loss = 4.45234015583992, train_acc = 0.9928970656730322\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 34, train_loss = 4.345145394094288, train_acc = 0.9931299487657196\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 35, train_loss = 4.240736160427332, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 36, train_loss = 4.145335454493761, train_acc = 0.9935957149510946\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 37, train_loss = 4.05000592302531, train_acc = 0.993828598043782\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 38, train_loss = 3.963089916855097, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 39, train_loss = 3.8787473822012544, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 40, train_loss = 3.7989118294790387, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 41, train_loss = 3.7227440094575286, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 42, train_loss = 3.6490247547626495, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 43, train_loss = 3.5800323029980063, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 44, train_loss = 3.5107498513534665, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 45, train_loss = 3.4481885405257344, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 46, train_loss = 3.38707694131881, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 47, train_loss = 3.329092795960605, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 48, train_loss = 3.2717080237343907, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 49, train_loss = 3.2175113558769226, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 50, train_loss = 3.165305898524821, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 51, train_loss = 3.11571095418185, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 52, train_loss = 3.066925127990544, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 53, train_loss = 3.02120860805735, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 54, train_loss = 2.9763459251262248, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 55, train_loss = 2.934703306760639, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 56, train_loss = 2.892412246670574, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 57, train_loss = 2.852279409766197, train_acc = 0.9958081043316255\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 58, train_loss = 2.8143634819425642, train_acc = 0.9958081043316255\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 59, train_loss = 2.7763062939047813, train_acc = 0.9958081043316255\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 60, train_loss = 2.7406101622618735, train_acc = 0.9958081043316255\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 61, train_loss = 2.7058180421590805, train_acc = 0.9958081043316255\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 62, train_loss = 2.6711600348353386, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 63, train_loss = 2.6387745775282383, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 64, train_loss = 2.6070328168570995, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 65, train_loss = 2.5760505660437047, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 66, train_loss = 2.547182729933411, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 67, train_loss = 2.5167946317233145, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 68, train_loss = 2.4889164329506457, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 69, train_loss = 2.461829184088856, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 70, train_loss = 2.4348336099646986, train_acc = 0.9961574289706567\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 71, train_loss = 2.4102226844988763, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 72, train_loss = 2.3842776245437562, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 73, train_loss = 2.3605116582475603, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 74, train_loss = 2.33654290670529, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 75, train_loss = 2.3137424611486495, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 76, train_loss = 2.2915904694236815, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 77, train_loss = 2.2699047066271305, train_acc = 0.9963903120633442\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 78, train_loss = 2.2481134100817144, train_acc = 0.9963903120633442\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 79, train_loss = 2.2280763327144086, train_acc = 0.9963903120633442\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 80, train_loss = 2.2077879807911813, train_acc = 0.996506753609688\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 81, train_loss = 2.1882765381596982, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 82, train_loss = 2.1697162142954767, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 83, train_loss = 2.1505194851197302, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 84, train_loss = 2.13220755988732, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 85, train_loss = 2.114173901733011, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 86, train_loss = 2.0973838954232633, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 87, train_loss = 2.0799998603761196, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 88, train_loss = 2.0631864741444588, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 89, train_loss = 2.0470677255652845, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 90, train_loss = 2.031223534140736, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 91, train_loss = 2.0159960500895977, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "23th- epoch: 92, train_loss = 2.000638415571302, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "23th- epoch: 93, train_loss = 1.9869968395214528, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "23th- epoch: 94, train_loss = 1.9728078059852123, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "23th- epoch: 95, train_loss = 1.9585435315966606, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "23th- epoch: 96, train_loss = 1.9455097366590053, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "23th- epoch: 97, train_loss = 1.9326713979244232, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 98, train_loss = 1.919837934197858, train_acc = 0.9966231951560317\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 99, train_loss = 1.9082704323809594, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 100, train_loss = 1.8953675962984562, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 101, train_loss = 1.8840549811720848, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 102, train_loss = 1.8721890300512314, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 103, train_loss = 1.861052046297118, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 104, train_loss = 1.8502857473213226, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 105, train_loss = 1.838910861639306, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 106, train_loss = 1.828516909154132, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 107, train_loss = 1.8183219495695084, train_acc = 0.9968560782487191\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 108, train_loss = 1.8081941939890385, train_acc = 0.9969725197950629\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 109, train_loss = 1.798377840546891, train_acc = 0.9969725197950629\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 110, train_loss = 1.7888109560590237, train_acc = 0.9969725197950629\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 111, train_loss = 1.7795893426518887, train_acc = 0.9969725197950629\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 112, train_loss = 1.7701782558578998, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 113, train_loss = 1.7610332407057285, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 114, train_loss = 1.7521539863664657, train_acc = 0.9969725197950629\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 115, train_loss = 1.7434864926617593, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 116, train_loss = 1.734508216381073, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 117, train_loss = 1.7261899400036782, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 118, train_loss = 1.7177419438958168, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 119, train_loss = 1.709336421219632, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 120, train_loss = 1.7011349413078278, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 121, train_loss = 1.6937085092067719, train_acc = 0.9970889613414066\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 122, train_loss = 1.6852561149280518, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 123, train_loss = 1.6774466782808304, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 124, train_loss = 1.6704926181118935, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 125, train_loss = 1.6630362893920392, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 126, train_loss = 1.6557843685150146, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 127, train_loss = 1.6487482599914074, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 128, train_loss = 1.6416080084163696, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 129, train_loss = 1.6342355634551495, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 130, train_loss = 1.6286696717143059, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 131, train_loss = 1.6213875524699688, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 132, train_loss = 1.615336460294202, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 133, train_loss = 1.6084885981399566, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 134, train_loss = 1.6023513276595622, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 135, train_loss = 1.5966422844212502, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 136, train_loss = 1.5901456836145371, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 137, train_loss = 1.5846035603899509, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 138, train_loss = 1.5786719496827573, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 139, train_loss = 1.5726691037416458, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 140, train_loss = 1.5669130806345493, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 141, train_loss = 1.5613112908322364, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 142, train_loss = 1.5562550064641982, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 143, train_loss = 1.5503463223576546, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 144, train_loss = 1.545063904253766, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 145, train_loss = 1.540206165285781, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 146, train_loss = 1.5350743632297963, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 147, train_loss = 1.529136101482436, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 148, train_loss = 1.5238012063782662, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 149, train_loss = 1.5191912837326527, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 150, train_loss = 1.5135752235073596, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 151, train_loss = 1.5088286934187636, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 152, train_loss = 1.5040850093355402, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 153, train_loss = 1.498827355564572, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 154, train_loss = 1.4946911769220605, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 155, train_loss = 1.489760865806602, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 156, train_loss = 1.4853978430619463, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 157, train_loss = 1.4811866568634287, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 158, train_loss = 1.4764967547962442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 159, train_loss = 1.47257750981953, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 160, train_loss = 1.467669416218996, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 161, train_loss = 1.4637987265596166, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 162, train_loss = 1.4594211602816358, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 163, train_loss = 1.45546653366182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 164, train_loss = 1.451321785687469, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 165, train_loss = 1.4475045265862718, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 166, train_loss = 1.4437279626727104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 167, train_loss = 1.4395171055803075, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 168, train_loss = 1.4355588778853416, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 169, train_loss = 1.4320047734072432, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 170, train_loss = 1.4279625402996317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 171, train_loss = 1.42400636151433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 172, train_loss = 1.4206710631260648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 173, train_loss = 1.417508096783422, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 174, train_loss = 1.4134032713482156, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 175, train_loss = 1.4096303036203608, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 176, train_loss = 1.4061179794371128, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 177, train_loss = 1.4029357098042965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 178, train_loss = 1.3993930108845234, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 179, train_loss = 1.3956750743091106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 180, train_loss = 1.3930196451256052, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 181, train_loss = 1.389205583720468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 182, train_loss = 1.3861279226839542, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 183, train_loss = 1.382693812251091, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 184, train_loss = 1.3795145651092753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 185, train_loss = 1.376403547823429, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 186, train_loss = 1.373267331509851, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 187, train_loss = 1.370080261141993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 188, train_loss = 1.3665026364615187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 189, train_loss = 1.3641314780106768, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 190, train_loss = 1.3607269314816222, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 191, train_loss = 1.357895360677503, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 192, train_loss = 1.3545744443545118, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 193, train_loss = 1.3514081364264712, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 194, train_loss = 1.3491905269911513, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 195, train_loss = 1.3456827191403136, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 196, train_loss = 1.3431343535194173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 197, train_loss = 1.340255156159401, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 198, train_loss = 1.3375116487732157, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 199, train_loss = 1.334363292902708, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 200, train_loss = 1.332225409685634, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 201, train_loss = 1.3290258646011353, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 202, train_loss = 1.3267414135625586, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 203, train_loss = 1.323957777232863, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 204, train_loss = 1.3211589170387015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 205, train_loss = 1.3186088800430298, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 206, train_loss = 1.3164862679550424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 207, train_loss = 1.3130826316773891, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 208, train_loss = 1.310452178120613, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 209, train_loss = 1.3083336340496317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 210, train_loss = 1.3059428358683363, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 211, train_loss = 1.3030802458524704, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 212, train_loss = 1.3009233437478542, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 213, train_loss = 1.2984612161526456, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 214, train_loss = 1.296030075638555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 215, train_loss = 1.2932858591666445, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 216, train_loss = 1.2910467697074637, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 217, train_loss = 1.28894756489899, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 218, train_loss = 1.286719380528666, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 219, train_loss = 1.2839848697185516, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 220, train_loss = 1.281726578832604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 221, train_loss = 1.2795673869550228, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 222, train_loss = 1.2771012472221628, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 223, train_loss = 1.2750479417154565, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 224, train_loss = 1.2722997615346685, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 225, train_loss = 1.270835254341364, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 226, train_loss = 1.267869575531222, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 227, train_loss = 1.266090756864287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 228, train_loss = 1.2638337487587705, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 229, train_loss = 1.261784490197897, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 230, train_loss = 1.2598363856086507, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 231, train_loss = 1.2574360718717799, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 232, train_loss = 1.2555528009543195, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 233, train_loss = 1.253299860865809, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 234, train_loss = 1.2515736682107672, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 235, train_loss = 1.2487084083259106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 236, train_loss = 1.2474731927504763, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 237, train_loss = 1.2454374941298738, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 238, train_loss = 1.2433161014923826, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 239, train_loss = 1.241348127485253, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 240, train_loss = 1.2390305139124393, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 241, train_loss = 1.2373340452322736, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 242, train_loss = 1.2348888566484675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 243, train_loss = 1.2330457320204005, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 244, train_loss = 1.2313199365744367, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 245, train_loss = 1.2293638127157465, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 246, train_loss = 1.2271802015602589, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 247, train_loss = 1.2254631171235815, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 248, train_loss = 1.2237557582557201, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 249, train_loss = 1.2214338791673072, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 250, train_loss = 1.220095870376099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 251, train_loss = 1.2178578053717501, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 252, train_loss = 1.2160167209804058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 253, train_loss = 1.2141193449497223, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 254, train_loss = 1.2129709161818027, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 255, train_loss = 1.2106668117339723, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 256, train_loss = 1.2087872375850566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 257, train_loss = 1.2071248702704906, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 258, train_loss = 1.2053703765268438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 259, train_loss = 1.2037262308294885, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 260, train_loss = 1.2022053326363675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 261, train_loss = 1.1999687564675696, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 262, train_loss = 1.1984218533034436, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 263, train_loss = 1.1969626906211488, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 264, train_loss = 1.194856232672464, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 265, train_loss = 1.1936277101631276, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 266, train_loss = 1.19187368825078, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 267, train_loss = 1.1901385597884655, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 268, train_loss = 1.1883901829714887, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 269, train_loss = 1.1868817408685572, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 270, train_loss = 1.1849427607958205, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 271, train_loss = 1.184068405360449, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 272, train_loss = 1.1815997424419038, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 273, train_loss = 1.1801077698473819, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 274, train_loss = 1.1786490107770078, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 275, train_loss = 1.177458867430687, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 276, train_loss = 1.175422441214323, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 277, train_loss = 1.173727524757851, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 278, train_loss = 1.1727962866425514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 279, train_loss = 1.1708763701026328, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 280, train_loss = 1.1696774860029109, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 281, train_loss = 1.167603325098753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 282, train_loss = 1.1670007109642029, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 283, train_loss = 1.1647589939530008, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 284, train_loss = 1.1632682767813094, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 285, train_loss = 1.1618680469691753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 286, train_loss = 1.1604815945029259, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 287, train_loss = 1.1594011833076365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 288, train_loss = 1.1576300052111037, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 289, train_loss = 1.1563002355396748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 290, train_loss = 1.154149555892218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 291, train_loss = 1.1532488837838173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 292, train_loss = 1.1511023578350432, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 293, train_loss = 1.149513565003872, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 294, train_loss = 1.14854009822011, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 295, train_loss = 1.1466181625728495, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 296, train_loss = 1.145414188504219, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 297, train_loss = 1.1433092790539376, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 298, train_loss = 1.1422566597466357, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 299, train_loss = 1.1406195312738419, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 300, train_loss = 1.1396560805733316, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 301, train_loss = 1.1375092305243015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 302, train_loss = 1.1359799069468863, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 303, train_loss = 1.134838989644777, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 304, train_loss = 1.1337011543218978, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 305, train_loss = 1.131549319892656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 306, train_loss = 1.1308318016235717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 307, train_loss = 1.1293581239879131, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 308, train_loss = 1.1285290059749968, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 309, train_loss = 1.1269936300814152, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 310, train_loss = 1.1252957942779176, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 311, train_loss = 1.1243101358413696, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 312, train_loss = 1.1230566526646726, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 313, train_loss = 1.121759353845846, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 314, train_loss = 1.121057439595461, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 315, train_loss = 1.1190743533079512, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 316, train_loss = 1.1182290464639664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 317, train_loss = 1.1171909756958485, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 318, train_loss = 1.1158846194739453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 319, train_loss = 1.1146655045449734, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 320, train_loss = 1.1132789862458594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 321, train_loss = 1.112077443569433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 322, train_loss = 1.110614288598299, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 323, train_loss = 1.110073032497894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 324, train_loss = 1.1081584468483925, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 325, train_loss = 1.106983222067356, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 326, train_loss = 1.1061265207827091, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 327, train_loss = 1.104814627498854, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 328, train_loss = 1.1034795480663888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 329, train_loss = 1.1026578458840959, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 330, train_loss = 1.1010483491118066, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 331, train_loss = 1.100668818980921, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 332, train_loss = 1.099239967763424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 333, train_loss = 1.0980881464784034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 334, train_loss = 1.0965288964216597, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 335, train_loss = 1.0958933755755424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 336, train_loss = 1.0948509846930392, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 337, train_loss = 1.0936731572146527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 338, train_loss = 1.0920488499104977, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 339, train_loss = 1.0914829621906392, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 340, train_loss = 1.0906347905402072, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 341, train_loss = 1.088671316683758, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 342, train_loss = 1.0878566379542463, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 343, train_loss = 1.0874487335677259, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 344, train_loss = 1.0855118173058145, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 345, train_loss = 1.0851234520669095, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 346, train_loss = 1.0838896445930004, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 347, train_loss = 1.0825310510699637, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 348, train_loss = 1.0816542382235639, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 349, train_loss = 1.0808917842805386, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 350, train_loss = 1.0796531736850739, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 351, train_loss = 1.0789060331881046, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 352, train_loss = 1.0772719445521943, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 353, train_loss = 1.0762841776013374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 354, train_loss = 1.075921283394564, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 355, train_loss = 1.0743454533512704, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 356, train_loss = 1.0739361383020878, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 357, train_loss = 1.0721040703356266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 358, train_loss = 1.071361307054758, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 359, train_loss = 1.0704418483073823, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 360, train_loss = 1.0692232201690786, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 361, train_loss = 1.0686419407720678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 362, train_loss = 1.0676346023683436, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 363, train_loss = 1.0664764605462551, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 364, train_loss = 1.0655267846887, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 365, train_loss = 1.0646779872477055, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 366, train_loss = 1.0632781088352203, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 367, train_loss = 1.0618472062051296, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 368, train_loss = 1.0621744468808174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 369, train_loss = 1.0609476591343991, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 370, train_loss = 1.0596975634689443, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 371, train_loss = 1.0589581218664534, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 372, train_loss = 1.0575446474249475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 373, train_loss = 1.0572012973134406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 374, train_loss = 1.0557775770430453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 375, train_loss = 1.0552113850717433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 376, train_loss = 1.053358814388048, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 377, train_loss = 1.0532086851890199, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 378, train_loss = 1.0519701738958247, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 379, train_loss = 1.0513801711495034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 380, train_loss = 1.0506731942296028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 381, train_loss = 1.0494189858436584, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 382, train_loss = 1.048226561397314, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 383, train_loss = 1.04838978004409, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 384, train_loss = 1.0467259610886686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 385, train_loss = 1.0460026413202286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 386, train_loss = 1.0450947458739392, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 387, train_loss = 1.0439186431467533, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 388, train_loss = 1.042751106142532, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 389, train_loss = 1.0427784000639804, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 390, train_loss = 1.041601449251175, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 391, train_loss = 1.0408039216999896, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 392, train_loss = 1.0397601437871344, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 393, train_loss = 1.0385658331215382, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 394, train_loss = 1.0385434739291668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 395, train_loss = 1.0369664306635968, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 396, train_loss = 1.036319062113762, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 397, train_loss = 1.035585646808613, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 398, train_loss = 1.034664697945118, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 399, train_loss = 1.0341637556557544, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 400, train_loss = 1.0329126715660095, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 401, train_loss = 1.0321550804073922, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 402, train_loss = 1.0310387189383619, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 403, train_loss = 1.0304432474076748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 404, train_loss = 1.0297098991577514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 405, train_loss = 1.0284797176718712, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 406, train_loss = 1.028230369091034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 407, train_loss = 1.0271990311448462, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 408, train_loss = 1.026224588335026, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 409, train_loss = 1.0252654664218426, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 410, train_loss = 1.0247631396050565, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 411, train_loss = 1.023838359862566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 412, train_loss = 1.0228300814633258, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 413, train_loss = 1.022194781631697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 414, train_loss = 1.0213247574865818, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 415, train_loss = 1.0203845177893527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 416, train_loss = 1.0200426777009852, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 417, train_loss = 1.0188168734312057, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 418, train_loss = 1.018401452631224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 419, train_loss = 1.0166753170487937, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 420, train_loss = 1.0166654189524706, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 421, train_loss = 1.0161708084342536, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 422, train_loss = 1.0148485029640142, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 423, train_loss = 1.014237434923416, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 424, train_loss = 1.0131532115337905, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 425, train_loss = 1.0125916190445423, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 426, train_loss = 1.0117920525372028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 427, train_loss = 1.0115290184912737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 428, train_loss = 1.0099413394927979, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 429, train_loss = 1.0096017966570798, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 430, train_loss = 1.0084872668085154, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 431, train_loss = 1.0083042606711388, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 432, train_loss = 1.006929375231266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 433, train_loss = 1.0062210112810135, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 434, train_loss = 1.005756501108408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 435, train_loss = 1.0049027775821742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 436, train_loss = 1.0040864795446396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 437, train_loss = 1.0034738866088446, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 438, train_loss = 1.0026046025159303, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 439, train_loss = 1.0017510242760181, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 440, train_loss = 1.001091606914997, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 441, train_loss = 1.0002988688647747, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 442, train_loss = 0.9998094861803111, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 443, train_loss = 0.9992065268161241, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 444, train_loss = 0.9981111114320811, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 445, train_loss = 0.9978486535546836, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 446, train_loss = 0.9966759905219078, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 447, train_loss = 0.9957674803736154, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 448, train_loss = 0.9960509650409222, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 449, train_loss = 0.9945627612469252, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 450, train_loss = 0.993964539229637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 451, train_loss = 0.9933020994067192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 452, train_loss = 0.9927402883768082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 453, train_loss = 0.9917560095491353, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 454, train_loss = 0.9909744746983051, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 455, train_loss = 0.990586301923031, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 456, train_loss = 0.9902529107930604, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 457, train_loss = 0.9892786269483622, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 458, train_loss = 0.988663088530302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 459, train_loss = 0.987114424497122, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 460, train_loss = 0.9868757811782416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 461, train_loss = 0.9871074805560056, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 462, train_loss = 0.9860385805368423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 463, train_loss = 0.9848413951694965, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 464, train_loss = 0.9846609892847482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 465, train_loss = 0.9843283171358053, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 466, train_loss = 0.9833122578857001, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 467, train_loss = 0.982482341438299, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 468, train_loss = 0.981832063436741, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 469, train_loss = 0.9813236792979296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 470, train_loss = 0.9803843175468501, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 471, train_loss = 0.9802983775734901, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 472, train_loss = 0.9794542131421622, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 473, train_loss = 0.9787776917219162, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 474, train_loss = 0.9777341137232725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 475, train_loss = 0.9775941744446754, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 476, train_loss = 0.9767972441914026, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 477, train_loss = 0.9761895375850145, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 478, train_loss = 0.9754497321846429, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 479, train_loss = 0.9748999463918153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 480, train_loss = 0.9746073447167873, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 481, train_loss = 0.9734611064195633, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 482, train_loss = 0.9729545240697917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 483, train_loss = 0.972266568482155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 484, train_loss = 0.9719085147080477, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 485, train_loss = 0.9708003761770669, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 486, train_loss = 0.9707869067788124, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 487, train_loss = 0.9694462989864405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 488, train_loss = 0.9694439148006495, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 489, train_loss = 0.9689584262669086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 490, train_loss = 0.9678910424408969, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 491, train_loss = 0.9675919065775815, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 492, train_loss = 0.9668114682135638, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 493, train_loss = 0.9660878790018614, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 494, train_loss = 0.965535007417202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 495, train_loss = 0.9646956399083138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 496, train_loss = 0.9647896985115949, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 497, train_loss = 0.963515643030405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 498, train_loss = 0.9632929737272207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 499, train_loss = 0.962644020706648, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████▋                | 23/30 [3:49:21<1:09:59, 599.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "24th- epoch: 0, train_loss = 137.42208197712898, train_acc = 0.7686306474149976\n",
      "test Acc 0.8850093109869647:\n",
      "24th- epoch: 1, train_loss = 45.073923259973526, train_acc = 0.9106893339543549\n",
      "test Acc 0.9152700186219739:\n",
      "24th- epoch: 2, train_loss = 32.72907539829612, train_acc = 0.9345598509548206\n",
      "test Acc 0.9287709497206704:\n",
      "24th- epoch: 3, train_loss = 26.363103833049536, train_acc = 0.9452724732184443\n",
      "test Acc 0.9418063314711359:\n",
      "24th- epoch: 4, train_loss = 22.300114516168833, train_acc = 0.9540055891942245\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 5, train_loss = 19.41576362401247, train_acc = 0.9605263157894737\n",
      "test Acc 0.9529795158286778:\n",
      "24th- epoch: 6, train_loss = 17.256730128079653, train_acc = 0.9640195621797858\n",
      "test Acc 0.9548417132216015:\n",
      "24th- epoch: 7, train_loss = 15.575528364628553, train_acc = 0.9677456916627852\n",
      "test Acc 0.9567039106145251:\n",
      "24th- epoch: 8, train_loss = 14.220502533018589, train_acc = 0.9708896134140661\n",
      "test Acc 0.9594972067039106:\n",
      "24th- epoch: 9, train_loss = 13.099527826532722, train_acc = 0.9743828598043782\n",
      "test Acc 0.9608938547486033:\n",
      "24th- epoch: 10, train_loss = 12.155281754210591, train_acc = 0.9755472752678156\n",
      "test Acc 0.9618249534450651:\n",
      "24th- epoch: 11, train_loss = 11.345206383615732, train_acc = 0.9775267815556591\n",
      "test Acc 0.9622905027932961:\n",
      "24th- epoch: 12, train_loss = 10.635086458176374, train_acc = 0.980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "24th- epoch: 13, train_loss = 10.005073057487607, train_acc = 0.9821844434094085\n",
      "test Acc 0.9641527001862198:\n",
      "24th- epoch: 14, train_loss = 9.447952138260007, train_acc = 0.9827666511411272\n",
      "test Acc 0.9641527001862198:\n",
      "24th- epoch: 15, train_loss = 8.947095798328519, train_acc = 0.9834653004191896\n",
      "test Acc 0.9646182495344506:\n",
      "24th- epoch: 16, train_loss = 8.492770474404097, train_acc = 0.9839310666045645\n",
      "test Acc 0.9655493482309124:\n",
      "24th- epoch: 17, train_loss = 8.08675104379654, train_acc = 0.9847461574289706\n",
      "test Acc 0.9660148975791434:\n",
      "24th- epoch: 18, train_loss = 7.714723575860262, train_acc = 0.9862598975314392\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 19, train_loss = 7.375337118282914, train_acc = 0.9876571960875641\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 20, train_loss = 7.06472251098603, train_acc = 0.9882394038192828\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 21, train_loss = 6.780199349857867, train_acc = 0.9890544946436889\n",
      "test Acc 0.9678770949720671:\n",
      "24th- epoch: 22, train_loss = 6.520272359251976, train_acc = 0.9895202608290639\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 23, train_loss = 6.281276284717023, train_acc = 0.9899860270144387\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 24, train_loss = 6.059774696826935, train_acc = 0.99033535165347\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 25, train_loss = 5.857906045392156, train_acc = 0.9906846762925011\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 26, train_loss = 5.670023920945823, train_acc = 0.9914997671169073\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 27, train_loss = 5.4952626982703805, train_acc = 0.9916162086632511\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 28, train_loss = 5.332100571133196, train_acc = 0.9918490917559385\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 29, train_loss = 5.180498149245977, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 30, train_loss = 5.03938049543649, train_acc = 0.9926641825803446\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 31, train_loss = 4.90727499127388, train_acc = 0.9928970656730322\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 32, train_loss = 4.781945608556271, train_acc = 0.9928970656730322\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 33, train_loss = 4.663125682622194, train_acc = 0.9932463903120633\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 34, train_loss = 4.5518216118216515, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 35, train_loss = 4.445903711952269, train_acc = 0.9937121564974383\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 36, train_loss = 4.34751429175958, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 37, train_loss = 4.251691004727036, train_acc = 0.9939450395901258\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 38, train_loss = 4.1616093455813825, train_acc = 0.9940614811364695\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 39, train_loss = 4.076217202935368, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 40, train_loss = 3.9952401109039783, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 41, train_loss = 3.9182490408420563, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 42, train_loss = 3.843760608229786, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 43, train_loss = 3.77468050038442, train_acc = 0.9951094550535631\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 44, train_loss = 3.706844714935869, train_acc = 0.9952258965999069\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 45, train_loss = 3.6405909270979464, train_acc = 0.9952258965999069\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 46, train_loss = 3.5793678238987923, train_acc = 0.9952258965999069\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 47, train_loss = 3.520325530320406, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 48, train_loss = 3.4628137671388686, train_acc = 0.995575221238938\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 49, train_loss = 3.4069441095925868, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 50, train_loss = 3.3555241972208023, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 51, train_loss = 3.304313780274242, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 52, train_loss = 3.2543115937151015, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 53, train_loss = 3.207306232303381, train_acc = 0.9956916627852818\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 54, train_loss = 3.1617605686187744, train_acc = 0.9956916627852818\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 55, train_loss = 3.1177994064055383, train_acc = 0.9956916627852818\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 56, train_loss = 3.073763370513916, train_acc = 0.9956916627852818\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 57, train_loss = 3.0340460292063653, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 58, train_loss = 2.9939747862517834, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 59, train_loss = 2.9539623535238206, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 60, train_loss = 2.9165509254671633, train_acc = 0.9959245458779693\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 61, train_loss = 2.8811075813136995, train_acc = 0.9959245458779693\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 62, train_loss = 2.8440655223093927, train_acc = 0.9959245458779693\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 63, train_loss = 2.8101869211532176, train_acc = 0.996040987424313\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 64, train_loss = 2.776832729578018, train_acc = 0.9961574289706567\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 65, train_loss = 2.743150408146903, train_acc = 0.9961574289706567\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 66, train_loss = 2.7129467215854675, train_acc = 0.9961574289706567\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 67, train_loss = 2.6808379031717777, train_acc = 0.9961574289706567\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 68, train_loss = 2.652005147188902, train_acc = 0.9961574289706567\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 69, train_loss = 2.6211402390617877, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 70, train_loss = 2.592938682762906, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 71, train_loss = 2.5663000158965588, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 72, train_loss = 2.5382427908480167, train_acc = 0.9963903120633442\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 73, train_loss = 2.510735643329099, train_acc = 0.9963903120633442\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 74, train_loss = 2.48356902343221, train_acc = 0.9963903120633442\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 75, train_loss = 2.4599517211318016, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 76, train_loss = 2.433638598769903, train_acc = 0.9963903120633442\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 77, train_loss = 2.410289303632453, train_acc = 0.996506753609688\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 78, train_loss = 2.384973728330806, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 79, train_loss = 2.3605224266648293, train_acc = 0.996506753609688\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 80, train_loss = 2.3390310641843826, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 81, train_loss = 2.31736122071743, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 82, train_loss = 2.294124082894996, train_acc = 0.9963903120633442\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 83, train_loss = 2.275205794721842, train_acc = 0.996506753609688\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 84, train_loss = 2.253790198592469, train_acc = 0.996506753609688\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 85, train_loss = 2.2328157015144825, train_acc = 0.996506753609688\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 86, train_loss = 2.214229818433523, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 87, train_loss = 2.194458995014429, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 88, train_loss = 2.1759443506598473, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 89, train_loss = 2.1580917946994305, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 90, train_loss = 2.1393961447756737, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 91, train_loss = 2.1212995883543044, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 92, train_loss = 2.105432976037264, train_acc = 0.9967396367023754\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 93, train_loss = 2.088131869910285, train_acc = 0.9967396367023754\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 94, train_loss = 2.0712135944049805, train_acc = 0.9967396367023754\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 95, train_loss = 2.0550415341276675, train_acc = 0.9967396367023754\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 96, train_loss = 2.039783652871847, train_acc = 0.9967396367023754\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 97, train_loss = 2.0241524528246373, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 98, train_loss = 2.0085002779960632, train_acc = 0.9969725197950629\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 99, train_loss = 1.9942041411995888, train_acc = 0.9969725197950629\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 100, train_loss = 1.9786075230222195, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 101, train_loss = 1.9655416395980865, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 102, train_loss = 1.9510060362517834, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 103, train_loss = 1.9384012941736728, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 104, train_loss = 1.9254065889399499, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 105, train_loss = 1.9116328407544643, train_acc = 0.9969725197950629\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 106, train_loss = 1.8987769011873752, train_acc = 0.9969725197950629\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 107, train_loss = 1.8864535553148016, train_acc = 0.9969725197950629\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 108, train_loss = 1.8744884779443964, train_acc = 0.9969725197950629\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 109, train_loss = 1.8625951670110226, train_acc = 0.9970889613414066\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 110, train_loss = 1.8505459887674078, train_acc = 0.9970889613414066\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 111, train_loss = 1.8385882452130318, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 112, train_loss = 1.8278537938604131, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 113, train_loss = 1.816523258923553, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 114, train_loss = 1.8055817857384682, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 115, train_loss = 1.7951995208859444, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 116, train_loss = 1.7845326215028763, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 117, train_loss = 1.7748727028956637, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 118, train_loss = 1.7648618817329407, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 119, train_loss = 1.7546219229698181, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 120, train_loss = 1.7453553589293733, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 121, train_loss = 1.7353186222026125, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 122, train_loss = 1.7267838543048128, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 123, train_loss = 1.717377127497457, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 124, train_loss = 1.708696493296884, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 125, train_loss = 1.6996922952821478, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 126, train_loss = 1.692485579638742, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 127, train_loss = 1.6831267513334751, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 128, train_loss = 1.6746083920588717, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 129, train_loss = 1.6671586396405473, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 130, train_loss = 1.6592257767915726, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 131, train_loss = 1.6504570891847834, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 132, train_loss = 1.6429937705397606, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 133, train_loss = 1.6352825487265363, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 134, train_loss = 1.6277620432665572, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 135, train_loss = 1.6215035939821973, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 136, train_loss = 1.6140289530158043, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 137, train_loss = 1.607998269260861, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 138, train_loss = 1.5998714318266138, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 139, train_loss = 1.5936309831449762, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 140, train_loss = 1.5874829143285751, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 141, train_loss = 1.5803318446269259, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 142, train_loss = 1.5741299651563168, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 143, train_loss = 1.5672964690020308, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 144, train_loss = 1.561488019884564, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 145, train_loss = 1.5556682348251343, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 146, train_loss = 1.5492344623198733, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 147, train_loss = 1.54324008023832, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 148, train_loss = 1.5378291172673926, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 149, train_loss = 1.5316209271550179, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 150, train_loss = 1.526660112082027, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 151, train_loss = 1.5204169489443302, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 152, train_loss = 1.5152099380502477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 153, train_loss = 1.5094624845078215, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 154, train_loss = 1.5044082142412663, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 155, train_loss = 1.4993448654422536, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 156, train_loss = 1.4933329373598099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 157, train_loss = 1.4888752177357674, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 158, train_loss = 1.4837002530694008, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 159, train_loss = 1.4786544628441334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 160, train_loss = 1.4741579765686765, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 161, train_loss = 1.469299259246327, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 162, train_loss = 1.4643752798438072, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 163, train_loss = 1.4596045030048117, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 164, train_loss = 1.4552765190601349, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 165, train_loss = 1.450499584316276, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 166, train_loss = 1.4458921663463116, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 167, train_loss = 1.4417640827596188, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 168, train_loss = 1.4370300496229902, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 169, train_loss = 1.4327098553767428, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 170, train_loss = 1.428669704706408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 171, train_loss = 1.4245925694704056, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 172, train_loss = 1.420007330714725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 173, train_loss = 1.415976689546369, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 174, train_loss = 1.4120160229504108, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 175, train_loss = 1.4079381550545804, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 176, train_loss = 1.4037749121780507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 177, train_loss = 1.400448915839661, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 178, train_loss = 1.3959776858682744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 179, train_loss = 1.3927276370231993, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 180, train_loss = 1.3883892707526684, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 181, train_loss = 1.3842995365266688, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 182, train_loss = 1.3811062673921697, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 183, train_loss = 1.3773926447029226, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 184, train_loss = 1.3737870256300084, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 185, train_loss = 1.3705180485849269, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 186, train_loss = 1.3667417205870152, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 187, train_loss = 1.3632873917813413, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 188, train_loss = 1.3593115123803727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 189, train_loss = 1.3558981877868064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 190, train_loss = 1.3525506642763503, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 191, train_loss = 1.3494147025048733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 192, train_loss = 1.3460935267503373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 193, train_loss = 1.3426882227067836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 194, train_loss = 1.3394214386935346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 195, train_loss = 1.3362315545673482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 196, train_loss = 1.333254475146532, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 197, train_loss = 1.3299834914505482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 198, train_loss = 1.326554595201742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 199, train_loss = 1.3235292509198189, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 200, train_loss = 1.3200826893444173, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 201, train_loss = 1.3172277274425142, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 202, train_loss = 1.3142400880460627, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 203, train_loss = 1.3112445821170695, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 204, train_loss = 1.308404091745615, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 205, train_loss = 1.3051060189609416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 206, train_loss = 1.3018929275567643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 207, train_loss = 1.2988281212747097, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 208, train_loss = 1.2961614181404002, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 209, train_loss = 1.2933380517060868, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 210, train_loss = 1.2901671442086808, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 211, train_loss = 1.287377803295385, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 212, train_loss = 1.2845086964662187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 213, train_loss = 1.2821233607828617, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 214, train_loss = 1.2795278020203114, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 215, train_loss = 1.2763595978613012, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 216, train_loss = 1.2738240982289426, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 217, train_loss = 1.271290585398674, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 218, train_loss = 1.2685536232893355, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 219, train_loss = 1.2662390160257928, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 220, train_loss = 1.2636641934514046, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 221, train_loss = 1.2607738934457302, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 222, train_loss = 1.2583414775435813, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 223, train_loss = 1.2561195480520837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 224, train_loss = 1.2537460562889464, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 225, train_loss = 1.2510397844016552, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 226, train_loss = 1.2486285927589051, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 227, train_loss = 1.2461236082017422, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 228, train_loss = 1.244173749058973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 229, train_loss = 1.241217193484772, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 230, train_loss = 1.2390710934996605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 231, train_loss = 1.2369522104854695, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 232, train_loss = 1.2344698433880694, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 233, train_loss = 1.2323180784587748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 234, train_loss = 1.229892601550091, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 235, train_loss = 1.2277387964422815, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 236, train_loss = 1.225486058741808, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 237, train_loss = 1.2231363579630852, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 238, train_loss = 1.2212225633556955, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 239, train_loss = 1.2189654732937925, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 240, train_loss = 1.216879082203377, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 241, train_loss = 1.214747407764662, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 242, train_loss = 1.2126172271673568, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 243, train_loss = 1.2106395227019675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 244, train_loss = 1.2085915058851242, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 245, train_loss = 1.2062565498054028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 246, train_loss = 1.2044658375089057, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 247, train_loss = 1.2026874236762524, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 248, train_loss = 1.2004608077113517, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 249, train_loss = 1.1986343984608538, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 250, train_loss = 1.1965868162806146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 251, train_loss = 1.194296222180128, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 252, train_loss = 1.1927229166030884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 253, train_loss = 1.1905240627820604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 254, train_loss = 1.188811098516453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 255, train_loss = 1.187211976677645, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 256, train_loss = 1.1847195687587373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 257, train_loss = 1.1832739462261088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 258, train_loss = 1.1812465650145896, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 259, train_loss = 1.179730809002649, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 260, train_loss = 1.1774447746574879, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 261, train_loss = 1.175645808398258, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 262, train_loss = 1.1739351687137969, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 263, train_loss = 1.1723850729758851, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 264, train_loss = 1.1704977129702456, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 265, train_loss = 1.1684845996205695, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 266, train_loss = 1.166841881989967, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 267, train_loss = 1.1652748535270803, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 268, train_loss = 1.163351324677933, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 269, train_loss = 1.1615813982789405, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 270, train_loss = 1.159975592046976, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 271, train_loss = 1.1583671433036216, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 272, train_loss = 1.1568839947576635, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 273, train_loss = 1.155103161931038, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 274, train_loss = 1.153593861788977, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 275, train_loss = 1.1518495790660381, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 276, train_loss = 1.1503213209216483, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 277, train_loss = 1.1481861385400407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 278, train_loss = 1.1469470150768757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 279, train_loss = 1.1449706989224069, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 280, train_loss = 1.1439660576288588, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 281, train_loss = 1.1416055423323996, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 282, train_loss = 1.1406973376870155, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 283, train_loss = 1.1392113578913268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 284, train_loss = 1.1374534778296947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 285, train_loss = 1.1359856302442495, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 286, train_loss = 1.1342592549917754, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 287, train_loss = 1.1327002061007079, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 288, train_loss = 1.1311790719628334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 289, train_loss = 1.129764129727846, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 290, train_loss = 1.1284083612263203, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 291, train_loss = 1.1268593457934912, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 292, train_loss = 1.125193556159502, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 293, train_loss = 1.123718739807373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 294, train_loss = 1.122300195187563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 295, train_loss = 1.1207364474830683, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 296, train_loss = 1.1193802542984486, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 297, train_loss = 1.11789140602923, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 298, train_loss = 1.1164186944661196, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 299, train_loss = 1.1150457163748797, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 300, train_loss = 1.1130405118165072, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 301, train_loss = 1.1112248239514884, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 302, train_loss = 1.1096098870038986, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 303, train_loss = 1.107765968888998, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 304, train_loss = 1.106446464866167, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 305, train_loss = 1.1048048486409243, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 306, train_loss = 1.1034303940832615, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 307, train_loss = 1.1022585543396417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 308, train_loss = 1.100276513636345, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 309, train_loss = 1.0993727259337902, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 310, train_loss = 1.0979326801898424, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 311, train_loss = 1.0962759430112783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 312, train_loss = 1.0954785756766796, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 313, train_loss = 1.0938541206123773, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 314, train_loss = 1.0921252183616161, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 315, train_loss = 1.0912423344852868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 316, train_loss = 1.089922378450865, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 317, train_loss = 1.088756868004566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 318, train_loss = 1.0876415756938513, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 319, train_loss = 1.086272078246111, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 320, train_loss = 1.0847603119909763, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 321, train_loss = 1.0830632758734282, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 322, train_loss = 1.0820947401225567, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 323, train_loss = 1.0802651134727057, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 324, train_loss = 1.0792674012482166, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 325, train_loss = 1.078212113439804, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 326, train_loss = 1.0773089776339475, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 327, train_loss = 1.0756178759038448, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 328, train_loss = 1.0744518339633942, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 329, train_loss = 1.072996029019123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 330, train_loss = 1.07191763818264, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 331, train_loss = 1.0703718749282416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 332, train_loss = 1.069467768073082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 333, train_loss = 1.0689523791370448, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 334, train_loss = 1.0670860732498113, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 335, train_loss = 1.0659437415597495, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 336, train_loss = 1.0652415230870247, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 337, train_loss = 1.0641184585692827, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 338, train_loss = 1.0627038727106992, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 339, train_loss = 1.0615197159349918, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 340, train_loss = 1.0603425428271294, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 341, train_loss = 1.059350768715376, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 342, train_loss = 1.0579802890715655, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 343, train_loss = 1.0573158537445124, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 344, train_loss = 1.0558186483976897, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 345, train_loss = 1.0547784219088499, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 346, train_loss = 1.0536250273289625, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 347, train_loss = 1.0523955523967743, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 348, train_loss = 1.0514301769435406, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 349, train_loss = 1.0507875631155912, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 350, train_loss = 1.0494197694060858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 351, train_loss = 1.048244340956444, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 352, train_loss = 1.0475674507615622, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 353, train_loss = 1.0465525723993778, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 354, train_loss = 1.045134972780943, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 355, train_loss = 1.0438302767870482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 356, train_loss = 1.043079807102913, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 357, train_loss = 1.0423347055912018, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 358, train_loss = 1.0411473189888056, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 359, train_loss = 1.040043188870186, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 360, train_loss = 1.0392306347785052, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 361, train_loss = 1.0381967624125537, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 362, train_loss = 1.0372534034249838, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 363, train_loss = 1.0362749944033567, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 364, train_loss = 1.034954303264385, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 365, train_loss = 1.0340090692043304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 366, train_loss = 1.0330096607503947, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 367, train_loss = 1.0324612843396608, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 368, train_loss = 1.0315739065408707, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 369, train_loss = 1.0300854345259722, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 370, train_loss = 1.029012775659794, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 371, train_loss = 1.0286954802868422, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 372, train_loss = 1.0270163491368294, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 373, train_loss = 1.0261609330773354, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 374, train_loss = 1.0258701319398824, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 375, train_loss = 1.0244514929654542, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 376, train_loss = 1.0232845383288804, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 377, train_loss = 1.0227452293038368, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 378, train_loss = 1.0213589631021023, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 379, train_loss = 1.0201356770994607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 380, train_loss = 1.0196221632359084, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 381, train_loss = 1.0185143488051835, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 382, train_loss = 1.0172500871121883, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 383, train_loss = 1.0168719688954297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 384, train_loss = 1.0156987147929613, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 385, train_loss = 1.0145732996461447, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 386, train_loss = 1.0137941800057888, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 387, train_loss = 1.0133248505590018, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 388, train_loss = 1.0124185917375144, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 389, train_loss = 1.010846558958292, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 390, train_loss = 1.0096262581646442, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 391, train_loss = 1.0082639691827353, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 392, train_loss = 1.0069782584905624, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 393, train_loss = 1.0066582995059434, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 394, train_loss = 1.0051395495829638, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 395, train_loss = 1.0047050577995833, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 396, train_loss = 1.0034998382034246, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 397, train_loss = 1.0029185637831688, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 398, train_loss = 1.0019428208470345, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 399, train_loss = 1.0010868621466216, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 400, train_loss = 1.0002061004342977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 401, train_loss = 0.9995278045535088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 402, train_loss = 0.9990614441630896, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 403, train_loss = 0.9979129023849964, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 404, train_loss = 0.99658658230328, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 405, train_loss = 0.996179822832346, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 406, train_loss = 0.9949793679115828, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 407, train_loss = 0.9944798660872038, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 408, train_loss = 0.993800587952137, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 409, train_loss = 0.9927979372441769, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 410, train_loss = 0.9920385554432869, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 411, train_loss = 0.9912538304924965, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 412, train_loss = 0.9903373246488627, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 413, train_loss = 0.9896092253329698, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 414, train_loss = 0.989101093262434, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 415, train_loss = 0.9883014348743018, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 416, train_loss = 0.9869723580777645, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 417, train_loss = 0.9861744344234467, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 418, train_loss = 0.9855894185602665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 419, train_loss = 0.984902768075699, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 420, train_loss = 0.9842789011599962, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 421, train_loss = 0.9835349830391351, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 422, train_loss = 0.9823393324913923, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 423, train_loss = 0.9821476327779237, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 424, train_loss = 0.9809541876020376, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 425, train_loss = 0.9806220655736979, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 426, train_loss = 0.9797910948691424, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 427, train_loss = 0.9785459339618683, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 428, train_loss = 0.9785358583030757, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 429, train_loss = 0.9770907014608383, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 430, train_loss = 0.9769403437676374, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 431, train_loss = 0.9762305617332458, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 432, train_loss = 0.9753446616232395, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 433, train_loss = 0.9747523963451385, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 434, train_loss = 0.9738013856112957, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 435, train_loss = 0.9736484015884344, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 436, train_loss = 0.9724698128702585, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 437, train_loss = 0.9715193907322828, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 438, train_loss = 0.9710928325948771, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 439, train_loss = 0.9702374401094858, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 440, train_loss = 0.9693897055985872, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 441, train_loss = 0.9691557573678438, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 442, train_loss = 0.9680006566049997, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 443, train_loss = 0.9678565139474813, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 444, train_loss = 0.9663964994251728, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 445, train_loss = 0.9664203648862895, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 446, train_loss = 0.9656406404974405, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 447, train_loss = 0.9645204035041388, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 448, train_loss = 0.9642559972999152, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 449, train_loss = 0.9633366788330022, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 450, train_loss = 0.9629526051285211, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 451, train_loss = 0.9623573149292497, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 452, train_loss = 0.9612863262445899, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 453, train_loss = 0.9606055431067944, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 454, train_loss = 0.9603476536722155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 455, train_loss = 0.959435532495263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 456, train_loss = 0.9586430092604132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 457, train_loss = 0.9579137985856505, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 458, train_loss = 0.9571224028914003, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 459, train_loss = 0.9570877527148696, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 460, train_loss = 0.9558272423892049, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 461, train_loss = 0.9556131958961487, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 462, train_loss = 0.9553525385708781, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 463, train_loss = 0.9539873115718365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 464, train_loss = 0.9535383358597755, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 465, train_loss = 0.9528263248503208, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 466, train_loss = 0.9522141205816297, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 467, train_loss = 0.951918225735426, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 468, train_loss = 0.9508996059448691, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 469, train_loss = 0.9505640305578709, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 470, train_loss = 0.9497544641344575, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 471, train_loss = 0.9488317954092054, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 472, train_loss = 0.9488048081548186, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 473, train_loss = 0.9479927544743987, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 474, train_loss = 0.9470788886101218, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 475, train_loss = 0.9470223560929298, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 476, train_loss = 0.9463174442498712, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 477, train_loss = 0.9450415608735057, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 478, train_loss = 0.944458103433135, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 479, train_loss = 0.9445507638156414, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 480, train_loss = 0.9437397594301729, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 481, train_loss = 0.9427073399274377, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 482, train_loss = 0.942705171808484, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 483, train_loss = 0.9417683891952038, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 484, train_loss = 0.9412616391928168, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 485, train_loss = 0.9409889417438535, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 486, train_loss = 0.9398750228137942, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 487, train_loss = 0.9392726421356201, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 488, train_loss = 0.9390710989682702, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 489, train_loss = 0.9382346769125434, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 490, train_loss = 0.9376186629087897, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 491, train_loss = 0.9373274520039558, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 492, train_loss = 0.9369174924941035, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 493, train_loss = 0.9359606765210629, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 494, train_loss = 0.9352631767542334, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 495, train_loss = 0.9351307762117358, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 496, train_loss = 0.9341306773276301, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 497, train_loss = 0.9337766915559769, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 498, train_loss = 0.9330605678260326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 499, train_loss = 0.932298103973153, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████              | 24/30 [3:59:21<1:00:00, 600.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "25th- epoch: 0, train_loss = 138.33161522448063, train_acc = 0.7538425710293433\n",
      "test Acc 0.8701117318435754:\n",
      "25th- epoch: 1, train_loss = 42.922269247472286, train_acc = 0.907545412203074\n",
      "test Acc 0.9227188081936686:\n",
      "25th- epoch: 2, train_loss = 30.127762608230114, train_acc = 0.935724266418258\n",
      "test Acc 0.9418063314711359:\n",
      "25th- epoch: 3, train_loss = 24.030582323670387, train_acc = 0.9491150442477876\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 4, train_loss = 20.26810473576188, train_acc = 0.9572659524918491\n",
      "test Acc 0.9534450651769087:\n",
      "25th- epoch: 5, train_loss = 17.64822068065405, train_acc = 0.9641360037261295\n",
      "test Acc 0.957635009310987:\n",
      "25th- epoch: 6, train_loss = 15.687856197357178, train_acc = 0.9680950163018165\n",
      "test Acc 0.9613594040968343:\n",
      "25th- epoch: 7, train_loss = 14.142276484519243, train_acc = 0.971821145784816\n",
      "test Acc 0.962756052141527:\n",
      "25th- epoch: 8, train_loss = 12.893380139023066, train_acc = 0.9751979506287843\n",
      "test Acc 0.9632216014897579:\n",
      "25th- epoch: 9, train_loss = 11.857756037265062, train_acc = 0.9771774569166278\n",
      "test Acc 0.9650837988826816:\n",
      "25th- epoch: 10, train_loss = 10.975702911615372, train_acc = 0.9791569632044713\n",
      "test Acc 0.9655493482309124:\n",
      "25th- epoch: 11, train_loss = 10.219149369746447, train_acc = 0.980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 12, train_loss = 9.559076860547066, train_acc = 0.9820680018630648\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 13, train_loss = 8.982612174004316, train_acc = 0.9832324173265021\n",
      "test Acc 0.9688081936685289:\n",
      "25th- epoch: 14, train_loss = 8.474730879068375, train_acc = 0.9843968327899395\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 15, train_loss = 8.02050449885428, train_acc = 0.9850954820680019\n",
      "test Acc 0.9716014897579144:\n",
      "25th- epoch: 16, train_loss = 7.612652255222201, train_acc = 0.9867256637168141\n",
      "test Acc 0.9716014897579144:\n",
      "25th- epoch: 17, train_loss = 7.242793017998338, train_acc = 0.9873078714485328\n",
      "test Acc 0.9716014897579144:\n",
      "25th- epoch: 18, train_loss = 6.907501136884093, train_acc = 0.9877736376339078\n",
      "test Acc 0.9711359404096834:\n",
      "25th- epoch: 19, train_loss = 6.604630114510655, train_acc = 0.9889380530973452\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 20, train_loss = 6.330250611528754, train_acc = 0.9891709361900326\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 21, train_loss = 6.078517818823457, train_acc = 0.9897531439217513\n",
      "test Acc 0.9725325884543762:\n",
      "25th- epoch: 22, train_loss = 5.845519229769707, train_acc = 0.9901024685607824\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 23, train_loss = 5.634562814608216, train_acc = 0.9904517931998137\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 24, train_loss = 5.440307481214404, train_acc = 0.9910340009315324\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 25, train_loss = 5.258627757430077, train_acc = 0.9912668840242198\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 26, train_loss = 5.090072091668844, train_acc = 0.9913833255705635\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 27, train_loss = 4.932817809283733, train_acc = 0.9917326502095948\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 28, train_loss = 4.786706416867673, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 29, train_loss = 4.648058152757585, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 30, train_loss = 4.520073510706425, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 31, train_loss = 4.398435198701918, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 32, train_loss = 4.284194980747998, train_acc = 0.9927806241266884\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 33, train_loss = 4.177060414105654, train_acc = 0.9927806241266884\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 34, train_loss = 4.076808740384877, train_acc = 0.9928970656730322\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 35, train_loss = 3.980561561882496, train_acc = 0.9931299487657196\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 36, train_loss = 3.8892299607396126, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 37, train_loss = 3.8022667691111565, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 38, train_loss = 3.721116100437939, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 39, train_loss = 3.64243798609823, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 40, train_loss = 3.5691754557192326, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 41, train_loss = 3.4976071333512664, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 42, train_loss = 3.4328057654201984, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 43, train_loss = 3.3701642835512757, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 44, train_loss = 3.309062677435577, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 45, train_loss = 3.2511491468176246, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 46, train_loss = 3.1960344845429063, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 47, train_loss = 3.1423001079820096, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 48, train_loss = 3.091881348285824, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 49, train_loss = 3.0432530231773853, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 50, train_loss = 2.9967236891388893, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 51, train_loss = 2.9524475024081767, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 52, train_loss = 2.90971622755751, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 53, train_loss = 2.8691266998648643, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 54, train_loss = 2.82898940006271, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 55, train_loss = 2.790761172771454, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 56, train_loss = 2.754573325160891, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 57, train_loss = 2.7183231078088284, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 58, train_loss = 2.684606209397316, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 59, train_loss = 2.6505717150866985, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 60, train_loss = 2.6185794807970524, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 61, train_loss = 2.5863883085548878, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 62, train_loss = 2.557942181825638, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 63, train_loss = 2.5281931557692587, train_acc = 0.9958081043316255\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 64, train_loss = 2.5001429566182196, train_acc = 0.9958081043316255\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 65, train_loss = 2.4723080806434155, train_acc = 0.9958081043316255\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 66, train_loss = 2.445700418204069, train_acc = 0.9958081043316255\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 67, train_loss = 2.4199200137518346, train_acc = 0.9958081043316255\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 68, train_loss = 2.394025912042707, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 69, train_loss = 2.3707680106163025, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 70, train_loss = 2.346783173736185, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 71, train_loss = 2.3246807493269444, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 72, train_loss = 2.3015149137936532, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 73, train_loss = 2.2804614999331534, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 74, train_loss = 2.259701317641884, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 75, train_loss = 2.2390601471997797, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 76, train_loss = 2.21814681077376, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 77, train_loss = 2.1996011710725725, train_acc = 0.9962738705170004\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 78, train_loss = 2.1803538925014436, train_acc = 0.9963903120633442\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 79, train_loss = 2.1621426045894623, train_acc = 0.9963903120633442\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 80, train_loss = 2.143159384606406, train_acc = 0.9963903120633442\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 81, train_loss = 2.126432067481801, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 82, train_loss = 2.109022118151188, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 83, train_loss = 2.091483688680455, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 84, train_loss = 2.0762635804712772, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 85, train_loss = 2.0598128736019135, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 86, train_loss = 2.044903166592121, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 87, train_loss = 2.0292479794006795, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 88, train_loss = 2.0148198504466563, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 89, train_loss = 1.9998750712256879, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 90, train_loss = 1.9862078365404159, train_acc = 0.9967396367023754\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 91, train_loss = 1.971916449489072, train_acc = 0.9967396367023754\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 92, train_loss = 1.9591902159154415, train_acc = 0.9967396367023754\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 93, train_loss = 1.945296098710969, train_acc = 0.9967396367023754\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 94, train_loss = 1.9328807357233018, train_acc = 0.9969725197950629\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 95, train_loss = 1.9193100270349532, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 96, train_loss = 1.9072327178437263, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 97, train_loss = 1.8949764694552869, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 98, train_loss = 1.8833466656506062, train_acc = 0.9969725197950629\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 99, train_loss = 1.8712415408808738, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 100, train_loss = 1.8609793223440647, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 101, train_loss = 1.8485117305535823, train_acc = 0.9969725197950629\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 102, train_loss = 1.8375483739655465, train_acc = 0.9969725197950629\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 103, train_loss = 1.826835097046569, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 104, train_loss = 1.8151015664916486, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 105, train_loss = 1.8043621182441711, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 106, train_loss = 1.7946845218539238, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 107, train_loss = 1.7839077822864056, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 108, train_loss = 1.77532680449076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 109, train_loss = 1.765069679589942, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 110, train_loss = 1.7557878941297531, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 111, train_loss = 1.746308907866478, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 112, train_loss = 1.737234152853489, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 113, train_loss = 1.7291504826862365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 114, train_loss = 1.7204603243153542, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 115, train_loss = 1.7121204372961074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 116, train_loss = 1.7045438289642334, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 117, train_loss = 1.6952492829877883, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 118, train_loss = 1.6876562039833516, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 119, train_loss = 1.6797538858372718, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 120, train_loss = 1.6715125404298306, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 121, train_loss = 1.664863746613264, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 122, train_loss = 1.6564484536647797, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 123, train_loss = 1.6498054701369256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 124, train_loss = 1.6428966398816556, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 125, train_loss = 1.635097273858264, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 126, train_loss = 1.6286619629245251, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 127, train_loss = 1.6221096839290112, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 128, train_loss = 1.6146187571575865, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 129, train_loss = 1.608611005009152, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 130, train_loss = 1.601786769926548, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 131, train_loss = 1.595727420062758, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 132, train_loss = 1.5894448148319498, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 133, train_loss = 1.5829216738929972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 134, train_loss = 1.5768213644623756, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 135, train_loss = 1.5710982903838158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 136, train_loss = 1.565230168402195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 137, train_loss = 1.5594112537801266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 138, train_loss = 1.5530970407417044, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 139, train_loss = 1.5479187654564157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 140, train_loss = 1.542243675678037, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 141, train_loss = 1.536428497522138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 142, train_loss = 1.5312380442628637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 143, train_loss = 1.5258694676449522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 144, train_loss = 1.5206589959561825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 145, train_loss = 1.515878226608038, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 146, train_loss = 1.5098048573127016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 147, train_loss = 1.5052157193422318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 148, train_loss = 1.5002997206756845, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 149, train_loss = 1.4952170526375994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 150, train_loss = 1.4907836044440046, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 151, train_loss = 1.4859527312219143, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 152, train_loss = 1.4813822557916865, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 153, train_loss = 1.4763168841600418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 154, train_loss = 1.4716570638120174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 155, train_loss = 1.4670799101004377, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 156, train_loss = 1.4629189856350422, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 157, train_loss = 1.458737626671791, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 158, train_loss = 1.4544343625893816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 159, train_loss = 1.4494676291942596, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 160, train_loss = 1.4443622914841399, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 161, train_loss = 1.4413617165992036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 162, train_loss = 1.4376147290458903, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 163, train_loss = 1.4332184853265062, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 164, train_loss = 1.4287633610656485, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 165, train_loss = 1.4258851011982188, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 166, train_loss = 1.420571013004519, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 167, train_loss = 1.4168742770561948, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 168, train_loss = 1.4127125268569216, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 169, train_loss = 1.4092163207242265, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 170, train_loss = 1.40544967725873, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 171, train_loss = 1.4019898362457752, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 172, train_loss = 1.397705620736815, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 173, train_loss = 1.3952076248824596, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 174, train_loss = 1.3906417129328474, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 175, train_loss = 1.38658767438028, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 176, train_loss = 1.3839952734997496, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 177, train_loss = 1.3796803342411295, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 178, train_loss = 1.3766034232685342, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 179, train_loss = 1.3730996251106262, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 180, train_loss = 1.3701545931398869, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 181, train_loss = 1.3660658797016367, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 182, train_loss = 1.3630416790256277, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 183, train_loss = 1.3602757031330839, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 184, train_loss = 1.3559336612233892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 185, train_loss = 1.353778786957264, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 186, train_loss = 1.349475464434363, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 187, train_loss = 1.346332366229035, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 188, train_loss = 1.3439318673918024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 189, train_loss = 1.3399755246937275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 190, train_loss = 1.3373700194060802, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 191, train_loss = 1.3340968452394009, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 192, train_loss = 1.331230695010163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 193, train_loss = 1.328330360352993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 194, train_loss = 1.325891625136137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 195, train_loss = 1.321800336241722, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 196, train_loss = 1.3191043622791767, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 197, train_loss = 1.3169385181972757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 198, train_loss = 1.3137962197652087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 199, train_loss = 1.3101832655956969, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 200, train_loss = 1.3087140880525112, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 201, train_loss = 1.3053085307474248, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 202, train_loss = 1.303011539101135, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 203, train_loss = 1.3002890211646445, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 204, train_loss = 1.297684796154499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 205, train_loss = 1.2945007421076298, train_acc = 0.9972054028877504\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 206, train_loss = 1.292699832469225, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 207, train_loss = 1.2892388800974004, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 208, train_loss = 1.2865113615989685, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 209, train_loss = 1.2845452266628854, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 210, train_loss = 1.2817253420944326, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 211, train_loss = 1.278488576412201, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 212, train_loss = 1.2765494299237616, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 213, train_loss = 1.2748799920082092, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 214, train_loss = 1.2716161173884757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 215, train_loss = 1.269417893141508, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 216, train_loss = 1.2672364823520184, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 217, train_loss = 1.26447044062661, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 218, train_loss = 1.2619928792119026, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 219, train_loss = 1.2601506263017654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 220, train_loss = 1.2570204213261604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 221, train_loss = 1.2545391581952572, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 222, train_loss = 1.2533486361498944, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 223, train_loss = 1.25100614503026, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 224, train_loss = 1.2486477333004586, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 225, train_loss = 1.2464118587668054, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 226, train_loss = 1.2435251213610172, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 227, train_loss = 1.241251161962282, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 228, train_loss = 1.239927377551794, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 229, train_loss = 1.2379661910235882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 230, train_loss = 1.2349128425121307, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 231, train_loss = 1.2322394835646264, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 232, train_loss = 1.2307910062372684, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 233, train_loss = 1.228788812935818, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 234, train_loss = 1.2255251904134639, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 235, train_loss = 1.2244208182091825, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 236, train_loss = 1.2222672402858734, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 237, train_loss = 1.2196530724759214, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 238, train_loss = 1.217733972996939, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 239, train_loss = 1.2149933290784247, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 240, train_loss = 1.2135694697499275, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 241, train_loss = 1.2107918349211104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 242, train_loss = 1.2096249610185623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 243, train_loss = 1.2070692789857276, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 244, train_loss = 1.2050153377349488, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 245, train_loss = 1.2030684724450111, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 246, train_loss = 1.2012240414624102, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 247, train_loss = 1.1996827733819373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 248, train_loss = 1.1977914422750473, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 249, train_loss = 1.1960657847230323, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 250, train_loss = 1.1939046382904053, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 251, train_loss = 1.1921718840603717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 252, train_loss = 1.1905658493633382, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 253, train_loss = 1.1883657909929752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 254, train_loss = 1.186063953966368, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 255, train_loss = 1.1840892061591148, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 256, train_loss = 1.182886254042387, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 257, train_loss = 1.1803251281380653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 258, train_loss = 1.1795419789850712, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 259, train_loss = 1.1773908424074762, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 260, train_loss = 1.1762643096153624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 261, train_loss = 1.1740734080667607, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 262, train_loss = 1.1728705788846128, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 263, train_loss = 1.170189257711172, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 264, train_loss = 1.1691949789528735, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 265, train_loss = 1.1674836439196952, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 266, train_loss = 1.1650105242733844, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 267, train_loss = 1.1642425644095056, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 268, train_loss = 1.162256972223986, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 269, train_loss = 1.1607668909127824, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 270, train_loss = 1.159090445667971, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 271, train_loss = 1.1572646424174309, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 272, train_loss = 1.1557810008525848, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 273, train_loss = 1.1543382667005062, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 274, train_loss = 1.1525016203522682, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 275, train_loss = 1.1515413944725879, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 276, train_loss = 1.1496764086186886, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 277, train_loss = 1.1485309712588787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 278, train_loss = 1.1466018185019493, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 279, train_loss = 1.1454704788629897, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 280, train_loss = 1.1433636012370698, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 281, train_loss = 1.1422102277283557, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 282, train_loss = 1.1409146562218666, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 283, train_loss = 1.138175191998016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 284, train_loss = 1.1381227672100067, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 285, train_loss = 1.136030311405193, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 286, train_loss = 1.1354737468063831, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 287, train_loss = 1.132988819212187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 288, train_loss = 1.1315463657374494, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 289, train_loss = 1.1308345757424831, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 290, train_loss = 1.128282515972387, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 291, train_loss = 1.1279531841282733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 292, train_loss = 1.1264360745553859, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 293, train_loss = 1.1246266278321855, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 294, train_loss = 1.123391946137417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 295, train_loss = 1.1216746692662127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 296, train_loss = 1.1209302730858326, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 297, train_loss = 1.1184703235630877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 298, train_loss = 1.1183379354770295, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 299, train_loss = 1.1170003712177277, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 300, train_loss = 1.115456686646212, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 301, train_loss = 1.1136550729279406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 302, train_loss = 1.1125355226104148, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 303, train_loss = 1.1120968709583394, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 304, train_loss = 1.110479723662138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 305, train_loss = 1.1088648426230066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 306, train_loss = 1.1071283519268036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 307, train_loss = 1.1051655883784406, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 308, train_loss = 1.104567851871252, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 309, train_loss = 1.103459374338854, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 310, train_loss = 1.1019111039640848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 311, train_loss = 1.1015588852169458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 312, train_loss = 1.0994705396296922, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 313, train_loss = 1.098138488829136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 314, train_loss = 1.097984690219164, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 315, train_loss = 1.0957460378704127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 316, train_loss = 1.0948421210050583, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 317, train_loss = 1.0935285650193691, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 318, train_loss = 1.0925835929811, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 319, train_loss = 1.091322235763073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 320, train_loss = 1.0899969351885375, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 321, train_loss = 1.0892730802297592, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 322, train_loss = 1.0878481157124043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 323, train_loss = 1.0864586730895098, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 324, train_loss = 1.0855519411561545, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 325, train_loss = 1.0846719530818518, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 326, train_loss = 1.0827972777187824, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 327, train_loss = 1.0818087173101958, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 328, train_loss = 1.0805997686984483, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 329, train_loss = 1.0808595480921213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 330, train_loss = 1.0786457608046476, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 331, train_loss = 1.077521620929474, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 332, train_loss = 1.0766461355087813, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 333, train_loss = 1.075444534420967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 334, train_loss = 1.073846527695423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 335, train_loss = 1.0737936509249266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 336, train_loss = 1.071775066346163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 337, train_loss = 1.0703175043163355, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 338, train_loss = 1.0699961396458093, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 339, train_loss = 1.0688971976342145, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 340, train_loss = 1.0679958698747214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 341, train_loss = 1.0672664642333984, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 342, train_loss = 1.0662200103106443, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 343, train_loss = 1.063913026213413, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 344, train_loss = 1.0637206745741423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 345, train_loss = 1.0628329490718897, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 346, train_loss = 1.0615160688757896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 347, train_loss = 1.060613725334406, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 348, train_loss = 1.059309317410225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 349, train_loss = 1.0587791986763477, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 350, train_loss = 1.0578652223048266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 351, train_loss = 1.056196928024292, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 352, train_loss = 1.0554700481297914, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 353, train_loss = 1.0545404851436615, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 354, train_loss = 1.053145615995163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 355, train_loss = 1.0522859158518258, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 356, train_loss = 1.0518843879399356, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 357, train_loss = 1.0503746680915356, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 358, train_loss = 1.0503486134111881, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 359, train_loss = 1.049072296678787, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 360, train_loss = 1.0473820020852145, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 361, train_loss = 1.0476640723645687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 362, train_loss = 1.0460589391586836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 363, train_loss = 1.045016922056675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 364, train_loss = 1.0446208802459296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 365, train_loss = 1.0434908395109233, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 366, train_loss = 1.0420940729381982, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 367, train_loss = 1.0413795734348241, train_acc = 0.9974382859804378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 368, train_loss = 1.0401655261812266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 369, train_loss = 1.0401201459171716, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 370, train_loss = 1.0387915236351546, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 371, train_loss = 1.0377385740575846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 372, train_loss = 1.0371138701739255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 373, train_loss = 1.036096140742302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 374, train_loss = 1.034454744309187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 375, train_loss = 1.0348518043756485, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 376, train_loss = 1.0326810727419797, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 377, train_loss = 1.0328911567630712, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 378, train_loss = 1.0313517935574055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 379, train_loss = 1.0303669956920203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 380, train_loss = 1.0292535411717836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 381, train_loss = 1.02868290245533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 382, train_loss = 1.0283275196852628, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 383, train_loss = 1.0269840372202452, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 384, train_loss = 1.026857959717745, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 385, train_loss = 1.0252719087002333, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 386, train_loss = 1.0240416775050107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 387, train_loss = 1.0235644318163395, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 388, train_loss = 1.0229228176176548, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 389, train_loss = 1.0219270537199918, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 390, train_loss = 1.0209214985370636, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 391, train_loss = 1.0206697173416615, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 392, train_loss = 1.019361956656212, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 393, train_loss = 1.018765209853882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 394, train_loss = 1.0173028955759946, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 395, train_loss = 1.0177986311318818, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 396, train_loss = 1.016132041811943, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 397, train_loss = 1.014931252837414, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 398, train_loss = 1.0145596750080585, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 399, train_loss = 1.0140458357927855, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 400, train_loss = 1.0138102322816849, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 401, train_loss = 1.0116744190454483, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 402, train_loss = 1.0121194049715996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 403, train_loss = 1.0109965676965658, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 404, train_loss = 1.0091182055475656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 405, train_loss = 1.008893147110939, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 406, train_loss = 1.0088396295905113, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 407, train_loss = 1.0072893661854323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 408, train_loss = 1.0069924965500832, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 409, train_loss = 1.0066551504132804, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 410, train_loss = 1.0047448029217776, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 411, train_loss = 1.0042425642313901, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 412, train_loss = 1.0032702063617762, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 413, train_loss = 1.0030266071262304, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 414, train_loss = 1.0025901570916176, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 415, train_loss = 1.0012513784167822, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 416, train_loss = 1.0004916998150293, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 417, train_loss = 0.9997549764811993, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 418, train_loss = 0.9997870338556822, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 419, train_loss = 0.9983122820558492, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 420, train_loss = 0.9977067373692989, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 421, train_loss = 0.9979875435528811, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 422, train_loss = 0.9964339062571526, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 423, train_loss = 0.9947581017913762, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 424, train_loss = 0.9952514792385045, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 425, train_loss = 0.9943099096417427, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 426, train_loss = 0.9935621867480222, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 427, train_loss = 0.9921940465865191, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 428, train_loss = 0.9920630815031473, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 429, train_loss = 0.991256116569275, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 430, train_loss = 0.9906250834465027, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 431, train_loss = 0.9896315783262253, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 432, train_loss = 0.9891526301798876, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 433, train_loss = 0.9883957505226135, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 434, train_loss = 0.9875823656620923, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 435, train_loss = 0.9873907218279783, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 436, train_loss = 0.9869472558202688, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 437, train_loss = 0.9863092564046383, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 438, train_loss = 0.9849509038031101, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 439, train_loss = 0.9839081739482936, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 440, train_loss = 0.9838985626993235, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 441, train_loss = 0.9835327640175819, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 442, train_loss = 0.9824916385114193, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 443, train_loss = 0.9818261961045209, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 444, train_loss = 0.9816378988325596, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 445, train_loss = 0.9802510303852614, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 446, train_loss = 0.9812686977384146, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 447, train_loss = 0.9790072242321912, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 448, train_loss = 0.9783036472799722, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 449, train_loss = 0.9790482483804226, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 450, train_loss = 0.977249483257765, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 451, train_loss = 0.9765820229949895, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 452, train_loss = 0.9763007735309657, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 453, train_loss = 0.9755030199885368, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 454, train_loss = 0.9747552263143007, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 455, train_loss = 0.9739292549493257, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 456, train_loss = 0.9741104456188623, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 457, train_loss = 0.9724443232116755, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 458, train_loss = 0.97211623689509, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 459, train_loss = 0.9717818039061967, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 460, train_loss = 0.9704959330556449, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 461, train_loss = 0.970173110574251, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 462, train_loss = 0.969489579409128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 463, train_loss = 0.969406529009575, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 464, train_loss = 0.9681391852500383, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 465, train_loss = 0.9679383523762226, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 466, train_loss = 0.9664773320255335, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 467, train_loss = 0.9667487156984862, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 468, train_loss = 0.96605034917593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 469, train_loss = 0.966009721159935, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 470, train_loss = 0.9655084175465163, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 471, train_loss = 0.9638592054543551, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 472, train_loss = 0.9636875080468599, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 473, train_loss = 0.9629004597663879, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 474, train_loss = 0.9626316614449024, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 475, train_loss = 0.961627154290909, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 476, train_loss = 0.9615768889489118, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 477, train_loss = 0.9608021254243795, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 478, train_loss = 0.9600319316086825, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 479, train_loss = 0.9603443294763565, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 480, train_loss = 0.9594389063713606, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 481, train_loss = 0.9583061089215335, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 482, train_loss = 0.9575417364540044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 483, train_loss = 0.9580627965333406, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 484, train_loss = 0.9564505219459534, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 485, train_loss = 0.9567837367358152, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 486, train_loss = 0.9559436874988023, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 487, train_loss = 0.9546474851667881, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 488, train_loss = 0.9542838508787099, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 489, train_loss = 0.9533824125828687, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 490, train_loss = 0.9532547257840633, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 491, train_loss = 0.9521906673908234, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 492, train_loss = 0.9521590756921796, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 493, train_loss = 0.9518536230025347, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 494, train_loss = 0.9509353687317343, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 495, train_loss = 0.9502654112875462, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 496, train_loss = 0.9496418125927448, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 497, train_loss = 0.9494838466198416, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 498, train_loss = 0.9495802919118432, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 499, train_loss = 0.9484029163868399, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████            | 25/30 [4:09:21<49:59, 599.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "26th- epoch: 0, train_loss = 117.53440274298191, train_acc = 0.7986725663716814\n",
      "test Acc 0.8822160148975792:\n",
      "26th- epoch: 1, train_loss = 41.28352787345648, train_acc = 0.9214019562179786\n",
      "test Acc 0.9194599627560521:\n",
      "26th- epoch: 2, train_loss = 30.401863306760788, train_acc = 0.9402654867256637\n",
      "test Acc 0.9338919925512105:\n",
      "26th- epoch: 3, train_loss = 24.629316225647926, train_acc = 0.9507452258965999\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 4, train_loss = 20.80338730290532, train_acc = 0.9588961341406614\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 5, train_loss = 18.049234628677368, train_acc = 0.9646017699115044\n",
      "test Acc 0.9553072625698324:\n",
      "26th- epoch: 6, train_loss = 15.978241426870227, train_acc = 0.9704238472286912\n",
      "test Acc 0.9567039106145251:\n",
      "26th- epoch: 7, train_loss = 14.334863236173987, train_acc = 0.9731020027945971\n",
      "test Acc 0.9594972067039106:\n",
      "26th- epoch: 8, train_loss = 12.98485061712563, train_acc = 0.976245924545878\n",
      "test Acc 0.9622905027932961:\n",
      "26th- epoch: 9, train_loss = 11.85055917315185, train_acc = 0.9784583139264089\n",
      "test Acc 0.962756052141527:\n",
      "26th- epoch: 10, train_loss = 10.90546746365726, train_acc = 0.9800884955752213\n",
      "test Acc 0.9646182495344506:\n",
      "26th- epoch: 11, train_loss = 10.099957397207618, train_acc = 0.9824173265020959\n",
      "test Acc 0.9669459962756052:\n",
      "26th- epoch: 12, train_loss = 9.413639498874545, train_acc = 0.9840475081509082\n",
      "test Acc 0.9669459962756052:\n",
      "26th- epoch: 13, train_loss = 8.8224370572716, train_acc = 0.9852119236143456\n",
      "test Acc 0.9664804469273743:\n",
      "26th- epoch: 14, train_loss = 8.302155930548906, train_acc = 0.986376339077783\n",
      "test Acc 0.9664804469273743:\n",
      "26th- epoch: 15, train_loss = 7.842114659026265, train_acc = 0.9878900791802515\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 16, train_loss = 7.434208439663053, train_acc = 0.9888216115510013\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 17, train_loss = 7.066910842433572, train_acc = 0.9892873777363763\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 18, train_loss = 6.740897779352963, train_acc = 0.9899860270144387\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 19, train_loss = 6.448489262722433, train_acc = 0.990801117838845\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 20, train_loss = 6.181570827960968, train_acc = 0.9911504424778761\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 21, train_loss = 5.940232823602855, train_acc = 0.9914997671169073\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 22, train_loss = 5.720772601664066, train_acc = 0.9916162086632511\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 23, train_loss = 5.516796726733446, train_acc = 0.9919655333022822\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 24, train_loss = 5.330526612699032, train_acc = 0.9921984163949698\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 25, train_loss = 5.155794047750533, train_acc = 0.9927806241266884\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 26, train_loss = 4.994390291161835, train_acc = 0.9928970656730322\n",
      "test Acc 0.9706703910614525:\n",
      "26th- epoch: 27, train_loss = 4.841551420278847, train_acc = 0.9931299487657196\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 28, train_loss = 4.697858411818743, train_acc = 0.9933628318584071\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 29, train_loss = 4.566989101469517, train_acc = 0.9934792734047508\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 30, train_loss = 4.441831967793405, train_acc = 0.9933628318584071\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 31, train_loss = 4.324937839061022, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 32, train_loss = 4.2133180079981685, train_acc = 0.9939450395901258\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 33, train_loss = 4.108750191517174, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 34, train_loss = 4.010679077357054, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 35, train_loss = 3.9162002010270953, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 36, train_loss = 3.8255640044808388, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 37, train_loss = 3.7395449047908187, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 38, train_loss = 3.6574318557977676, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 39, train_loss = 3.580619861371815, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 40, train_loss = 3.5044725639745593, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 41, train_loss = 3.43478015717119, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 42, train_loss = 3.3652046881616116, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 43, train_loss = 3.298285758588463, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "26th- epoch: 44, train_loss = 3.236949983984232, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "26th- epoch: 45, train_loss = 3.17324918275699, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "26th- epoch: 46, train_loss = 3.116183467209339, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "26th- epoch: 47, train_loss = 3.060611102730036, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 48, train_loss = 3.006372316274792, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 49, train_loss = 2.956602394580841, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 50, train_loss = 2.908153895288706, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 51, train_loss = 2.8599890717305243, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 52, train_loss = 2.814675336237997, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 53, train_loss = 2.770722035318613, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 54, train_loss = 2.7301703132689, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 55, train_loss = 2.6894106827676296, train_acc = 0.9954587796925943\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 56, train_loss = 2.649653439875692, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 57, train_loss = 2.612749988678843, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 58, train_loss = 2.5776762603782117, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 59, train_loss = 2.5436895452439785, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 60, train_loss = 2.510500042233616, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 61, train_loss = 2.4786258838139474, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 62, train_loss = 2.4489193074405193, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 63, train_loss = 2.4186813817359507, train_acc = 0.9959245458779693\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 64, train_loss = 2.391108029987663, train_acc = 0.9959245458779693\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 65, train_loss = 2.364109616726637, train_acc = 0.9959245458779693\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 66, train_loss = 2.3376401565037668, train_acc = 0.9959245458779693\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 67, train_loss = 2.311618570238352, train_acc = 0.9959245458779693\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 68, train_loss = 2.2873995527625084, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 69, train_loss = 2.263193966355175, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 70, train_loss = 2.2397211268544197, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 71, train_loss = 2.2172503299079835, train_acc = 0.9962738705170004\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 72, train_loss = 2.1947822719812393, train_acc = 0.9963903120633442\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 73, train_loss = 2.1752561889588833, train_acc = 0.9963903120633442\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 74, train_loss = 2.154355260077864, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 75, train_loss = 2.134953466709703, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 76, train_loss = 2.115741854067892, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 77, train_loss = 2.097079226281494, train_acc = 0.9966231951560317\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 78, train_loss = 2.078462142497301, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 79, train_loss = 2.060490815434605, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 80, train_loss = 2.043328945990652, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 81, train_loss = 2.0277072601020336, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 82, train_loss = 2.0111027942039073, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 83, train_loss = 1.9962907694280148, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 84, train_loss = 1.980792788323015, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 85, train_loss = 1.966549624921754, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 86, train_loss = 1.9518548038322479, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 87, train_loss = 1.9386765558738261, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 88, train_loss = 1.924841585336253, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 89, train_loss = 1.9118692527990788, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 90, train_loss = 1.8985009752213955, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 91, train_loss = 1.8861169915180653, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 92, train_loss = 1.8739577035885304, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 93, train_loss = 1.8621638007462025, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 94, train_loss = 1.8506622302811593, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 95, train_loss = 1.8391070005018264, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 96, train_loss = 1.8281160879414529, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 97, train_loss = 1.817100101383403, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 98, train_loss = 1.8070873070973903, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 99, train_loss = 1.795954342931509, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 100, train_loss = 1.7864383507985622, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 101, train_loss = 1.7762176617980003, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 102, train_loss = 1.7666913841385394, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 103, train_loss = 1.7571220695972443, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 104, train_loss = 1.7474015429615974, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 105, train_loss = 1.7385343376081437, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 106, train_loss = 1.729742332128808, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 107, train_loss = 1.7210336711723357, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 108, train_loss = 1.7120161391794682, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 109, train_loss = 1.7037139448802918, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 110, train_loss = 1.6951070204377174, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 111, train_loss = 1.6869592790026218, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 112, train_loss = 1.6791912529151887, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 113, train_loss = 1.6712414983194321, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 114, train_loss = 1.663274637190625, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 115, train_loss = 1.6559390872716904, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 116, train_loss = 1.6485255521256477, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 117, train_loss = 1.640909707872197, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 118, train_loss = 1.63419300573878, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 119, train_loss = 1.627081309678033, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 120, train_loss = 1.6201799523551017, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 121, train_loss = 1.6130129434168339, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 122, train_loss = 1.6066388003528118, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 123, train_loss = 1.5998364526312798, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 124, train_loss = 1.5935050349216908, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 125, train_loss = 1.5870096285361797, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 126, train_loss = 1.581075803609565, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 127, train_loss = 1.5746303785126656, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 128, train_loss = 1.569049907149747, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 129, train_loss = 1.5629196565132588, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 130, train_loss = 1.5567584347445518, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 131, train_loss = 1.5511468052864075, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 132, train_loss = 1.5453380942344666, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 133, train_loss = 1.5397859700024128, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 134, train_loss = 1.5344217009842396, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 135, train_loss = 1.5286915861070156, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 136, train_loss = 1.5236669715959579, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 137, train_loss = 1.5180321161169559, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 138, train_loss = 1.5132047210354358, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 139, train_loss = 1.5081664163153619, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 140, train_loss = 1.5028913132846355, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 141, train_loss = 1.497987549751997, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 142, train_loss = 1.4928507072618231, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 143, train_loss = 1.4884630354354158, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 144, train_loss = 1.4832227788865566, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 145, train_loss = 1.4788022935390472, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 146, train_loss = 1.474029072909616, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 147, train_loss = 1.4696301569929346, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 148, train_loss = 1.465147795737721, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 149, train_loss = 1.460497229010798, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 150, train_loss = 1.4563804218778387, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 151, train_loss = 1.4520923495292664, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 152, train_loss = 1.4475133419036865, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 153, train_loss = 1.4432771106949076, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 154, train_loss = 1.439251055358909, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 155, train_loss = 1.4349072141340002, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 156, train_loss = 1.4309309646487236, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 157, train_loss = 1.4268157618353143, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 158, train_loss = 1.423047841875814, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 159, train_loss = 1.4191518364241347, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 160, train_loss = 1.4147786051034927, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 161, train_loss = 1.4114808551967144, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 162, train_loss = 1.4073141863336787, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 163, train_loss = 1.4038055626442656, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 164, train_loss = 1.400048295618035, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 165, train_loss = 1.3965317433467135, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 166, train_loss = 1.392639166326262, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 167, train_loss = 1.3887948679039255, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 168, train_loss = 1.3856968680629507, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 169, train_loss = 1.382365549565293, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 170, train_loss = 1.3784530175616965, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 171, train_loss = 1.3750985799124464, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 172, train_loss = 1.3718322044005617, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 173, train_loss = 1.3681778410682455, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 174, train_loss = 1.3651126039912924, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 175, train_loss = 1.3617530539631844, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 176, train_loss = 1.3588972488651052, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 177, train_loss = 1.3556312235305086, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 178, train_loss = 1.3521766712656245, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 179, train_loss = 1.3491089530289173, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 180, train_loss = 1.3459217250347137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 181, train_loss = 1.3427047642180696, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 182, train_loss = 1.339764972566627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 183, train_loss = 1.3364108627429232, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 184, train_loss = 1.3335947481682524, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 185, train_loss = 1.3306918343296275, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 186, train_loss = 1.3279340006411076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 187, train_loss = 1.3249018104979768, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 188, train_loss = 1.321883230120875, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 189, train_loss = 1.3189402098068967, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 190, train_loss = 1.316581548540853, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 191, train_loss = 1.3132491757860407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 192, train_loss = 1.3105684369802475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 193, train_loss = 1.3081558272242546, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 194, train_loss = 1.3050747712841257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 195, train_loss = 1.3023674202850088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 196, train_loss = 1.2996306283166632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 197, train_loss = 1.2972172921290621, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 198, train_loss = 1.2942977858474478, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 199, train_loss = 1.2918992129852995, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 200, train_loss = 1.2893752405652776, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 201, train_loss = 1.2861017286777496, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 202, train_loss = 1.2842309238621965, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 203, train_loss = 1.281430690200068, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 204, train_loss = 1.2791161040076986, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 205, train_loss = 1.2763718093046919, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 206, train_loss = 1.2741609985241666, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 207, train_loss = 1.2715225517749786, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 208, train_loss = 1.2689399471273646, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 209, train_loss = 1.2668083930620924, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 210, train_loss = 1.2644109651446342, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 211, train_loss = 1.2620387499919161, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 212, train_loss = 1.2595103656640276, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 213, train_loss = 1.2572027383139357, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 214, train_loss = 1.2552386423340067, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 215, train_loss = 1.2525666927685961, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 216, train_loss = 1.2508450051536784, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 217, train_loss = 1.2482374546816573, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 218, train_loss = 1.2461941664805636, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 219, train_loss = 1.2441023351857439, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 220, train_loss = 1.2414788355818018, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 221, train_loss = 1.2397247863700613, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 222, train_loss = 1.237327596754767, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 223, train_loss = 1.2353567691752687, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 224, train_loss = 1.2331302476814017, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 225, train_loss = 1.2310869991779327, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 226, train_loss = 1.229198906570673, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 227, train_loss = 1.2267944725463167, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 228, train_loss = 1.2248386977007613, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 229, train_loss = 1.2228433241834864, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 230, train_loss = 1.220610585063696, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 231, train_loss = 1.2187991291284561, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 232, train_loss = 1.2168434424092993, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 233, train_loss = 1.215057066292502, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 234, train_loss = 1.212564054876566, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 235, train_loss = 1.2110430771717802, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 236, train_loss = 1.2088656574487686, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 237, train_loss = 1.2069896049797535, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 238, train_loss = 1.2050488019594923, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 239, train_loss = 1.2031751436297782, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 240, train_loss = 1.201160303025972, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 241, train_loss = 1.1992034427821636, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 242, train_loss = 1.1973250322043896, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 243, train_loss = 1.1959413315053098, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 244, train_loss = 1.1936992593109608, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 245, train_loss = 1.1917141924495809, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 246, train_loss = 1.1903315472300164, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 247, train_loss = 1.1881410057540052, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 248, train_loss = 1.1864347693626769, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 249, train_loss = 1.1846706842188723, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 250, train_loss = 1.1832785879378207, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 251, train_loss = 1.1812062350218184, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 252, train_loss = 1.1797904024715535, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 253, train_loss = 1.1778170987963676, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 254, train_loss = 1.1756982617080212, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 255, train_loss = 1.174419344693888, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 256, train_loss = 1.1729265687172301, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 257, train_loss = 1.1707865446805954, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 258, train_loss = 1.1692976343329065, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 259, train_loss = 1.1676670399610884, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 260, train_loss = 1.1660195402801037, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 261, train_loss = 1.1639900493319146, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 262, train_loss = 1.1627934438292868, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 263, train_loss = 1.1611821253900416, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 264, train_loss = 1.1592200547456741, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 265, train_loss = 1.1576953095500357, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 266, train_loss = 1.1563764897291549, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 267, train_loss = 1.1547037114505656, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 268, train_loss = 1.1530390630359761, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 269, train_loss = 1.1512461329693906, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 270, train_loss = 1.1502364228363149, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 271, train_loss = 1.1479444789583795, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 272, train_loss = 1.1466735638678074, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 273, train_loss = 1.1448952828650363, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 274, train_loss = 1.1433909560437314, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 275, train_loss = 1.1418268618290313, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 276, train_loss = 1.1401228581671603, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 277, train_loss = 1.1388355568051338, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 278, train_loss = 1.1373635046184063, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 279, train_loss = 1.1354056584532373, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 280, train_loss = 1.1344821006059647, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 281, train_loss = 1.1329101547598839, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 282, train_loss = 1.131110339134466, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 283, train_loss = 1.1299703195691109, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 284, train_loss = 1.1287628002464771, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 285, train_loss = 1.1274526566267014, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 286, train_loss = 1.1259871634538285, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 287, train_loss = 1.124171819537878, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 288, train_loss = 1.1229264922440052, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 289, train_loss = 1.1217901396448724, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 290, train_loss = 1.1199271008372307, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 291, train_loss = 1.1189439098234288, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 292, train_loss = 1.11760687205242, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 293, train_loss = 1.1159868041868322, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 294, train_loss = 1.1150908296112902, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 295, train_loss = 1.1134378065471537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 296, train_loss = 1.112073142081499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 297, train_loss = 1.1109363946015947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 298, train_loss = 1.1095160891418345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 299, train_loss = 1.1081283055245876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 300, train_loss = 1.106923212588299, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 301, train_loss = 1.1057651415467262, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 302, train_loss = 1.1045555832679383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 303, train_loss = 1.103272621810902, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 304, train_loss = 1.1017531243269332, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 305, train_loss = 1.1008653976023197, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 306, train_loss = 1.0994139077956788, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 307, train_loss = 1.0986018503899686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 308, train_loss = 1.0972489367122762, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 309, train_loss = 1.0958191913668998, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 310, train_loss = 1.0940352479810826, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 311, train_loss = 1.093527626246214, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 312, train_loss = 1.0921986823086627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 313, train_loss = 1.0909508702461608, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 314, train_loss = 1.0893897252972238, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 315, train_loss = 1.0883728762273677, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 316, train_loss = 1.0876842352445237, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 317, train_loss = 1.0865524746477604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 318, train_loss = 1.0849467950756662, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 319, train_loss = 1.0839484234456904, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 320, train_loss = 1.0825194865465164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 321, train_loss = 1.0817296281456947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 322, train_loss = 1.0803548221592791, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 323, train_loss = 1.0791565937106498, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 324, train_loss = 1.0785532034933567, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 325, train_loss = 1.0772842156584375, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 326, train_loss = 1.0759883324499242, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 327, train_loss = 1.0747825093567371, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 328, train_loss = 1.0736765849287622, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 329, train_loss = 1.0728782552178018, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 330, train_loss = 1.0713623017072678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 331, train_loss = 1.070305346220266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 332, train_loss = 1.0695219859480858, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 333, train_loss = 1.0683795611257665, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 334, train_loss = 1.06697602692293, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 335, train_loss = 1.066229013085831, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 336, train_loss = 1.06497461599065, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 337, train_loss = 1.0638467110693455, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 338, train_loss = 1.0632470101118088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 339, train_loss = 1.061387439549435, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 340, train_loss = 1.0613371655344963, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 341, train_loss = 1.0597711627488025, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 342, train_loss = 1.0586773988907225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 343, train_loss = 1.057464074343443, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 344, train_loss = 1.056604791432619, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 345, train_loss = 1.055456918955315, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 346, train_loss = 1.0548435126547702, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 347, train_loss = 1.0536393125657924, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 348, train_loss = 1.0524833872914314, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 349, train_loss = 1.0516024393145926, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 350, train_loss = 1.0509536117315292, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 351, train_loss = 1.0492973129148595, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 352, train_loss = 1.0487845316529274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 353, train_loss = 1.0473735444247723, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 354, train_loss = 1.04676179215312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 355, train_loss = 1.0457991522853263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 356, train_loss = 1.044298242777586, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 357, train_loss = 1.0440211321110837, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 358, train_loss = 1.0428318629856221, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 359, train_loss = 1.0419604827766307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 360, train_loss = 1.0408694197540171, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 361, train_loss = 1.040296786755789, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 362, train_loss = 1.0390292294323444, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 363, train_loss = 1.038294696540106, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 364, train_loss = 1.0368419488077052, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 365, train_loss = 1.0366478984360583, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 366, train_loss = 1.035370887548197, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 367, train_loss = 1.0342061308328994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 368, train_loss = 1.033680568158161, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 369, train_loss = 1.0327087926561944, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 370, train_loss = 1.0316494914586656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 371, train_loss = 1.0307418033480644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 372, train_loss = 1.0298090328578837, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 373, train_loss = 1.0296831776504405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 374, train_loss = 1.0280703765456565, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 375, train_loss = 1.0270599673094694, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 376, train_loss = 1.0266658017935697, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 377, train_loss = 1.025393354386324, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 378, train_loss = 1.024603195488453, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 379, train_loss = 1.0240602555277292, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 380, train_loss = 1.0228565447032452, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 381, train_loss = 1.0221515434386674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 382, train_loss = 1.021271458506817, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 383, train_loss = 1.020585781574482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 384, train_loss = 1.0196893190441187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 385, train_loss = 1.0185282652673777, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 386, train_loss = 1.0183167643845081, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 387, train_loss = 1.0168359950184822, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 388, train_loss = 1.0158726535737514, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 389, train_loss = 1.015688594430685, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 390, train_loss = 1.014488690852886, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 391, train_loss = 1.0138809407653753, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 392, train_loss = 1.0128176870348398, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 393, train_loss = 1.0122918213310186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 394, train_loss = 1.011271346360445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 395, train_loss = 1.0108793266117573, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 396, train_loss = 1.0096545008418616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 397, train_loss = 1.00875074416399, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 398, train_loss = 1.008167984575266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 399, train_loss = 1.007171450793976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 400, train_loss = 1.006758530944353, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 401, train_loss = 1.0060786331596319, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 402, train_loss = 1.0048915570077952, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 403, train_loss = 1.0041044739482459, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 404, train_loss = 1.0033778958022594, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 405, train_loss = 1.0023452565073967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 406, train_loss = 1.002688955515623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 407, train_loss = 1.0011669471859932, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 408, train_loss = 1.0004784440097865, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 409, train_loss = 0.9999484730360564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 410, train_loss = 0.9989333214762155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 411, train_loss = 0.998036620527273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 412, train_loss = 0.9974810481071472, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 413, train_loss = 0.9964141957461834, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 414, train_loss = 0.9962797040643636, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 415, train_loss = 0.9949077094497625, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 416, train_loss = 0.9941080771386623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 417, train_loss = 0.9944318259658758, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 418, train_loss = 0.9928203374147415, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 419, train_loss = 0.9927634447813034, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 420, train_loss = 0.9916913645865861, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 421, train_loss = 0.990785119443899, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 422, train_loss = 0.9900758527219296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 423, train_loss = 0.9892062358558178, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 424, train_loss = 0.9883846826851368, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 425, train_loss = 0.9882841296494007, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 426, train_loss = 0.9871790210308973, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 427, train_loss = 0.9866150133311749, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 428, train_loss = 0.9864933167991694, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 429, train_loss = 0.9852655815484468, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 430, train_loss = 0.9849019472894724, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 431, train_loss = 0.9837073037924711, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 432, train_loss = 0.9831897119584028, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 433, train_loss = 0.9823267360625323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 434, train_loss = 0.9818162396550179, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 435, train_loss = 0.9807654196920339, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 436, train_loss = 0.9810475185513496, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 437, train_loss = 0.9797484216687735, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 438, train_loss = 0.9791078878042754, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 439, train_loss = 0.9781451560556889, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 440, train_loss = 0.9782586954534054, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 441, train_loss = 0.9769663065671921, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 442, train_loss = 0.9767102648911532, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 443, train_loss = 0.9759055425820407, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 444, train_loss = 0.974983461201191, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 445, train_loss = 0.9747690769436304, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 446, train_loss = 0.9738850519061089, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 447, train_loss = 0.9730054500105325, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 448, train_loss = 0.972576587140793, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 449, train_loss = 0.9718788651225623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 450, train_loss = 0.9712860534491483, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 451, train_loss = 0.9703831622900907, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 452, train_loss = 0.9697952407004777, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 453, train_loss = 0.9695807260868605, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 454, train_loss = 0.9688474150898401, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 455, train_loss = 0.9675071810779627, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 456, train_loss = 0.9674323188664857, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 457, train_loss = 0.9668299642798956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 458, train_loss = 0.9662452811899129, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 459, train_loss = 0.9656980521976948, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 460, train_loss = 0.9645879144372884, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 461, train_loss = 0.9645843952894211, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 462, train_loss = 0.9639169275760651, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 463, train_loss = 0.9631458284857217, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 464, train_loss = 0.9625379157660063, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 465, train_loss = 0.9617962998745497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 466, train_loss = 0.9614636041224003, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 467, train_loss = 0.9608651821909007, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 468, train_loss = 0.9600580086407717, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 469, train_loss = 0.9590182850661222, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 470, train_loss = 0.9587747814657632, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 471, train_loss = 0.9587147037091199, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 472, train_loss = 0.957740673184162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 473, train_loss = 0.9571718325314578, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 474, train_loss = 0.956312745809555, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 475, train_loss = 0.9565582399663981, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 476, train_loss = 0.9550539627671242, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 477, train_loss = 0.9548238702118397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 478, train_loss = 0.9537328382430132, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 479, train_loss = 0.9535037974419538, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 480, train_loss = 0.9532754185202066, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 481, train_loss = 0.9521434009075165, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 482, train_loss = 0.9522078782320023, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 483, train_loss = 0.9514219077827875, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 484, train_loss = 0.9501627472636756, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 485, train_loss = 0.9504197115602437, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 486, train_loss = 0.9496475532650948, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 487, train_loss = 0.9488790979085024, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 488, train_loss = 0.9489669961330947, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 489, train_loss = 0.9475934890506323, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 490, train_loss = 0.9475415050983429, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 491, train_loss = 0.9465499669313431, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 492, train_loss = 0.9465798785386141, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 493, train_loss = 0.9456314432027284, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 494, train_loss = 0.9452544202504214, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 495, train_loss = 0.9446019393799361, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 496, train_loss = 0.9440769515931606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 497, train_loss = 0.9439701239170972, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 498, train_loss = 0.9427167835237924, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 499, train_loss = 0.9420898891985416, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████▍         | 26/30 [4:19:21<40:00, 600.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "27th- epoch: 0, train_loss = 120.01467788219452, train_acc = 0.7812063344201211\n",
      "test Acc 0.86731843575419:\n",
      "27th- epoch: 1, train_loss = 43.486647963523865, train_acc = 0.9126688402421984\n",
      "test Acc 0.909683426443203:\n",
      "27th- epoch: 2, train_loss = 31.42276230081916, train_acc = 0.9382859804378202\n",
      "test Acc 0.9283054003724395:\n",
      "27th- epoch: 3, train_loss = 25.287669137120247, train_acc = 0.9491150442477876\n",
      "test Acc 0.9390130353817505:\n",
      "27th- epoch: 4, train_loss = 21.402035631239414, train_acc = 0.9570330693991617\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 5, train_loss = 18.646835807710886, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "27th- epoch: 6, train_loss = 16.547229170799255, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "27th- epoch: 7, train_loss = 14.888796171173453, train_acc = 0.9717047042384723\n",
      "test Acc 0.9553072625698324:\n",
      "27th- epoch: 8, train_loss = 13.527552478015423, train_acc = 0.974033535165347\n",
      "test Acc 0.9604283054003724:\n",
      "27th- epoch: 9, train_loss = 12.387708064168692, train_acc = 0.9760130414531905\n",
      "test Acc 0.9604283054003724:\n",
      "27th- epoch: 10, train_loss = 11.413678102195263, train_acc = 0.9782254308337215\n",
      "test Acc 0.9599627560521415:\n",
      "27th- epoch: 11, train_loss = 10.581237606704235, train_acc = 0.9792734047508151\n",
      "test Acc 0.9613594040968343:\n",
      "27th- epoch: 12, train_loss = 9.848535910248756, train_acc = 0.9809035863996274\n",
      "test Acc 0.962756052141527:\n",
      "27th- epoch: 13, train_loss = 9.210441755130887, train_acc = 0.9821844434094085\n",
      "test Acc 0.9641527001862198:\n",
      "27th- epoch: 14, train_loss = 8.650581421330571, train_acc = 0.9829995342338146\n",
      "test Acc 0.9650837988826816:\n",
      "27th- epoch: 15, train_loss = 8.147857122123241, train_acc = 0.9835817419655333\n",
      "test Acc 0.9669459962756052:\n",
      "27th- epoch: 16, train_loss = 7.702270219102502, train_acc = 0.9842803912435957\n",
      "test Acc 0.9678770949720671:\n",
      "27th- epoch: 17, train_loss = 7.301774390041828, train_acc = 0.985444806707033\n",
      "test Acc 0.9678770949720671:\n",
      "27th- epoch: 18, train_loss = 6.941162638366222, train_acc = 0.9867256637168141\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 19, train_loss = 6.616810530424118, train_acc = 0.9870749883558454\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 20, train_loss = 6.320339186117053, train_acc = 0.9877736376339078\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 21, train_loss = 6.052237069234252, train_acc = 0.9882394038192828\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 22, train_loss = 5.809883942827582, train_acc = 0.9890544946436889\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 23, train_loss = 5.588684929534793, train_acc = 0.9896367023754076\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 24, train_loss = 5.384839283302426, train_acc = 0.9902189101071263\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 25, train_loss = 5.19754471257329, train_acc = 0.9910340009315324\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 26, train_loss = 5.023005481809378, train_acc = 0.9917326502095948\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 27, train_loss = 4.8647729977965355, train_acc = 0.9918490917559385\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 28, train_loss = 4.714681204408407, train_acc = 0.9921984163949698\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 29, train_loss = 4.576027916744351, train_acc = 0.9923148579413135\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 30, train_loss = 4.445959383621812, train_acc = 0.9927806241266884\n",
      "test Acc 0.9720670391061452:\n",
      "27th- epoch: 31, train_loss = 4.323678174056113, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 32, train_loss = 4.211390193551779, train_acc = 0.9935957149510946\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 33, train_loss = 4.105495322495699, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 34, train_loss = 4.005418127402663, train_acc = 0.9941779226828132\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 35, train_loss = 3.9113343125209212, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "27th- epoch: 36, train_loss = 3.821437733247876, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 37, train_loss = 3.7383091198280454, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 38, train_loss = 3.6592157697305083, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 39, train_loss = 3.5830111438408494, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 40, train_loss = 3.5123679358512163, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 41, train_loss = 3.4435642417520285, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 42, train_loss = 3.3804969573393464, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 43, train_loss = 3.3176282700151205, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 44, train_loss = 3.2599263908341527, train_acc = 0.9951094550535631\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 45, train_loss = 3.2039007088169456, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 46, train_loss = 3.150439567863941, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 47, train_loss = 3.0987619841471314, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 48, train_loss = 3.0495744636282325, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 49, train_loss = 3.003263355232775, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 50, train_loss = 2.957967688329518, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 51, train_loss = 2.914705823175609, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 52, train_loss = 2.873773359693587, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 53, train_loss = 2.8331715427339077, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 54, train_loss = 2.794817585963756, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 55, train_loss = 2.7580429813824594, train_acc = 0.9958081043316255\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 56, train_loss = 2.7223989833146334, train_acc = 0.9958081043316255\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 57, train_loss = 2.6873934608884156, train_acc = 0.9958081043316255\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 58, train_loss = 2.6542775905691087, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 59, train_loss = 2.6219676029868424, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 60, train_loss = 2.5909688002429903, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 61, train_loss = 2.560721129179001, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 62, train_loss = 2.5319864391349256, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 63, train_loss = 2.5028820633888245, train_acc = 0.9963903120633442\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 64, train_loss = 2.4758620797656476, train_acc = 0.9963903120633442\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 65, train_loss = 2.4494095291011035, train_acc = 0.9963903120633442\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 66, train_loss = 2.4242005962878466, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 67, train_loss = 2.398512384388596, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 68, train_loss = 2.374664907809347, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 69, train_loss = 2.3510257550515234, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 70, train_loss = 2.327721482142806, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 71, train_loss = 2.3049515685997903, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 72, train_loss = 2.2835069596767426, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 73, train_loss = 2.2619108739309013, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 74, train_loss = 2.242214991245419, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 75, train_loss = 2.221162418369204, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 76, train_loss = 2.201816306915134, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 77, train_loss = 2.182647338602692, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 78, train_loss = 2.164225375279784, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 79, train_loss = 2.1452846792526543, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 80, train_loss = 2.127990139182657, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 81, train_loss = 2.1098281177692115, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 82, train_loss = 2.0934534315019846, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 83, train_loss = 2.076272640377283, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 84, train_loss = 2.059841707814485, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 85, train_loss = 2.0438088946975768, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 86, train_loss = 2.0284922402352095, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 87, train_loss = 2.013411832973361, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 88, train_loss = 1.9974404745735228, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 89, train_loss = 1.983387395273894, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 90, train_loss = 1.9694279755931348, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 91, train_loss = 1.9540513220708817, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 92, train_loss = 1.9408287275582552, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 93, train_loss = 1.9266172249335796, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 94, train_loss = 1.9136346869636327, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 95, train_loss = 1.9005776431877166, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 96, train_loss = 1.888044324470684, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 97, train_loss = 1.875499812187627, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 98, train_loss = 1.8630769227165729, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 99, train_loss = 1.850466110976413, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 100, train_loss = 1.8392280396074057, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 101, train_loss = 1.827965896576643, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 102, train_loss = 1.816006300970912, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 103, train_loss = 1.805700010387227, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 104, train_loss = 1.7943569726776332, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 105, train_loss = 1.7849066245835274, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 106, train_loss = 1.7741837091743946, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 107, train_loss = 1.763809348223731, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 108, train_loss = 1.7544465635437518, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 109, train_loss = 1.7444947108160704, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 110, train_loss = 1.7343600254971534, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 111, train_loss = 1.7263809964060783, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 112, train_loss = 1.7169637146871537, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 113, train_loss = 1.708249791758135, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 114, train_loss = 1.699045430868864, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 115, train_loss = 1.6919595059007406, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 116, train_loss = 1.6828998897690326, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 117, train_loss = 1.6745698645245284, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 118, train_loss = 1.6666548170614988, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 119, train_loss = 1.6586536653339863, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 120, train_loss = 1.651374626206234, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 121, train_loss = 1.644174799323082, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 122, train_loss = 1.6361771554220468, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 123, train_loss = 1.6291338752489537, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 124, train_loss = 1.6220392815303057, train_acc = 0.9968560782487191\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 125, train_loss = 1.6151081162970513, train_acc = 0.9969725197950629\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 126, train_loss = 1.6081851057242602, train_acc = 0.9969725197950629\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 127, train_loss = 1.6016250904649496, train_acc = 0.9969725197950629\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 128, train_loss = 1.5947757188696414, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 129, train_loss = 1.5886707075405866, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 130, train_loss = 1.581935802474618, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 131, train_loss = 1.5760459352750331, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 132, train_loss = 1.5699912402778864, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 133, train_loss = 1.5629707139451057, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 134, train_loss = 1.5580071229487658, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 135, train_loss = 1.5518734592478722, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 136, train_loss = 1.5456218123435974, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 137, train_loss = 1.5400363572407514, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 138, train_loss = 1.5344542141538113, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 139, train_loss = 1.529324398143217, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 140, train_loss = 1.5233124252408743, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 141, train_loss = 1.5184187267441303, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 142, train_loss = 1.5128362334799021, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 143, train_loss = 1.507933359593153, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 144, train_loss = 1.5026480748783797, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 145, train_loss = 1.4979132569860667, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 146, train_loss = 1.4923815820366144, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 147, train_loss = 1.487522494746372, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 148, train_loss = 1.4829026882071048, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 149, train_loss = 1.477587535395287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 150, train_loss = 1.4732680296292529, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 151, train_loss = 1.468651640578173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 152, train_loss = 1.4635423409054056, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 153, train_loss = 1.459710213006474, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 154, train_loss = 1.4547110112616792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 155, train_loss = 1.4503488764166832, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 156, train_loss = 1.4465879375347868, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 157, train_loss = 1.4417136298725381, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 158, train_loss = 1.436783196986653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 159, train_loss = 1.433715634047985, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 160, train_loss = 1.4289554184069857, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 161, train_loss = 1.4248714646091685, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 162, train_loss = 1.4208871014416218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 163, train_loss = 1.4170913696289062, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 164, train_loss = 1.4133624719688669, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 165, train_loss = 1.408927240758203, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 166, train_loss = 1.4052212039241567, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 167, train_loss = 1.4014662392437458, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 168, train_loss = 1.397437276900746, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 169, train_loss = 1.3943044120678678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 170, train_loss = 1.3896871767938137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 171, train_loss = 1.3868062371620908, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 172, train_loss = 1.38328068703413, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 173, train_loss = 1.3794217283139005, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 174, train_loss = 1.3761450164020061, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 175, train_loss = 1.3727180026471615, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 176, train_loss = 1.3687046034028754, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 177, train_loss = 1.3658694351324812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 178, train_loss = 1.3621634095907211, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 179, train_loss = 1.3589781472692266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 180, train_loss = 1.355731020332314, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 181, train_loss = 1.3520467666676268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 182, train_loss = 1.3493192568421364, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 183, train_loss = 1.3457970494637266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 184, train_loss = 1.3426430920371786, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 185, train_loss = 1.339430283755064, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 186, train_loss = 1.336541622877121, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 187, train_loss = 1.333300298661925, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 188, train_loss = 1.3299037279793993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 189, train_loss = 1.327546313405037, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 190, train_loss = 1.3241826171288267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 191, train_loss = 1.3215886006364599, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 192, train_loss = 1.318400433869101, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 193, train_loss = 1.3155501708388329, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 194, train_loss = 1.312550508766435, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 195, train_loss = 1.3096505142748356, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 196, train_loss = 1.306707593263127, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 197, train_loss = 1.3041929254541174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 198, train_loss = 1.3013290973613039, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 199, train_loss = 1.2980692150304094, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 200, train_loss = 1.295529555529356, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 201, train_loss = 1.2924971841275692, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 202, train_loss = 1.2883366929600015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 203, train_loss = 1.2866407930850983, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 204, train_loss = 1.2835008142283186, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 205, train_loss = 1.2809372171759605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 206, train_loss = 1.2779302088310942, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 207, train_loss = 1.2752835924038664, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 208, train_loss = 1.2734798664459959, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 209, train_loss = 1.2699862407753244, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 210, train_loss = 1.2679523540427908, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 211, train_loss = 1.2657013088464737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 212, train_loss = 1.2626707131275907, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 213, train_loss = 1.2605081623187289, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 214, train_loss = 1.2580348761985078, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 215, train_loss = 1.2554263634374365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 216, train_loss = 1.2533492682268843, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 217, train_loss = 1.2511513171484694, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 218, train_loss = 1.2488219303777441, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 219, train_loss = 1.2463209690758958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 220, train_loss = 1.2437938811490312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 221, train_loss = 1.2419199062278494, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 222, train_loss = 1.2393448190996423, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 223, train_loss = 1.2371978299925104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 224, train_loss = 1.2352079065749422, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 225, train_loss = 1.2327888855943456, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 226, train_loss = 1.2306092344224453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 227, train_loss = 1.2289881892502308, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 228, train_loss = 1.226086862385273, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 229, train_loss = 1.2241914881160483, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 230, train_loss = 1.2216858913889155, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 231, train_loss = 1.2197969494154677, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 232, train_loss = 1.2180277133593336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 233, train_loss = 1.2162531614303589, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 234, train_loss = 1.2136512337019667, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 235, train_loss = 1.211615783511661, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 236, train_loss = 1.209903979091905, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 237, train_loss = 1.2074748364975676, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 238, train_loss = 1.2061748206615448, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 239, train_loss = 1.2030167293851264, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 240, train_loss = 1.201705988496542, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 241, train_loss = 1.1997804691200145, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 242, train_loss = 1.1978773375158198, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 243, train_loss = 1.1959502932731993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 244, train_loss = 1.1936005602474324, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 245, train_loss = 1.191997500776779, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 246, train_loss = 1.1902765234117396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 247, train_loss = 1.1880646112258546, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 248, train_loss = 1.1863426007330418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 249, train_loss = 1.1850154573912732, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 250, train_loss = 1.1824624786968343, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 251, train_loss = 1.1812776016886346, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 252, train_loss = 1.1791609923238866, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 253, train_loss = 1.1779180591111071, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 254, train_loss = 1.175723561376799, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 255, train_loss = 1.1740578028257005, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 256, train_loss = 1.1722456328570843, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 257, train_loss = 1.170692566782236, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 258, train_loss = 1.1685907778446563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 259, train_loss = 1.1674628145992756, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 260, train_loss = 1.1652339932625182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 261, train_loss = 1.1643158781225793, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 262, train_loss = 1.1618478745222092, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 263, train_loss = 1.1610646322369576, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 264, train_loss = 1.1590265830163844, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 265, train_loss = 1.1574874110519886, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 266, train_loss = 1.1556157320737839, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 267, train_loss = 1.1541925209457986, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 268, train_loss = 1.1525459389085881, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 269, train_loss = 1.1513868470792659, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 270, train_loss = 1.1491628661751747, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 271, train_loss = 1.1481163389980793, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 272, train_loss = 1.1461184434592724, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 273, train_loss = 1.1451674091513269, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 274, train_loss = 1.1426333412528038, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 275, train_loss = 1.1423880904912949, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 276, train_loss = 1.1401389713282697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 277, train_loss = 1.1391500395839103, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 278, train_loss = 1.137398177117575, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 279, train_loss = 1.135983704298269, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 280, train_loss = 1.134319080680143, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 281, train_loss = 1.132820809900295, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 282, train_loss = 1.1310362021322362, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 283, train_loss = 1.1301627196371555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 284, train_loss = 1.1285268006031401, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 285, train_loss = 1.1269066495005973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 286, train_loss = 1.1255770400166512, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 287, train_loss = 1.1241467644576915, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 288, train_loss = 1.122906765609514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 289, train_loss = 1.121706550300587, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 290, train_loss = 1.1202181937987916, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 291, train_loss = 1.119048221677076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 292, train_loss = 1.1172134702210315, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 293, train_loss = 1.1157637722790241, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 294, train_loss = 1.1142721797223203, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 295, train_loss = 1.1123787226970308, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 296, train_loss = 1.1116937473416328, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 297, train_loss = 1.110567172348965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 298, train_loss = 1.108452149957884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 299, train_loss = 1.107162928848993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 300, train_loss = 1.1062324084341526, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 301, train_loss = 1.1046915091574192, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 302, train_loss = 1.1034976367955096, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 303, train_loss = 1.101981233805418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 304, train_loss = 1.100844319909811, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 305, train_loss = 1.0994996639783494, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 306, train_loss = 1.098557848483324, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 307, train_loss = 1.0971185130183585, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 308, train_loss = 1.095956888049841, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 309, train_loss = 1.0940237107570283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 310, train_loss = 1.0938770174980164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 311, train_loss = 1.0919985274667852, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 312, train_loss = 1.0909624844789505, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 313, train_loss = 1.0895284612779506, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 314, train_loss = 1.0883441132609732, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 315, train_loss = 1.0869060468976386, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 316, train_loss = 1.0864922031760216, train_acc = 0.9973218444340941\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 317, train_loss = 1.0846310493652709, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 318, train_loss = 1.083781085908413, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 319, train_loss = 1.0823815874755383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 320, train_loss = 1.081322569400072, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 321, train_loss = 1.080130398273468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 322, train_loss = 1.0787054846878164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 323, train_loss = 1.0777720498736016, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 324, train_loss = 1.0769463616306894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 325, train_loss = 1.0752549667959101, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 326, train_loss = 1.0744789590244181, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 327, train_loss = 1.0736342743039131, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 328, train_loss = 1.0725792137091048, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 329, train_loss = 1.0707524729077704, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 330, train_loss = 1.069591914594639, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 331, train_loss = 1.0686268483405001, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 332, train_loss = 1.0679860127274878, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 333, train_loss = 1.0665096317534335, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 334, train_loss = 1.0655360159580596, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 335, train_loss = 1.0643007941544056, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 336, train_loss = 1.063436025113333, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 337, train_loss = 1.061808557540644, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 338, train_loss = 1.0609182342886925, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 339, train_loss = 1.0596533007919788, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 340, train_loss = 1.0586428281967528, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 341, train_loss = 1.0573254848713987, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 342, train_loss = 1.0565311424434185, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 343, train_loss = 1.0556974982027896, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 344, train_loss = 1.0549515125458129, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 345, train_loss = 1.0536399793927558, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 346, train_loss = 1.052745419263374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 347, train_loss = 1.0507063654367812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 348, train_loss = 1.051003793894779, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 349, train_loss = 1.0496508963406086, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 350, train_loss = 1.0488846438820474, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 351, train_loss = 1.0473652866785415, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 352, train_loss = 1.0466134175658226, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 353, train_loss = 1.0456683672964573, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 354, train_loss = 1.0449045983259566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 355, train_loss = 1.044069581956137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 356, train_loss = 1.0426408263738267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 357, train_loss = 1.0415979363024235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 358, train_loss = 1.0405853427946568, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 359, train_loss = 1.0400001294910908, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 360, train_loss = 1.0388062347774394, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 361, train_loss = 1.0380564195220359, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 362, train_loss = 1.036736823618412, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 363, train_loss = 1.0363837778568268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 364, train_loss = 1.0345610938966274, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 365, train_loss = 1.0344371174578555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 366, train_loss = 1.0330091652576812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 367, train_loss = 1.0325799360871315, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 368, train_loss = 1.031348982185591, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 369, train_loss = 1.0305163500015624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 370, train_loss = 1.0293626872007735, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 371, train_loss = 1.0284301328356378, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 372, train_loss = 1.0284386239945889, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 373, train_loss = 1.0263922872836702, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 374, train_loss = 1.0262394733726978, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 375, train_loss = 1.0247163648309652, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 376, train_loss = 1.0246582254767418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 377, train_loss = 1.0229774253966752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 378, train_loss = 1.0222829232516233, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 379, train_loss = 1.021485511213541, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 380, train_loss = 1.0208033757808153, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 381, train_loss = 1.019838926702505, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 382, train_loss = 1.0190003576281015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 383, train_loss = 1.0180564063193742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 384, train_loss = 1.0171898268163204, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 385, train_loss = 1.0164908915758133, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 386, train_loss = 1.0153884837927762, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 387, train_loss = 1.014930047094822, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 388, train_loss = 1.0138710662722588, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 389, train_loss = 1.0127202297153417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 390, train_loss = 1.012249513209099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 391, train_loss = 1.0110984543862287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 392, train_loss = 1.0109326938691083, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 393, train_loss = 1.009761663764948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 394, train_loss = 1.0091763846576214, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 395, train_loss = 1.0082651885750238, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 396, train_loss = 1.007096263259882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 397, train_loss = 1.0069794667360839, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 398, train_loss = 1.0051374720933381, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 399, train_loss = 1.004793235420948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 400, train_loss = 1.0043152595462743, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 401, train_loss = 1.0028021521866322, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 402, train_loss = 1.0023091062903404, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 403, train_loss = 1.0014553517103195, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 404, train_loss = 1.0008128186163958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 405, train_loss = 1.0005512634816114, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 406, train_loss = 0.99891746789217, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 407, train_loss = 0.9985651547613088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 408, train_loss = 0.9975534031691495, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 409, train_loss = 0.9971491570177022, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 410, train_loss = 0.9964605669083539, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 411, train_loss = 0.995665250957245, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 412, train_loss = 0.9948788782057818, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 413, train_loss = 0.993724811822176, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 414, train_loss = 0.9934637484548148, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 415, train_loss = 0.9926411956548691, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 416, train_loss = 0.9921874652209226, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 417, train_loss = 0.9903697048721369, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 418, train_loss = 0.9904319619236048, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 419, train_loss = 0.9891661033034325, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 420, train_loss = 0.9888276544807013, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 421, train_loss = 0.9879251569509506, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 422, train_loss = 0.9874844588339329, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 423, train_loss = 0.9867714072170202, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 424, train_loss = 0.9857624409196433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 425, train_loss = 0.9856334378418978, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 426, train_loss = 0.9839466425182763, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 427, train_loss = 0.9840309023857117, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 428, train_loss = 0.9829333561065141, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 429, train_loss = 0.9823036218585912, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 430, train_loss = 0.9815464367566165, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 431, train_loss = 0.9810014764370862, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 432, train_loss = 0.9800774355826434, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 433, train_loss = 0.9799008344707545, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 434, train_loss = 0.9782251094875392, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 435, train_loss = 0.978194173425436, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 436, train_loss = 0.977334982395405, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 437, train_loss = 0.9763724456133787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 438, train_loss = 0.9761945145728532, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 439, train_loss = 0.975119523704052, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 440, train_loss = 0.9747134471836034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 441, train_loss = 0.9733957412245218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 442, train_loss = 0.973397991299862, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 443, train_loss = 0.9727197749016341, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 444, train_loss = 0.9718932794930879, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 445, train_loss = 0.9713353179395199, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 446, train_loss = 0.9701818401517812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 447, train_loss = 0.9703519642353058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 448, train_loss = 0.9689968029560987, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 449, train_loss = 0.9687136709690094, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 450, train_loss = 0.9673893935978413, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 451, train_loss = 0.9672845353779849, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 452, train_loss = 0.9667661152780056, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 453, train_loss = 0.9658933766186237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 454, train_loss = 0.9655811861157417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 455, train_loss = 0.9650512387452181, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 456, train_loss = 0.9637230584921781, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 457, train_loss = 0.9630990475416183, train_acc = 0.9973218444340941\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 458, train_loss = 0.9624133408069611, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 459, train_loss = 0.9618952795863152, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 460, train_loss = 0.9621536234917585, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 461, train_loss = 0.9606394370493945, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 462, train_loss = 0.9604861438274384, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 463, train_loss = 0.9592828402819578, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 464, train_loss = 0.9592183406057302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 465, train_loss = 0.9579809730348643, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 466, train_loss = 0.9575864523649216, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 467, train_loss = 0.957470385968918, train_acc = 0.9974382859804378\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 468, train_loss = 0.9561154159309808, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 469, train_loss = 0.9560790695250034, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 470, train_loss = 0.9553897120058537, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 471, train_loss = 0.9548312313854694, train_acc = 0.9974382859804378\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 472, train_loss = 0.9540585540235043, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 473, train_loss = 0.9535395105776843, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 474, train_loss = 0.9528721695241984, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 475, train_loss = 0.9519395641982555, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 476, train_loss = 0.951933953911066, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 477, train_loss = 0.9503492129442748, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 478, train_loss = 0.9506391746399458, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 479, train_loss = 0.9488255990145262, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 480, train_loss = 0.948953952640295, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 481, train_loss = 0.9488395042717457, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 482, train_loss = 0.9475699576141778, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 483, train_loss = 0.9474756965937559, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 484, train_loss = 0.946965196490055, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 485, train_loss = 0.945882255822653, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 486, train_loss = 0.9451845685543958, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 487, train_loss = 0.9452827610075474, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 488, train_loss = 0.9441995757224504, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 489, train_loss = 0.943376287817955, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 490, train_loss = 0.9432247554359492, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 491, train_loss = 0.9426849658193532, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 492, train_loss = 0.9422272406518459, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 493, train_loss = 0.9412725195288658, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 494, train_loss = 0.9405877813696861, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 495, train_loss = 0.9406363579037134, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 496, train_loss = 0.9393588813545648, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 497, train_loss = 0.9389239586889744, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 498, train_loss = 0.9381351383926813, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 499, train_loss = 0.9379412308335304, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████▊       | 27/30 [4:29:20<29:58, 599.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "28th- epoch: 0, train_loss = 123.47101902961731, train_acc = 0.7782952957615277\n",
      "test Acc 0.8631284916201117:\n",
      "28th- epoch: 1, train_loss = 43.898209907114506, train_acc = 0.9108057755006986\n",
      "test Acc 0.9110800744878957:\n",
      "28th- epoch: 2, train_loss = 32.08491016179323, train_acc = 0.9351420586865393\n",
      "test Acc 0.9292364990689013:\n",
      "28th- epoch: 3, train_loss = 26.10694331675768, train_acc = 0.9479506287843502\n",
      "test Acc 0.9352886405959032:\n",
      "28th- epoch: 4, train_loss = 22.23122033290565, train_acc = 0.955985095482068\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 5, train_loss = 19.455635583028197, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 6, train_loss = 17.33907631598413, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 7, train_loss = 15.637904986739159, train_acc = 0.9691429902189101\n",
      "test Acc 0.952048417132216:\n",
      "28th- epoch: 8, train_loss = 14.231801381334662, train_acc = 0.972286911970191\n",
      "test Acc 0.957169459962756:\n",
      "28th- epoch: 9, train_loss = 13.034987952560186, train_acc = 0.9736842105263158\n",
      "test Acc 0.9590316573556797:\n",
      "28th- epoch: 10, train_loss = 12.019404992461205, train_acc = 0.9751979506287843\n",
      "test Acc 0.9608938547486033:\n",
      "28th- epoch: 11, train_loss = 11.146937320008874, train_acc = 0.9770610153702841\n",
      "test Acc 0.962756052141527:\n",
      "28th- epoch: 12, train_loss = 10.386306496337056, train_acc = 0.9784583139264089\n",
      "test Acc 0.9636871508379888:\n",
      "28th- epoch: 13, train_loss = 9.724141540005803, train_acc = 0.9798556124825337\n",
      "test Acc 0.9655493482309124:\n",
      "28th- epoch: 14, train_loss = 9.138616241514683, train_acc = 0.9813693525850024\n",
      "test Acc 0.9669459962756052:\n",
      "28th- epoch: 15, train_loss = 8.620052760466933, train_acc = 0.9835817419655333\n",
      "test Acc 0.9674115456238361:\n",
      "28th- epoch: 16, train_loss = 8.157574120908976, train_acc = 0.9847461574289706\n",
      "test Acc 0.9683426443202979:\n",
      "28th- epoch: 17, train_loss = 7.744712186977267, train_acc = 0.9853283651606893\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 18, train_loss = 7.369276240468025, train_acc = 0.9856776897997206\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 19, train_loss = 7.034236133098602, train_acc = 0.9862598975314392\n",
      "test Acc 0.9706703910614525:\n",
      "28th- epoch: 20, train_loss = 6.726676479913294, train_acc = 0.9868421052631579\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 21, train_loss = 6.4484753124415874, train_acc = 0.9876571960875641\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 22, train_loss = 6.193442314863205, train_acc = 0.9880065207265952\n",
      "test Acc 0.9716014897579144:\n",
      "28th- epoch: 23, train_loss = 5.957362688146532, train_acc = 0.9889380530973452\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 24, train_loss = 5.7406378807500005, train_acc = 0.9890544946436889\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 25, train_loss = 5.541608411818743, train_acc = 0.989869585468095\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 26, train_loss = 5.3532640459015965, train_acc = 0.99033535165347\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 27, train_loss = 5.179383737966418, train_acc = 0.9906846762925011\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 28, train_loss = 5.015351512469351, train_acc = 0.9909175593851887\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 29, train_loss = 4.863601409830153, train_acc = 0.9912668840242198\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 30, train_loss = 4.721296943724155, train_acc = 0.9914997671169073\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 31, train_loss = 4.584989489987493, train_acc = 0.992081974848626\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 32, train_loss = 4.4594960222020745, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 33, train_loss = 4.339955562725663, train_acc = 0.9924312994876572\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 34, train_loss = 4.2275386936962605, train_acc = 0.9925477410340009\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 35, train_loss = 4.121841671876609, train_acc = 0.9926641825803446\n",
      "test Acc 0.9725325884543762:\n",
      "28th- epoch: 36, train_loss = 4.021352498792112, train_acc = 0.9927806241266884\n",
      "test Acc 0.9725325884543762:\n",
      "28th- epoch: 37, train_loss = 3.9270527167245746, train_acc = 0.9927806241266884\n",
      "test Acc 0.9725325884543762:\n",
      "28th- epoch: 38, train_loss = 3.837097921874374, train_acc = 0.9928970656730322\n",
      "test Acc 0.9725325884543762:\n",
      "28th- epoch: 39, train_loss = 3.751284260302782, train_acc = 0.9931299487657196\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 40, train_loss = 3.672220923472196, train_acc = 0.9933628318584071\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 41, train_loss = 3.5937583185732365, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 42, train_loss = 3.521772019099444, train_acc = 0.9935957149510946\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 43, train_loss = 3.4506568051874638, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 44, train_loss = 3.384988105390221, train_acc = 0.9937121564974383\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 45, train_loss = 3.319704645778984, train_acc = 0.9937121564974383\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 46, train_loss = 3.259224279318005, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 47, train_loss = 3.2023852462880313, train_acc = 0.9940614811364695\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 48, train_loss = 3.1456998200155795, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 49, train_loss = 3.09350050566718, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 50, train_loss = 3.043763858731836, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 51, train_loss = 2.9944789391011, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 52, train_loss = 2.9465596601366997, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 53, train_loss = 2.9042730177752674, train_acc = 0.9951094550535631\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 54, train_loss = 2.860805235337466, train_acc = 0.9951094550535631\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 55, train_loss = 2.819217186421156, train_acc = 0.9951094550535631\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 56, train_loss = 2.7793474211357534, train_acc = 0.9951094550535631\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 57, train_loss = 2.741385019849986, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 58, train_loss = 2.704552883282304, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 59, train_loss = 2.6697594695724547, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 60, train_loss = 2.6355204973369837, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 61, train_loss = 2.6014361307024956, train_acc = 0.9958081043316255\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 62, train_loss = 2.5704531692899764, train_acc = 0.9958081043316255\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 63, train_loss = 2.539715317543596, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 64, train_loss = 2.5099705210886896, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 65, train_loss = 2.4808508404530585, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 66, train_loss = 2.454541916726157, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 67, train_loss = 2.4270615179557353, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 68, train_loss = 2.4014437969308347, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 69, train_loss = 2.37690833886154, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 70, train_loss = 2.3523517053108662, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 71, train_loss = 2.3303665530402213, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 72, train_loss = 2.3079240929801017, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 73, train_loss = 2.285239716991782, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 74, train_loss = 2.264702696353197, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 75, train_loss = 2.243790162028745, train_acc = 0.9962738705170004\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 76, train_loss = 2.2246476139407605, train_acc = 0.9962738705170004\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 77, train_loss = 2.2046750150620937, train_acc = 0.9963903120633442\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 78, train_loss = 2.18587909755297, train_acc = 0.9963903120633442\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 79, train_loss = 2.167490169405937, train_acc = 0.996506753609688\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 80, train_loss = 2.1501876313704997, train_acc = 0.9963903120633442\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 81, train_loss = 2.1318920701742172, train_acc = 0.996506753609688\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 82, train_loss = 2.115166687173769, train_acc = 0.996506753609688\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 83, train_loss = 2.0996030245441943, train_acc = 0.996506753609688\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 84, train_loss = 2.083099264651537, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 85, train_loss = 2.067754350602627, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 86, train_loss = 2.052017867565155, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 87, train_loss = 2.036643970757723, train_acc = 0.9966231951560317\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 88, train_loss = 2.0235541209112853, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 89, train_loss = 2.008886874653399, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 90, train_loss = 1.9961486586835235, train_acc = 0.996506753609688\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 91, train_loss = 1.9811006309464574, train_acc = 0.9966231951560317\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 92, train_loss = 1.968214303953573, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 93, train_loss = 1.955831978470087, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 94, train_loss = 1.9421888440847397, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 95, train_loss = 1.9306005390826613, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 96, train_loss = 1.918399376096204, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 97, train_loss = 1.9068823410198092, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 98, train_loss = 1.8953197745140642, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 99, train_loss = 1.8841328972484916, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 100, train_loss = 1.8736576607916504, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 101, train_loss = 1.8628586183767766, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 102, train_loss = 1.8520493181422353, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 103, train_loss = 1.842146741808392, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 104, train_loss = 1.8321023458847776, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 105, train_loss = 1.8217618024209514, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 106, train_loss = 1.812594429240562, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 107, train_loss = 1.8028877867618576, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 108, train_loss = 1.794113602489233, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 109, train_loss = 1.7847139468649402, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 110, train_loss = 1.7766164342174307, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 111, train_loss = 1.766897969529964, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 112, train_loss = 1.7586287135491148, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 113, train_loss = 1.750909484922886, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 114, train_loss = 1.7420333238551393, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 115, train_loss = 1.7334710011491552, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 116, train_loss = 1.7259615963557735, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 117, train_loss = 1.7179758064448833, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 118, train_loss = 1.7104355990886688, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 119, train_loss = 1.7027244120836258, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 120, train_loss = 1.6950862830271944, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 121, train_loss = 1.6877201031893492, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 122, train_loss = 1.681156032369472, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 123, train_loss = 1.6728925798088312, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 124, train_loss = 1.6667742313584313, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 125, train_loss = 1.6588091099401936, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 126, train_loss = 1.652319679618813, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 127, train_loss = 1.6455952891847119, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 128, train_loss = 1.6392629960319027, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 129, train_loss = 1.6325598489493132, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 130, train_loss = 1.6265992453554645, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 131, train_loss = 1.619305252446793, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 132, train_loss = 1.6144286742201075, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 133, train_loss = 1.6081270407885313, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 134, train_loss = 1.6023451859364286, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 135, train_loss = 1.5956564353546128, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 136, train_loss = 1.590751780779101, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 137, train_loss = 1.5846791360527277, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 138, train_loss = 1.578895067796111, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 139, train_loss = 1.5739271392812952, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 140, train_loss = 1.5674124056240544, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 141, train_loss = 1.5631189992418513, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 142, train_loss = 1.5573476565768942, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 143, train_loss = 1.5527005977928638, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 144, train_loss = 1.5466177426278591, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 145, train_loss = 1.5419040335109457, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 146, train_loss = 1.5371391406515613, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 147, train_loss = 1.5315421937266365, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 148, train_loss = 1.5265132244676352, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 149, train_loss = 1.5219339666655287, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 150, train_loss = 1.5178879337618127, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 151, train_loss = 1.5121434709290043, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 152, train_loss = 1.5086986651876941, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 153, train_loss = 1.5035695662954822, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 154, train_loss = 1.4984728383133188, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 155, train_loss = 1.4953510096529499, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 156, train_loss = 1.490013183443807, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 157, train_loss = 1.4862103847553954, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 158, train_loss = 1.48136322631035, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 159, train_loss = 1.4776387339225039, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 160, train_loss = 1.47280827537179, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 161, train_loss = 1.4691202441463247, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 162, train_loss = 1.4656351382145658, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 163, train_loss = 1.460141610354185, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 164, train_loss = 1.4574581725755706, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 165, train_loss = 1.4529438050230965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 166, train_loss = 1.4492911217967048, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 167, train_loss = 1.4452036414295435, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 168, train_loss = 1.4416184624424204, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 169, train_loss = 1.4383783787488937, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 170, train_loss = 1.4334875451168045, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 171, train_loss = 1.4304456351092085, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 172, train_loss = 1.4266334188869223, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 173, train_loss = 1.4230310624698177, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 174, train_loss = 1.4192459589685313, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 175, train_loss = 1.4160760721424595, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 176, train_loss = 1.4128071535378695, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 177, train_loss = 1.4085362975602038, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 178, train_loss = 1.4058302237535827, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 179, train_loss = 1.4020473565906286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 180, train_loss = 1.3988087549805641, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 181, train_loss = 1.3956549422000535, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 182, train_loss = 1.392314463853836, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 183, train_loss = 1.3881931696087122, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 184, train_loss = 1.3861823920160532, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 185, train_loss = 1.3823501777951606, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 186, train_loss = 1.3796726173604839, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 187, train_loss = 1.3760017435997725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 188, train_loss = 1.3731968223000877, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 189, train_loss = 1.370417324185837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 190, train_loss = 1.3665663562715054, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 191, train_loss = 1.3639320681686513, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 192, train_loss = 1.3607057115877979, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 193, train_loss = 1.3576247220044024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 194, train_loss = 1.3545995925669558, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 195, train_loss = 1.3520949687808752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 196, train_loss = 1.3492138367146254, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 197, train_loss = 1.3460026439279318, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 198, train_loss = 1.3434851777856238, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 199, train_loss = 1.340772119059693, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 200, train_loss = 1.33709155023098, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 201, train_loss = 1.3353319491143338, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 202, train_loss = 1.3325434059952386, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 203, train_loss = 1.3283009330625646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 204, train_loss = 1.3262929606135003, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 205, train_loss = 1.3238068235223182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 206, train_loss = 1.321026673540473, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 207, train_loss = 1.3188966705347411, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 208, train_loss = 1.3160662166774273, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 209, train_loss = 1.3128170780837536, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 210, train_loss = 1.3103362235124223, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 211, train_loss = 1.30858924734639, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 212, train_loss = 1.3053703817422502, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 213, train_loss = 1.3024952486157417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 214, train_loss = 1.3014347553253174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 215, train_loss = 1.2983973932568915, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 216, train_loss = 1.2952415496110916, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 217, train_loss = 1.2931025897269137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 218, train_loss = 1.290599664032925, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 219, train_loss = 1.2891997545957565, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 220, train_loss = 1.285882256925106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 221, train_loss = 1.2833266953821294, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 222, train_loss = 1.2811988231842406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 223, train_loss = 1.2792964242398739, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 224, train_loss = 1.2764750855858438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 225, train_loss = 1.2743275699322112, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 226, train_loss = 1.2723454609513283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 227, train_loss = 1.2695315939490683, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 228, train_loss = 1.2672297109966166, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 229, train_loss = 1.2654598355293274, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 230, train_loss = 1.2626989570562728, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 231, train_loss = 1.2610314413905144, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 232, train_loss = 1.2585083109443076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 233, train_loss = 1.2563291266560555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 234, train_loss = 1.2536306381225586, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 235, train_loss = 1.2516095328028314, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 236, train_loss = 1.2501202535931952, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 237, train_loss = 1.2477675986592658, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 238, train_loss = 1.2457541078329086, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 239, train_loss = 1.2433470475370996, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 240, train_loss = 1.241845741868019, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 241, train_loss = 1.2391929291188717, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 242, train_loss = 1.2371209748089314, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 243, train_loss = 1.2344492301344872, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 244, train_loss = 1.233539608598221, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 245, train_loss = 1.230522695928812, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 246, train_loss = 1.2295878405566327, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 247, train_loss = 1.2271756306290627, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 248, train_loss = 1.2243932497804053, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 249, train_loss = 1.2236065429751761, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 250, train_loss = 1.2211809965665452, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 251, train_loss = 1.2183041970129125, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 252, train_loss = 1.2177733319695108, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 253, train_loss = 1.2151527131791227, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 254, train_loss = 1.2136434118147008, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 255, train_loss = 1.211583886295557, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 256, train_loss = 1.2094534722273238, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 257, train_loss = 1.2078292829100974, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 258, train_loss = 1.205932053446304, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 259, train_loss = 1.2033791926805861, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 260, train_loss = 1.2012390457093716, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 261, train_loss = 1.2007943031494506, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 262, train_loss = 1.1991123706102371, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 263, train_loss = 1.1960128781502135, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 264, train_loss = 1.1949655376374722, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 265, train_loss = 1.193161555856932, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 266, train_loss = 1.1907994846696965, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 267, train_loss = 1.1887533304397948, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 268, train_loss = 1.1877872521872632, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 269, train_loss = 1.1852474312181585, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 270, train_loss = 1.1838671527802944, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 271, train_loss = 1.1814536030287854, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 272, train_loss = 1.180859923362732, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 273, train_loss = 1.178291019052267, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 274, train_loss = 1.1763530522584915, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 275, train_loss = 1.1742934957146645, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 276, train_loss = 1.173067208379507, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 277, train_loss = 1.1710516872699372, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 278, train_loss = 1.168929626524914, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 279, train_loss = 1.167590967088472, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 280, train_loss = 1.166233103722334, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 281, train_loss = 1.1645222107763402, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 282, train_loss = 1.162891702086199, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 283, train_loss = 1.1612613362376578, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 284, train_loss = 1.1603799611330032, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 285, train_loss = 1.1575807146728039, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 286, train_loss = 1.156876855820883, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 287, train_loss = 1.1546382829546928, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 288, train_loss = 1.1536444127559662, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 289, train_loss = 1.1517420920426957, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 290, train_loss = 1.1501714761252515, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 291, train_loss = 1.149646234989632, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 292, train_loss = 1.1472141544218175, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 293, train_loss = 1.1462262024288066, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 294, train_loss = 1.1445267188246362, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 295, train_loss = 1.1430235877633095, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 296, train_loss = 1.141221794008743, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 297, train_loss = 1.1401268243789673, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 298, train_loss = 1.1393849961459637, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 299, train_loss = 1.1378368201549165, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 300, train_loss = 1.1355124625260942, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 301, train_loss = 1.134385820478201, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 302, train_loss = 1.133472554385662, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 303, train_loss = 1.1319302842020988, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 304, train_loss = 1.1300226251187269, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 305, train_loss = 1.1291877403855324, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 306, train_loss = 1.1279989331960678, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 307, train_loss = 1.1269123603997286, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 308, train_loss = 1.1250646188855171, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 309, train_loss = 1.1230475567281246, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 310, train_loss = 1.1224154805240687, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 311, train_loss = 1.1210177043976728, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 312, train_loss = 1.1194244412181433, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 313, train_loss = 1.1180729729530867, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 314, train_loss = 1.117062646895647, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 315, train_loss = 1.1158491360547487, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 316, train_loss = 1.1137939468026161, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 317, train_loss = 1.1130262538790703, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 318, train_loss = 1.1119677486422006, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 319, train_loss = 1.109978437423706, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 320, train_loss = 1.10881014043116, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 321, train_loss = 1.1077583158912603, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 322, train_loss = 1.1066393665969372, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 323, train_loss = 1.10501934462809, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 324, train_loss = 1.1040039310755674, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 325, train_loss = 1.1028408085403498, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 326, train_loss = 1.1015460515918676, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 327, train_loss = 1.0999635942280293, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 328, train_loss = 1.0984077764151152, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 329, train_loss = 1.0977382262644824, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 330, train_loss = 1.096562954277033, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 331, train_loss = 1.095635775476694, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 332, train_loss = 1.0948714961705264, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 333, train_loss = 1.092571746557951, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 334, train_loss = 1.0916713600454386, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 335, train_loss = 1.0906975579855498, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 336, train_loss = 1.089575724065071, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 337, train_loss = 1.0886217752995435, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 338, train_loss = 1.086533614754444, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 339, train_loss = 1.0860141230223235, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 340, train_loss = 1.0842023330333177, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 341, train_loss = 1.0837163726391736, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 342, train_loss = 1.0818326684238855, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 343, train_loss = 1.0811044449510518, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 344, train_loss = 1.0802612403931562, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 345, train_loss = 1.0784242438676301, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 346, train_loss = 1.0774477621016558, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 347, train_loss = 1.0764312222599983, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 348, train_loss = 1.0749668987991754, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 349, train_loss = 1.0741775520145893, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 350, train_loss = 1.072567847877508, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 351, train_loss = 1.072258642554516, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 352, train_loss = 1.0710817947983742, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 353, train_loss = 1.070238088577753, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 354, train_loss = 1.0679221016762313, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 355, train_loss = 1.067507485538954, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 356, train_loss = 1.06677676239633, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 357, train_loss = 1.0653218738734722, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 358, train_loss = 1.063625077396864, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 359, train_loss = 1.0629083067178726, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 360, train_loss = 1.0625221928057726, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 361, train_loss = 1.0610935675504152, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 362, train_loss = 1.0602252557873726, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 363, train_loss = 1.058395553380251, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 364, train_loss = 1.0577421821653843, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 365, train_loss = 1.0569281627831515, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 366, train_loss = 1.0553890876471996, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 367, train_loss = 1.0545241236686707, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 368, train_loss = 1.0537212751805782, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 369, train_loss = 1.0533604423108045, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 370, train_loss = 1.051661528646946, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 371, train_loss = 1.0507485332491342, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 372, train_loss = 1.0493876996042673, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 373, train_loss = 1.0484000655415002, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 374, train_loss = 1.0480471874179784, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 375, train_loss = 1.0472900519671384, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 376, train_loss = 1.045098348200554, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 377, train_loss = 1.045139666646719, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 378, train_loss = 1.043330118060112, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 379, train_loss = 1.0435216538608074, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 380, train_loss = 1.0414780589344446, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 381, train_loss = 1.0410968264041003, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 382, train_loss = 1.039916381239891, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 383, train_loss = 1.0384591730835382, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 384, train_loss = 1.0380393601953983, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 385, train_loss = 1.036833543330431, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 386, train_loss = 1.036177116126055, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 387, train_loss = 1.0351019191148225, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 388, train_loss = 1.034288934111828, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 389, train_loss = 1.0331981827912387, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 390, train_loss = 1.0323691219091415, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 391, train_loss = 1.0315459718403872, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 392, train_loss = 1.0303415693342686, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 393, train_loss = 1.0295062536897603, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 394, train_loss = 1.0286985424754675, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 395, train_loss = 1.0268647757766303, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 396, train_loss = 1.026925786078209, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 397, train_loss = 1.0261364603939, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 398, train_loss = 1.0244801069202367, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 399, train_loss = 1.0239484161138535, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 400, train_loss = 1.0237001540663186, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 401, train_loss = 1.0217380610702094, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 402, train_loss = 1.0221593317983206, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 403, train_loss = 1.020970248937374, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 404, train_loss = 1.0193790954945143, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 405, train_loss = 1.0186551672813948, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 406, train_loss = 1.0182830914855003, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 407, train_loss = 1.0171267738041934, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 408, train_loss = 1.015894714742899, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 409, train_loss = 1.0155570482311305, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 410, train_loss = 1.0146497947571333, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 411, train_loss = 1.0137280660273973, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 412, train_loss = 1.0122176172735635, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 413, train_loss = 1.0122429293987807, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 414, train_loss = 1.011653291672701, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 415, train_loss = 1.0102052365837153, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 416, train_loss = 1.0090588169696275, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 417, train_loss = 1.0083868131041527, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 418, train_loss = 1.0077650075254496, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 419, train_loss = 1.006956239551073, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 420, train_loss = 1.0060945451259613, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 421, train_loss = 1.0050224214792252, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 422, train_loss = 1.0044997222721577, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 423, train_loss = 1.003256412834162, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 424, train_loss = 1.003026810794836, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 425, train_loss = 1.002270832657814, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 426, train_loss = 1.001473213225836, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 427, train_loss = 1.0001911334693432, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 428, train_loss = 0.9998440891504288, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 429, train_loss = 0.9985784962773323, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 430, train_loss = 0.9977226456103381, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 431, train_loss = 0.9975384486315306, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 432, train_loss = 0.9969048885104712, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 433, train_loss = 0.9957954896090087, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 434, train_loss = 0.9944239208998624, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 435, train_loss = 0.9945667423307896, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 436, train_loss = 0.9934141747653484, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 437, train_loss = 0.992772309720749, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 438, train_loss = 0.9915085310640279, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 439, train_loss = 0.9913293483259622, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 440, train_loss = 0.9905721681716386, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 441, train_loss = 0.9894275541009847, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 442, train_loss = 0.988519156962866, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 443, train_loss = 0.9879535399377346, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 444, train_loss = 0.9871546886861324, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 445, train_loss = 0.9866179650125559, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 446, train_loss = 0.9856634587049484, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 447, train_loss = 0.9852564409375191, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 448, train_loss = 0.9842071744205896, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 449, train_loss = 0.9839968457818031, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 450, train_loss = 0.982322341442341, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 451, train_loss = 0.9823421016335487, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 452, train_loss = 0.9814226627349854, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 453, train_loss = 0.9806920675036963, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 454, train_loss = 0.980137538164854, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 455, train_loss = 0.9793509480950888, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 456, train_loss = 0.9786244916322175, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 457, train_loss = 0.9779713787138462, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 458, train_loss = 0.9768007335660513, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 459, train_loss = 0.9765064703824464, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 460, train_loss = 0.9757778508064803, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 461, train_loss = 0.9750696569681168, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 462, train_loss = 0.9738878458738327, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 463, train_loss = 0.973985243588686, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 464, train_loss = 0.9728670120239258, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 465, train_loss = 0.9722106121480465, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 466, train_loss = 0.971570186316967, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 467, train_loss = 0.9710291388037149, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 468, train_loss = 0.9702636438014451, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 469, train_loss = 0.9694052152335644, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 470, train_loss = 0.9688918305037078, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 471, train_loss = 0.9682825493218843, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 472, train_loss = 0.9669234777393285, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 473, train_loss = 0.9666571989655495, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 474, train_loss = 0.9659757067856845, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 475, train_loss = 0.9661512312886771, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 476, train_loss = 0.9643171677889768, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 477, train_loss = 0.9643771027622279, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 478, train_loss = 0.9633994661271572, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 479, train_loss = 0.9632511759700719, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 480, train_loss = 0.961640248686308, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 481, train_loss = 0.961729316652054, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 482, train_loss = 0.9608144375088159, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 483, train_loss = 0.9601236768066883, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 484, train_loss = 0.9600883734819945, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 485, train_loss = 0.9586868546903133, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 486, train_loss = 0.9584172355534974, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 487, train_loss = 0.9579176964762155, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 488, train_loss = 0.9565398581326008, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 489, train_loss = 0.9563406904635485, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 490, train_loss = 0.9556866598722991, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 491, train_loss = 0.9549896108510438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 492, train_loss = 0.9542487797734793, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 493, train_loss = 0.9536605253815651, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 494, train_loss = 0.9529112242162228, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 495, train_loss = 0.9524424957635347, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 496, train_loss = 0.9515791249868926, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 497, train_loss = 0.9515850233437959, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 498, train_loss = 0.9504169821739197, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 499, train_loss = 0.9506169023516122, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████▏    | 28/30 [4:38:13<19:19, 579.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "29th- epoch: 0, train_loss = 124.39278297126293, train_acc = 0.7633907778295296\n",
      "test Acc 0.8649906890130353:\n",
      "29th- epoch: 1, train_loss = 41.68598657846451, train_acc = 0.9151141127154169\n",
      "test Acc 0.9129422718808193:\n",
      "29th- epoch: 2, train_loss = 30.06034354865551, train_acc = 0.9380530973451328\n",
      "test Acc 0.9352886405959032:\n",
      "29th- epoch: 3, train_loss = 24.272865671664476, train_acc = 0.9485328365160689\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 4, train_loss = 20.51719507202506, train_acc = 0.9563344201210993\n",
      "test Acc 0.9501862197392924:\n",
      "29th- epoch: 5, train_loss = 17.85262414626777, train_acc = 0.9608756404285049\n",
      "test Acc 0.9548417132216015:\n",
      "29th- epoch: 6, train_loss = 15.835155384615064, train_acc = 0.966115510013973\n",
      "test Acc 0.957169459962756:\n",
      "29th- epoch: 7, train_loss = 14.266187865287066, train_acc = 0.9694923148579413\n",
      "test Acc 0.9594972067039106:\n",
      "29th- epoch: 8, train_loss = 12.994339749217033, train_acc = 0.9725197950628784\n",
      "test Acc 0.962756052141527:\n",
      "29th- epoch: 9, train_loss = 11.93705990538001, train_acc = 0.9756637168141593\n",
      "test Acc 0.9632216014897579:\n",
      "29th- epoch: 10, train_loss = 11.043940728530288, train_acc = 0.977992547741034\n",
      "test Acc 0.9646182495344506:\n",
      "29th- epoch: 11, train_loss = 10.277840545400977, train_acc = 0.9792734047508151\n",
      "test Acc 0.9646182495344506:\n",
      "29th- epoch: 12, train_loss = 9.61549837142229, train_acc = 0.9804378202142524\n",
      "test Acc 0.9660148975791434:\n",
      "29th- epoch: 13, train_loss = 9.034247180446982, train_acc = 0.9820680018630648\n",
      "test Acc 0.9664804469273743:\n",
      "29th- epoch: 14, train_loss = 8.516201420687139, train_acc = 0.9831159757801584\n",
      "test Acc 0.9664804469273743:\n",
      "29th- epoch: 15, train_loss = 8.058538790792227, train_acc = 0.9839310666045645\n",
      "test Acc 0.9674115456238361:\n",
      "29th- epoch: 16, train_loss = 7.640021960251033, train_acc = 0.985444806707033\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 17, train_loss = 7.265056811273098, train_acc = 0.986376339077783\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 18, train_loss = 6.929706208407879, train_acc = 0.9875407545412203\n",
      "test Acc 0.9688081936685289:\n",
      "29th- epoch: 19, train_loss = 6.624286697246134, train_acc = 0.9880065207265952\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 20, train_loss = 6.3434236375615, train_acc = 0.9888216115510013\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 21, train_loss = 6.087977047078311, train_acc = 0.98940381928272\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 22, train_loss = 5.8523382022976875, train_acc = 0.99033535165347\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 23, train_loss = 5.6363997692242265, train_acc = 0.9906846762925011\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 24, train_loss = 5.4375501880422235, train_acc = 0.9909175593851887\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 25, train_loss = 5.25195175036788, train_acc = 0.9911504424778761\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 26, train_loss = 5.081598510034382, train_acc = 0.9916162086632511\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 27, train_loss = 4.922555063851178, train_acc = 0.9919655333022822\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 28, train_loss = 4.774887326173484, train_acc = 0.9925477410340009\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 29, train_loss = 4.636991293169558, train_acc = 0.9928970656730322\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 30, train_loss = 4.508318939246237, train_acc = 0.9931299487657196\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 31, train_loss = 4.385428306646645, train_acc = 0.9933628318584071\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 32, train_loss = 4.272336565889418, train_acc = 0.9935957149510946\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 33, train_loss = 4.165346508380026, train_acc = 0.993828598043782\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 34, train_loss = 4.064415397588164, train_acc = 0.9940614811364695\n",
      "test Acc 0.9720670391061452:\n",
      "29th- epoch: 35, train_loss = 3.96888759592548, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "29th- epoch: 36, train_loss = 3.8785500414669514, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 37, train_loss = 3.7956921495497227, train_acc = 0.994294364229157\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 38, train_loss = 3.7150653661228716, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 39, train_loss = 3.638379342854023, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 40, train_loss = 3.5667049437761307, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "29th- epoch: 41, train_loss = 3.499963991343975, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "29th- epoch: 42, train_loss = 3.4347092718817294, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 43, train_loss = 3.3734284676611423, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 44, train_loss = 3.3136527077294886, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 45, train_loss = 3.2572146602906287, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 46, train_loss = 3.2027448914013803, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 47, train_loss = 3.1499875648878515, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 48, train_loss = 3.099431478884071, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 49, train_loss = 3.0508931018412113, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 50, train_loss = 3.0045585460029542, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 51, train_loss = 2.9594304808415473, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 52, train_loss = 2.9172857492230833, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 53, train_loss = 2.8738605491816998, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 54, train_loss = 2.8339434913359582, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 55, train_loss = 2.7940818131901324, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 56, train_loss = 2.7575262277387083, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 57, train_loss = 2.7207813845016062, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 58, train_loss = 2.6858247122727334, train_acc = 0.9962738705170004\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 59, train_loss = 2.652232486754656, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 60, train_loss = 2.619357703719288, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 61, train_loss = 2.587516857776791, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 62, train_loss = 2.557266062591225, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 63, train_loss = 2.5266617871820927, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 64, train_loss = 2.4982814961113036, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 65, train_loss = 2.4690665751695633, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 66, train_loss = 2.4420180222950876, train_acc = 0.9962738705170004\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 67, train_loss = 2.4163324958644807, train_acc = 0.9963903120633442\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 68, train_loss = 2.3897001568693668, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 69, train_loss = 2.3644098739605397, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 70, train_loss = 2.3410301331896335, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 71, train_loss = 2.316216976614669, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 72, train_loss = 2.2946379221975803, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 73, train_loss = 2.271172559587285, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 74, train_loss = 2.24982359749265, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 75, train_loss = 2.2292657557409257, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 76, train_loss = 2.2083958461880684, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 77, train_loss = 2.188626794843003, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 78, train_loss = 2.16979664680548, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 79, train_loss = 2.1509899348020554, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 80, train_loss = 2.1328440867364407, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 81, train_loss = 2.1147164031863213, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 82, train_loss = 2.0978552512824535, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 83, train_loss = 2.080388467758894, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 84, train_loss = 2.0645880103111267, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 85, train_loss = 2.047767274081707, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 86, train_loss = 2.0329580642282963, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 87, train_loss = 2.0175789047498256, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 88, train_loss = 2.002000207779929, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 89, train_loss = 1.9878608137369156, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 90, train_loss = 1.9737698410172015, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 91, train_loss = 1.9600015580654144, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 92, train_loss = 1.9469149957876652, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 93, train_loss = 1.9334292386192828, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 94, train_loss = 1.9208357085008174, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 95, train_loss = 1.9077282522339374, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 96, train_loss = 1.895448473514989, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 97, train_loss = 1.8836004186887294, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 98, train_loss = 1.8713153016287833, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 99, train_loss = 1.8606545850634575, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 100, train_loss = 1.849221410928294, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 101, train_loss = 1.8380426864605397, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 102, train_loss = 1.8275521136820316, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 103, train_loss = 1.8165823940653354, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 104, train_loss = 1.8067787860054523, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 105, train_loss = 1.7963462744373828, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 106, train_loss = 1.7871341046411544, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 107, train_loss = 1.7768575486261398, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 108, train_loss = 1.7671619441825897, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 109, train_loss = 1.7588540825527161, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 110, train_loss = 1.7489281732123345, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 111, train_loss = 1.7399453360121697, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 112, train_loss = 1.7308604654390365, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 113, train_loss = 1.7222868402022868, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 114, train_loss = 1.7138487286865711, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 115, train_loss = 1.7055687617976218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 116, train_loss = 1.697467040270567, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 117, train_loss = 1.6889369140844792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 118, train_loss = 1.6813549734652042, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 119, train_loss = 1.673057669075206, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 120, train_loss = 1.665559347718954, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 121, train_loss = 1.6574629594106227, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 122, train_loss = 1.6508637107908726, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 123, train_loss = 1.6432053856551647, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 124, train_loss = 1.6361537426710129, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 125, train_loss = 1.6292480813572183, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 126, train_loss = 1.6217820917954668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 127, train_loss = 1.615188855677843, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 128, train_loss = 1.6081944977631792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 129, train_loss = 1.602388812811114, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 130, train_loss = 1.5956001728773117, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 131, train_loss = 1.589369056164287, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 132, train_loss = 1.5833249861607328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 133, train_loss = 1.5767508210847154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 134, train_loss = 1.5711497677257285, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 135, train_loss = 1.5650768479099497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 136, train_loss = 1.559622502536513, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 137, train_loss = 1.5531503284582868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 138, train_loss = 1.548397765844129, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 139, train_loss = 1.5422546690097079, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 140, train_loss = 1.5369211559882388, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 141, train_loss = 1.5315297531196848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 142, train_loss = 1.5261836213758215, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 143, train_loss = 1.5207952732453123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 144, train_loss = 1.5159420780837536, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 145, train_loss = 1.5105675620725378, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 146, train_loss = 1.5058959648013115, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 147, train_loss = 1.5009861724684015, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 148, train_loss = 1.4959180740406737, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 149, train_loss = 1.4911636946490034, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 150, train_loss = 1.4866319857537746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 151, train_loss = 1.4814726511249319, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 152, train_loss = 1.4775034511694685, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 153, train_loss = 1.4724133176496252, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 154, train_loss = 1.467881960212253, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 155, train_loss = 1.464131603599526, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 156, train_loss = 1.4593569251010194, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 157, train_loss = 1.4548474414041266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 158, train_loss = 1.450805153697729, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 159, train_loss = 1.446778236539103, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 160, train_loss = 1.4425313770771027, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 161, train_loss = 1.4380728267133236, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 162, train_loss = 1.4345682300627232, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 163, train_loss = 1.4301876971730962, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 164, train_loss = 1.4267871478805318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 165, train_loss = 1.422535845427774, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 166, train_loss = 1.4186493480810896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 167, train_loss = 1.4148491272935644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 168, train_loss = 1.4112840183079243, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 169, train_loss = 1.4075119607150555, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 170, train_loss = 1.4036227712640539, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 171, train_loss = 1.4002947881817818, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 172, train_loss = 1.3963569005718455, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 173, train_loss = 1.3928883584449068, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 174, train_loss = 1.389372387318872, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 175, train_loss = 1.3861651172628626, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 176, train_loss = 1.382653390406631, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 177, train_loss = 1.3793235743651167, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 178, train_loss = 1.3755132468650118, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 179, train_loss = 1.372654533595778, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 180, train_loss = 1.3691210498800501, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 181, train_loss = 1.3662929398706183, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 182, train_loss = 1.3627324476838112, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 183, train_loss = 1.3594526449451223, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 184, train_loss = 1.356388279586099, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 185, train_loss = 1.3531792350113392, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 186, train_loss = 1.350093693821691, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 187, train_loss = 1.3471747860312462, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 188, train_loss = 1.3441833319375291, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 189, train_loss = 1.3409133615205064, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 190, train_loss = 1.3379478119313717, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 191, train_loss = 1.3349848029902205, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 192, train_loss = 1.3320515044033527, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 193, train_loss = 1.329278126358986, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 194, train_loss = 1.3264335095882416, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 195, train_loss = 1.323345024138689, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 196, train_loss = 1.3208502158522606, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 197, train_loss = 1.3175716263940558, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 198, train_loss = 1.3145021423697472, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 199, train_loss = 1.3113610185682774, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 200, train_loss = 1.3082086443901062, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 201, train_loss = 1.3051885651657358, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 202, train_loss = 1.3028293872484937, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 203, train_loss = 1.299741443246603, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 204, train_loss = 1.2970827160170302, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 205, train_loss = 1.294993069022894, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 206, train_loss = 1.2923405803740025, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 207, train_loss = 1.2898077058489434, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 208, train_loss = 1.2869001937215216, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 209, train_loss = 1.2847868390381336, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 210, train_loss = 1.2820883828098886, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 211, train_loss = 1.2797753463382833, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 212, train_loss = 1.2771032030577771, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 213, train_loss = 1.2750280151958577, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 214, train_loss = 1.2722873191232793, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 215, train_loss = 1.2696987316012383, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 216, train_loss = 1.2671589056844823, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 217, train_loss = 1.2645985608105548, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 218, train_loss = 1.262727343768347, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 219, train_loss = 1.260538063943386, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 220, train_loss = 1.2581971660256386, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 221, train_loss = 1.2558610613341443, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 222, train_loss = 1.253490983217489, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 223, train_loss = 1.2509692994062789, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 224, train_loss = 1.249380137771368, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 225, train_loss = 1.2473495677113533, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 226, train_loss = 1.2448980510234833, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 227, train_loss = 1.2428133562207222, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 228, train_loss = 1.2403995729982853, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 229, train_loss = 1.2385977643425576, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 230, train_loss = 1.2361679822206497, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 231, train_loss = 1.2343105052714236, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 232, train_loss = 1.2321484709973447, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 233, train_loss = 1.2299449158017524, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 234, train_loss = 1.2283712674980052, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 235, train_loss = 1.2260159614379518, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 236, train_loss = 1.2242196897859685, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 237, train_loss = 1.2222608476877213, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 238, train_loss = 1.220122791826725, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 239, train_loss = 1.21855902048992, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 240, train_loss = 1.2165156925912015, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 241, train_loss = 1.2145992529694922, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 242, train_loss = 1.2123945380444638, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 243, train_loss = 1.210802510380745, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 244, train_loss = 1.2090931286220439, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 245, train_loss = 1.2070090174674988, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 246, train_loss = 1.2050384866888635, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 247, train_loss = 1.203475524962414, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 248, train_loss = 1.2014395321602933, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 249, train_loss = 1.1996185258030891, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 250, train_loss = 1.198108493059408, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 251, train_loss = 1.1960408737068065, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 252, train_loss = 1.1947048765723594, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 253, train_loss = 1.192533367604483, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 254, train_loss = 1.1908901308779605, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 255, train_loss = 1.1891817413270473, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 256, train_loss = 1.1871862225234509, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 257, train_loss = 1.1856157357688062, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 258, train_loss = 1.1837700754404068, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 259, train_loss = 1.1821623742580414, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 260, train_loss = 1.1805864783818834, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 261, train_loss = 1.178491536527872, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 262, train_loss = 1.1773213247652166, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 263, train_loss = 1.1754154724185355, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 264, train_loss = 1.1737398828263395, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 265, train_loss = 1.1721923897857778, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 266, train_loss = 1.1707550349528901, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 267, train_loss = 1.169106932997238, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 268, train_loss = 1.1671958193182945, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 269, train_loss = 1.1657189205288887, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 270, train_loss = 1.1639149573748, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 271, train_loss = 1.162743341177702, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 272, train_loss = 1.1609170424635522, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 273, train_loss = 1.1597719949786551, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 274, train_loss = 1.157816772640217, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 275, train_loss = 1.1567606900935061, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 276, train_loss = 1.154964990913868, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 277, train_loss = 1.1533302242751233, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 278, train_loss = 1.1519803914125077, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 279, train_loss = 1.1503153418307193, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 280, train_loss = 1.1488878701929934, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 281, train_loss = 1.1476252600550652, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 282, train_loss = 1.1461087030475028, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 283, train_loss = 1.1444378669257276, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 284, train_loss = 1.1428617189521901, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 285, train_loss = 1.1418358509545214, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 286, train_loss = 1.1400061510503292, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 287, train_loss = 1.1393025629222393, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 288, train_loss = 1.1371997793321498, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 289, train_loss = 1.1362559087574482, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 290, train_loss = 1.1344841134850867, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 291, train_loss = 1.1332839180831797, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 292, train_loss = 1.1320681422948837, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 293, train_loss = 1.1303534917533398, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 294, train_loss = 1.1290164031088352, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 295, train_loss = 1.1279140946571715, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 296, train_loss = 1.126618891954422, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 297, train_loss = 1.1252710695262067, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 298, train_loss = 1.123453814536333, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 299, train_loss = 1.1219585959916003, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 300, train_loss = 1.1201411460642703, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 301, train_loss = 1.1186983709339984, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 302, train_loss = 1.1175530080799945, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 303, train_loss = 1.1159478885238059, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 304, train_loss = 1.1147484593093395, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 305, train_loss = 1.1132593142683618, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 306, train_loss = 1.1120131115312688, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 307, train_loss = 1.1107882385258563, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 308, train_loss = 1.10928538069129, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 309, train_loss = 1.1079419975285418, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 310, train_loss = 1.106679002463352, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 311, train_loss = 1.1055511471931823, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 312, train_loss = 1.1044371264870279, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 313, train_loss = 1.103199413686525, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 314, train_loss = 1.1020552031695843, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 315, train_loss = 1.100220741063822, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 316, train_loss = 1.099383479624521, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 317, train_loss = 1.0981590139563195, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 318, train_loss = 1.0968649325077422, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 319, train_loss = 1.0952750146389008, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 320, train_loss = 1.0944876546855085, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 321, train_loss = 1.0934760446543805, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 322, train_loss = 1.0920510229771025, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 323, train_loss = 1.090944740921259, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 324, train_loss = 1.0895703074638732, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 325, train_loss = 1.0885502137243748, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 326, train_loss = 1.0874610282480717, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 327, train_loss = 1.0860768246348016, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 328, train_loss = 1.085383192927111, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 329, train_loss = 1.083810084790457, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 330, train_loss = 1.083088718354702, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 331, train_loss = 1.0811033248901367, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 332, train_loss = 1.0805771189625375, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 333, train_loss = 1.079486666887533, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 334, train_loss = 1.0782122649252415, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 335, train_loss = 1.076641486317385, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 336, train_loss = 1.0761182407732122, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 337, train_loss = 1.074358971149195, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 338, train_loss = 1.0737372785806656, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 339, train_loss = 1.0723831430077553, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 340, train_loss = 1.071516151248943, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 341, train_loss = 1.070590949326288, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 342, train_loss = 1.069056509702932, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 343, train_loss = 1.0684244980220683, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 344, train_loss = 1.067116890102625, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 345, train_loss = 1.0665020483429544, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 346, train_loss = 1.064840464561712, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 347, train_loss = 1.0635337966377847, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 348, train_loss = 1.0628745679860003, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 349, train_loss = 1.0618465766310692, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 350, train_loss = 1.0604435081477277, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 351, train_loss = 1.0593956274096854, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 352, train_loss = 1.0588527557847556, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 353, train_loss = 1.057401488214964, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 354, train_loss = 1.0566071669163648, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 355, train_loss = 1.0550674498081207, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 356, train_loss = 1.0546733414230403, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 357, train_loss = 1.0535149089992046, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 358, train_loss = 1.0522429359552916, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 359, train_loss = 1.051165467739338, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 360, train_loss = 1.0505973932740744, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 361, train_loss = 1.0495407953858376, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 362, train_loss = 1.0482886446116026, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 363, train_loss = 1.0475532983837184, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 364, train_loss = 1.0466960445046425, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 365, train_loss = 1.0455590871570166, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 366, train_loss = 1.04445637887693, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 367, train_loss = 1.0438253991305828, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 368, train_loss = 1.0428005444409791, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 369, train_loss = 1.0416615431604441, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 370, train_loss = 1.0407716557383537, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 371, train_loss = 1.0396950977446977, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 372, train_loss = 1.0388950767519418, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 373, train_loss = 1.0382381839153823, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 374, train_loss = 1.0369695561530534, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 375, train_loss = 1.0359294352529105, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 376, train_loss = 1.0355376116931438, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 377, train_loss = 1.0346644719538745, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 378, train_loss = 1.033738018333679, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 379, train_loss = 1.0324484681186732, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 380, train_loss = 1.0319743839500006, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 381, train_loss = 1.0306155011057854, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 382, train_loss = 1.0301828694937285, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 383, train_loss = 1.0290727565588895, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 384, train_loss = 1.028241982072359, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 385, train_loss = 1.0274660723807756, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 386, train_loss = 1.0263505168259144, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 387, train_loss = 1.025635610014433, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 388, train_loss = 1.0251689242722932, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 389, train_loss = 1.0237345894274767, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 390, train_loss = 1.023246318101883, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 391, train_loss = 1.022187920898432, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 392, train_loss = 1.021331261843443, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 393, train_loss = 1.0208334289491177, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 394, train_loss = 1.0197757383284625, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 395, train_loss = 1.0189287500979844, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 396, train_loss = 1.01789421835565, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 397, train_loss = 1.0172520627675112, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 398, train_loss = 1.016402860492235, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 399, train_loss = 1.0155487656593323, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 400, train_loss = 1.0143834377231542, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 401, train_loss = 1.0136194763181265, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 402, train_loss = 1.0129160583019257, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 403, train_loss = 1.0121048937144224, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 404, train_loss = 1.0109940990805626, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 405, train_loss = 1.010406631976366, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 406, train_loss = 1.0095104463398457, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 407, train_loss = 1.0088347544369753, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 408, train_loss = 1.008149084955221, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 409, train_loss = 1.0066514114441816, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 410, train_loss = 1.006482475757366, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 411, train_loss = 1.005369283258915, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 412, train_loss = 1.0049040081503335, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 413, train_loss = 1.0038702500460204, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 414, train_loss = 1.0030807008442935, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 415, train_loss = 1.0025530358252581, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 416, train_loss = 1.0016319366695825, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 417, train_loss = 1.0006347447633743, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 418, train_loss = 0.9999014946224634, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 419, train_loss = 0.9988934546709061, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 420, train_loss = 0.9979662001132965, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 421, train_loss = 0.9977099485695362, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 422, train_loss = 0.9964258050022181, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 423, train_loss = 0.9962553394434508, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 424, train_loss = 0.9953578983840998, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 425, train_loss = 0.9945083893835545, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 426, train_loss = 0.993438646197319, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 427, train_loss = 0.9930165683326777, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 428, train_loss = 0.9919688304362353, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 429, train_loss = 0.9916380755603313, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 430, train_loss = 0.9902240745723248, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 431, train_loss = 0.9902173442242201, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 432, train_loss = 0.9891648131015245, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 433, train_loss = 0.9885699239966925, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 434, train_loss = 0.987700322031742, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 435, train_loss = 0.9869422850606497, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 436, train_loss = 0.9864602436718997, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 437, train_loss = 0.9853979063627776, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 438, train_loss = 0.9847880154848099, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 439, train_loss = 0.9842320842144545, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 440, train_loss = 0.9832340975699481, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 441, train_loss = 0.9826067102549132, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 442, train_loss = 0.9817592588660773, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 443, train_loss = 0.9812135882675648, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 444, train_loss = 0.9807729820313398, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 445, train_loss = 0.9800400212407112, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 446, train_loss = 0.9792225124838296, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 447, train_loss = 0.9783533426525537, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 448, train_loss = 0.9778978700342122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 449, train_loss = 0.9772547992470209, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 450, train_loss = 0.9765234341321047, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 451, train_loss = 0.9760262357594911, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 452, train_loss = 0.9751282247307245, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 453, train_loss = 0.9745763912796974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 454, train_loss = 0.9736052801308688, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 455, train_loss = 0.9731668407621328, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 456, train_loss = 0.9721336178481579, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 457, train_loss = 0.9719417480228003, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 458, train_loss = 0.9709404048917349, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 459, train_loss = 0.9705932401120663, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 460, train_loss = 0.9698539922537748, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 461, train_loss = 0.9694913936255034, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 462, train_loss = 0.9682741413416807, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 463, train_loss = 0.9680279555323068, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 464, train_loss = 0.9672152921557426, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 465, train_loss = 0.9667011623678263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 466, train_loss = 0.9663306089641992, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 467, train_loss = 0.9655792340636253, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 468, train_loss = 0.964951928704977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 469, train_loss = 0.9641879759728909, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 470, train_loss = 0.9638725183904171, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 471, train_loss = 0.9631552820501383, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 472, train_loss = 0.9623250228760298, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 473, train_loss = 0.9616652925906237, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 474, train_loss = 0.9610983282327652, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 475, train_loss = 0.9602797788975295, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 476, train_loss = 0.9598436839878559, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 477, train_loss = 0.95961188399815, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 478, train_loss = 0.9588493394257966, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 479, train_loss = 0.9583818080427591, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 480, train_loss = 0.9575015939772129, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 481, train_loss = 0.9567465856671333, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 482, train_loss = 0.9560375151631888, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 483, train_loss = 0.9558194763958454, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 484, train_loss = 0.954895619302988, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 485, train_loss = 0.9541608765721321, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 486, train_loss = 0.9537478300335351, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 487, train_loss = 0.9532319431600627, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 488, train_loss = 0.9523588046431541, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 489, train_loss = 0.9517164143326227, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 490, train_loss = 0.9513241586682852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 491, train_loss = 0.9508672455849592, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 492, train_loss = 0.9506065050663892, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 493, train_loss = 0.9497030364873353, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 494, train_loss = 0.9487968000175897, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 495, train_loss = 0.9487560354173183, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 496, train_loss = 0.947952256858116, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 497, train_loss = 0.9471927011909429, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 498, train_loss = 0.9468545988202095, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 499, train_loss = 0.945863494038349, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████▌  | 29/30 [4:46:48<09:20, 560.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "30th- epoch: 0, train_loss = 113.69584788382053, train_acc = 0.7729389846297159\n",
      "test Acc 0.8631284916201117:\n",
      "30th- epoch: 1, train_loss = 44.04290430247784, train_acc = 0.9076618537494178\n",
      "test Acc 0.9115456238361266:\n",
      "30th- epoch: 2, train_loss = 32.305283308029175, train_acc = 0.9331625523986958\n",
      "test Acc 0.9273743016759777:\n",
      "30th- epoch: 3, train_loss = 26.40425281971693, train_acc = 0.9442244993013508\n",
      "test Acc 0.9376163873370578:\n",
      "30th- epoch: 4, train_loss = 22.59037795290351, train_acc = 0.9531904983698184\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 5, train_loss = 19.901660047471523, train_acc = 0.9601769911504425\n",
      "test Acc 0.9492551210428305:\n",
      "30th- epoch: 6, train_loss = 17.861004158854485, train_acc = 0.9648346530041919\n",
      "test Acc 0.9543761638733705:\n",
      "30th- epoch: 7, train_loss = 16.22397292032838, train_acc = 0.9682114578481602\n",
      "test Acc 0.9553072625698324:\n",
      "30th- epoch: 8, train_loss = 14.879688590765, train_acc = 0.9710060549604099\n",
      "test Acc 0.957169459962756:\n",
      "30th- epoch: 9, train_loss = 13.741354988887906, train_acc = 0.9729855612482534\n",
      "test Acc 0.9594972067039106:\n",
      "30th- epoch: 10, train_loss = 12.754863819107413, train_acc = 0.9750815090824406\n",
      "test Acc 0.9599627560521415:\n",
      "30th- epoch: 11, train_loss = 11.893020315095782, train_acc = 0.976245924545878\n",
      "test Acc 0.9599627560521415:\n",
      "30th- epoch: 12, train_loss = 11.138650216162205, train_acc = 0.9770610153702841\n",
      "test Acc 0.9594972067039106:\n",
      "30th- epoch: 13, train_loss = 10.463947670534253, train_acc = 0.9784583139264089\n",
      "test Acc 0.9590316573556797:\n",
      "30th- epoch: 14, train_loss = 9.867382679134607, train_acc = 0.97973917093619\n",
      "test Acc 0.9604283054003724:\n",
      "30th- epoch: 15, train_loss = 9.33105032891035, train_acc = 0.9812529110386586\n",
      "test Acc 0.9608938547486033:\n",
      "30th- epoch: 16, train_loss = 8.852491546422243, train_acc = 0.981951560316721\n",
      "test Acc 0.9618249534450651:\n",
      "30th- epoch: 17, train_loss = 8.419912649318576, train_acc = 0.9826502095947834\n",
      "test Acc 0.9632216014897579:\n",
      "30th- epoch: 18, train_loss = 8.024380402639508, train_acc = 0.9834653004191896\n",
      "test Acc 0.9636871508379888:\n",
      "30th- epoch: 19, train_loss = 7.662826849147677, train_acc = 0.983698183511877\n",
      "test Acc 0.9636871508379888:\n",
      "30th- epoch: 20, train_loss = 7.332835694774985, train_acc = 0.9850954820680019\n",
      "test Acc 0.9636871508379888:\n",
      "30th- epoch: 21, train_loss = 7.028967896476388, train_acc = 0.985910572892408\n",
      "test Acc 0.9636871508379888:\n",
      "30th- epoch: 22, train_loss = 6.755656026303768, train_acc = 0.986376339077783\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 23, train_loss = 6.502327758818865, train_acc = 0.9868421052631579\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 24, train_loss = 6.2645432110875845, train_acc = 0.9875407545412203\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 25, train_loss = 6.046488942578435, train_acc = 0.9883558453656265\n",
      "test Acc 0.9664804469273743:\n",
      "30th- epoch: 26, train_loss = 5.844698077067733, train_acc = 0.9892873777363763\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 27, train_loss = 5.656334415078163, train_acc = 0.9902189101071263\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 28, train_loss = 5.481779724359512, train_acc = 0.9905682347461574\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 29, train_loss = 5.320099212229252, train_acc = 0.9909175593851887\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 30, train_loss = 5.170582075603306, train_acc = 0.9914997671169073\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 31, train_loss = 5.026346697472036, train_acc = 0.9917326502095948\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 32, train_loss = 4.894549165852368, train_acc = 0.9921984163949698\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 33, train_loss = 4.767508257180452, train_acc = 0.9923148579413135\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 34, train_loss = 4.648902310989797, train_acc = 0.9926641825803446\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 35, train_loss = 4.536537141539156, train_acc = 0.9933628318584071\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 36, train_loss = 4.429406605660915, train_acc = 0.9933628318584071\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 37, train_loss = 4.329580120742321, train_acc = 0.9935957149510946\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 38, train_loss = 4.233577654697001, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "30th- epoch: 39, train_loss = 4.143228719942272, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 40, train_loss = 4.056141882203519, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 41, train_loss = 3.974908850155771, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 42, train_loss = 3.897375133819878, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 43, train_loss = 3.8232433618977666, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 44, train_loss = 3.7536579109728336, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 45, train_loss = 3.686892203055322, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 46, train_loss = 3.6229977309703827, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 47, train_loss = 3.5614172741770744, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 48, train_loss = 3.503228127025068, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 49, train_loss = 3.4473397778347135, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 50, train_loss = 3.3924369169399142, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 51, train_loss = 3.3414564356207848, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 52, train_loss = 3.2911289604380727, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 53, train_loss = 3.244075537659228, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 54, train_loss = 3.1971036829054356, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 55, train_loss = 3.1526620695367455, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 56, train_loss = 3.1108831902965903, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 57, train_loss = 3.0692362277768552, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 58, train_loss = 3.030811170581728, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 59, train_loss = 2.992792595177889, train_acc = 0.9956916627852818\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 60, train_loss = 2.95602817973122, train_acc = 0.9956916627852818\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 61, train_loss = 2.9201790443621576, train_acc = 0.9956916627852818\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 62, train_loss = 2.8867367804050446, train_acc = 0.9958081043316255\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 63, train_loss = 2.8523154431022704, train_acc = 0.9958081043316255\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 64, train_loss = 2.820951430592686, train_acc = 0.9959245458779693\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 65, train_loss = 2.7890454991720617, train_acc = 0.996040987424313\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 66, train_loss = 2.759269139263779, train_acc = 0.996040987424313\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 67, train_loss = 2.7294668704271317, train_acc = 0.996040987424313\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 68, train_loss = 2.7010232298634946, train_acc = 0.9959245458779693\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 69, train_loss = 2.6733421557582915, train_acc = 0.9959245458779693\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 70, train_loss = 2.646541466470808, train_acc = 0.9959245458779693\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 71, train_loss = 2.62055583903566, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 72, train_loss = 2.5949076167307794, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 73, train_loss = 2.569951737765223, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 74, train_loss = 2.5460841828025877, train_acc = 0.996040987424313\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 75, train_loss = 2.5227392106316984, train_acc = 0.9962738705170004\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 76, train_loss = 2.4995835958980024, train_acc = 0.9962738705170004\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 77, train_loss = 2.47716266149655, train_acc = 0.9962738705170004\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 78, train_loss = 2.455353645142168, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 79, train_loss = 2.4340437189675868, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 80, train_loss = 2.414101466536522, train_acc = 0.9963903120633442\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 81, train_loss = 2.393830619752407, train_acc = 0.996506753609688\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 82, train_loss = 2.373612148221582, train_acc = 0.996506753609688\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 83, train_loss = 2.355225245002657, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 84, train_loss = 2.3359199799597263, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 85, train_loss = 2.317843885626644, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 86, train_loss = 2.299858426209539, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 87, train_loss = 2.2830335102044046, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 88, train_loss = 2.26525059575215, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 89, train_loss = 2.2492196024395525, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 90, train_loss = 2.232151108328253, train_acc = 0.9968560782487191\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 91, train_loss = 2.2170847482047975, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 92, train_loss = 2.201102720107883, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 93, train_loss = 2.186419194098562, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 94, train_loss = 2.171176301781088, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 95, train_loss = 2.156928428914398, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 96, train_loss = 2.1427173926495016, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 97, train_loss = 2.128734742756933, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 98, train_loss = 2.1153487502597272, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 99, train_loss = 2.101832064334303, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 100, train_loss = 2.0884438157081604, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 101, train_loss = 2.0754687660373747, train_acc = 0.9969725197950629\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 102, train_loss = 2.063245218247175, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 103, train_loss = 2.0504964850842953, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 104, train_loss = 2.0384111292660236, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 105, train_loss = 2.026579989818856, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 106, train_loss = 2.015494219958782, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 107, train_loss = 2.003539967117831, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 108, train_loss = 1.9922070938628167, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 109, train_loss = 1.980841003358364, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 110, train_loss = 1.9699986081104726, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 111, train_loss = 1.9591798570472747, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 112, train_loss = 1.9489898767787963, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 113, train_loss = 1.9386199328582734, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 114, train_loss = 1.9288137007970363, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 115, train_loss = 1.9184089999180287, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 116, train_loss = 1.9093765069264919, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 117, train_loss = 1.8988193646073341, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 118, train_loss = 1.890080752549693, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 119, train_loss = 1.880393425701186, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 120, train_loss = 1.8710118383169174, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 121, train_loss = 1.8622269730549306, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 122, train_loss = 1.8536085225641727, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 123, train_loss = 1.8440706979017705, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 124, train_loss = 1.836277635069564, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 125, train_loss = 1.827761773020029, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 126, train_loss = 1.819816930918023, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 127, train_loss = 1.811784591525793, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 128, train_loss = 1.8030590403359383, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 129, train_loss = 1.795709355501458, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 130, train_loss = 1.7882865767460316, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 131, train_loss = 1.7808360904455185, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 132, train_loss = 1.773166298866272, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 133, train_loss = 1.765795910032466, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 134, train_loss = 1.758078807266429, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 135, train_loss = 1.7515153524000198, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 136, train_loss = 1.7441425509750843, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 137, train_loss = 1.7376621824223548, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 138, train_loss = 1.7306046995799989, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 139, train_loss = 1.724395754514262, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 140, train_loss = 1.7179852686822414, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 141, train_loss = 1.7115160375833511, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 142, train_loss = 1.7046970936935395, train_acc = 0.9970889613414066\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 143, train_loss = 1.6984427832067013, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 144, train_loss = 1.6924259513616562, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 145, train_loss = 1.6859120812732726, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 146, train_loss = 1.6795437771361321, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 147, train_loss = 1.672990445047617, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 148, train_loss = 1.667089828522876, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 149, train_loss = 1.660900266142562, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 150, train_loss = 1.6553485665936023, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 151, train_loss = 1.6500129513442516, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 152, train_loss = 1.6446180827915668, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 153, train_loss = 1.6386900593061, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 154, train_loss = 1.6334287784993649, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 155, train_loss = 1.628068332793191, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 156, train_loss = 1.6229072797577828, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 157, train_loss = 1.6175859209615737, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 158, train_loss = 1.6124812837224454, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 159, train_loss = 1.6074816982727498, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 160, train_loss = 1.6026061985176057, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 161, train_loss = 1.5973919096868485, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 162, train_loss = 1.5930700674653053, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 163, train_loss = 1.5880672323983163, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 164, train_loss = 1.5840096659958363, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 165, train_loss = 1.5787497211713344, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 166, train_loss = 1.5737919274251908, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 167, train_loss = 1.5695623520296067, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 168, train_loss = 1.5650660085957497, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 169, train_loss = 1.5608686432242393, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 170, train_loss = 1.5563131360104308, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 171, train_loss = 1.5517529459903017, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 172, train_loss = 1.547773809521459, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 173, train_loss = 1.5431164739420637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 174, train_loss = 1.538726576953195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 175, train_loss = 1.534892120747827, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 176, train_loss = 1.5305782966315746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 177, train_loss = 1.5266971016535535, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 178, train_loss = 1.5223515232792124, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 179, train_loss = 1.51810071116779, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 180, train_loss = 1.5146461687982082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 181, train_loss = 1.5109610458603129, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 182, train_loss = 1.5064319284865633, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 183, train_loss = 1.50295850133989, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 184, train_loss = 1.4990592101821676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 185, train_loss = 1.4951009787619114, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 186, train_loss = 1.491422594874166, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 187, train_loss = 1.4874750599265099, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 188, train_loss = 1.4846168620279059, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 189, train_loss = 1.4807914098491892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 190, train_loss = 1.4766830453881994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 191, train_loss = 1.4735145954182371, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 192, train_loss = 1.4703234197804704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 193, train_loss = 1.466897390782833, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 194, train_loss = 1.4630218719830737, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 195, train_loss = 1.459814259200357, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 196, train_loss = 1.456930493353866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 197, train_loss = 1.453019822598435, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 198, train_loss = 1.4499081583926454, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 199, train_loss = 1.4464305801084265, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 200, train_loss = 1.443358089774847, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 201, train_loss = 1.440530437976122, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 202, train_loss = 1.4369350522756577, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 203, train_loss = 1.4334400756051764, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 204, train_loss = 1.4310780204832554, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 205, train_loss = 1.427691193879582, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 206, train_loss = 1.4244184233248234, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 207, train_loss = 1.421680868952535, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 208, train_loss = 1.4180807484081015, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 209, train_loss = 1.4156207168707624, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 210, train_loss = 1.4127183792879805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 211, train_loss = 1.4096501482417807, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 212, train_loss = 1.4072462233016267, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 213, train_loss = 1.4036957422504202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 214, train_loss = 1.4012240780284628, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 215, train_loss = 1.3979740962386131, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 216, train_loss = 1.3958660823991522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 217, train_loss = 1.392532967031002, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 218, train_loss = 1.3897972715785727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 219, train_loss = 1.3877168893814087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 220, train_loss = 1.3844442566623911, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 221, train_loss = 1.3815999006619677, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 222, train_loss = 1.3790889965603128, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 223, train_loss = 1.3766861049225554, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 224, train_loss = 1.374130830168724, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 225, train_loss = 1.3713714828481898, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 226, train_loss = 1.3684741668403149, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 227, train_loss = 1.3656221590936184, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 228, train_loss = 1.3636890078196302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 229, train_loss = 1.3605890795588493, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 230, train_loss = 1.358502613962628, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 231, train_loss = 1.3556795679032803, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 232, train_loss = 1.353618481545709, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 233, train_loss = 1.3508234272012487, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 234, train_loss = 1.3487252393970266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 235, train_loss = 1.346080149174668, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 236, train_loss = 1.343679379671812, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 237, train_loss = 1.3417607670417055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 238, train_loss = 1.3389550721039996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 239, train_loss = 1.336378626525402, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 240, train_loss = 1.3344732833793387, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 241, train_loss = 1.3319421770283952, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 242, train_loss = 1.3300933862337843, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 243, train_loss = 1.3276325203478336, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 244, train_loss = 1.3256413812050596, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 245, train_loss = 1.323280523181893, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 246, train_loss = 1.3211578776827082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 247, train_loss = 1.318465605378151, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 248, train_loss = 1.316555573255755, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 249, train_loss = 1.3146793892374262, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 250, train_loss = 1.312266532331705, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 251, train_loss = 1.309795050532557, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 252, train_loss = 1.3079885492334142, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 253, train_loss = 1.3053681465098634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 254, train_loss = 1.3034469112753868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 255, train_loss = 1.3007774539291859, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 256, train_loss = 1.2985393665730953, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 257, train_loss = 1.29645963141229, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 258, train_loss = 1.2939483312657103, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 259, train_loss = 1.292613352299668, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 260, train_loss = 1.2899006145307794, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 261, train_loss = 1.288012258708477, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 262, train_loss = 1.2860524294665083, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 263, train_loss = 1.2840287499129772, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 264, train_loss = 1.2823039380600676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 265, train_loss = 1.2796839041402563, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 266, train_loss = 1.2779572071740404, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 267, train_loss = 1.2762887912103906, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 268, train_loss = 1.2740909407148138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 269, train_loss = 1.2724445586791262, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 270, train_loss = 1.2702270025620237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 271, train_loss = 1.2687971791019663, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 272, train_loss = 1.2666655580396764, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 273, train_loss = 1.2646525179152377, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 274, train_loss = 1.2630449831485748, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 275, train_loss = 1.261025893210899, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 276, train_loss = 1.258918508887291, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 277, train_loss = 1.2576914429664612, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 278, train_loss = 1.2551303952932358, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 279, train_loss = 1.2539001156692393, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 280, train_loss = 1.2514839668874629, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 281, train_loss = 1.2503972587292083, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 282, train_loss = 1.2481534779071808, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 283, train_loss = 1.2466697444324382, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 284, train_loss = 1.2448068472440355, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 285, train_loss = 1.2435417585074902, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 286, train_loss = 1.241597915708553, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 287, train_loss = 1.2392479069530964, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 288, train_loss = 1.2378777948324569, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 289, train_loss = 1.2362078453297727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 290, train_loss = 1.2347174572641961, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 291, train_loss = 1.2326708969776519, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 292, train_loss = 1.2312536003882997, train_acc = 0.9974382859804378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 293, train_loss = 1.229230533062946, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 294, train_loss = 1.2278116096858867, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 295, train_loss = 1.226123172789812, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 296, train_loss = 1.2244715367560275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 297, train_loss = 1.222823987423908, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 298, train_loss = 1.2210462081129663, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 299, train_loss = 1.2199715388123877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 300, train_loss = 1.218146726489067, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 301, train_loss = 1.2165484887664206, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 302, train_loss = 1.2149817397003062, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 303, train_loss = 1.2132909037172794, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 304, train_loss = 1.2119429272715934, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 305, train_loss = 1.2099294103682041, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 306, train_loss = 1.2092096097767353, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 307, train_loss = 1.2071336979861371, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 308, train_loss = 1.2057647605543025, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 309, train_loss = 1.204361277341377, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 310, train_loss = 1.202663390606176, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 311, train_loss = 1.201289489865303, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 312, train_loss = 1.1996349369292147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 313, train_loss = 1.1983873595600016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 314, train_loss = 1.1960987485945225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 315, train_loss = 1.1950060265953653, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 316, train_loss = 1.1940056619350798, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 317, train_loss = 1.1919406044180505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 318, train_loss = 1.1910035994951613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 319, train_loss = 1.18974931538105, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 320, train_loss = 1.1879125398700126, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 321, train_loss = 1.186040848493576, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 322, train_loss = 1.1850667049293406, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 323, train_loss = 1.1839197613298893, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 324, train_loss = 1.1821475327014923, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 325, train_loss = 1.1808181417291053, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 326, train_loss = 1.1793717766995542, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 327, train_loss = 1.17824311676668, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 328, train_loss = 1.1763596683740616, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 329, train_loss = 1.1751339063048363, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 330, train_loss = 1.1741416193544865, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 331, train_loss = 1.1723658393020742, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 332, train_loss = 1.171796277165413, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 333, train_loss = 1.169976266741287, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 334, train_loss = 1.16881975781871, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 335, train_loss = 1.1673866237397306, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 336, train_loss = 1.166019192605745, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 337, train_loss = 1.1647955651278608, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 338, train_loss = 1.162945881485939, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 339, train_loss = 1.1625914027099498, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 340, train_loss = 1.1607536959345452, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 341, train_loss = 1.1591909900307655, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 342, train_loss = 1.1586322002112865, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 343, train_loss = 1.1569393835961819, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 344, train_loss = 1.155232235789299, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 345, train_loss = 1.1544474263791926, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 346, train_loss = 1.1532337181270123, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 347, train_loss = 1.1519489015336148, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 348, train_loss = 1.1508708223700523, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 349, train_loss = 1.149374948174227, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 350, train_loss = 1.1478932425379753, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 351, train_loss = 1.1470279258792289, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 352, train_loss = 1.1457545794546604, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 353, train_loss = 1.1443519555032253, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 354, train_loss = 1.1431136864121072, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 355, train_loss = 1.142141304910183, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 356, train_loss = 1.140994870394934, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 357, train_loss = 1.1395520381629467, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 358, train_loss = 1.1382805866305716, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 359, train_loss = 1.137133400887251, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 360, train_loss = 1.136098934977781, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 361, train_loss = 1.135311224788893, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 362, train_loss = 1.1337137508089654, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 363, train_loss = 1.1321502290666103, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 364, train_loss = 1.1315928151016124, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 365, train_loss = 1.1301703676581383, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 366, train_loss = 1.1289513893425465, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 367, train_loss = 1.128123013942968, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 368, train_loss = 1.1271756452624686, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 369, train_loss = 1.1256360771949403, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 370, train_loss = 1.1243080298299901, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 371, train_loss = 1.1229594610631466, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 372, train_loss = 1.1227364738588221, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 373, train_loss = 1.1212868218426593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 374, train_loss = 1.120340183377266, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 375, train_loss = 1.1187519406084903, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 376, train_loss = 1.1175095339422114, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 377, train_loss = 1.116615455597639, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 378, train_loss = 1.115180466324091, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 379, train_loss = 1.114045213907957, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 380, train_loss = 1.1135258910362609, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 381, train_loss = 1.111376665532589, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 382, train_loss = 1.1107528495485894, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 383, train_loss = 1.1099304494564421, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 384, train_loss = 1.1087531546945684, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 385, train_loss = 1.1077367166872136, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 386, train_loss = 1.1064079168136232, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 387, train_loss = 1.1055901708896272, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 388, train_loss = 1.1041155370767228, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 389, train_loss = 1.1032580062747002, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 390, train_loss = 1.1025913283228874, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 391, train_loss = 1.100972204178106, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 392, train_loss = 1.0996208128635772, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 393, train_loss = 1.099349686235655, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 394, train_loss = 1.0974986255168915, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 395, train_loss = 1.0967594124376774, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 396, train_loss = 1.0961984135210514, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 397, train_loss = 1.0948917989735492, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 398, train_loss = 1.0934063245658763, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 399, train_loss = 1.0925419951672666, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 400, train_loss = 1.0915392798488028, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 401, train_loss = 1.090871263295412, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 402, train_loss = 1.0896179129485972, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 403, train_loss = 1.0888433580403216, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 404, train_loss = 1.0873440963332541, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 405, train_loss = 1.086719869344961, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 406, train_loss = 1.085849978029728, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 407, train_loss = 1.0848021532292478, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 408, train_loss = 1.0836777587537654, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 409, train_loss = 1.0827570383553393, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 410, train_loss = 1.0816159807145596, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 411, train_loss = 1.0808240796322934, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 412, train_loss = 1.0797014112467878, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 413, train_loss = 1.0787750693853013, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 414, train_loss = 1.0779274466331117, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 415, train_loss = 1.0765479343826883, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 416, train_loss = 1.0759229113464244, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 417, train_loss = 1.0752443696255796, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 418, train_loss = 1.0736601340468042, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 419, train_loss = 1.0727221183478832, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 420, train_loss = 1.0718835194711573, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 421, train_loss = 1.0711825738544576, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 422, train_loss = 1.0700935870409012, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 423, train_loss = 1.0693079307675362, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 424, train_loss = 1.0681430498952977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 425, train_loss = 1.0672873544390313, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 426, train_loss = 1.0667781606316566, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 427, train_loss = 1.065673265606165, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 428, train_loss = 1.0646739602088928, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 429, train_loss = 1.0639009575243108, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 430, train_loss = 1.062198492407333, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 431, train_loss = 1.0625104966457002, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 432, train_loss = 1.0611403696238995, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 433, train_loss = 1.0605905565316789, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 434, train_loss = 1.059404720843304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 435, train_loss = 1.0583448596298695, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 436, train_loss = 1.057590572803747, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 437, train_loss = 1.0567396208643913, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 438, train_loss = 1.0554459442500956, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 439, train_loss = 1.0550894414191134, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 440, train_loss = 1.0538547411561012, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 441, train_loss = 1.0531300939619541, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 442, train_loss = 1.0526515779201873, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 443, train_loss = 1.0512943863868713, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 444, train_loss = 1.050635240972042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 445, train_loss = 1.0494477525353432, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 446, train_loss = 1.0491261171700899, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 447, train_loss = 1.0479557067155838, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 448, train_loss = 1.0474299217166845, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 449, train_loss = 1.046138887613779, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 450, train_loss = 1.0450522576866206, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 451, train_loss = 1.0448248622415122, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 452, train_loss = 1.0432918891310692, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 453, train_loss = 1.0431306858954486, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 454, train_loss = 1.042049277573824, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 455, train_loss = 1.0408836925926153, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 456, train_loss = 1.039954093605047, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 457, train_loss = 1.0395714938640594, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 458, train_loss = 1.0385332157311495, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 459, train_loss = 1.0378553196787834, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 460, train_loss = 1.0374508711101953, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 461, train_loss = 1.0360829358396586, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 462, train_loss = 1.0351960895059165, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 463, train_loss = 1.034626740962267, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 464, train_loss = 1.0338255365786608, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 465, train_loss = 1.0331990805862006, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 466, train_loss = 1.0319498889148235, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 467, train_loss = 1.0312188975512981, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 468, train_loss = 1.0307499071059283, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 469, train_loss = 1.0299562824366149, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 470, train_loss = 1.0285781199636403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 471, train_loss = 1.0282065806386527, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 472, train_loss = 1.0274226528999861, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 473, train_loss = 1.0263481909933034, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 474, train_loss = 1.0261380523443222, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 475, train_loss = 1.025004601717228, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 476, train_loss = 1.0240941010415554, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 477, train_loss = 1.0234841890633106, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 478, train_loss = 1.0228832177817822, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 479, train_loss = 1.0217465671303216, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 480, train_loss = 1.0213005865516607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 481, train_loss = 1.0205470820365008, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 482, train_loss = 1.0196333937346935, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 483, train_loss = 1.0189058532414492, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 484, train_loss = 1.0179350636899471, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 485, train_loss = 1.0177204571664333, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 486, train_loss = 1.016444562614197, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 487, train_loss = 1.0159613688883837, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 488, train_loss = 1.015170512109762, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 489, train_loss = 1.0142839886248112, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 490, train_loss = 1.013643067330122, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 491, train_loss = 1.0131203470227774, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 492, train_loss = 1.0122605425713118, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 493, train_loss = 1.0114254467189312, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 494, train_loss = 1.0107323167321738, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 495, train_loss = 1.010151993483305, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 496, train_loss = 1.0088807294669095, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 497, train_loss = 1.0089255943894386, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 498, train_loss = 1.0077005202474538, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 499, train_loss = 1.006890653312439, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 30/30 [4:55:22<00:00, 546.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 55min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    read_path = 'D:virus/image/3gram_768/'\n",
    "    \n",
    "    temp = [[],[]]\n",
    "    \n",
    "    Loader = D.File_loader()\n",
    "    data_a, label_a = Loader.read_files(read_path, interp = False)\n",
    "    \n",
    "    idx = np.argsort(label_a)\n",
    "    \n",
    "    sorted_data = data_a[idx].reshape(10736, -1)\n",
    "    sorted_label = sorted(label_a)\n",
    "        \n",
    "    BATCH_SIZE = 64\n",
    "    TOTAL = 30\n",
    "    EPOCH =500\n",
    "    NUM_CLASS = 9\n",
    "    LR = 0.0001\n",
    "    SEED = [s for s in range(TOTAL)]\n",
    "    Num_Nodes = 768\n",
    "    \n",
    "    CUDA_N = 'cuda:1'\n",
    "    \n",
    "    # creating data indices for spliting\n",
    "    full_dataset = CustomDataset(sorted_data, sorted_label)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # spliting\n",
    "    torch.manual_seed(10)\n",
    "    train_dataset, test_dataset = data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(TOTAL)):\n",
    "        \n",
    "        \n",
    "        device = torch.device(CUDA_N if torch.cuda.is_available() else 'cpu')\n",
    "        torch.manual_seed(SEED[i])\n",
    "        net = Mcslt(Num_Nodes, NUM_CLASS)\n",
    "        net.to(device)\n",
    "        print(net)\n",
    "        \n",
    "        softmax = nn.Softmax()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum = 0.1)\n",
    "        \n",
    "        loss_list = []\n",
    "        train_acc_list = []\n",
    "        test_acc_list = []\n",
    "        \n",
    "        pred_temp = []\n",
    "        true_temp = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            net.train()\n",
    "            running_loss = 0\n",
    "            total = train_size\n",
    "            correct = 0 \n",
    "            \n",
    "            for step, images_labels in enumerate(train_loader):\n",
    "                inputs, labels = images_labels\n",
    "                inputs, labels = inputs.type(torch.FloatTensor).to(device), labels.type(torch.LongTensor).to(device)\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            train_acc = correct/total\n",
    "            loss_list.append(running_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "            print('{}th- epoch: {}, train_loss = {}, train_acc = {}'.format(i+1, epoch, running_loss, train_acc))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                correct = 0\n",
    "                total = test_size\n",
    "                pt, tt = [], []\n",
    "                \n",
    "                for step_t, images_labels_t in enumerate(test_loader):\n",
    "                    inputs_t, labels_t = images_labels_t\n",
    "                    inputs_t, labels_t = inputs_t.type(torch.FloatTensor).to(device), labels_t.type(torch.LongTensor).to(device)\n",
    "                    \n",
    "                    outputs_t = net(inputs_t)\n",
    "                    outputs_t = softmax(outputs_t)\n",
    "                    \n",
    "                    # test accuracy\n",
    "                    _, pred_t = torch.max(outputs_t, dim = 1)\n",
    "                    \n",
    "                    pt.append(pred_t)\n",
    "                    tt.append(labels_t)\n",
    "                    \n",
    "                    correct += (pred_t == labels_t).sum().item()\n",
    "                    \n",
    "                pred_temp.append(torch.cat(pt))\n",
    "                true_temp.append(torch.cat(tt))\n",
    "                \n",
    "                test_acc = correct/total\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print('test Acc {}:'.format(test_acc))\n",
    "                \n",
    "        best_result_index = np.argmax(np.array(test_acc_list))\n",
    "        loss_total.append(loss_list[best_result_index])\n",
    "        acc_total.append(test_acc_list[best_result_index])\n",
    "        pred_total.append(pred_temp[best_result_index].tolist())\n",
    "        true_total.append(true_temp[best_result_index].tolist())\n",
    "        \n",
    "    file_name = 'res/Mcslt_4gram'\n",
    "    torch.save(net.state_dict(), file_name +'.pth')\n",
    "    \n",
    "    loss_DF = pd.DataFrame(loss_total)\n",
    "    loss_DF.to_csv(file_name+\" loss.csv\")\n",
    "    \n",
    "    acc_DF = pd.DataFrame(acc_total)\n",
    "    acc_DF.to_csv(file_name +\" acc.csv\")\n",
    "    \n",
    "    pred_DF = pd.DataFrame(pred_total)\n",
    "    pred_DF.to_csv(file_name +\" pred.csv\")\n",
    "    \n",
    "    true_DF = pd.DataFrame(true_total)\n",
    "    true_DF.to_csv(file_name +\" true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
